[
  {
    "chunk_id": "qa_000001",
    "content": "在浏览器中输⼊URL并按下回⻋之后会发⽣什么\n\n超⾼频⾯试题，从这道⾯试题开始可以延伸到计算机⽹络有关的很多问题，如果这道题答的很好，可以把⾯\n试官引导到你更熟悉的地⽅。\n## 第⼀步：输⼊URL并解析\n这⾥可以引申到URL的组成部分，这⾥不做过多的展开。\n输⼊URL 后，浏览器会解析出协议、主机、端⼝、路径等信息，并构造⼀个HTTP请求（浏览器会根据请求头判断\n是否有HTTP缓存 ,并根据是否有缓存决定是从服务器获取资源还是使⽤缓存资源，具体内容会在HTTP缓存章节讲\n## 第⼆步：DNS域名解析, 将域名解析成对应的IP地址\n在发送HTTP请求之前，浏览器需要知道想要访问⽹⻚(url)对应的IP地址，这就需要使⽤到 DNS域名解析 （DNS域名\n的具体内容也会在后⾯章节中讲解）。\n## 第三步：建⽴起TCP连接之三次握⼿\n这⾥是重中之重，可以扩展很多问题，⽐如为什么是三次，不是两次、四次？如果第⼀次握⼿丢失了会发⽣\n什么？三次握⼿过程中可以携带数据吗？\n客户端和服务器之间进⾏HTTP请求和HTTP响应的过程中，需要建⽴起TCP连接，TCP连接需要进⾏三次握⼿（具\n体内容在后⾯章节中讲解）。\n## 第四步：浏览器发送HTTP/HTTPS请求到web服务器\n这⼀步也可以扩展很多问题，⽐如HTTP/HTTPS的区别？请求的⽅式？请求的状态码，凡是与HTTP请求的问\n题都可以问。\n## 第五步：服务器处理HTTP请求并返回HTTP报⽂\nHTTP响应报⽂和状态码也是常考的内容。\n服务器会接受请求并将其传递给请求处理程序并发送HTTP响应，⼀般响应报⽂包含：请求的⽹⻚以及状态码，压\n缩类型，如何缓存的⻚⾯，设置的cookie;\n## 第六步：浏览器渲染⻚⾯\n浏览器渲染⻚⾯的流程对于前端同学来说也是必会的、还会牵扯到回流和重绘的问题。\n## 第七步：断开连接之TCP四次挥⼿\n这⾥也是特别重要的知识点，四次挥⼿的过程，为什么是四次？\n客户端和服务器之间断开连接需要进⾏四次挥⼿（具体内容在后⾯章节汇总讲解）。\nDNS",
    "question": "在浏览器中输⼊URL并按下回⻋之后会发⽣什么",
    "answer": "超⾼频⾯试题，从这道⾯试题开始可以延伸到计算机⽹络有关的很多问题，如果这道题答的很好，可以把⾯\n试官引导到你更熟悉的地⽅。\n## 第⼀步：输⼊URL并解析\n这⾥可以引申到URL的组成部分，这⾥不做过多的展开。\n输⼊URL 后，浏览器会解析出协议、主机、端⼝、路径等信息，并构造⼀个HTTP请求（浏览器会根据请求头判断\n是否有HTTP缓存 ,并根据是否有缓存决定是从服务器获取资源还是使⽤缓存资源，具体内容会在HTTP缓存章节讲\n## 第⼆步：DNS域名解析, 将域名解析成对应的IP地址\n在发送HTTP请求之前，浏览器需要知道想要访问⽹⻚(url)对应的IP地址，这就需要使⽤到 DNS域名解析 （DNS域名\n的具体内容也会在后⾯章节中讲解）。\n## 第三步：建⽴起TCP连接之三次握⼿\n这⾥是重中之重，可以扩展很多问题，⽐如为什么是三次，不是两次、四次？如果第⼀次握⼿丢失了会发⽣\n什么？三次握⼿过程中可以携带数据吗？\n客户端和服务器之间进⾏HTTP请求和HTTP响应的过程中，需要建⽴起TCP连接，TCP连接需要进⾏三次握⼿（具\n体内容在后⾯章节中讲解）。\n## 第四步：浏览器发送HTTP/HTTPS请求到web服务器\n这⼀步也可以扩展很多问题，⽐如HTTP/HTTPS的区别？请求的⽅式？请求的状态码，凡是与HTTP请求的问\n题都可以问。\n## 第五步：服务器处理HTTP请求并返回HTTP报⽂\nHTTP响应报⽂和状态码也是常考的内容。\n服务器会接受请求并将其传递给请求处理程序并发送HTTP响应，⼀般响应报⽂包含：请求的⽹⻚以及状态码，压\n缩类型，如何缓存的⻚⾯，设置的cookie;\n## 第六步：浏览器渲染⻚⾯\n浏览器渲染⻚⾯的流程对于前端同学来说也是必会的、还会牵扯到回流和重绘的问题。\n## 第七步：断开连接之TCP四次挥⼿\n这⾥也是特别重要的知识点，四次挥⼿的过程，为什么是四次？\n客户端和服务器之间断开连接需要进⾏四次挥⼿（具体内容在后⾯章节汇总讲解）。\nDNS",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 866,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000002",
    "content": "## 第四步：浏览器发送HTTP/HTTPS请求到web服务器\n\n这⼀步也可以扩展很多问题，⽐如HTTP/HTTPS的区别？请求的⽅式？请求的状态码，凡是与HTTP请求的问\n题都可以问。\n## 第五步：服务器处理HTTP请求并返回HTTP报⽂\nHTTP响应报⽂和状态码也是常考的内容。\n服务器会接受请求并将其传递给请求处理程序并发送HTTP响应，⼀般响应报⽂包含：请求的⽹⻚以及状态码，压\n缩类型，如何缓存的⻚⾯，设置的cookie;\n## 第六步：浏览器渲染⻚⾯\n浏览器渲染⻚⾯的流程对于前端同学来说也是必会的、还会牵扯到回流和重绘的问题。\n## 第七步：断开连接之TCP四次挥⼿\n这⾥也是特别重要的知识点，四次挥⼿的过程，为什么是四次？\n客户端和服务器之间断开连接需要进⾏四次挥⼿（具体内容在后⾯章节汇总讲解）。\nDNS\nDNS是什么\nDNS（Domain Name System） 是⼀种⽤于将域名（例如www.baidu.com）转换为IP地址（例如",
    "question": "## 第四步：浏览器发送HTTP/HTTPS请求到web服务器",
    "answer": "这⼀步也可以扩展很多问题，⽐如HTTP/HTTPS的区别？请求的⽅式？请求的状态码，凡是与HTTP请求的问\n题都可以问。\n## 第五步：服务器处理HTTP请求并返回HTTP报⽂\nHTTP响应报⽂和状态码也是常考的内容。\n服务器会接受请求并将其传递给请求处理程序并发送HTTP响应，⼀般响应报⽂包含：请求的⽹⻚以及状态码，压\n缩类型，如何缓存的⻚⾯，设置的cookie;\n## 第六步：浏览器渲染⻚⾯\n浏览器渲染⻚⾯的流程对于前端同学来说也是必会的、还会牵扯到回流和重绘的问题。\n## 第七步：断开连接之TCP四次挥⼿\n这⾥也是特别重要的知识点，四次挥⼿的过程，为什么是四次？\n客户端和服务器之间断开连接需要进⾏四次挥⼿（具体内容在后⾯章节汇总讲解）。\nDNS\nDNS是什么\nDNS（Domain Name System） 是⼀种⽤于将域名（例如www.baidu.com）转换为IP地址（例如",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 429,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000003",
    "content": "DNS是什么\n\nDNS（Domain Name System） 是⼀种⽤于将域名（例如www.baidu.com）转换为IP地址（例如\n## ）的分布式系统。在互联⽹上，计算机和其他⽹络设备使⽤IP地址来相互识别和通信。然⽽，\nIP地址是⼀串数字，不太⽅便⼈们使⽤和记忆，所以就使⽤了域名来代替复杂的IP地址\n对于DNS服务器若采⽤集中式的设计有以下问题\n## 单点故障\n如果 DNS 服务器崩溃，那么整个⽹络随之瘫痪。通信容量(traaffic volume) ，单个 DNS 服务器不得不处理所有的\nDNS  查询，这种查询级别可能是上百万上千万级，⼀台服务器很难满⾜;\n## 远距离集中式数据库\n单个 DNS 服务器不可能 邻近 所有的⽤户，假设在美国的 DNS 服务器不可能临近让澳⼤利亚的查询使⽤，其中查\n询请求势必会经过低速和拥堵的链路，造成严重的时延;\n## 维护\n维护成本巨⼤，⽽且还需要频繁更新。\n域名的层级关系\nDNS 中的域名都是⽤句点来分隔的，⽐如 www.server.com ，这⾥的句点代表了不同层次之间的界限。\n在域名中，越靠右的位置表示其层级越⾼。\nDNS解析过程\n## 先查询浏览器缓存是否有该域名对应的IP地址。\n## 如果浏览器缓存中没有，会去计算机本地的Host⽂件中查询是否有对应的缓存。\n## 如果Host⽂件中也没有则会向本地的DNS服务器（通常由你的互联⽹服务提供商（ISP）提供， ⽐如中国移\n动）发送⼀个DNS查询请求。\n## 如果本地DNS解析器有该域名的ip地址，就会直接返回，如果没有缓存该域名的解析记录，它会向根DNS服\n务器发出查询请求。根DNS服务器并不负责解析域名，但它能告诉本地DNS解析器应该向哪个顶级域\n（.com/.net/.org）的DNS服务器继续查询。\n## 本地DNS解析器接着向指定的顶级域名DNS服务器发出查询请求。顶级域DNS服务器也不负责具体的域名解\n析，但它能告诉本地DNS解析器应该前往哪个权威DNS服务器查询下⼀步的信息。\n## 本地DNS解析器最后向权威DNS服务器发送查询请求。 权威DNS服务器是负责存储特定域名和IP地址映射的\n服务器。当权威DNS服务器收到查询请求时，它会查找\"example.com\"域名对应的IP地址，并将结果返回给本\n地DNS解析器。\n## 本地DNS解析器将收到的IP地址返回给浏览器，并且还会将域名解析结果缓存在本地，以便下次访问时更快地\n## 浏览器发起连接： 本地DNS解析器已经将IP地址返回给您的计算机，您的浏览器可以使⽤该IP地址与⽬标服\n务器建⽴连接，开始获取⽹⻚内容。\n递归查询和迭代查询\n递归查询和迭代查询是在DNS解析过程中⽤于获取域名解析信息的两种不同⽅法。\n## 递归查询\n在递归查询中，DNS客户端（通常是本地DNS解析器）向上层DNS服务器（如根域名服务器、顶级域名服务器）发\n起查询请求，并要求这些服务器直接提供完整的解析结果。递归查询的特点是，DNS客户端只需要发送⼀个查询请\n求，然后等待完整的解析结果。上层DNS服务器会⾃⾏查询下⼀级的服务器，并将最终结果返回给DNS客户端。\n## 迭代查询\n在迭代查询中，DNS客户端向上层DNS服务器发起查询请求，但不要求直接提供完整的解析结果。相反，DNS客户\n端只是询问上层服务器⼀个更⾼级的域名服务器的地址，然后再⾃⾏向那个更⾼级的服务器发起查询请求，以此类\n推，直到获取完整的解析结果为⽌。\n递归查询适合普通⽤户和客户端，⽽迭代查询适⽤于DNS服务器之间的通信。\nHTTP特性与简述\n特性：简单、灵活、易于扩展、应⽤⼴泛和跨平台。\n简述：\nWeb 上的通信都是建⽴在 HTTP 协议上的\n## 客户端发起 HTTP 请求；\n## 服务器做出响应处理后，返回 HTTP 响应报⽂\n最初设想的基本理念是：借助多⽂档之间相互关联形成的超⽂本（HyperText），连成可相互参阅的 WWW\n（World Wide Web，万维⽹）\nWWW 构建技术（3 项）：\n## HTML (HyperText Markup Language)：作为⻚⾯的⽂本标记语⾔\n## HTTP (HyperText Transfer Protocol)：⽂档传递协议；\n## URL (Uniform Resource Locator)：指定⽂档所在地址\nHTTP 版本：",
    "question": "DNS是什么",
    "answer": "DNS（Domain Name System） 是⼀种⽤于将域名（例如www.baidu.com）转换为IP地址（例如\n## ）的分布式系统。在互联⽹上，计算机和其他⽹络设备使⽤IP地址来相互识别和通信。然⽽，\nIP地址是⼀串数字，不太⽅便⼈们使⽤和记忆，所以就使⽤了域名来代替复杂的IP地址\n对于DNS服务器若采⽤集中式的设计有以下问题\n## 单点故障\n如果 DNS 服务器崩溃，那么整个⽹络随之瘫痪。通信容量(traaffic volume) ，单个 DNS 服务器不得不处理所有的\nDNS  查询，这种查询级别可能是上百万上千万级，⼀台服务器很难满⾜;\n## 远距离集中式数据库\n单个 DNS 服务器不可能 邻近 所有的⽤户，假设在美国的 DNS 服务器不可能临近让澳⼤利亚的查询使⽤，其中查\n询请求势必会经过低速和拥堵的链路，造成严重的时延;\n## 维护\n维护成本巨⼤，⽽且还需要频繁更新。\n域名的层级关系\nDNS 中的域名都是⽤句点来分隔的，⽐如 www.server.com ，这⾥的句点代表了不同层次之间的界限。\n在域名中，越靠右的位置表示其层级越⾼。\nDNS解析过程\n## 先查询浏览器缓存是否有该域名对应的IP地址。\n## 如果浏览器缓存中没有，会去计算机本地的Host⽂件中查询是否有对应的缓存。\n## 如果Host⽂件中也没有则会向本地的DNS服务器（通常由你的互联⽹服务提供商（ISP）提供， ⽐如中国移\n动）发送⼀个DNS查询请求。\n## 如果本地DNS解析器有该域名的ip地址，就会直接返回，如果没有缓存该域名的解析记录，它会向根DNS服\n务器发出查询请求。根DNS服务器并不负责解析域名，但它能告诉本地DNS解析器应该向哪个顶级域\n（.com/.net/.org）的DNS服务器继续查询。\n## 本地DNS解析器接着向指定的顶级域名DNS服务器发出查询请求。顶级域DNS服务器也不负责具体的域名解\n析，但它能告诉本地DNS解析器应该前往哪个权威DNS服务器查询下⼀步的信息。\n## 本地DNS解析器最后向权威DNS服务器发送查询请求。 权威DNS服务器是负责存储特定域名和IP地址映射的\n服务器。当权威DNS服务器收到查询请求时，它会查找\"example.com\"域名对应的IP地址，并将结果返回给本\n地DNS解析器。\n## 本地DNS解析器将收到的IP地址返回给浏览器，并且还会将域名解析结果缓存在本地，以便下次访问时更快地\n## 浏览器发起连接： 本地DNS解析器已经将IP地址返回给您的计算机，您的浏览器可以使⽤该IP地址与⽬标服\n务器建⽴连接，开始获取⽹⻚内容。\n递归查询和迭代查询\n递归查询和迭代查询是在DNS解析过程中⽤于获取域名解析信息的两种不同⽅法。\n## 递归查询\n在递归查询中，DNS客户端（通常是本地DNS解析器）向上层DNS服务器（如根域名服务器、顶级域名服务器）发\n起查询请求，并要求这些服务器直接提供完整的解析结果。递归查询的特点是，DNS客户端只需要发送⼀个查询请\n求，然后等待完整的解析结果。上层DNS服务器会⾃⾏查询下⼀级的服务器，并将最终结果返回给DNS客户端。\n## 迭代查询\n在迭代查询中，DNS客户端向上层DNS服务器发起查询请求，但不要求直接提供完整的解析结果。相反，DNS客户\n端只是询问上层服务器⼀个更⾼级的域名服务器的地址，然后再⾃⾏向那个更⾼级的服务器发起查询请求，以此类\n推，直到获取完整的解析结果为⽌。\n递归查询适合普通⽤户和客户端，⽽迭代查询适⽤于DNS服务器之间的通信。\nHTTP特性与简述\n特性：简单、灵活、易于扩展、应⽤⼴泛和跨平台。\n简述：\nWeb 上的通信都是建⽴在 HTTP 协议上的\n## 客户端发起 HTTP 请求；\n## 服务器做出响应处理后，返回 HTTP 响应报⽂\n最初设想的基本理念是：借助多⽂档之间相互关联形成的超⽂本（HyperText），连成可相互参阅的 WWW\n（World Wide Web，万维⽹）\nWWW 构建技术（3 项）：\n## HTML (HyperText Markup Language)：作为⻚⾯的⽂本标记语⾔\n## HTTP (HyperText Transfer Protocol)：⽂档传递协议；\n## URL (Uniform Resource Locator)：指定⽂档所在地址\nHTTP 版本：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1830,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000004",
    "content": "## 1997 年 1 ⽉，发布 HTTP/1.1 ，是⽬前主流的 HTTP 协议版本\n\n## 现今，HTTP/2.0  正在制订中，但还未得到⼴泛的使⽤\n特性：\n## 简单\n基本报⽂格式为header+body，头部信息也是key-value简单⽂本的形式，易于理解。\n## 灵活和易于扩展\nHTTP协议⾥的各种请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，允许开发⼈员⾃\n定义和扩充;\nHTTP⼯作在应⽤层（OSI第七层），下层可以随意变化;\nHTTPS就是在HTTP与TCP之间增加了SSL/TSL安全传输层，HTTP/3把TCP换成了基于UDP的QUIC。\n## ⽆状态、明⽂传输、不安全\n⽆状态：\n服务器不会去记忆HTTP的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担。但它在完成有\n关联性的操作时会⾮常麻烦。\n对于⽆状态的问题，解决⽅案友很多种，其中⽐较简单的⽅式的是 Cookie 技术， Cookie 通过在请求和响\n应报⽂中写⼊ Cookie 信息来控制客户端的状态。\n明⽂传输：\n传输过程中的信息，是可⽅便阅读的，通过浏览器的F12控制台或Wireshark抓包都可以直接⾁眼查看\n明⽂传输为我们调试⼯作带来了极⼤的便利性，但信息透明，容易被窃取。\n不安全：\n## 通信使⽤明⽂（不加密），内容可能被窃听\n## 不验证通信⽅的身份，因此有可能遭遇伪装\n## ⽆法证明报⽂的完整性，所以有可能已遭篡改\n可以⽤ HTTPS 的⽅式解决，也就是通过引⼊\n层，使得在安全上达到了极致。\nSSL/TLS\nHTTP版本演变\n⽬前为⽌，HTTP 常⻅的版本有 HTTP/1.1 ， HTTP/2.0 ， HTTP/3.0 ，不同版本的 HTTP 特性是不⼀样的。\nHTTP/0.9\nHTTP/0.9 是最早的HTTP版本，在1991年就已经发布，只⽀持 GET ⽅法，也没有请求头，服务器只能返回HTML\n格式的内容。\nHTTP/1.0\nHTTP/1.0 是HTTTP 协议的第⼀个正式版本, 主要具有以下特性：\n引⼊了请求头和响应头，⽀持多种请求⽅法和状态码\n不⽀持持久连接，每次请求都需要建⽴新的连接\nHTTP/1.1\n为了解决HTTP/1.0 每次请求都需要建⽴新的连接的问题， HTTP/1.1 提出了⻓连接（持久连接），只要客户端和\n服务器任意⼀端没有明确提出断开连接，则保持TCP连接状态。\n## 管道⽹络传输\n在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请\n求出去，可以减少整体的响应时间。\n客户端需要请求两个资源。以前的做法是，在同⼀个 TCP 连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，\n收到后再发出 B 请求。那么，管道机制则是允许浏览器同时发出 A 请求和 B 请求\n但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应。\n如果服务端在处理 A 请求时耗时⽐较⻓，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。\n所以，HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞。\nHTTP/1.1 管道化技术不是默认开启，⽽且浏览器基本都没有⽀持\n## 队头阻塞\n当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户\n端⼀直请求不到数据，这也就是「队头阻塞」\n但是HTTP1.1 仍然存在着不少问题：\n头部冗余：每个请求和响应都需要带有⼀定的头部信息，每次互相发送相同的⾸部造成的浪费较多；\n服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；\n没有请求优先级控制；\n请求只能从客户端开始，服务器只能被动响应。\nHTTP/2\nHTTP/2 协议是基于 HTTPS 的, 所以HTTP/2的安全性也是有保障的\n## 头部压缩：HTTP/2 使⽤\n压缩算法对请求和响应头部进⾏压缩，减少了传输的头部数据量，降低了延\n## ⼆进制帧：HTTP/2 将数据分割成⼆进制帧进⾏传输，分为头信息帧（Headers Frame）和数据帧（Data\nFrame），增加了数据传输的效率。\n## 并发传输：引出了 Stream 概念，多个 Stream 复⽤在⼀条 TCP 连接，针对不同的 HTTP 请求⽤独⼀⽆⼆的\nStream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送\n的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并⾏交错地发送请求和响应。\n## 服务器推送：在\n中，服务器可以对客户端的⼀个请求发送多个响应，即服务器可以额外的向客户端\n推送资源，⽽⽆需客户端明确的请求。\n但是HTTP/2 仍然存在着队头阻塞的问题，只不过问题是在传输层。\nHTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这\n样内核才会将缓冲区⾥的数据返回给 HTTP 应⽤，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能\n存放在内核缓冲区⾥，只有等到这 1 个字节数据到达时，HTTP/2 应⽤层才能从内核中拿到数据，这就是 HTTP/2\n队头阻塞问题。\nHPACK\nHTTP/2\nHTTP1.1协议的性能问题\n## HTTP1.1常⻅性能问题\n## 为解决HTTP1.1性能问题⽽提出的常⻅优化⼿段\n但是上述优化⼿段都只是“外部”优化，效果不够好。\n兼容HTTP1.1\nHTTP2，为改善HTTP1.1⽽提出，同时兼容了HTTP1.1，具体做法如下：\n头部压缩\n## HTTP1.1报⽂中Header部分存在的问题：\n## HTTP2的改造：\n使⽤HPACK算法压缩头部。HPACK算法包含三个组成部分：\n（i） 静态字典\n（ii） 动态字典\n（iii） Huffman编码（压缩算法）\n客户端和服务器都会建⽴和维护【字典】，⽤⻓度较⼩的索引号表示重复的字符串，再⽤Huffman 编码压缩数\n（1） 静态表编码：\nHTTP2 为⾼频出现在头部的字符串和字段建⽴了⼀张静态表，它是写⼊到 HTTP2 框架⾥的，不会变化的，静态表\n⾥共有 61 组：\n（2） 动态表编码：\n使得动态表⽣效的⼀个前提：必须同⼀个连接上，重复传输完全相同的HTTP头部。\n动态表越⼤，占⽤的内存也就越⼤，如果占⽤了太多内存，是会影响服务器性能的，因此 Web 服务器都会提供类\n似  http2_max_requests 的配置，⽤于限制⼀个连接上能够传输的请求数，避免动态表⽆限增⼤，请求数到达上\n限后，就会关闭 HTTP/2 连接来释放内存。\nHTTP2头部的编码通过【静态表、动态表、Huffman编码】共同完成。\n⼆进制帧\nHTTP2更厉害的地⽅在于：将HTTP1的⽂本格式改成⼆进制格式传输数据，极⼤提⾼了HTTP传输效率，⽽且⼆进\n制数据使⽤位运算能⾼效解析。\n两者响应区别（如下图）：\nHTTP2⼆进制帧的结构：\nHTTP2总共定义了10种类型的帧，分为两类，即数据帧和控制帧：\n标志位⽤于携带简单的控制信息，⽐如：\n流标识符（Stream ID)：\n⽤来标识该Fream属于哪个Stream。接收⽅可以根据这个信息从乱序的帧⾥找到相同Stream ID的帧，从⽽有序组\n装信息。\n帧数据：\n⽤于存放 通过HPACK 算法压缩过的HTTP头部和包体。\n并发传输\n## HTTP1.1与HTTP2的⽐较\nHTTP1.1 基于请求-响应模型。同⼀个连接中，HTTP完成⼀个事务（请求与响应），才能处理下⼀个事务。即：再\n发出请求等待响应的过程种是没办法做其他事情的，会造成【队头阻塞】问题。\nHTTP2通过Stream这个设计（多个Stream复⽤⼀条TCP连接，达到并发的效果），解决了【队头阻塞】的问题，\n提⾼了HTTP传输的吞吐量。\n## HTTPS并发的实现\nHTTP2并发是如何实现的呢？\n先来理解三个概念，即：Stream、Message、frame。\n从上图可以看到：\n## HTTP消息可以由多个Frame构成\n## ⼀个Frame可以由多个TCP报⽂构成\n在HTTP2连接上，不同Stream的帧可以乱序发送（因此可以并发不同的Stream），接收端可以通过Stream ID 有\n序组装HTTP消息。\n服务器主动推送资源\n## HTTP1.1与HTTP2的⽐较：\nHTTP1.1不⽀持服务器主动推送资源给客户端，都是由客户端向服务器发起请求后，才能获取到服务器响应的资\n源。在HTTP2中，客户端在访问HTML时，服务器可以直接主动推送CSS⽂件，减少了消息传递的次数。\nHTTP2推送的具体实现⽅式：\nHTTP2协议还包括：流控制、流状态、依赖关系等。\n本次主要介绍了关于HTTP如何提升性能：\nHTTP/3\nHTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！\nHTTP/3 基于 QUIC 协议，具有以下特点：\n零 RTT 连接建⽴：QUIC 允许在⾸次连接时进⾏零往返时间（Zero Round Trip Time）连接建⽴，从⽽减少\n了连接延迟，加快了⻚⾯加载速度。\n⽆队头阻塞:   QUIC 使⽤UDP 协议来传输数据。⼀个连接上的多个stream之间没有依赖,  如果⼀个stream丢了\n⼀个UDP包，不会影响后⾯的stream，不存在 TCP 队头阻塞\n连接迁移：QUIC 允许在⽹络切换（如从 Wi-Fi 到移动⽹络）时，将连接迁移到新的 IP 地址，从⽽减少连接的\n中断时间。\n向前纠错机制：每个数据包除了它本身的内容之外，还包括了部分其他数据包的数据，因此少量的丢包可以通\n过其他包的冗余数据直接组装⽽⽆需重传。向前纠错牺牲了每个数据包可以发送数据的上限，但是减少了因为\n丢包导致的数据重传。\nHTTP/2的缺点\nHTTP2协议是基于TCP实现的，所以存在三个缺陷：\n（i） 队头阻塞\n（ii） TCP与TLS的握⼿时延迟\n（iii)⽹络迁移需要重新连接\n## 队头阻塞\nTCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在⽹络传输中丢失\n了，即使序列号较⾼的 TCP 段已经被接收了，应⽤层也⽆法从内核中读取到这部分数据，从 HTTP 视⻆看，就是请\n求被阻塞了。\n## TCP与TLS的握⼿时延迟\n发出HTTP请求时，需要经过TCP三次握⼿和TLS四次握⼿，共计3RTT的时延才能发出请求数据。\n## ⽹络迁移需要重新连接\n⼀个TCP连接由【源IP地址，源端⼝，⽬标IP地址，⽬标端⼝】确定。若IP地址或端⼝发⽣变暖，这需要重新进⾏\n连接。这不利于移动设备切换⽹络的场景。要解决该问题，就要修改传输层协议。在HTTP3中传输层协议修改为了\nUDP。",
    "question": "## 1997 年 1 ⽉，发布 HTTP/1.1 ，是⽬前主流的 HTTP 协议版本",
    "answer": "## 现今，HTTP/2.0  正在制订中，但还未得到⼴泛的使⽤\n特性：\n## 简单\n基本报⽂格式为header+body，头部信息也是key-value简单⽂本的形式，易于理解。\n## 灵活和易于扩展\nHTTP协议⾥的各种请求⽅法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，允许开发⼈员⾃\n定义和扩充;\nHTTP⼯作在应⽤层（OSI第七层），下层可以随意变化;\nHTTPS就是在HTTP与TCP之间增加了SSL/TSL安全传输层，HTTP/3把TCP换成了基于UDP的QUIC。\n## ⽆状态、明⽂传输、不安全\n⽆状态：\n服务器不会去记忆HTTP的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担。但它在完成有\n关联性的操作时会⾮常麻烦。\n对于⽆状态的问题，解决⽅案友很多种，其中⽐较简单的⽅式的是 Cookie 技术， Cookie 通过在请求和响\n应报⽂中写⼊ Cookie 信息来控制客户端的状态。\n明⽂传输：\n传输过程中的信息，是可⽅便阅读的，通过浏览器的F12控制台或Wireshark抓包都可以直接⾁眼查看\n明⽂传输为我们调试⼯作带来了极⼤的便利性，但信息透明，容易被窃取。\n不安全：\n## 通信使⽤明⽂（不加密），内容可能被窃听\n## 不验证通信⽅的身份，因此有可能遭遇伪装\n## ⽆法证明报⽂的完整性，所以有可能已遭篡改\n可以⽤ HTTPS 的⽅式解决，也就是通过引⼊\n层，使得在安全上达到了极致。\nSSL/TLS\nHTTP版本演变\n⽬前为⽌，HTTP 常⻅的版本有 HTTP/1.1 ， HTTP/2.0 ， HTTP/3.0 ，不同版本的 HTTP 特性是不⼀样的。\nHTTP/0.9\nHTTP/0.9 是最早的HTTP版本，在1991年就已经发布，只⽀持 GET ⽅法，也没有请求头，服务器只能返回HTML\n格式的内容。\nHTTP/1.0\nHTTP/1.0 是HTTTP 协议的第⼀个正式版本, 主要具有以下特性：\n引⼊了请求头和响应头，⽀持多种请求⽅法和状态码\n不⽀持持久连接，每次请求都需要建⽴新的连接\nHTTP/1.1\n为了解决HTTP/1.0 每次请求都需要建⽴新的连接的问题， HTTP/1.1 提出了⻓连接（持久连接），只要客户端和\n服务器任意⼀端没有明确提出断开连接，则保持TCP连接状态。\n## 管道⽹络传输\n在同⼀个 TCP 连接⾥⾯，客户端可以发起多个请求，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请\n求出去，可以减少整体的响应时间。\n客户端需要请求两个资源。以前的做法是，在同⼀个 TCP 连接⾥⾯，先发送 A 请求，然后等待服务器做出回应，\n收到后再发出 B 请求。那么，管道机制则是允许浏览器同时发出 A 请求和 B 请求\n但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应。\n如果服务端在处理 A 请求时耗时⽐较⻓，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。\n所以，HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞。\nHTTP/1.1 管道化技术不是默认开启，⽽且浏览器基本都没有⽀持\n## 队头阻塞\n当顺序发送的请求序列中的⼀个请求因为某种原因被阻塞时，在后⾯排队的所有请求也⼀同被阻塞了，会招致客户\n端⼀直请求不到数据，这也就是「队头阻塞」\n但是HTTP1.1 仍然存在着不少问题：\n头部冗余：每个请求和响应都需要带有⼀定的头部信息，每次互相发送相同的⾸部造成的浪费较多；\n服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是队头阻塞；\n没有请求优先级控制；\n请求只能从客户端开始，服务器只能被动响应。\nHTTP/2\nHTTP/2 协议是基于 HTTPS 的, 所以HTTP/2的安全性也是有保障的\n## 头部压缩：HTTP/2 使⽤\n压缩算法对请求和响应头部进⾏压缩，减少了传输的头部数据量，降低了延\n## ⼆进制帧：HTTP/2 将数据分割成⼆进制帧进⾏传输，分为头信息帧（Headers Frame）和数据帧（Data\nFrame），增加了数据传输的效率。\n## 并发传输：引出了 Stream 概念，多个 Stream 复⽤在⼀条 TCP 连接，针对不同的 HTTP 请求⽤独⼀⽆⼆的\nStream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送\n的，因此可以并发不同的 Stream ，也就是 HTTP/2 可以并⾏交错地发送请求和响应。\n## 服务器推送：在\n中，服务器可以对客户端的⼀个请求发送多个响应，即服务器可以额外的向客户端\n推送资源，⽽⽆需客户端明确的请求。\n但是HTTP/2 仍然存在着队头阻塞的问题，只不过问题是在传输层。\nHTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这\n样内核才会将缓冲区⾥的数据返回给 HTTP 应⽤，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能\n存放在内核缓冲区⾥，只有等到这 1 个字节数据到达时，HTTP/2 应⽤层才能从内核中拿到数据，这就是 HTTP/2\n队头阻塞问题。\nHPACK\nHTTP/2\nHTTP1.1协议的性能问题\n## HTTP1.1常⻅性能问题\n## 为解决HTTP1.1性能问题⽽提出的常⻅优化⼿段\n但是上述优化⼿段都只是“外部”优化，效果不够好。\n兼容HTTP1.1\nHTTP2，为改善HTTP1.1⽽提出，同时兼容了HTTP1.1，具体做法如下：\n头部压缩\n## HTTP1.1报⽂中Header部分存在的问题：\n## HTTP2的改造：\n使⽤HPACK算法压缩头部。HPACK算法包含三个组成部分：\n（i） 静态字典\n（ii） 动态字典\n（iii） Huffman编码（压缩算法）\n客户端和服务器都会建⽴和维护【字典】，⽤⻓度较⼩的索引号表示重复的字符串，再⽤Huffman 编码压缩数\n（1） 静态表编码：\nHTTP2 为⾼频出现在头部的字符串和字段建⽴了⼀张静态表，它是写⼊到 HTTP2 框架⾥的，不会变化的，静态表\n⾥共有 61 组：\n（2） 动态表编码：\n使得动态表⽣效的⼀个前提：必须同⼀个连接上，重复传输完全相同的HTTP头部。\n动态表越⼤，占⽤的内存也就越⼤，如果占⽤了太多内存，是会影响服务器性能的，因此 Web 服务器都会提供类\n似  http2_max_requests 的配置，⽤于限制⼀个连接上能够传输的请求数，避免动态表⽆限增⼤，请求数到达上\n限后，就会关闭 HTTP/2 连接来释放内存。\nHTTP2头部的编码通过【静态表、动态表、Huffman编码】共同完成。\n⼆进制帧\nHTTP2更厉害的地⽅在于：将HTTP1的⽂本格式改成⼆进制格式传输数据，极⼤提⾼了HTTP传输效率，⽽且⼆进\n制数据使⽤位运算能⾼效解析。\n两者响应区别（如下图）：\nHTTP2⼆进制帧的结构：\nHTTP2总共定义了10种类型的帧，分为两类，即数据帧和控制帧：\n标志位⽤于携带简单的控制信息，⽐如：\n流标识符（Stream ID)：\n⽤来标识该Fream属于哪个Stream。接收⽅可以根据这个信息从乱序的帧⾥找到相同Stream ID的帧，从⽽有序组\n装信息。\n帧数据：\n⽤于存放 通过HPACK 算法压缩过的HTTP头部和包体。\n并发传输\n## HTTP1.1与HTTP2的⽐较\nHTTP1.1 基于请求-响应模型。同⼀个连接中，HTTP完成⼀个事务（请求与响应），才能处理下⼀个事务。即：再\n发出请求等待响应的过程种是没办法做其他事情的，会造成【队头阻塞】问题。\nHTTP2通过Stream这个设计（多个Stream复⽤⼀条TCP连接，达到并发的效果），解决了【队头阻塞】的问题，\n提⾼了HTTP传输的吞吐量。\n## HTTPS并发的实现\nHTTP2并发是如何实现的呢？\n先来理解三个概念，即：Stream、Message、frame。\n从上图可以看到：\n## HTTP消息可以由多个Frame构成\n## ⼀个Frame可以由多个TCP报⽂构成\n在HTTP2连接上，不同Stream的帧可以乱序发送（因此可以并发不同的Stream），接收端可以通过Stream ID 有\n序组装HTTP消息。\n服务器主动推送资源\n## HTTP1.1与HTTP2的⽐较：\nHTTP1.1不⽀持服务器主动推送资源给客户端，都是由客户端向服务器发起请求后，才能获取到服务器响应的资\n源。在HTTP2中，客户端在访问HTML时，服务器可以直接主动推送CSS⽂件，减少了消息传递的次数。\nHTTP2推送的具体实现⽅式：\nHTTP2协议还包括：流控制、流状态、依赖关系等。\n本次主要介绍了关于HTTP如何提升性能：\nHTTP/3\nHTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！\nHTTP/3 基于 QUIC 协议，具有以下特点：\n零 RTT 连接建⽴：QUIC 允许在⾸次连接时进⾏零往返时间（Zero Round Trip Time）连接建⽴，从⽽减少\n了连接延迟，加快了⻚⾯加载速度。\n⽆队头阻塞:   QUIC 使⽤UDP 协议来传输数据。⼀个连接上的多个stream之间没有依赖,  如果⼀个stream丢了\n⼀个UDP包，不会影响后⾯的stream，不存在 TCP 队头阻塞\n连接迁移：QUIC 允许在⽹络切换（如从 Wi-Fi 到移动⽹络）时，将连接迁移到新的 IP 地址，从⽽减少连接的\n中断时间。\n向前纠错机制：每个数据包除了它本身的内容之外，还包括了部分其他数据包的数据，因此少量的丢包可以通\n过其他包的冗余数据直接组装⽽⽆需重传。向前纠错牺牲了每个数据包可以发送数据的上限，但是减少了因为\n丢包导致的数据重传。\nHTTP/2的缺点\nHTTP2协议是基于TCP实现的，所以存在三个缺陷：\n（i） 队头阻塞\n（ii） TCP与TLS的握⼿时延迟\n（iii)⽹络迁移需要重新连接\n## 队头阻塞\nTCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在⽹络传输中丢失\n了，即使序列号较⾼的 TCP 段已经被接收了，应⽤层也⽆法从内核中读取到这部分数据，从 HTTP 视⻆看，就是请\n求被阻塞了。\n## TCP与TLS的握⼿时延迟\n发出HTTP请求时，需要经过TCP三次握⼿和TLS四次握⼿，共计3RTT的时延才能发出请求数据。\n## ⽹络迁移需要重新连接\n⼀个TCP连接由【源IP地址，源端⼝，⽬标IP地址，⽬标端⼝】确定。若IP地址或端⼝发⽣变暖，这需要重新进⾏\n连接。这不利于移动设备切换⽹络的场景。要解决该问题，就要修改传输层协议。在HTTP3中传输层协议修改为了\nUDP。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": 1997,
    "char_count": 4546,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000005",
    "content": "## ⽹络迁移需要重新连接\n\n⼀个TCP连接由【源IP地址，源端⼝，⽬标IP地址，⽬标端⼝】确定。若IP地址或端⼝发⽣变暖，这需要重新进⾏\n连接。这不利于移动设备切换⽹络的场景。要解决该问题，就要修改传输层协议。在HTTP3中传输层协议修改为了\nUDP。\nQUIC协议的特点\nUDP是⼀个简单的、不可靠的传输协议，⽽且UDP包之间是⽆序的，也没有依赖关系。UDP也不需要连接。\nHTTP3基于UDP协议在 应⽤层 实现了QUIC 协议，它有类似TCP的连接管理、拥塞窗⼝、流量控制的⽹络特性，相\n当于将不可靠的UDP协议变成可靠的了，⽆需担⼼数据包丢包的问题。",
    "question": "## ⽹络迁移需要重新连接",
    "answer": "⼀个TCP连接由【源IP地址，源端⼝，⽬标IP地址，⽬标端⼝】确定。若IP地址或端⼝发⽣变暖，这需要重新进⾏\n连接。这不利于移动设备切换⽹络的场景。要解决该问题，就要修改传输层协议。在HTTP3中传输层协议修改为了\nUDP。\nQUIC协议的特点\nUDP是⼀个简单的、不可靠的传输协议，⽽且UDP包之间是⽆序的，也没有依赖关系。UDP也不需要连接。\nHTTP3基于UDP协议在 应⽤层 实现了QUIC 协议，它有类似TCP的连接管理、拥塞窗⼝、流量控制的⽹络特性，相\n当于将不可靠的UDP协议变成可靠的了，⽆需担⼼数据包丢包的问题。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 280,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000006",
    "content": "QUIC协议的特点\n\nUDP是⼀个简单的、不可靠的传输协议，⽽且UDP包之间是⽆序的，也没有依赖关系。UDP也不需要连接。\nHTTP3基于UDP协议在 应⽤层 实现了QUIC 协议，它有类似TCP的连接管理、拥塞窗⼝、流量控制的⽹络特性，相\n当于将不可靠的UDP协议变成可靠的了，⽆需担⼼数据包丢包的问题。\n## ⽆队头阻塞\nHTTP2:只要某个流中的数据包丢失了，其他流也会因此受影响。\nHTTP3:流与流（Stream)之间不影响。\n## 更快的连接建⽴\n对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因\n此它们难以合并在⼀起，需要分批次来握⼿，先 TCP 握⼿，再 TLS 握⼿。\nHTTP/3 在传输数据前虽然需要 QUIC 协议握⼿，这个握⼿过程只需要 1 RTT，握⼿的⽬的是为确认双⽅的「连接\nID」，连接迁移就是基于连接 ID 实现的。\n但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，⽽是QUIC 内部包含了 TLS，它在⾃⼰的帧会携带 TLS ⾥的“记\n录”，再加上 QUIC 使⽤的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与密钥协商，甚⾄在第⼆次\n连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息 + TLS 信息）⼀起发送，达到 0-RTT 的效果。\n## 连接迁移\nHTTP/3协议\nHTTP/3 同 HTTP/2 ⼀样采⽤⼆进制帧的结构，不同的地⽅在于 HTTP/2 的⼆进制帧⾥需要定义 Stream，⽽\nHTTP/3 ⾃身不需要再定义 Stream，直接使⽤ QUIC ⾥的 Stream，于是 HTTP/3 的帧的结构也变简单了。\n## 对⽐图如下：\n## 头部压缩算法：\nHTTP2:HPACK\nHTTP3:QPACK\n## 静态表：\nHTTP2:静态表61项\nHTTP3:静态表91项\n## 动态表：\nHTTP2：动态表是具有时序性的，如果⾸次出现的请求发⽣了丢包，后续的收到请求，对⽅就⽆法解码出HPACK\n头部，因为对⽅还没建⽴好动态表，因此后续的请求解码会阻塞到⾸次请求中丢失的数据包重传过来。\nHTTP3的QPACK解决了上述问题，具体⽅案如下：\nHTTP缓存\n对于已经请求过的资源，客户端或代理服务器会将其副本保存在本地存储中，并且在下次请求同⼀资源时，⾸先检\n查缓存中是否存在有效的副本。如果存在有效的缓存，就直接读取本地的数据，不必在通过⽹络获取服务器的响应\n了，这就是HTTP缓存\nHTTP 缓存有两种实现⽅式，分别是强制缓存和协商缓存\n强制缓存\n强缓存：浏览器判断请求的⽬标资源是否有效命中强缓存，如果命中，则可以直接从内存中读取⽬标资源，⽆需与\n服务器做任何通讯。\nExpires强缓存 ：设置⼀个强缓存时间，此时间范围内，从内存中读取缓存并返回，因为Expires 判断强缓\n存过期的机制是获取本地时间戳，与之前拿到的资源⽂件中的Expires 字段的时间做⽐较。来判断是否需要\n对服务器发起请求, 所以这⾥有⼀个巨⼤的漏洞：“如果我本地时间不准咋办？”正是因为这个原因，该字段⽬\n前已经基本上被废弃了。\nCache-Control强缓存 ： http1.1 中增加该字段，只要在资源的响应头上写上需要缓存多久就好了，单位是\n秒。 Cache-Control:max-age=N , 有max-age、s-maxage、no-cache、no-store、private、public这\n六个属性。\nmax-age 决定客户端资源被缓存多久。\ns-maxage 决定代理服务器缓存的时⻓。\nno-cache 表示是强制进⾏协商缓存。\nno-store 是表示禁⽌任何缓存策略。\npublic 表示资源既可以被浏览器缓存也可以被代理服务器缓存。\nprivate 表示资源只能被浏览器缓存，默认为private\n具体的流程如下：\n当浏览器第⼀次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-\nControl，Cache-Control 中设置了过期时间⼤⼩；\n浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间⼤\n⼩，来计算出该资源是否过期，如果没有，则使⽤该缓存，否则重新请求服务器；\n服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。\n协商缓存\n当我们在浏览器使⽤开发者⼯具的时候，你可能会看到过某些请求的响应码是  304 ，这个是告诉浏览器可以使⽤\n本地缓存的资源，通常这种通过服务端告知客户端是否可以使⽤缓存的⽅式被称为协商缓存。\n## 基于Last-Modified 和If-Modified-Since 的协商缓存\n流程：\n⾸先需要在服务器端读出⽂件修改时间，\n将读出来的修改时间赋给响应头的Last-Modified 字段。\n最后设置Cache-control:no-cache\n当客户端读取到Last-Modified 的时候，会在下次的请求标头中携带⼀个字段: If-Modified-Since ，⽽这\n个请求头中的If-Modified-Since 就是服务器第⼀次修改时候给他的时间\n之后每次对该资源的请求，都会带上If-Modified-Since 这个字段，⽽服务端就需要拿到这个时间并再次读\n取该资源的修改时间，让他们两个做⼀个⽐对来决定是读取缓存还是返回新的资源\n如果最后修改时间较新（⼤），说明资源⼜被改过，则返回最新资源， HTTP 200 OK 如果最后修改时间较旧\n（⼩），说明资源⽆新修改，响应HTTP 304 ⾛缓存。\n因为是根据⽂件修改时间来判断的，所以，在⽂件内容本身不修改的情况下，依然有可能更新⽂件修改时间\n（⽐如修改⽂件名再改回来），这样，就有可能⽂件内容明明没有修改，但是缓存依然失效了。\n当⽂件在极短时间内完成修改的时候（⽐如⼏百毫秒）。因为⽂件修改时间记录的最⼩单位是秒，所以，如果\n⽂件在⼏百毫秒内完成修改的话，⽂件修改时间不会改变，这样，即使⽂件内容修改了，依然不会   返回新的\n⽂件。\n⽽基于ETag 的协商缓存则解决了上⾯的两个问题，相⽐于Last-Modified ,  ETag 的优先级更⾼。\n## 基于 ETag 的协商缓存：将原先协商缓存的⽐较时间戳的形式修改成了⽐较⽂件指纹（根据⽂件内容计算出的\n唯⼀哈希值）。\n第⼀次请求某资源的时候，服务端读取⽂件并计算出⽂件指纹，将⽂件指纹放在响应头的Etag  字段中跟资源\n⼀起返回给客户端。\n第⼆次请求某资源的时候，客户端⾃动从缓存中读取出上⼀次服务端返回的ETag 也就是⽂件指纹。并赋给请\n求头的If-None-Match 字段，让上⼀次的⽂件指纹跟随请求⼀起回到服务端。\n服务端拿到请求头中的If-None-Match 字段值（也就是上⼀次的⽂件指纹），并再次读取⽬标资源并⽣成⽂\n件指纹，两个指纹做对⽐。如果两个⽂件指纹完全吻合，说明⽂件没有被改变，则直接返回 304 状态码和⼀个\n空的响应体并return。如果两个⽂件指纹不吻合，则说明⽂件被更改，那么将新的⽂件指纹重新存储到响应头\n的ETag中并返回给客户端\nETag需要计算⽂件指纹这样意味着，服务端需要更多的计算开销。如果⽂件尺⼨⼤，数量多，并且计算频\n繁，那么ETag的计算就会影响服务器的性能。显然，ETag在这样的场景下就不是很适合。\nETag有强验证和弱验证，所谓将强验证，ETag⽣成的哈希码深⼊到每个字节。哪怕⽂件中只有⼀个字节改变\n了，也会⽣成不同的哈希值，它可以保证⽂件内容绝对的不变。但是，强验证⾮常消耗计算量。ETag还有⼀个\n弱验证，弱验证是提取⽂件的部分属性来⽣成哈希值。因为不必精确到每个字节，所以他的整体速度会⽐强验\n证快，但是准确率不⾼。会降低协商缓存的有效性。\n协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使⽤，只有在未能命中强制缓存的时候，\n才能发起带有协商缓存字段的请求。\nHTTPS\nHTTPS协议\n协议（protocol）：通信双⽅需要遵守的 统⼀规则。\nHTTP：Hyper Text Transfer Protocol：超⽂本传输协议 HTTPS：\nHyper Text Transfer Protocol Secure：超⽂本安全传输协议 SSL：\nSecure Socket Layer 安全套接字\nTSL：Transport Layer Security 安全传输层协议\nHTTPS = HTTP+SSL/TSL\nSSL/TLS",
    "question": "QUIC协议的特点",
    "answer": "UDP是⼀个简单的、不可靠的传输协议，⽽且UDP包之间是⽆序的，也没有依赖关系。UDP也不需要连接。\nHTTP3基于UDP协议在 应⽤层 实现了QUIC 协议，它有类似TCP的连接管理、拥塞窗⼝、流量控制的⽹络特性，相\n当于将不可靠的UDP协议变成可靠的了，⽆需担⼼数据包丢包的问题。\n## ⽆队头阻塞\nHTTP2:只要某个流中的数据包丢失了，其他流也会因此受影响。\nHTTP3:流与流（Stream)之间不影响。\n## 更快的连接建⽴\n对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因\n此它们难以合并在⼀起，需要分批次来握⼿，先 TCP 握⼿，再 TLS 握⼿。\nHTTP/3 在传输数据前虽然需要 QUIC 协议握⼿，这个握⼿过程只需要 1 RTT，握⼿的⽬的是为确认双⽅的「连接\nID」，连接迁移就是基于连接 ID 实现的。\n但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，⽽是QUIC 内部包含了 TLS，它在⾃⼰的帧会携带 TLS ⾥的“记\n录”，再加上 QUIC 使⽤的是 TLS1.3，因此仅需 1 个 RTT 就可以「同时」完成建⽴连接与密钥协商，甚⾄在第⼆次\n连接的时候，应⽤数据包可以和 QUIC 握⼿信息（连接信息 + TLS 信息）⼀起发送，达到 0-RTT 的效果。\n## 连接迁移\nHTTP/3协议\nHTTP/3 同 HTTP/2 ⼀样采⽤⼆进制帧的结构，不同的地⽅在于 HTTP/2 的⼆进制帧⾥需要定义 Stream，⽽\nHTTP/3 ⾃身不需要再定义 Stream，直接使⽤ QUIC ⾥的 Stream，于是 HTTP/3 的帧的结构也变简单了。\n## 对⽐图如下：\n## 头部压缩算法：\nHTTP2:HPACK\nHTTP3:QPACK\n## 静态表：\nHTTP2:静态表61项\nHTTP3:静态表91项\n## 动态表：\nHTTP2：动态表是具有时序性的，如果⾸次出现的请求发⽣了丢包，后续的收到请求，对⽅就⽆法解码出HPACK\n头部，因为对⽅还没建⽴好动态表，因此后续的请求解码会阻塞到⾸次请求中丢失的数据包重传过来。\nHTTP3的QPACK解决了上述问题，具体⽅案如下：\nHTTP缓存\n对于已经请求过的资源，客户端或代理服务器会将其副本保存在本地存储中，并且在下次请求同⼀资源时，⾸先检\n查缓存中是否存在有效的副本。如果存在有效的缓存，就直接读取本地的数据，不必在通过⽹络获取服务器的响应\n了，这就是HTTP缓存\nHTTP 缓存有两种实现⽅式，分别是强制缓存和协商缓存\n强制缓存\n强缓存：浏览器判断请求的⽬标资源是否有效命中强缓存，如果命中，则可以直接从内存中读取⽬标资源，⽆需与\n服务器做任何通讯。\nExpires强缓存 ：设置⼀个强缓存时间，此时间范围内，从内存中读取缓存并返回，因为Expires 判断强缓\n存过期的机制是获取本地时间戳，与之前拿到的资源⽂件中的Expires 字段的时间做⽐较。来判断是否需要\n对服务器发起请求, 所以这⾥有⼀个巨⼤的漏洞：“如果我本地时间不准咋办？”正是因为这个原因，该字段⽬\n前已经基本上被废弃了。\nCache-Control强缓存 ： http1.1 中增加该字段，只要在资源的响应头上写上需要缓存多久就好了，单位是\n秒。 Cache-Control:max-age=N , 有max-age、s-maxage、no-cache、no-store、private、public这\n六个属性。\nmax-age 决定客户端资源被缓存多久。\ns-maxage 决定代理服务器缓存的时⻓。\nno-cache 表示是强制进⾏协商缓存。\nno-store 是表示禁⽌任何缓存策略。\npublic 表示资源既可以被浏览器缓存也可以被代理服务器缓存。\nprivate 表示资源只能被浏览器缓存，默认为private\n具体的流程如下：\n当浏览器第⼀次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-\nControl，Cache-Control 中设置了过期时间⼤⼩；\n浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间⼤\n⼩，来计算出该资源是否过期，如果没有，则使⽤该缓存，否则重新请求服务器；\n服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。\n协商缓存\n当我们在浏览器使⽤开发者⼯具的时候，你可能会看到过某些请求的响应码是  304 ，这个是告诉浏览器可以使⽤\n本地缓存的资源，通常这种通过服务端告知客户端是否可以使⽤缓存的⽅式被称为协商缓存。\n## 基于Last-Modified 和If-Modified-Since 的协商缓存\n流程：\n⾸先需要在服务器端读出⽂件修改时间，\n将读出来的修改时间赋给响应头的Last-Modified 字段。\n最后设置Cache-control:no-cache\n当客户端读取到Last-Modified 的时候，会在下次的请求标头中携带⼀个字段: If-Modified-Since ，⽽这\n个请求头中的If-Modified-Since 就是服务器第⼀次修改时候给他的时间\n之后每次对该资源的请求，都会带上If-Modified-Since 这个字段，⽽服务端就需要拿到这个时间并再次读\n取该资源的修改时间，让他们两个做⼀个⽐对来决定是读取缓存还是返回新的资源\n如果最后修改时间较新（⼤），说明资源⼜被改过，则返回最新资源， HTTP 200 OK 如果最后修改时间较旧\n（⼩），说明资源⽆新修改，响应HTTP 304 ⾛缓存。\n因为是根据⽂件修改时间来判断的，所以，在⽂件内容本身不修改的情况下，依然有可能更新⽂件修改时间\n（⽐如修改⽂件名再改回来），这样，就有可能⽂件内容明明没有修改，但是缓存依然失效了。\n当⽂件在极短时间内完成修改的时候（⽐如⼏百毫秒）。因为⽂件修改时间记录的最⼩单位是秒，所以，如果\n⽂件在⼏百毫秒内完成修改的话，⽂件修改时间不会改变，这样，即使⽂件内容修改了，依然不会   返回新的\n⽂件。\n⽽基于ETag 的协商缓存则解决了上⾯的两个问题，相⽐于Last-Modified ,  ETag 的优先级更⾼。\n## 基于 ETag 的协商缓存：将原先协商缓存的⽐较时间戳的形式修改成了⽐较⽂件指纹（根据⽂件内容计算出的\n唯⼀哈希值）。\n第⼀次请求某资源的时候，服务端读取⽂件并计算出⽂件指纹，将⽂件指纹放在响应头的Etag  字段中跟资源\n⼀起返回给客户端。\n第⼆次请求某资源的时候，客户端⾃动从缓存中读取出上⼀次服务端返回的ETag 也就是⽂件指纹。并赋给请\n求头的If-None-Match 字段，让上⼀次的⽂件指纹跟随请求⼀起回到服务端。\n服务端拿到请求头中的If-None-Match 字段值（也就是上⼀次的⽂件指纹），并再次读取⽬标资源并⽣成⽂\n件指纹，两个指纹做对⽐。如果两个⽂件指纹完全吻合，说明⽂件没有被改变，则直接返回 304 状态码和⼀个\n空的响应体并return。如果两个⽂件指纹不吻合，则说明⽂件被更改，那么将新的⽂件指纹重新存储到响应头\n的ETag中并返回给客户端\nETag需要计算⽂件指纹这样意味着，服务端需要更多的计算开销。如果⽂件尺⼨⼤，数量多，并且计算频\n繁，那么ETag的计算就会影响服务器的性能。显然，ETag在这样的场景下就不是很适合。\nETag有强验证和弱验证，所谓将强验证，ETag⽣成的哈希码深⼊到每个字节。哪怕⽂件中只有⼀个字节改变\n了，也会⽣成不同的哈希值，它可以保证⽂件内容绝对的不变。但是，强验证⾮常消耗计算量。ETag还有⼀个\n弱验证，弱验证是提取⽂件的部分属性来⽣成哈希值。因为不必精确到每个字节，所以他的整体速度会⽐强验\n证快，但是准确率不⾼。会降低协商缓存的有效性。\n协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使⽤，只有在未能命中强制缓存的时候，\n才能发起带有协商缓存字段的请求。\nHTTPS\nHTTPS协议\n协议（protocol）：通信双⽅需要遵守的 统⼀规则。\nHTTP：Hyper Text Transfer Protocol：超⽂本传输协议 HTTPS：\nHyper Text Transfer Protocol Secure：超⽂本安全传输协议 SSL：\nSecure Socket Layer 安全套接字\nTSL：Transport Layer Security 安全传输层协议\nHTTPS = HTTP+SSL/TSL\nSSL/TLS",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3624,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000007",
    "content": "## 基于 ETag 的协商缓存：将原先协商缓存的⽐较时间戳的形式修改成了⽐较⽂件指纹（根据⽂件内容计算出的\n\n唯⼀哈希值）。\n第⼀次请求某资源的时候，服务端读取⽂件并计算出⽂件指纹，将⽂件指纹放在响应头的Etag  字段中跟资源\n⼀起返回给客户端。\n第⼆次请求某资源的时候，客户端⾃动从缓存中读取出上⼀次服务端返回的ETag 也就是⽂件指纹。并赋给请\n求头的If-None-Match 字段，让上⼀次的⽂件指纹跟随请求⼀起回到服务端。\n服务端拿到请求头中的If-None-Match 字段值（也就是上⼀次的⽂件指纹），并再次读取⽬标资源并⽣成⽂\n件指纹，两个指纹做对⽐。如果两个⽂件指纹完全吻合，说明⽂件没有被改变，则直接返回 304 状态码和⼀个\n空的响应体并return。如果两个⽂件指纹不吻合，则说明⽂件被更改，那么将新的⽂件指纹重新存储到响应头\n的ETag中并返回给客户端\nETag需要计算⽂件指纹这样意味着，服务端需要更多的计算开销。如果⽂件尺⼨⼤，数量多，并且计算频\n繁，那么ETag的计算就会影响服务器的性能。显然，ETag在这样的场景下就不是很适合。\nETag有强验证和弱验证，所谓将强验证，ETag⽣成的哈希码深⼊到每个字节。哪怕⽂件中只有⼀个字节改变\n了，也会⽣成不同的哈希值，它可以保证⽂件内容绝对的不变。但是，强验证⾮常消耗计算量。ETag还有⼀个\n弱验证，弱验证是提取⽂件的部分属性来⽣成哈希值。因为不必精确到每个字节，所以他的整体速度会⽐强验\n证快，但是准确率不⾼。会降低协商缓存的有效性。\n协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使⽤，只有在未能命中强制缓存的时候，\n才能发起带有协商缓存字段的请求。\nHTTPS\nHTTPS协议\n协议（protocol）：通信双⽅需要遵守的 统⼀规则。\nHTTP：Hyper Text Transfer Protocol：超⽂本传输协议 HTTPS：\nHyper Text Transfer Protocol Secure：超⽂本安全传输协议 SSL：\nSecure Socket Layer 安全套接字\nTSL：Transport Layer Security 安全传输层协议\nHTTPS = HTTP+SSL/TSL\nSSL/TLS\nHTTPS的特点",
    "question": "## 基于 ETag 的协商缓存：将原先协商缓存的⽐较时间戳的形式修改成了⽐较⽂件指纹（根据⽂件内容计算出的",
    "answer": "唯⼀哈希值）。\n第⼀次请求某资源的时候，服务端读取⽂件并计算出⽂件指纹，将⽂件指纹放在响应头的Etag  字段中跟资源\n⼀起返回给客户端。\n第⼆次请求某资源的时候，客户端⾃动从缓存中读取出上⼀次服务端返回的ETag 也就是⽂件指纹。并赋给请\n求头的If-None-Match 字段，让上⼀次的⽂件指纹跟随请求⼀起回到服务端。\n服务端拿到请求头中的If-None-Match 字段值（也就是上⼀次的⽂件指纹），并再次读取⽬标资源并⽣成⽂\n件指纹，两个指纹做对⽐。如果两个⽂件指纹完全吻合，说明⽂件没有被改变，则直接返回 304 状态码和⼀个\n空的响应体并return。如果两个⽂件指纹不吻合，则说明⽂件被更改，那么将新的⽂件指纹重新存储到响应头\n的ETag中并返回给客户端\nETag需要计算⽂件指纹这样意味着，服务端需要更多的计算开销。如果⽂件尺⼨⼤，数量多，并且计算频\n繁，那么ETag的计算就会影响服务器的性能。显然，ETag在这样的场景下就不是很适合。\nETag有强验证和弱验证，所谓将强验证，ETag⽣成的哈希码深⼊到每个字节。哪怕⽂件中只有⼀个字节改变\n了，也会⽣成不同的哈希值，它可以保证⽂件内容绝对的不变。但是，强验证⾮常消耗计算量。ETag还有⼀个\n弱验证，弱验证是提取⽂件的部分属性来⽣成哈希值。因为不必精确到每个字节，所以他的整体速度会⽐强验\n证快，但是准确率不⾼。会降低协商缓存的有效性。\n协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使⽤，只有在未能命中强制缓存的时候，\n才能发起带有协商缓存字段的请求。\nHTTPS\nHTTPS协议\n协议（protocol）：通信双⽅需要遵守的 统⼀规则。\nHTTP：Hyper Text Transfer Protocol：超⽂本传输协议 HTTPS：\nHyper Text Transfer Protocol Secure：超⽂本安全传输协议 SSL：\nSecure Socket Layer 安全套接字\nTSL：Transport Layer Security 安全传输层协议\nHTTPS = HTTP+SSL/TSL\nSSL/TLS\nHTTPS的特点",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 977,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000008",
    "content": "## 特点\n\n信息加密：采⽤对称加密+⾮对称加密的混合加密的⽅式，对传输的数据加密，实现信息的机密性，解决了窃\n听的⻛险。\n校验机制：⽤摘要算法为数据⽣成独⼀⽆⼆的「指纹」校验码，指纹⽤来校验数据的完整性，解决了被篡改的\n⻛险。\n身份证书：将服务端的公钥放⼊到CA数字证书中，解决了服务端被冒充的⻛险。\n## 优点\n在数据传输过程中，使⽤秘钥加密，安全性更⾼\n可认证⽤户和服务器，确保数据发送到正确的⽤户和服务器\n## 缺点\n握⼿阶段延时较⾼：在会话前还需进⾏SSL握⼿\n部署成本⾼：需要购买CA证书；需要加解密计算，占⽤CPU资源，需要服务器配置或数⽬⾼",
    "question": "## 特点",
    "answer": "信息加密：采⽤对称加密+⾮对称加密的混合加密的⽅式，对传输的数据加密，实现信息的机密性，解决了窃\n听的⻛险。\n校验机制：⽤摘要算法为数据⽣成独⼀⽆⼆的「指纹」校验码，指纹⽤来校验数据的完整性，解决了被篡改的\n⻛险。\n身份证书：将服务端的公钥放⼊到CA数字证书中，解决了服务端被冒充的⻛险。\n## 优点\n在数据传输过程中，使⽤秘钥加密，安全性更⾼\n可认证⽤户和服务器，确保数据发送到正确的⽤户和服务器\n## 缺点\n握⼿阶段延时较⾼：在会话前还需进⾏SSL握⼿\n部署成本⾼：需要购买CA证书；需要加解密计算，占⽤CPU资源，需要服务器配置或数⽬⾼",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 278,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000009",
    "content": "## 缺点\n\n握⼿阶段延时较⾼：在会话前还需进⾏SSL握⼿\n部署成本⾼：需要购买CA证书；需要加解密计算，占⽤CPU资源，需要服务器配置或数⽬⾼\nHTTPS和HTTP的区别\nHTTP： 以明⽂的⽅式在⽹络中传输数据，HTTPS 解决了HTTP 不安全的缺陷，在 TCP 和 HTTP ⽹络层之间\n加⼊了\n安全协议，使得报⽂能够加密传输。\nHTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。\nHTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。\nHTTPS 协议需要向CA（证书权威机构） 申请数字证书，来保证服务器的身份是可信的。\n对称加密\n对称加密也称为私钥加密，使⽤相同的密钥来进⾏加密和解密。\n在加密过程中，明⽂数据通过应⽤特定的算法和密钥进⾏加密，⽣成密⽂数据。解密过程则是将密⽂数据应⽤\n同样的算法和密钥进⾏解密，恢复为明⽂数据。\n由于加密和解密都使⽤相同的密钥，因此对称加密算法的速度通常较快，但密钥的安全性很重要。如果密钥泄\n漏，攻击者可以轻易地解密数据。\n⾮对称加密\n⾮对称加密也称为公钥加密，使⽤⼀对不同但相关的密钥：公钥和私钥。\n公钥⽤于加密数据，私钥⽤于解密数据。如果使⽤公钥加密数据，只有拥有相应私钥的⼈才能解密数据；如果\n使⽤私钥加密数据，可以使⽤相应公钥解密。\n除了加密和解密，⾮对称加密还⽤于【数字签名】，可以验证消息的来源和完整性。\n混合加密\nHTTPS采⽤对称加密和⾮对称加密结合的【混合加密】⽅式，保证信息的机密性，解决了窃听的⻛险。\n通信建⽴前：\n采⽤⾮对称加密的⽅式交换【会话密钥】，后续不再使⽤⾮对称加密;\n通信过程中：\n全部使⽤对称加密的【会话密钥】⽅式，加密明⽂数据。\n采⽤「混合加密」的⽅式的原因：\n对称加密：只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换;\n⾮对称加密：使⽤两个密钥，公钥可以任意分发⽽私钥保密，解决密钥交换问题，但速度慢。\n摘要算法+数字签名\n为了保证传输的内容不被修改，可以将传输的内容计算出⼀个【指纹】，对⽅收到后，也把接收的内容计算出⼀个\n【指纹】，然后进⾏对⽐，如果【指纹】相同，则说明内容没有被篡改，常常会使⽤摘要算法（哈希函数）来计算\n出内容的哈希值，通过摘要算法可以⽣成数据的唯⼀标识，从⽽验证数据的完整性。\n但是摘要算法只能保证内容不被修改，不能保证发送者的身份，为了避免这种情况，计算机⾥会⽤⾮对称加密算法\n来解决，共有两个密钥：公钥⽤于验证签名，私钥⽤于⽣成签名。私钥是由服务端保管，然后服务端会向客户端颁\n发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。",
    "question": "## 缺点",
    "answer": "握⼿阶段延时较⾼：在会话前还需进⾏SSL握⼿\n部署成本⾼：需要购买CA证书；需要加解密计算，占⽤CPU资源，需要服务器配置或数⽬⾼\nHTTPS和HTTP的区别\nHTTP： 以明⽂的⽅式在⽹络中传输数据，HTTPS 解决了HTTP 不安全的缺陷，在 TCP 和 HTTP ⽹络层之间\n加⼊了\n安全协议，使得报⽂能够加密传输。\nHTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。\nHTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。\nHTTPS 协议需要向CA（证书权威机构） 申请数字证书，来保证服务器的身份是可信的。\n对称加密\n对称加密也称为私钥加密，使⽤相同的密钥来进⾏加密和解密。\n在加密过程中，明⽂数据通过应⽤特定的算法和密钥进⾏加密，⽣成密⽂数据。解密过程则是将密⽂数据应⽤\n同样的算法和密钥进⾏解密，恢复为明⽂数据。\n由于加密和解密都使⽤相同的密钥，因此对称加密算法的速度通常较快，但密钥的安全性很重要。如果密钥泄\n漏，攻击者可以轻易地解密数据。\n⾮对称加密\n⾮对称加密也称为公钥加密，使⽤⼀对不同但相关的密钥：公钥和私钥。\n公钥⽤于加密数据，私钥⽤于解密数据。如果使⽤公钥加密数据，只有拥有相应私钥的⼈才能解密数据；如果\n使⽤私钥加密数据，可以使⽤相应公钥解密。\n除了加密和解密，⾮对称加密还⽤于【数字签名】，可以验证消息的来源和完整性。\n混合加密\nHTTPS采⽤对称加密和⾮对称加密结合的【混合加密】⽅式，保证信息的机密性，解决了窃听的⻛险。\n通信建⽴前：\n采⽤⾮对称加密的⽅式交换【会话密钥】，后续不再使⽤⾮对称加密;\n通信过程中：\n全部使⽤对称加密的【会话密钥】⽅式，加密明⽂数据。\n采⽤「混合加密」的⽅式的原因：\n对称加密：只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换;\n⾮对称加密：使⽤两个密钥，公钥可以任意分发⽽私钥保密，解决密钥交换问题，但速度慢。\n摘要算法+数字签名\n为了保证传输的内容不被修改，可以将传输的内容计算出⼀个【指纹】，对⽅收到后，也把接收的内容计算出⼀个\n【指纹】，然后进⾏对⽐，如果【指纹】相同，则说明内容没有被篡改，常常会使⽤摘要算法（哈希函数）来计算\n出内容的哈希值，通过摘要算法可以⽣成数据的唯⼀标识，从⽽验证数据的完整性。\n但是摘要算法只能保证内容不被修改，不能保证发送者的身份，为了避免这种情况，计算机⾥会⽤⾮对称加密算法\n来解决，共有两个密钥：公钥⽤于验证签名，私钥⽤于⽣成签名。私钥是由服务端保管，然后服务端会向客户端颁\n发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1125,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000010",
    "content": "HTTPS和HTTP的区别\n\nHTTP： 以明⽂的⽅式在⽹络中传输数据，HTTPS 解决了HTTP 不安全的缺陷，在 TCP 和 HTTP ⽹络层之间\n加⼊了\n安全协议，使得报⽂能够加密传输。\nHTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。\nHTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。\nHTTPS 协议需要向CA（证书权威机构） 申请数字证书，来保证服务器的身份是可信的。\n对称加密\n对称加密也称为私钥加密，使⽤相同的密钥来进⾏加密和解密。\n在加密过程中，明⽂数据通过应⽤特定的算法和密钥进⾏加密，⽣成密⽂数据。解密过程则是将密⽂数据应⽤\n同样的算法和密钥进⾏解密，恢复为明⽂数据。\n由于加密和解密都使⽤相同的密钥，因此对称加密算法的速度通常较快，但密钥的安全性很重要。如果密钥泄\n漏，攻击者可以轻易地解密数据。\n⾮对称加密\n⾮对称加密也称为公钥加密，使⽤⼀对不同但相关的密钥：公钥和私钥。\n公钥⽤于加密数据，私钥⽤于解密数据。如果使⽤公钥加密数据，只有拥有相应私钥的⼈才能解密数据；如果\n使⽤私钥加密数据，可以使⽤相应公钥解密。\n除了加密和解密，⾮对称加密还⽤于【数字签名】，可以验证消息的来源和完整性。\n混合加密\nHTTPS采⽤对称加密和⾮对称加密结合的【混合加密】⽅式，保证信息的机密性，解决了窃听的⻛险。\n通信建⽴前：\n采⽤⾮对称加密的⽅式交换【会话密钥】，后续不再使⽤⾮对称加密;\n通信过程中：\n全部使⽤对称加密的【会话密钥】⽅式，加密明⽂数据。\n采⽤「混合加密」的⽅式的原因：\n对称加密：只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换;\n⾮对称加密：使⽤两个密钥，公钥可以任意分发⽽私钥保密，解决密钥交换问题，但速度慢。\n摘要算法+数字签名\n为了保证传输的内容不被修改，可以将传输的内容计算出⼀个【指纹】，对⽅收到后，也把接收的内容计算出⼀个\n【指纹】，然后进⾏对⽐，如果【指纹】相同，则说明内容没有被篡改，常常会使⽤摘要算法（哈希函数）来计算\n出内容的哈希值，通过摘要算法可以⽣成数据的唯⼀标识，从⽽验证数据的完整性。\n但是摘要算法只能保证内容不被修改，不能保证发送者的身份，为了避免这种情况，计算机⾥会⽤⾮对称加密算法\n来解决，共有两个密钥：公钥⽤于验证签名，私钥⽤于⽣成签名。私钥是由服务端保管，然后服务端会向客户端颁\n发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。\n## ⽣成数字签名：\n发送者使⽤私钥对消息的摘要（通常是通过哈希函数计算得到）进⾏加密，⽣成数字签名。\n数字签名是消息的哈希值经过私钥加密的结果。\n## 发送消息和数字签名：\n发送者将原始消息和⽣成的数字签名⼀起发送给接收者。\n## 验证数字签名：\n接收者收到消息和数字签名后，使⽤发送者的公钥对数字签名进⾏解密，得到摘要值。\n接收者再次计算收到的消息的摘要（使⽤相同的哈希函数），将其与解密得到的摘要值进⾏⽐较。\n如果两个摘要值相同，说明消息未被篡改过，数字签名有效，消息来源可信。\n数字证书\n根据上⾯的介绍，我们已经知道可以通过摘要算法保证内容不被修改，以及通过私钥和公钥保证消息来源的可靠\n性，但是却缺少身份验证的环节，如果此时在客户端和服务器之间有⼀个中间⼈，中间⼈把原本双⽅通信的公钥篡\n改成⾃⼰的公钥，这⼜该怎么办呢？这就需要使⽤到数字证书。\n## 密钥⽣成：\n⾸先，实体（例如服务器、个⼈或组织）需要⽣成⼀对密钥：公钥和私钥。\n公钥是⽤于加密和验证的，可以被公开分享。\n私钥⽤于解密和签名，必须保密，只有持有者知道。\n## 证书请求（CSR - Certificate Signing Request）：\n实体⽣成⼀个证书请求，其中包含公钥、实体信息（如名称、电⼦邮件等）和签名。\nCSR是⼀个包含有关实体信息的⽂本块，可以被发送到 数字证书颁发机构（CA） 以获取数字证书。\n## 证书颁发：\n实体将证书请求发送给数字证书颁发机构（CA）。\nCA会验证请求者的身份，然后使⽤⾃⼰的私钥对请求中的信息进⾏签名，⽣成数字证书。\n数字证书包括公钥、实体信息、CA的信息和签名等内容。\n## 证书验证：\n当实体收到数字证书时，它可以使⽤CA的公钥验证证书的签名，确保证书未被篡改且由合法的CA签发。\n接收者可以检查证书中的实体信息以及CA的信息，确保证书的合法性。\n## 数字证书使⽤：\n接收者可以使⽤数字证书中的公钥来加密数据，然后发送给证书的持有者。\n持有者使⽤私钥解密数据，保护数据的机密性。\n持有者还可以使⽤私钥⽣成数字签名，接收者使⽤公钥验证签名，验证数据的来源和完整性。\n证书信任链\n证书信任链（Certificate Trust Chain）是数字证书的验证过程中的⼀部分，确保数字证书是由可信的证书颁发机\n构（CA）签发的，并最终连接到根证书，形成⼀条链条。\n## 根证书：信任链的顶端是根证书（Root Certificate），也称为根CA证书。根证书是数字证书体系中的根基，\n它由操作系统或浏览器内置，作为信任的起点。\n## 中间证书颁发机构（Intermediate CA）：在信任链中，根证书下⽅可能有⼀个或多个中间CA，也称为中间\n证书颁发机构。这些中间CA的数字证书由根CA签发，它们作为信任链中的中继，⽤于签发其他证书。\n## 服务器证书：在最底层是服务器的数字证书，它是由中间CA签发的，包含了服务器的公钥和相关信息。服务\n器证书需要在客户端验证的过程中被验证。\n证书验证过程中，客户端会依次验证服务器证书、中间CA的证书、根CA的证书。如果整个链条中的所有证书都可\n以被成功验证，那么数字证书被视为合法和可信的。相反，如果任何⼀个证书⽆法验证，整个信任链就会被打断，\n数字证书将被视为不合法或不可信的。\nHTTPS是怎么建⽴连接的\nSSL/TLS 协议基本流程：\n客户端向服务器索要并验证服务器的公钥。\n双⽅协商⽣产「会话秘钥」。\n双⽅采⽤「会话秘钥」进⾏加密通信。\n具体流程如下：\n## ⾸先，客户端向服务器端发送加密通信请求，也就是\n请求，请求与服务端建⽴连接。\n## 服务端产⽣⼀对公私钥，然后将⾃⼰的公钥发送给CA机构，CA机构也有⼀对公私钥，然后CA机构使⽤⾃⼰的\n私钥将服务端发送过来的公钥进⾏加密，产⽣⼀个CA数字证书。\n## 服务端响应客户端的请求，也就是  SeverHello ， 将CA机构⽣成的数字证书发送给客户端。\n## 客户端将服务端发送过来的数字证书进⾏解析(因为浏览器产商跟CA机构有合作，所以浏览器中已经保存了⼤\n部分CA机构的密钥，⽤于对服务端发送过来的数字证书进⾏解密)，验证这个CA数字证书是否合法，如果不合\n法，会发送⼀个警告。如果合法，从数字证书中取出服务端⽣成的公钥。\n## 客户端取出公钥并⽣成⼀个随机码key（其实就是对称加密中的密钥）\n## 客户端将加密后的随机码key发送给服务端，作为接下来的对称加密的密钥\n## 服务端接收到随机码key后，使⽤⾃⼰的私钥对它进⾏解密，然后获得到随机码key。\n## 服务端使⽤随机码key对传输的数据进⾏加密，在传输加密后的内容给客户端\n## 客户端使⽤⾃⼰⽣成的随机码key解密服务端发送过来的数据，之后，客户端和服务端通过对称加密传输数\n据，随机码Key作为传输的密钥。\nClientHello\nTCP与UDP头部格式\nUDP\n⽬标端⼝和源端⼝：\n主要是告诉 UDP 协议应该把报⽂发给哪个进程。\n包⻓度：\n该字段保存了 UDP ⾸部的⻓度跟数据的⻓度之和。\n校验和：\n校验和是为了提供可靠的  UDP  ⾸部和数据⽽设计，接收⽅使⽤检验和来检查该报⽂段中是否出现差错。\nTCP\n源端⼝号和⽬的端⼝号：\n⽤于多路复⽤/分解来⾃或送到上层应⽤的数据。告诉主机报⽂段来⾃哪⾥，传给哪个上层协议或应⽤程序。\n序列号：\n该报⽂段⾸字节的字节流编号，⽤来解决⽹络包乱序问题。确认应答号：对发送来的 TCP 报⽂段的响应，值是收到\n的 TCP 报⽂段的序号值加1，⽤来解决不丢包的问题。序列号和确认应答号都⽤于实现可靠数据传输。\n⾸部⻓度：\n标识 TCP 头部有多少字节，最⻓ 60。\n窗⼝⼤⼩：\n接收窗⼝，告诉对⽅本端TCP缓冲区还有多少空间可以接收数据，⽤来做流量控制。\n标志字段：\nACK：⽤于指示确认应答号值是否有效，置1表示包含⼀个对已成功接收报⽂段的确认；\nRST：⽤于重置⼀个已经混乱的连接，或拒绝⼀个⽆效的数据段或者连接请求；   SYN：\n⽤于连接建⽴过程，请求建⽴⼀个连接；                      FIN：⽤于\n断开连接，表示发送⽅没有数据要传输了。\n检验和：\n接收⽅使⽤检验和来检查该报⽂段(头部+数据)中是否出现差错（CRC算法），同  UDP。\n列举TCP选项\nTCP头部的最后⼀个选项字段（options）是可变⻓的可选信息。这部分最多包含40字节，因为TCP头部最⻓是60\n字节（其中还包含前⾯讨论的20字节的固定部分）。\n选项的第⼀个字段kind说明选项的类型，有的TCP选项没有后⾯两个字段，仅包含1字节的kind字段。\n第⼆个字段length（如果有的话）指定该选项的总⻓度。该⻓度包括kind字段和length字段占据的2字节。\n第三个字段info（如果有的话）是选项的具体信息。\n常⻅的TCP选项有7种：\n## kind=0，选项表结束（EOP）选项。\n⼀个报⽂段仅⽤⼀次。放在末尾⽤于填充，⽤途是说明：⾸部已经没有更多的消息，应⽤数据在下⼀个32位字开始\n## kind=1，空操作（NOP）选项。\n没有特殊含义，⼀般⽤于将TCP选项的总⻓度填充为4字节的整数倍。\n## kind=2，最⼤报⽂段⻓度（MSS）选项。\nTCP连接初始化时，通信双⽅使⽤该选项来协商最⼤报⽂段⻓度。TCP模块通常将MSS设置为（MTU-40）字节（减\n掉的这40字节包括20字节的TCP头部和20字节的IP头部）。\n这样携带TCP报⽂段的IP数据报的⻓度就不会超过MTU（假设TCP头部和IP头部都不包含选项字段，并且这也是⼀\n般情况），从⽽避免本机发⽣IP分⽚。对以太⽹⽽⾔，MSS值是1460（1500-40）字节。\n## kind=3，窗⼝扩⼤因⼦选项。\nTCP连接初始化时，通信双⽅使⽤该选项来协商接收窗⼝的扩⼤因⼦。在TCP的头部中，接收窗⼝⼤⼩是⽤16位表\n示的，故最⼤为65535字节，但实际上TCP模块允许的接收窗⼝⼤⼩远不⽌这个数（为了提⾼TCP通信的吞吐\n量）。窗⼝扩⼤因⼦解决了这个问题。\n假设 TCP 头部中的接收通告窗⼝⼤⼩是 N，窗⼝扩⼤因⼦（移位数）是 M，那么 TCP 报⽂段的实际接收通告窗⼝\n⼤⼩是 N*2M，或者说 N 左移 M 位。注意，M的取值范围是 0～14。\n和  MSS  选项⼀样，窗⼝扩⼤因⼦选项只能出现在同步报⽂段中，否则将被忽略。但同步报⽂段本身不执⾏窗⼝扩\n⼤操作，即同步报⽂段头部的接收窗⼝⼤⼩就是该 TCP 报⽂段的实际接收窗⼝⼤⼩。当连接建⽴好之后，每个数据\n传输⽅向的窗⼝扩⼤因⼦就固定不变了。\n## kind=4，选择性确认（Selective Acknowledgment，SACK）选项。\nTCP 通信时，如果某个 TCP 报⽂段丢失，则 TCP 会重传最后被确认的 TCP 报⽂段后续的所有报⽂段，这样原先已\n经正确传输的 TCP 报⽂段也可能重复发送，从⽽降低了 TCP 性能。\nSACK 技术使 TCP 只重新发送丢失的 TCP 报⽂段，⽽不⽤发送所有未被确认的 TCP 报⽂段。选择性确认选项⽤在\n连接初始化时，表示是否⽀持 SACK 技术。\n## kind=5，SACK实际⼯作的选项。\n该选项的参数告诉发送⽅本端已经收到并缓存的不连续的数据块，从⽽让发送端可以据此检查并重发丢失的数据\n每个块边沿（edge of block）参数包含⼀个4字节的序号。其中块左边沿表示不连续块的第⼀个数据的序号，⽽块\n右边沿则表示不连续块的最后⼀个数据的序号的下⼀个序号。这样⼀对参数（块左边沿和块右边沿）之间的数据是\n没有收到的。因为⼀个块信息占⽤8字节，所以 TCP 头部选项中实际上最多可以包含4个这样的不连续数据块（考\n虑选项类型和⻓度占⽤的2字节）。\n## kind=8，时间戳选项。\n该选项提供了较为准确的计算通信双⽅之间的回路时间（Round Trip Time，RTT）的⽅法，为TCP流量控制提供信\nTCP三次握⼿\n三次握⼿的过程\nTCP 是⾯向连接的协议，所以使⽤ TCP 前必须先建⽴连接，⽽建⽴连接是通过三次握⼿来进⾏的。\nserver_isn + 1\n## 第⼀次握⼿：SYN报⽂：\n客户端随机初始化序列号client_isn ，放进TCP⾸部序列号段，然后把SYN置1。把SYN报⽂发送给服务端，表示\n发起连接，之后客户端处于SYN-SENT 状态。\n## 第⼆次握⼿：SYN+ACK报⽂：\n服务端收到客户端的SYN报⽂之后，会把⾃⼰随机初始化的序号 server_isn 放进TCP⾸部序列号段，「确认应答\n号」填⼊client_isn + 1 ，把SYN和ACK标志位置为1。把SYN+ACK报⽂发送给客户端，然后进⼊ SYN-RCVD 状\n态,表示服务器接受了客户端的请求，并希望建⽴连接。\n## 第三次握⼿：ACK报⽂：\n客户端收到服务端报⽂后，还要向服务端回应最后⼀个应答报⽂。⾸先该应答报⽂ TCP ⾸部 ACK 标志位置为 1 ，\n其次「确认应答号」字段填⼊\n，最后把报⽂发送给服务端，这次报⽂可以携带客户到服务器的\n数据，之后客户端处于ESTABLISHED 状态, 表示客户端已经准备好与服务器进⾏数据传输。\n服务器收到客户端的应答报⽂后，也进⼊ESTABLISHED 状态。\n此时，TCP 连接已经建⽴起来，通信双⽅可以开始进⾏数据传输。\n第三次握⼿是可以携带数据的，但是前两次握⼿是不可以携带数据的。\n为什么需要三次握⼿？\n三次握⼿才能保证双⽅具有接收和发送的能⼒\n## 三次握⼿才可以阻⽌重复历史连接的初始化(主因)\n## 三次握⼿才可以同步双⽅的初始序列号\n## 三次握⼿才可以避免资源浪费\n解释：\n## 阻⽌重复历史连接的初始化（主因）\n## 当因为⽹络阻塞原因，客户端向服务器发送了两次SYN报⽂\n## 旧的SYN报⽂先到达服务端，服务端回⼀个ACK+SYN报⽂\n## 客户端收到后可以根据⾃身的上下⽂，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送\nRST 报⽂给服务端，表示中⽌这⼀次连接。\n## 服务器收到RST报⽂，会释放连接\n## 新的SYN报⽂抵达之后，客户端和服务器之间进⾏正常的三次握⼿\n如果只是两次握⼿，服务端在收到SYN报⽂之后，就进⼊到 ESTABLISHED 状态,  服务器端并不知道这次是历史连\n接，直接与客户端建⽴连接并向客户端发送数据（资源浪费），但是客户端会判定这次连接是历史连接，从⽽发送\nRST报⽂来断开连接。\n所以要想让服务器发送数据前，阻⽌掉历史连接，就需要三次握⼿。\n## 同步双⽅的初始序列号\nTCP 协议的通信双⽅， 都必须维护⼀个「序列号」， 序列号是可靠传输的⼀个关键因素。\n接收端可以去除重复数据。\n接收端可以按照序列号顺序接收。\n标识发送的数据包，哪些已经被收到。\n## 客户端发送第⼀个报⽂，携带客户端初始序列号的SYN报⽂。\n## 服务器发送第⼆个报⽂，携带服务器初始序列号的ACK +  SYN的应答报⽂，表示收到客户端的SYN报⽂。\n## 客户端发送第三个报⽂，携带服务器的ACK应答报⽂。\n这样⼀来⼀回，才能确保双⽅的初始序列号能被可靠的同步。\n两次握⼿只保证了⼀⽅的初始序列号能被对⽅成功接收，没办法保证双⽅的初始序列号都能被确认接收。四次握⼿\n也能保证双⽅的初始化序号同步，但是可以省略成三次。\n## 避免资源浪费。\n## 只有两次握⼿时，如果客户端的SYN请求连接在⽹络中阻塞，客户端没有收到服务端的ACK报⽂，会重新发送\nSYN。\n## 由于没有第三次握⼿，服务器不清楚客户端是否收到了⾃⼰发送的建⽴连接的 ACK 确认信号，所以每收到⼀\n个 SYN 就只能先主动建⽴⼀个连接， 建⽴多个冗余的⽆效链接，造成不必要的资源浪费。\n所以通过TCP三次握⼿，能能防⽌历史连接的建⽴，能减少双⽅不必要的资源开销，能帮助双⽅同步初始化序列号\n「两次握⼿」：⽆法防⽌历史连接的建⽴，会造成双⽅资源的浪费，也⽆法可靠的同步双⽅序列号；\n「四次握⼿」：三次握⼿就已经理论上最少可靠连接建⽴，所以不需要使⽤更多的通信次数。\n什么是半连接队列\n半连接队列（SYN队列）⽤于存放已经发送了 SYN（同步）包，但还未完成三次握⼿的连接：服务器第⼀次收到客\n户端的 SYN 之后，就会处于  SYN_RCVD 状态，此时双⽅还没有完全建⽴其连接，服务器会把此种状态下请求连接\n放在⼀个队列⾥，我们把这种队列称之为半连接队列。\n全连接队列（Accept队列）⽤于存放已经完成三次握⼿，处于完全建⽴连接状态的连接。\n什么是SYN攻击\n在 SYN 攻击中，攻击者发送⼤量伪造的 SYN 请求到⽬标服务器，但不完成后续的握⼿过程，从⽽让服务器⼀直等\n待确认，消耗服务器的资源（如半连接队列和系统资源），当半连接队列满了之后，后续再收到SYN报⽂就会丢弃，\n导致⽆法与客户端之间建⽴连接。\nTCP四次挥⼿\nTCP  断开连接是通过四次挥⼿来进⾏的，四次挥⼿的过程如下图：\n四次挥⼿的过程\n在挥⼿之前，客户端和服务器都处于ESTABLISHED 状态\n## 第⼀次挥⼿：假设客户端打算关闭连接，发送⼀个TCP⾸部FIN被置1的FIN 报⽂给服务端, 此时客户端处于\nFIN_WAIT1 状态\n## 第⼆次挥⼿：服务端收到以后，向客户端发送ACK应答报⽂，且把客户端的序列号值+1作为ACK报⽂的序列号\n值，表明已经收到客户端的报⽂了，此时服务端处于CLOSE_WAIT 状态\n## 第三次挥⼿：等待服务端处理完数据后，向客户端发送FIN报⽂。此时服务端处于LAST_ACK  的状态\n## 第四次挥⼿：客户端接收到FIN报⽂后回⼀个ACK应答报⽂，之后客户端处于TIME_WAIT 状态\n## 服务器收到ACK报⽂后，进⼊CLOSE 状态，服务器完成连接关闭。\n## 客户端在经过 2MSL ⼀段时间后，⾃动进⼊CLOSE 状态，客户端也完成连接的关闭。\n为什么挥⼿需要四次\n关闭连接时，客户端发送FIN报⽂，表示其不再发送数据，但还可以接收数据。\n服务端收到FIN报⽂，可以直接发送SYN+ACK报⽂。其中ACK报⽂是⽤来应答的，SYN报⽂是⽤来同步的。但是关\n闭连接时，服务端可能还要数据需要处理和发送，所以先回⼀个ACK应答报⽂，等到其不再发送数据时，才发送\nFIN报⽂给客户端表示同意关闭连接。\n从上⾯过程可知：服务端通常需要等待完成数据的发送和处理，所以服务端的ACK和FIN⼀般都会分开发送，从⽽\n⽐三次握⼿导致多了⼀次。\n为什么需要 TIME_WAIT 状态\n主动发起关闭连接的⼀⽅，才会有 TIME-WAIT 状态。\n需要 TIME-WAIT 状态，主要是两个原因：\n## 防⽌历史连接中的数据，被后⾯相同四元组的连接错误的接收；\n如果⽹络出现拥塞或延迟，数据包可能会在⽹络中滞留⼀段时间，甚⾄超过了原始连接关闭的时间。如果没有\nTIME_WAIT 状态，客户端直接进⼊到CLOSE状态，这些滞留的数据包可能会被传递给新连接，导致新连接的数据\n被旧连接的数据⼲扰。\n经过 2MSL 这个时间，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再出现\n的数据包⼀定都是新建⽴连接所产⽣的。\n## 保证「被动关闭连接」的⼀⽅能被正确的关闭，即保证最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关\n如果最后的⼀次ACK报⽂丢失（第四次挥⼿），客户端没有TIME_WAIT 状态，直接进⼊ClOSE，服务端⼀直在等待\nACK状态，⼀直没有等到，就会重发FIN报⽂，⽽客户端已经进⼊到关闭状态，在收到服务端重传的 FIN 报⽂后，\n就会回 RST 报⽂,服务端收到这个 RST 并将其解释为⼀个错误, 为了防⽌这种情况出现，客户端必须等待⾜够⻓的时\n间，确保服务端能够收到 ACK，如果服务端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送⼀个\nFIN，这样⼀去⼀来刚好两个 MSL 的时间。\n如果 TIME-WAIT 等待⾜够⻓的情况就会遇到两种情况：\n## 服务端正常收到四次挥⼿的最后⼀个 ACK 报⽂，则服务端正常关闭连接。\n## 服务端没有收到四次挥⼿的最后⼀个 ACK 报⽂时，则会重发 FIN 关闭连接报⽂并等待新的 ACK 报⽂。\n为什么 TIME_WAIT 等待的时间是 2MSL\n## MSL是 Maximum Segment Lifetime ，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这\n个时间报⽂将被丢弃。\n## 等待MSL两倍：⽹络中可能存在发送⽅的数据包，当这些发送⽅的数据包被接收⽅处理后⼜会向对⽅发送响\n应，所以⼀来⼀回需要等待 2 倍的时间。",
    "question": "HTTPS和HTTP的区别",
    "answer": "HTTP： 以明⽂的⽅式在⽹络中传输数据，HTTPS 解决了HTTP 不安全的缺陷，在 TCP 和 HTTP ⽹络层之间\n加⼊了\n安全协议，使得报⽂能够加密传输。\nHTTPS 在 TCP 三次握⼿之后，还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。\nHTTP 的端⼝号是 80，HTTPS 的端⼝号是 443。\nHTTPS 协议需要向CA（证书权威机构） 申请数字证书，来保证服务器的身份是可信的。\n对称加密\n对称加密也称为私钥加密，使⽤相同的密钥来进⾏加密和解密。\n在加密过程中，明⽂数据通过应⽤特定的算法和密钥进⾏加密，⽣成密⽂数据。解密过程则是将密⽂数据应⽤\n同样的算法和密钥进⾏解密，恢复为明⽂数据。\n由于加密和解密都使⽤相同的密钥，因此对称加密算法的速度通常较快，但密钥的安全性很重要。如果密钥泄\n漏，攻击者可以轻易地解密数据。\n⾮对称加密\n⾮对称加密也称为公钥加密，使⽤⼀对不同但相关的密钥：公钥和私钥。\n公钥⽤于加密数据，私钥⽤于解密数据。如果使⽤公钥加密数据，只有拥有相应私钥的⼈才能解密数据；如果\n使⽤私钥加密数据，可以使⽤相应公钥解密。\n除了加密和解密，⾮对称加密还⽤于【数字签名】，可以验证消息的来源和完整性。\n混合加密\nHTTPS采⽤对称加密和⾮对称加密结合的【混合加密】⽅式，保证信息的机密性，解决了窃听的⻛险。\n通信建⽴前：\n采⽤⾮对称加密的⽅式交换【会话密钥】，后续不再使⽤⾮对称加密;\n通信过程中：\n全部使⽤对称加密的【会话密钥】⽅式，加密明⽂数据。\n采⽤「混合加密」的⽅式的原因：\n对称加密：只使⽤⼀个密钥，运算速度快，密钥必须保密，⽆法做到安全的密钥交换;\n⾮对称加密：使⽤两个密钥，公钥可以任意分发⽽私钥保密，解决密钥交换问题，但速度慢。\n摘要算法+数字签名\n为了保证传输的内容不被修改，可以将传输的内容计算出⼀个【指纹】，对⽅收到后，也把接收的内容计算出⼀个\n【指纹】，然后进⾏对⽐，如果【指纹】相同，则说明内容没有被篡改，常常会使⽤摘要算法（哈希函数）来计算\n出内容的哈希值，通过摘要算法可以⽣成数据的唯⼀标识，从⽽验证数据的完整性。\n但是摘要算法只能保证内容不被修改，不能保证发送者的身份，为了避免这种情况，计算机⾥会⽤⾮对称加密算法\n来解决，共有两个密钥：公钥⽤于验证签名，私钥⽤于⽣成签名。私钥是由服务端保管，然后服务端会向客户端颁\n发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。\n## ⽣成数字签名：\n发送者使⽤私钥对消息的摘要（通常是通过哈希函数计算得到）进⾏加密，⽣成数字签名。\n数字签名是消息的哈希值经过私钥加密的结果。\n## 发送消息和数字签名：\n发送者将原始消息和⽣成的数字签名⼀起发送给接收者。\n## 验证数字签名：\n接收者收到消息和数字签名后，使⽤发送者的公钥对数字签名进⾏解密，得到摘要值。\n接收者再次计算收到的消息的摘要（使⽤相同的哈希函数），将其与解密得到的摘要值进⾏⽐较。\n如果两个摘要值相同，说明消息未被篡改过，数字签名有效，消息来源可信。\n数字证书\n根据上⾯的介绍，我们已经知道可以通过摘要算法保证内容不被修改，以及通过私钥和公钥保证消息来源的可靠\n性，但是却缺少身份验证的环节，如果此时在客户端和服务器之间有⼀个中间⼈，中间⼈把原本双⽅通信的公钥篡\n改成⾃⼰的公钥，这⼜该怎么办呢？这就需要使⽤到数字证书。\n## 密钥⽣成：\n⾸先，实体（例如服务器、个⼈或组织）需要⽣成⼀对密钥：公钥和私钥。\n公钥是⽤于加密和验证的，可以被公开分享。\n私钥⽤于解密和签名，必须保密，只有持有者知道。\n## 证书请求（CSR - Certificate Signing Request）：\n实体⽣成⼀个证书请求，其中包含公钥、实体信息（如名称、电⼦邮件等）和签名。\nCSR是⼀个包含有关实体信息的⽂本块，可以被发送到 数字证书颁发机构（CA） 以获取数字证书。\n## 证书颁发：\n实体将证书请求发送给数字证书颁发机构（CA）。\nCA会验证请求者的身份，然后使⽤⾃⼰的私钥对请求中的信息进⾏签名，⽣成数字证书。\n数字证书包括公钥、实体信息、CA的信息和签名等内容。\n## 证书验证：\n当实体收到数字证书时，它可以使⽤CA的公钥验证证书的签名，确保证书未被篡改且由合法的CA签发。\n接收者可以检查证书中的实体信息以及CA的信息，确保证书的合法性。\n## 数字证书使⽤：\n接收者可以使⽤数字证书中的公钥来加密数据，然后发送给证书的持有者。\n持有者使⽤私钥解密数据，保护数据的机密性。\n持有者还可以使⽤私钥⽣成数字签名，接收者使⽤公钥验证签名，验证数据的来源和完整性。\n证书信任链\n证书信任链（Certificate Trust Chain）是数字证书的验证过程中的⼀部分，确保数字证书是由可信的证书颁发机\n构（CA）签发的，并最终连接到根证书，形成⼀条链条。\n## 根证书：信任链的顶端是根证书（Root Certificate），也称为根CA证书。根证书是数字证书体系中的根基，\n它由操作系统或浏览器内置，作为信任的起点。\n## 中间证书颁发机构（Intermediate CA）：在信任链中，根证书下⽅可能有⼀个或多个中间CA，也称为中间\n证书颁发机构。这些中间CA的数字证书由根CA签发，它们作为信任链中的中继，⽤于签发其他证书。\n## 服务器证书：在最底层是服务器的数字证书，它是由中间CA签发的，包含了服务器的公钥和相关信息。服务\n器证书需要在客户端验证的过程中被验证。\n证书验证过程中，客户端会依次验证服务器证书、中间CA的证书、根CA的证书。如果整个链条中的所有证书都可\n以被成功验证，那么数字证书被视为合法和可信的。相反，如果任何⼀个证书⽆法验证，整个信任链就会被打断，\n数字证书将被视为不合法或不可信的。\nHTTPS是怎么建⽴连接的\nSSL/TLS 协议基本流程：\n客户端向服务器索要并验证服务器的公钥。\n双⽅协商⽣产「会话秘钥」。\n双⽅采⽤「会话秘钥」进⾏加密通信。\n具体流程如下：\n## ⾸先，客户端向服务器端发送加密通信请求，也就是\n请求，请求与服务端建⽴连接。\n## 服务端产⽣⼀对公私钥，然后将⾃⼰的公钥发送给CA机构，CA机构也有⼀对公私钥，然后CA机构使⽤⾃⼰的\n私钥将服务端发送过来的公钥进⾏加密，产⽣⼀个CA数字证书。\n## 服务端响应客户端的请求，也就是  SeverHello ， 将CA机构⽣成的数字证书发送给客户端。\n## 客户端将服务端发送过来的数字证书进⾏解析(因为浏览器产商跟CA机构有合作，所以浏览器中已经保存了⼤\n部分CA机构的密钥，⽤于对服务端发送过来的数字证书进⾏解密)，验证这个CA数字证书是否合法，如果不合\n法，会发送⼀个警告。如果合法，从数字证书中取出服务端⽣成的公钥。\n## 客户端取出公钥并⽣成⼀个随机码key（其实就是对称加密中的密钥）\n## 客户端将加密后的随机码key发送给服务端，作为接下来的对称加密的密钥\n## 服务端接收到随机码key后，使⽤⾃⼰的私钥对它进⾏解密，然后获得到随机码key。\n## 服务端使⽤随机码key对传输的数据进⾏加密，在传输加密后的内容给客户端\n## 客户端使⽤⾃⼰⽣成的随机码key解密服务端发送过来的数据，之后，客户端和服务端通过对称加密传输数\n据，随机码Key作为传输的密钥。\nClientHello\nTCP与UDP头部格式\nUDP\n⽬标端⼝和源端⼝：\n主要是告诉 UDP 协议应该把报⽂发给哪个进程。\n包⻓度：\n该字段保存了 UDP ⾸部的⻓度跟数据的⻓度之和。\n校验和：\n校验和是为了提供可靠的  UDP  ⾸部和数据⽽设计，接收⽅使⽤检验和来检查该报⽂段中是否出现差错。\nTCP\n源端⼝号和⽬的端⼝号：\n⽤于多路复⽤/分解来⾃或送到上层应⽤的数据。告诉主机报⽂段来⾃哪⾥，传给哪个上层协议或应⽤程序。\n序列号：\n该报⽂段⾸字节的字节流编号，⽤来解决⽹络包乱序问题。确认应答号：对发送来的 TCP 报⽂段的响应，值是收到\n的 TCP 报⽂段的序号值加1，⽤来解决不丢包的问题。序列号和确认应答号都⽤于实现可靠数据传输。\n⾸部⻓度：\n标识 TCP 头部有多少字节，最⻓ 60。\n窗⼝⼤⼩：\n接收窗⼝，告诉对⽅本端TCP缓冲区还有多少空间可以接收数据，⽤来做流量控制。\n标志字段：\nACK：⽤于指示确认应答号值是否有效，置1表示包含⼀个对已成功接收报⽂段的确认；\nRST：⽤于重置⼀个已经混乱的连接，或拒绝⼀个⽆效的数据段或者连接请求；   SYN：\n⽤于连接建⽴过程，请求建⽴⼀个连接；                      FIN：⽤于\n断开连接，表示发送⽅没有数据要传输了。\n检验和：\n接收⽅使⽤检验和来检查该报⽂段(头部+数据)中是否出现差错（CRC算法），同  UDP。\n列举TCP选项\nTCP头部的最后⼀个选项字段（options）是可变⻓的可选信息。这部分最多包含40字节，因为TCP头部最⻓是60\n字节（其中还包含前⾯讨论的20字节的固定部分）。\n选项的第⼀个字段kind说明选项的类型，有的TCP选项没有后⾯两个字段，仅包含1字节的kind字段。\n第⼆个字段length（如果有的话）指定该选项的总⻓度。该⻓度包括kind字段和length字段占据的2字节。\n第三个字段info（如果有的话）是选项的具体信息。\n常⻅的TCP选项有7种：\n## kind=0，选项表结束（EOP）选项。\n⼀个报⽂段仅⽤⼀次。放在末尾⽤于填充，⽤途是说明：⾸部已经没有更多的消息，应⽤数据在下⼀个32位字开始\n## kind=1，空操作（NOP）选项。\n没有特殊含义，⼀般⽤于将TCP选项的总⻓度填充为4字节的整数倍。\n## kind=2，最⼤报⽂段⻓度（MSS）选项。\nTCP连接初始化时，通信双⽅使⽤该选项来协商最⼤报⽂段⻓度。TCP模块通常将MSS设置为（MTU-40）字节（减\n掉的这40字节包括20字节的TCP头部和20字节的IP头部）。\n这样携带TCP报⽂段的IP数据报的⻓度就不会超过MTU（假设TCP头部和IP头部都不包含选项字段，并且这也是⼀\n般情况），从⽽避免本机发⽣IP分⽚。对以太⽹⽽⾔，MSS值是1460（1500-40）字节。\n## kind=3，窗⼝扩⼤因⼦选项。\nTCP连接初始化时，通信双⽅使⽤该选项来协商接收窗⼝的扩⼤因⼦。在TCP的头部中，接收窗⼝⼤⼩是⽤16位表\n示的，故最⼤为65535字节，但实际上TCP模块允许的接收窗⼝⼤⼩远不⽌这个数（为了提⾼TCP通信的吞吐\n量）。窗⼝扩⼤因⼦解决了这个问题。\n假设 TCP 头部中的接收通告窗⼝⼤⼩是 N，窗⼝扩⼤因⼦（移位数）是 M，那么 TCP 报⽂段的实际接收通告窗⼝\n⼤⼩是 N*2M，或者说 N 左移 M 位。注意，M的取值范围是 0～14。\n和  MSS  选项⼀样，窗⼝扩⼤因⼦选项只能出现在同步报⽂段中，否则将被忽略。但同步报⽂段本身不执⾏窗⼝扩\n⼤操作，即同步报⽂段头部的接收窗⼝⼤⼩就是该 TCP 报⽂段的实际接收窗⼝⼤⼩。当连接建⽴好之后，每个数据\n传输⽅向的窗⼝扩⼤因⼦就固定不变了。\n## kind=4，选择性确认（Selective Acknowledgment，SACK）选项。\nTCP 通信时，如果某个 TCP 报⽂段丢失，则 TCP 会重传最后被确认的 TCP 报⽂段后续的所有报⽂段，这样原先已\n经正确传输的 TCP 报⽂段也可能重复发送，从⽽降低了 TCP 性能。\nSACK 技术使 TCP 只重新发送丢失的 TCP 报⽂段，⽽不⽤发送所有未被确认的 TCP 报⽂段。选择性确认选项⽤在\n连接初始化时，表示是否⽀持 SACK 技术。\n## kind=5，SACK实际⼯作的选项。\n该选项的参数告诉发送⽅本端已经收到并缓存的不连续的数据块，从⽽让发送端可以据此检查并重发丢失的数据\n每个块边沿（edge of block）参数包含⼀个4字节的序号。其中块左边沿表示不连续块的第⼀个数据的序号，⽽块\n右边沿则表示不连续块的最后⼀个数据的序号的下⼀个序号。这样⼀对参数（块左边沿和块右边沿）之间的数据是\n没有收到的。因为⼀个块信息占⽤8字节，所以 TCP 头部选项中实际上最多可以包含4个这样的不连续数据块（考\n虑选项类型和⻓度占⽤的2字节）。\n## kind=8，时间戳选项。\n该选项提供了较为准确的计算通信双⽅之间的回路时间（Round Trip Time，RTT）的⽅法，为TCP流量控制提供信\nTCP三次握⼿\n三次握⼿的过程\nTCP 是⾯向连接的协议，所以使⽤ TCP 前必须先建⽴连接，⽽建⽴连接是通过三次握⼿来进⾏的。\nserver_isn + 1\n## 第⼀次握⼿：SYN报⽂：\n客户端随机初始化序列号client_isn ，放进TCP⾸部序列号段，然后把SYN置1。把SYN报⽂发送给服务端，表示\n发起连接，之后客户端处于SYN-SENT 状态。\n## 第⼆次握⼿：SYN+ACK报⽂：\n服务端收到客户端的SYN报⽂之后，会把⾃⼰随机初始化的序号 server_isn 放进TCP⾸部序列号段，「确认应答\n号」填⼊client_isn + 1 ，把SYN和ACK标志位置为1。把SYN+ACK报⽂发送给客户端，然后进⼊ SYN-RCVD 状\n态,表示服务器接受了客户端的请求，并希望建⽴连接。\n## 第三次握⼿：ACK报⽂：\n客户端收到服务端报⽂后，还要向服务端回应最后⼀个应答报⽂。⾸先该应答报⽂ TCP ⾸部 ACK 标志位置为 1 ，\n其次「确认应答号」字段填⼊\n，最后把报⽂发送给服务端，这次报⽂可以携带客户到服务器的\n数据，之后客户端处于ESTABLISHED 状态, 表示客户端已经准备好与服务器进⾏数据传输。\n服务器收到客户端的应答报⽂后，也进⼊ESTABLISHED 状态。\n此时，TCP 连接已经建⽴起来，通信双⽅可以开始进⾏数据传输。\n第三次握⼿是可以携带数据的，但是前两次握⼿是不可以携带数据的。\n为什么需要三次握⼿？\n三次握⼿才能保证双⽅具有接收和发送的能⼒\n## 三次握⼿才可以阻⽌重复历史连接的初始化(主因)\n## 三次握⼿才可以同步双⽅的初始序列号\n## 三次握⼿才可以避免资源浪费\n解释：\n## 阻⽌重复历史连接的初始化（主因）\n## 当因为⽹络阻塞原因，客户端向服务器发送了两次SYN报⽂\n## 旧的SYN报⽂先到达服务端，服务端回⼀个ACK+SYN报⽂\n## 客户端收到后可以根据⾃身的上下⽂，判断这是⼀个历史连接（序列号过期或超时），那么客户端就会发送\nRST 报⽂给服务端，表示中⽌这⼀次连接。\n## 服务器收到RST报⽂，会释放连接\n## 新的SYN报⽂抵达之后，客户端和服务器之间进⾏正常的三次握⼿\n如果只是两次握⼿，服务端在收到SYN报⽂之后，就进⼊到 ESTABLISHED 状态,  服务器端并不知道这次是历史连\n接，直接与客户端建⽴连接并向客户端发送数据（资源浪费），但是客户端会判定这次连接是历史连接，从⽽发送\nRST报⽂来断开连接。\n所以要想让服务器发送数据前，阻⽌掉历史连接，就需要三次握⼿。\n## 同步双⽅的初始序列号\nTCP 协议的通信双⽅， 都必须维护⼀个「序列号」， 序列号是可靠传输的⼀个关键因素。\n接收端可以去除重复数据。\n接收端可以按照序列号顺序接收。\n标识发送的数据包，哪些已经被收到。\n## 客户端发送第⼀个报⽂，携带客户端初始序列号的SYN报⽂。\n## 服务器发送第⼆个报⽂，携带服务器初始序列号的ACK +  SYN的应答报⽂，表示收到客户端的SYN报⽂。\n## 客户端发送第三个报⽂，携带服务器的ACK应答报⽂。\n这样⼀来⼀回，才能确保双⽅的初始序列号能被可靠的同步。\n两次握⼿只保证了⼀⽅的初始序列号能被对⽅成功接收，没办法保证双⽅的初始序列号都能被确认接收。四次握⼿\n也能保证双⽅的初始化序号同步，但是可以省略成三次。\n## 避免资源浪费。\n## 只有两次握⼿时，如果客户端的SYN请求连接在⽹络中阻塞，客户端没有收到服务端的ACK报⽂，会重新发送\nSYN。\n## 由于没有第三次握⼿，服务器不清楚客户端是否收到了⾃⼰发送的建⽴连接的 ACK 确认信号，所以每收到⼀\n个 SYN 就只能先主动建⽴⼀个连接， 建⽴多个冗余的⽆效链接，造成不必要的资源浪费。\n所以通过TCP三次握⼿，能能防⽌历史连接的建⽴，能减少双⽅不必要的资源开销，能帮助双⽅同步初始化序列号\n「两次握⼿」：⽆法防⽌历史连接的建⽴，会造成双⽅资源的浪费，也⽆法可靠的同步双⽅序列号；\n「四次握⼿」：三次握⼿就已经理论上最少可靠连接建⽴，所以不需要使⽤更多的通信次数。\n什么是半连接队列\n半连接队列（SYN队列）⽤于存放已经发送了 SYN（同步）包，但还未完成三次握⼿的连接：服务器第⼀次收到客\n户端的 SYN 之后，就会处于  SYN_RCVD 状态，此时双⽅还没有完全建⽴其连接，服务器会把此种状态下请求连接\n放在⼀个队列⾥，我们把这种队列称之为半连接队列。\n全连接队列（Accept队列）⽤于存放已经完成三次握⼿，处于完全建⽴连接状态的连接。\n什么是SYN攻击\n在 SYN 攻击中，攻击者发送⼤量伪造的 SYN 请求到⽬标服务器，但不完成后续的握⼿过程，从⽽让服务器⼀直等\n待确认，消耗服务器的资源（如半连接队列和系统资源），当半连接队列满了之后，后续再收到SYN报⽂就会丢弃，\n导致⽆法与客户端之间建⽴连接。\nTCP四次挥⼿\nTCP  断开连接是通过四次挥⼿来进⾏的，四次挥⼿的过程如下图：\n四次挥⼿的过程\n在挥⼿之前，客户端和服务器都处于ESTABLISHED 状态\n## 第⼀次挥⼿：假设客户端打算关闭连接，发送⼀个TCP⾸部FIN被置1的FIN 报⽂给服务端, 此时客户端处于\nFIN_WAIT1 状态\n## 第⼆次挥⼿：服务端收到以后，向客户端发送ACK应答报⽂，且把客户端的序列号值+1作为ACK报⽂的序列号\n值，表明已经收到客户端的报⽂了，此时服务端处于CLOSE_WAIT 状态\n## 第三次挥⼿：等待服务端处理完数据后，向客户端发送FIN报⽂。此时服务端处于LAST_ACK  的状态\n## 第四次挥⼿：客户端接收到FIN报⽂后回⼀个ACK应答报⽂，之后客户端处于TIME_WAIT 状态\n## 服务器收到ACK报⽂后，进⼊CLOSE 状态，服务器完成连接关闭。\n## 客户端在经过 2MSL ⼀段时间后，⾃动进⼊CLOSE 状态，客户端也完成连接的关闭。\n为什么挥⼿需要四次\n关闭连接时，客户端发送FIN报⽂，表示其不再发送数据，但还可以接收数据。\n服务端收到FIN报⽂，可以直接发送SYN+ACK报⽂。其中ACK报⽂是⽤来应答的，SYN报⽂是⽤来同步的。但是关\n闭连接时，服务端可能还要数据需要处理和发送，所以先回⼀个ACK应答报⽂，等到其不再发送数据时，才发送\nFIN报⽂给客户端表示同意关闭连接。\n从上⾯过程可知：服务端通常需要等待完成数据的发送和处理，所以服务端的ACK和FIN⼀般都会分开发送，从⽽\n⽐三次握⼿导致多了⼀次。\n为什么需要 TIME_WAIT 状态\n主动发起关闭连接的⼀⽅，才会有 TIME-WAIT 状态。\n需要 TIME-WAIT 状态，主要是两个原因：\n## 防⽌历史连接中的数据，被后⾯相同四元组的连接错误的接收；\n如果⽹络出现拥塞或延迟，数据包可能会在⽹络中滞留⼀段时间，甚⾄超过了原始连接关闭的时间。如果没有\nTIME_WAIT 状态，客户端直接进⼊到CLOSE状态，这些滞留的数据包可能会被传递给新连接，导致新连接的数据\n被旧连接的数据⼲扰。\n经过 2MSL 这个时间，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再出现\n的数据包⼀定都是新建⽴连接所产⽣的。\n## 保证「被动关闭连接」的⼀⽅能被正确的关闭，即保证最后的 ACK 能让被动关闭⽅接收，从⽽帮助其正常关\n如果最后的⼀次ACK报⽂丢失（第四次挥⼿），客户端没有TIME_WAIT 状态，直接进⼊ClOSE，服务端⼀直在等待\nACK状态，⼀直没有等到，就会重发FIN报⽂，⽽客户端已经进⼊到关闭状态，在收到服务端重传的 FIN 报⽂后，\n就会回 RST 报⽂,服务端收到这个 RST 并将其解释为⼀个错误, 为了防⽌这种情况出现，客户端必须等待⾜够⻓的时\n间，确保服务端能够收到 ACK，如果服务端没有收到 ACK，那么就会触发 TCP 重传机制，服务端会重新发送⼀个\nFIN，这样⼀去⼀来刚好两个 MSL 的时间。\n如果 TIME-WAIT 等待⾜够⻓的情况就会遇到两种情况：\n## 服务端正常收到四次挥⼿的最后⼀个 ACK 报⽂，则服务端正常关闭连接。\n## 服务端没有收到四次挥⼿的最后⼀个 ACK 报⽂时，则会重发 FIN 关闭连接报⽂并等待新的 ACK 报⽂。\n为什么 TIME_WAIT 等待的时间是 2MSL\n## MSL是 Maximum Segment Lifetime ，报⽂最⼤⽣存时间，它是任何报⽂在⽹络上存在的最⻓时间，超过这\n个时间报⽂将被丢弃。\n## 等待MSL两倍：⽹络中可能存在发送⽅的数据包，当这些发送⽅的数据包被接收⽅处理后⼜会向对⽅发送响\n应，所以⼀来⼀回需要等待 2 倍的时间。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 8801,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000011",
    "content": "## 2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK\n\n没有传输到服务端，客户端⼜接收到了服务端重发的 FIN 报⽂，那么 2MSL 时间将重新计时。\nTIME_WAIT  过多有什么危害？\n过多的TIME-WAIT 状态主要的危害有两种：\n## 内存资源占⽤；\n## 对端⼝资源的占⽤，⼀个 TCP 连接⾄少消耗⼀个本地端⼝；\n如果发起连接⼀⽅的  TIME_WAIT 状态过多，占满了所有端⼝资源，则会导致⽆法创建新连接。\nTCP的重传机制\nTCP 实现可靠传输的⽅式之⼀，是通过序列号与确认应答。\n在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回⼀个确认应答消息，表示已收到消息。\n但是如果传输的过程中，数据包丢失了，就会使⽤重传机制来解决。\n## 超时重传：\n设定⼀个计时器，当超过指定的时间后，没有收到对⽅的确认ACK应答报⽂，就会重发该数据。\n超时重传的两种情况如下：\nRTT(round-trip time):往返时延,指的是数据包的往返时间\nRTO（Retransmission Timeout）：超时重传时间\nRTO较⻓或较短可能发⽣的情况如下：\n由上图可知：超时重传时间RTO的值 应该略⼤于 报⽂往返RTT的值，且是动态变化的。\n如果超时重发的数据，再次超时⼜要重传的时候，TCP的策略是将超时间隔加倍，也就是每当遇到⼀次超时重传的\n时候，都会将下⼀次超时时间间隔设为先前值的两倍。\n## 快速重传：\n快速重传（Fast Retransmit）机制，它不以时间为驱动，⽽是以数据驱动重传。\n⼯作原理：\n当收到三个相同的ACK报⽂时，会在定时器过期之前，重传丢失的报⽂段。\n快速重传解决了超时时间的问题，但还⾯临另外⼀个问题：重传的时候，是重传之前的⼀个，还是重传所有的问\n## SACK（Selective  Acknowledgment,选择性确认）：\n为了解决 重传哪些报⽂的问题⽽提出。\n这种⽅式需要在 TCP 头部「选项」字段⾥加⼀个 SACK 的东⻄，可以将已收到的数据的信息发送给「发送⽅」，这\n样发送⽅就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。\n## D-SACK（Duplicate SACK）:\n主要使⽤了SACK来告诉【发送⽅】有哪些数据被重复接收了。下⾯举例来说明D-SACK 的作⽤：\nACK丢包：\n⽹络延时：\n使⽤D-SACK的好处：\n（1） 可以让【发送⽅】知道，是发出去的包丢了，还是接收⽅回应的ACK包丢了；\n（2） 可以知道是不是【发送⽅】的数据包被⽹络演示了；\n（3） 可以知道⽹络中是不是把【发送⽅】的数据包给复制了。\nTCP的滑动窗⼝\n## 什么是窗⼝\nTCP每发送⼀个数据，都需要⼀次应答，然后继续发送，这样为每个数据包都进⾏确认应答，缺点是：数据往返时\n间越⻓，⽹络吞吐量越低。为了解决这个问题，TCP 引⼊了窗⼝这个概念。即使在往返时间较⻓的情况下，它也不\n会降低⽹络通信的效率。⽽窗⼝的⼤⼩呢，就是⽆需等待确认应答，可以继续发送数据的最⼤值。\n假设窗⼝⼤⼩为\n个 TCP 段，那么发送⽅就可以「连续发送」\n个 TCP 段，并且中途若有 ACK 丢失，可以通过\n「下⼀个确认应答进⾏确认」。如下图：\n窗⼝的实现就是操作系统开辟的⼀个缓存空间，发送⽅主机在等到确认应答返回之前，必须在缓冲区中保留已发送\n的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。\n图中的 ACK 600 确认应答报⽂丢失，也没关系，因为可以通过下⼀个确认应答进⾏确认，只要发送⽅收到了 ACK\n700 确认应答，就意味着 700 之前的所有数据「接收⽅」都收到了。这个模式就叫累计确认或者累计应答。\n## 什么决定窗⼝⼤⼩\nTCP头部有⼀个字段叫window，窗⼝⼤⼩。\n这个字段是接收端告诉发送端⾃⼰还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能⼒来\n发送数据，⽽不会导致接收端处理不过来\n通常窗⼝的⼤⼩是由接收⽅的窗⼝⼤⼩来决定的。\n发送⽅发送的数据⼤⼩不能超过接收⽅的窗⼝⼤⼩，否则接收⽅就⽆法正常接收到数据。\n## 发送⽅的滑动窗⼝\n下图就是发送⽅缓存的数据，根据处理的情况分成四个部分：",
    "question": "## 2MSL 的时间是从客户端接收到 FIN 后发送 ACK 开始计时的。如果在 TIME-WAIT 时间内，因为客户端的 ACK",
    "answer": "没有传输到服务端，客户端⼜接收到了服务端重发的 FIN 报⽂，那么 2MSL 时间将重新计时。\nTIME_WAIT  过多有什么危害？\n过多的TIME-WAIT 状态主要的危害有两种：\n## 内存资源占⽤；\n## 对端⼝资源的占⽤，⼀个 TCP 连接⾄少消耗⼀个本地端⼝；\n如果发起连接⼀⽅的  TIME_WAIT 状态过多，占满了所有端⼝资源，则会导致⽆法创建新连接。\nTCP的重传机制\nTCP 实现可靠传输的⽅式之⼀，是通过序列号与确认应答。\n在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回⼀个确认应答消息，表示已收到消息。\n但是如果传输的过程中，数据包丢失了，就会使⽤重传机制来解决。\n## 超时重传：\n设定⼀个计时器，当超过指定的时间后，没有收到对⽅的确认ACK应答报⽂，就会重发该数据。\n超时重传的两种情况如下：\nRTT(round-trip time):往返时延,指的是数据包的往返时间\nRTO（Retransmission Timeout）：超时重传时间\nRTO较⻓或较短可能发⽣的情况如下：\n由上图可知：超时重传时间RTO的值 应该略⼤于 报⽂往返RTT的值，且是动态变化的。\n如果超时重发的数据，再次超时⼜要重传的时候，TCP的策略是将超时间隔加倍，也就是每当遇到⼀次超时重传的\n时候，都会将下⼀次超时时间间隔设为先前值的两倍。\n## 快速重传：\n快速重传（Fast Retransmit）机制，它不以时间为驱动，⽽是以数据驱动重传。\n⼯作原理：\n当收到三个相同的ACK报⽂时，会在定时器过期之前，重传丢失的报⽂段。\n快速重传解决了超时时间的问题，但还⾯临另外⼀个问题：重传的时候，是重传之前的⼀个，还是重传所有的问\n## SACK（Selective  Acknowledgment,选择性确认）：\n为了解决 重传哪些报⽂的问题⽽提出。\n这种⽅式需要在 TCP 头部「选项」字段⾥加⼀个 SACK 的东⻄，可以将已收到的数据的信息发送给「发送⽅」，这\n样发送⽅就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以只重传丢失的数据。\n## D-SACK（Duplicate SACK）:\n主要使⽤了SACK来告诉【发送⽅】有哪些数据被重复接收了。下⾯举例来说明D-SACK 的作⽤：\nACK丢包：\n⽹络延时：\n使⽤D-SACK的好处：\n（1） 可以让【发送⽅】知道，是发出去的包丢了，还是接收⽅回应的ACK包丢了；\n（2） 可以知道是不是【发送⽅】的数据包被⽹络演示了；\n（3） 可以知道⽹络中是不是把【发送⽅】的数据包给复制了。\nTCP的滑动窗⼝\n## 什么是窗⼝\nTCP每发送⼀个数据，都需要⼀次应答，然后继续发送，这样为每个数据包都进⾏确认应答，缺点是：数据往返时\n间越⻓，⽹络吞吐量越低。为了解决这个问题，TCP 引⼊了窗⼝这个概念。即使在往返时间较⻓的情况下，它也不\n会降低⽹络通信的效率。⽽窗⼝的⼤⼩呢，就是⽆需等待确认应答，可以继续发送数据的最⼤值。\n假设窗⼝⼤⼩为\n个 TCP 段，那么发送⽅就可以「连续发送」\n个 TCP 段，并且中途若有 ACK 丢失，可以通过\n「下⼀个确认应答进⾏确认」。如下图：\n窗⼝的实现就是操作系统开辟的⼀个缓存空间，发送⽅主机在等到确认应答返回之前，必须在缓冲区中保留已发送\n的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。\n图中的 ACK 600 确认应答报⽂丢失，也没关系，因为可以通过下⼀个确认应答进⾏确认，只要发送⽅收到了 ACK\n700 确认应答，就意味着 700 之前的所有数据「接收⽅」都收到了。这个模式就叫累计确认或者累计应答。\n## 什么决定窗⼝⼤⼩\nTCP头部有⼀个字段叫window，窗⼝⼤⼩。\n这个字段是接收端告诉发送端⾃⼰还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能⼒来\n发送数据，⽽不会导致接收端处理不过来\n通常窗⼝的⼤⼩是由接收⽅的窗⼝⼤⼩来决定的。\n发送⽅发送的数据⼤⼩不能超过接收⽅的窗⼝⼤⼩，否则接收⽅就⽆法正常接收到数据。\n## 发送⽅的滑动窗⼝\n下图就是发送⽅缓存的数据，根据处理的情况分成四个部分：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": 2,
    "char_count": 1800,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000012",
    "content": "#4  是未发送但总⼤⼩超过接收⽅处理范围（接收⽅没有空间）：52字节以后\n\n下图表示数据全都发送以后，可⽤窗⼝⼤⼩为0，在没收到ACK确认应答之前⽆法继续发送数据。\n下图，当收到之前发送的数据\n字节的 ACK 确认应答后，如果发送窗⼝的⼤⼩没有变化，则滑动窗⼝往右边\n移动 5 个字节，因为有 5 个字节的数据被应答确认，接下来\n字节⼜变成了可⽤窗⼝，那么后续也就可以发\n这 5 个字节的数据了。\n在收到32-36的ACK应答后，如果窗⼝⼤⼩不变，则滑动窗⼝先后移动5个字节，那么52-56变成可⽤窗⼝，可以继\n续发送数据。\n32~36\n52~56\n52~56",
    "question": "#4  是未发送但总⼤⼩超过接收⽅处理范围（接收⽅没有空间）：52字节以后",
    "answer": "下图表示数据全都发送以后，可⽤窗⼝⼤⼩为0，在没收到ACK确认应答之前⽆法继续发送数据。\n下图，当收到之前发送的数据\n字节的 ACK 确认应答后，如果发送窗⼝的⼤⼩没有变化，则滑动窗⼝往右边\n移动 5 个字节，因为有 5 个字节的数据被应答确认，接下来\n字节⼜变成了可⽤窗⼝，那么后续也就可以发\n这 5 个字节的数据了。\n在收到32-36的ACK应答后，如果窗⼝⼤⼩不变，则滑动窗⼝先后移动5个字节，那么52-56变成可⽤窗⼝，可以继\n续发送数据。\n32~36\n52~56\n52~56",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": 4,
    "char_count": 281,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000013",
    "content": "## 程序是如何表示发送⽅的四个部分的呢？\n\nTCP 滑动窗⼝⽅案使⽤三个指针来跟踪在四个传输类别中的每⼀个类别中的字节。其中两个指针是绝对指针（指特\n定的序列号），⼀个是相对指针（需要做偏移）。\nSND.WND ：表示发送窗⼝的⼤⼩（⼤⼩是由接收⽅指定的）；\nSND.UNA ：是⼀个绝对指针，它指向的是已发送但未收到确认的第⼀个字节的序列号，也就是 #2 的第⼀个\n字节。\nSND.NXT ：也是⼀个绝对指针，它指向未发送但可发送范围的第⼀个字节的序列号，也就是 #3 的第⼀个字\n指向 #4 的第⼀个字节是个相对指针，它需要 SND.UNA 指针加上SND.WND ⼤⼩的偏移量，就可以指向 #4 的\n第⼀个字节了。\n可⽤窗⼝⼤⼩ = 发送窗⼝ - 已发送未确定(SND.WND -（SND.NXT - SND.UNA))\n已发送未确认 =\n## 接收⽅滑动窗⼝\n接收窗⼝根据处理的情况划分成三个部分：",
    "question": "## 程序是如何表示发送⽅的四个部分的呢？",
    "answer": "TCP 滑动窗⼝⽅案使⽤三个指针来跟踪在四个传输类别中的每⼀个类别中的字节。其中两个指针是绝对指针（指特\n定的序列号），⼀个是相对指针（需要做偏移）。\nSND.WND ：表示发送窗⼝的⼤⼩（⼤⼩是由接收⽅指定的）；\nSND.UNA ：是⼀个绝对指针，它指向的是已发送但未收到确认的第⼀个字节的序列号，也就是 #2 的第⼀个\n字节。\nSND.NXT ：也是⼀个绝对指针，它指向未发送但可发送范围的第⼀个字节的序列号，也就是 #3 的第⼀个字\n指向 #4 的第⼀个字节是个相对指针，它需要 SND.UNA 指针加上SND.WND ⼤⼩的偏移量，就可以指向 #4 的\n第⼀个字节了。\n可⽤窗⼝⼤⼩ = 发送窗⼝ - 已发送未确定(SND.WND -（SND.NXT - SND.UNA))\n已发送未确认 =\n## 接收⽅滑动窗⼝\n接收窗⼝根据处理的情况划分成三个部分：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 404,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000014",
    "content": "#4 未收到数据并不可以接收的数据\n\n其中三个接收部分，使⽤两个指针进⾏划分:\nRCV.WND ：表示接收窗⼝的⼤⼩，它会通告给发送⽅。\nRCV.NXT ：是⼀个指针，它指向期望从发送⽅发送来的下⼀个数据字节的序列号，也就是 #3 的第⼀个字节。\n指向 #4 的第⼀个字节是个相对指针，它需要\n第⼀个字节了。",
    "question": "#4 未收到数据并不可以接收的数据",
    "answer": "其中三个接收部分，使⽤两个指针进⾏划分:\nRCV.WND ：表示接收窗⼝的⼤⼩，它会通告给发送⽅。\nRCV.NXT ：是⼀个指针，它指向期望从发送⽅发送来的下⼀个数据字节的序列号，也就是 #3 的第⼀个字节。\n指向 #4 的第⼀个字节是个相对指针，它需要\n第⼀个字节了。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": 4,
    "char_count": 154,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000015",
    "content": "## 接收窗⼝和发送窗⼝的⼤⼩是相等的吗？\n\n指针加上RCV.WND ⼤⼩的偏移量，就可以指向 #4 的\n并不是完全相等，接收窗⼝的⼤⼩是约等于发送窗⼝的⼤⼩的。\n因为滑动窗⼝并不是⼀成不变的。⽐如，当接收⽅的应⽤进程读取数据的速度⾮常快的话，这样的话接收窗⼝可以\n很快的就空缺出来。那么新的接收窗⼝⼤⼩，是通过 TCP 报⽂中的 Windows 字段来告诉发送⽅。那么这个传输过\n程是存在时延的，所以接收窗⼝和发送窗⼝是约等于的关系。\nTCP的流量控制机制\nTCP 流量控制的基本原理是使⽤滑动窗⼝机制，其中接收⽅可以通过调整窗⼝⼤⼩来告诉发送⽅其当前处理数据的\n能⼒。\n## 接收窗⼝：接收⽅维护⼀个接收窗⼝，表示可以接收的数据段的范围。窗⼝⼤⼩可以根据接收⽅的处理能⼒进\n⾏调整。\n## 通告窗⼝⼤⼩：接收⽅通过 TCP 报⽂中的确认信息，通告当前的接收窗⼝⼤⼩给发送⽅。发送⽅会根据这个\n窗⼝⼤⼩来控制发送数据的速率。\n## 窗⼝滑动：随着接收⽅处理数据的能⼒，窗⼝可以向前滑动。接收⽅可以通告更⼤的窗⼝，表示它可以接收更\n多的数据。\n## 发送速率控制：发送⽅会根据接收⽅通告的窗⼝⼤⼩来控制发送数据的速率。如果接收窗⼝变⼩，表示接收⽅\n的处理能⼒减弱，发送⽅会减慢发送速率，避免数据拥塞。\n## 动态调整：TCP 流量控制是动态的，适应⽹络和接收⽅的变化。如果⽹络拥塞或接收⽅的处理速度变慢，流\n量控制可以适时地减少发送速率。\nTCP的拥塞控制机制\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀\n重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放\n⼤   , 于是，就有了拥塞控制，控制的⽬的就是避免「发送⽅」的数据填满整个⽹络。\n拥塞控制通过拥塞窗⼝  来防⽌过多的数据注⼊⽹络，使得⽹络中的路由器或者链路过载。\n拥塞窗⼝cwnd 是发送⽅维护的⼀个状态变量，根据⽹络拥塞程度⽽变化。\n发送窗⼝的值是swnd = min(cwnd, rwnd) ，也就是拥塞窗⼝和接收窗⼝中的最⼩值。\n⽹络中没有出现拥塞，cwnd增⼤，出现拥塞，cwnd减⼩。\n其实只要发送⽅没有在规定时间内接收到 ACK 应答报⽂，也就是发⽣了超时重传，就会认为⽹络出现了拥塞。\n拥塞控制的常⻅算法：\n## 慢启动\n## 拥塞避免\nRCV.NXT\nssthresh\nMSS\n## 拥塞发⽣\n## 快速恢复\n## 慢启动\nTCP 在刚建⽴连接完成后，⾸先是有个慢启动的过程，这个慢启动的意思就是⼀点⼀点的提⾼发送数据包的数量。\n慢启动的算法记住⼀个规则就⾏：当发送⽅每收到⼀个 ACK，拥塞窗⼝ cwnd 的⼤⼩就会加 1。\n慢启动算法，发包的个数是指数性的增⻓。\n不过，慢启动有⼀个⻔限ssthresh 状态变量：\n## 当 cwnd < ssthresh 时，使⽤慢启动算法。\n## 当 cwnd >= ssthresh 时，就会使⽤拥塞避免算法。\n## 拥塞避免\n⼀般来说  ssthresh 的⼤⼩是65535字节。超过后会就会进⼊拥塞避免算法。\n进⼊拥塞避免算法后，它的规则是：每当收到⼀个 ACK 时，cwnd 增加1/cwnd。\n现假定\n为 8 ：\n当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd ⼀共增加 1，于是这⼀次能够发送 9\n⼤⼩的数据，变成了线性增⻓。\ncwnd\n所以拥塞避免算法就是将原本慢启动算法的指数增⻓变成了线性增⻓，还是增⻓阶段，但是增⻓速度缓慢了⼀些。\n不过⽹络就会慢慢进⼊了拥塞的状况了，就会出现丢包现象，这时就需要对丢失的数据包进⾏重传。\n当触发了重传机制，也就进⼊了拥塞发⽣算法。\n## 拥塞发⽣\n当⽹络出现拥塞，也就是会发⽣数据包重传，重传机制主要有两种：\n超时重传\n快速重传\n（1） 发⽣超时重传的拥塞发⽣算法：\n这个时候，ssthresh 和 cwnd 的值会发⽣变化\n## ssthresh 设为 cwnd/2 ，\n重置为 1\n接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是⼀旦「超时重传」，⻢上回到解放前。但是这种\n⽅式太激进了，反应也很强烈，会造成⽹络卡顿。\n（2） 快速重传拥塞算法：\nTCP 认为这种情况不严重，因为⼤部分没丢，只丢了⼀⼩部分，则 ssthresh 和 cwnd 变化如下：\n## cwnd =  cwnd/2 ，也就是设置为原来的⼀半\n## ssthresh = cwnd\n## 进⼊快速恢复算法\n## 快速恢复\n快速重传和快速恢复算法⼀般同时使⽤，快速恢复算法是认为，还能收到 3 个重复 ACK 说明⽹络也不那么糟糕，\n所以没有必要像 RTO 超时那么强烈。\n进⼊快速恢复：\n## 拥塞窗⼝\n## 重传丢失的数据包；\n（ 3 的意思是确认有 3 个数据包被收到了）；\n## 如果再收到重复的 ACK，那么 cwnd 增加 1；\n## 如果收到新数据的 ACK 后，把 cwnd 设置为第⼀步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说\n明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进⼊\n拥塞避免状态；\n⽽是还在⽐较⾼的值，后续呈线性增⻓。\ncwnd = ssthresh + 3\nIP基础\nIP基础\nIP位于TCP/IP参考模型的第三层，也就是⽹络层。\n⽹络层的主要作⽤是：实现主机与主机之间的通信，也叫点对点通信。",
    "question": "## 接收窗⼝和发送窗⼝的⼤⼩是相等的吗？",
    "answer": "指针加上RCV.WND ⼤⼩的偏移量，就可以指向 #4 的\n并不是完全相等，接收窗⼝的⼤⼩是约等于发送窗⼝的⼤⼩的。\n因为滑动窗⼝并不是⼀成不变的。⽐如，当接收⽅的应⽤进程读取数据的速度⾮常快的话，这样的话接收窗⼝可以\n很快的就空缺出来。那么新的接收窗⼝⼤⼩，是通过 TCP 报⽂中的 Windows 字段来告诉发送⽅。那么这个传输过\n程是存在时延的，所以接收窗⼝和发送窗⼝是约等于的关系。\nTCP的流量控制机制\nTCP 流量控制的基本原理是使⽤滑动窗⼝机制，其中接收⽅可以通过调整窗⼝⼤⼩来告诉发送⽅其当前处理数据的\n能⼒。\n## 接收窗⼝：接收⽅维护⼀个接收窗⼝，表示可以接收的数据段的范围。窗⼝⼤⼩可以根据接收⽅的处理能⼒进\n⾏调整。\n## 通告窗⼝⼤⼩：接收⽅通过 TCP 报⽂中的确认信息，通告当前的接收窗⼝⼤⼩给发送⽅。发送⽅会根据这个\n窗⼝⼤⼩来控制发送数据的速率。\n## 窗⼝滑动：随着接收⽅处理数据的能⼒，窗⼝可以向前滑动。接收⽅可以通告更⼤的窗⼝，表示它可以接收更\n多的数据。\n## 发送速率控制：发送⽅会根据接收⽅通告的窗⼝⼤⼩来控制发送数据的速率。如果接收窗⼝变⼩，表示接收⽅\n的处理能⼒减弱，发送⽅会减慢发送速率，避免数据拥塞。\n## 动态调整：TCP 流量控制是动态的，适应⽹络和接收⽅的变化。如果⽹络拥塞或接收⽅的处理速度变慢，流\n量控制可以适时地减少发送速率。\nTCP的拥塞控制机制\n在⽹络出现拥堵时，如果继续发送⼤量数据包，可能会导致数据包时延、丢失等，这时 TCP 就会重传数据，但是⼀\n重传就会导致⽹络的负担更重，于是会导致更⼤的延迟以及更多的丢包，这个情况就会进⼊恶性循环被不断地放\n⼤   , 于是，就有了拥塞控制，控制的⽬的就是避免「发送⽅」的数据填满整个⽹络。\n拥塞控制通过拥塞窗⼝  来防⽌过多的数据注⼊⽹络，使得⽹络中的路由器或者链路过载。\n拥塞窗⼝cwnd 是发送⽅维护的⼀个状态变量，根据⽹络拥塞程度⽽变化。\n发送窗⼝的值是swnd = min(cwnd, rwnd) ，也就是拥塞窗⼝和接收窗⼝中的最⼩值。\n⽹络中没有出现拥塞，cwnd增⼤，出现拥塞，cwnd减⼩。\n其实只要发送⽅没有在规定时间内接收到 ACK 应答报⽂，也就是发⽣了超时重传，就会认为⽹络出现了拥塞。\n拥塞控制的常⻅算法：\n## 慢启动\n## 拥塞避免\nRCV.NXT\nssthresh\nMSS\n## 拥塞发⽣\n## 快速恢复\n## 慢启动\nTCP 在刚建⽴连接完成后，⾸先是有个慢启动的过程，这个慢启动的意思就是⼀点⼀点的提⾼发送数据包的数量。\n慢启动的算法记住⼀个规则就⾏：当发送⽅每收到⼀个 ACK，拥塞窗⼝ cwnd 的⼤⼩就会加 1。\n慢启动算法，发包的个数是指数性的增⻓。\n不过，慢启动有⼀个⻔限ssthresh 状态变量：\n## 当 cwnd < ssthresh 时，使⽤慢启动算法。\n## 当 cwnd >= ssthresh 时，就会使⽤拥塞避免算法。\n## 拥塞避免\n⼀般来说  ssthresh 的⼤⼩是65535字节。超过后会就会进⼊拥塞避免算法。\n进⼊拥塞避免算法后，它的规则是：每当收到⼀个 ACK 时，cwnd 增加1/cwnd。\n现假定\n为 8 ：\n当 8 个 ACK 应答确认到来时，每个确认增加 1/8，8 个 ACK 确认 cwnd ⼀共增加 1，于是这⼀次能够发送 9\n⼤⼩的数据，变成了线性增⻓。\ncwnd\n所以拥塞避免算法就是将原本慢启动算法的指数增⻓变成了线性增⻓，还是增⻓阶段，但是增⻓速度缓慢了⼀些。\n不过⽹络就会慢慢进⼊了拥塞的状况了，就会出现丢包现象，这时就需要对丢失的数据包进⾏重传。\n当触发了重传机制，也就进⼊了拥塞发⽣算法。\n## 拥塞发⽣\n当⽹络出现拥塞，也就是会发⽣数据包重传，重传机制主要有两种：\n超时重传\n快速重传\n（1） 发⽣超时重传的拥塞发⽣算法：\n这个时候，ssthresh 和 cwnd 的值会发⽣变化\n## ssthresh 设为 cwnd/2 ，\n重置为 1\n接着，就重新开始慢启动，慢启动是会突然减少数据流的。这真是⼀旦「超时重传」，⻢上回到解放前。但是这种\n⽅式太激进了，反应也很强烈，会造成⽹络卡顿。\n（2） 快速重传拥塞算法：\nTCP 认为这种情况不严重，因为⼤部分没丢，只丢了⼀⼩部分，则 ssthresh 和 cwnd 变化如下：\n## cwnd =  cwnd/2 ，也就是设置为原来的⼀半\n## ssthresh = cwnd\n## 进⼊快速恢复算法\n## 快速恢复\n快速重传和快速恢复算法⼀般同时使⽤，快速恢复算法是认为，还能收到 3 个重复 ACK 说明⽹络也不那么糟糕，\n所以没有必要像 RTO 超时那么强烈。\n进⼊快速恢复：\n## 拥塞窗⼝\n## 重传丢失的数据包；\n（ 3 的意思是确认有 3 个数据包被收到了）；\n## 如果再收到重复的 ACK，那么 cwnd 增加 1；\n## 如果收到新数据的 ACK 后，把 cwnd 设置为第⼀步中的 ssthresh 的值，原因是该 ACK 确认了新的数据，说\n明从 duplicated ACK 时的数据都已收到，该恢复过程已经结束，可以回到恢复之前的状态了，也即再次进⼊\n拥塞避免状态；\n⽽是还在⽐较⾼的值，后续呈线性增⻓。\ncwnd = ssthresh + 3\nIP基础\nIP基础\nIP位于TCP/IP参考模型的第三层，也就是⽹络层。\n⽹络层的主要作⽤是：实现主机与主机之间的通信，也叫点对点通信。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2315,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000016",
    "content": "## ⽹络层（IP)与数据链路层(MAC)有什么关系呢？\n\nMAC的作⽤：\n实现【直连】的两个设备之间通信。\nIP的作⽤：\n负责在【没有直连】的两个⽹络之间进⾏通信传输。\n在⽹络数据包传输中，源IP地址和⽬标IP地址在传输过程中是不会变的，只有源MAC地址和⽬标MAC⼀直在变化。\nIP地址\n实际上让 43 亿台计算机全部连⽹其实是不可能的，更何况 IP 地址是由「⽹络标识」和「主机标识」这两个部分组\n成的，所以实际能够连接到⽹络的计算机个数更是少了很多。\n但可以根据⼀种可以更换IP地址的技术NAT，使得可连接计算机数超过43亿台。\n## IP地址分类\nIP地址被分为了五种类型：\n（1） A、B、C类地址\n最⼤主机数=2^主机号位数-2，其中有两个地址，全0和全1是⽐较特殊的：\n⼴播地址⽤于在同⼀个链路中相互连接的主机之间发送数据包。⼴播地址可以分为本地⼴播和直接⼴播两种。\n在本⽹络内⼴播的叫做本地⼴播。例如⽹络地址为 192.168.0.0/24 的情况下，⼴播地址是 192.168.0.255 。\n因为这个⼴播地址的 IP 包会被路由器屏蔽，所以不会到达\n以外的其他链路上。\n在不同⽹络之间的⼴播叫做直接⼴播。\n例如⽹络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的⽬标地址发送 IP 包。收到这个包的路由器，\n将数据转发给 192.168.1.0/24 从⽽使得所有  192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接\n⼴播有⼀定的安全问题，多数情况下会在路由  器上设置为不转发。）\n## /24\n（2） 什么是D、E类地址？\nD 类和 E 类地址是没有主机号的，所以不可⽤于主机 IP，D 类常被⽤于多播，E 类是预留的分类，暂时未使⽤。\n多播地址⽤于将包发送给特定组内的所有主机。由于⼴播⽆法穿透路由，若想给其他⽹段发送同样的包，就可以使\n⽤可以穿透路由的多播。\n多播使⽤的 D 类地址，其前四位是 1110 就表示是多播地址，⽽剩下的 28 位是多播的组编号。\n从 224.0.0.0 ~ 239.255.255.255 都是多播的可⽤范围，其划分为以下三类：\n## ~ 224.0.0.255 为预留的组播地址，只能在局域⽹中，路由器是不会进⾏转发的。\n## ~ 238.255.255.255 为⽤户可⽤的组播地址，可以⽤于 Internet 上。\n## ~ 239.255.255.255 为本地管理组播地址，可供内部⽹在内部使⽤，仅在特定的本地范围内有效。",
    "question": "## ⽹络层（IP)与数据链路层(MAC)有什么关系呢？",
    "answer": "MAC的作⽤：\n实现【直连】的两个设备之间通信。\nIP的作⽤：\n负责在【没有直连】的两个⽹络之间进⾏通信传输。\n在⽹络数据包传输中，源IP地址和⽬标IP地址在传输过程中是不会变的，只有源MAC地址和⽬标MAC⼀直在变化。\nIP地址\n实际上让 43 亿台计算机全部连⽹其实是不可能的，更何况 IP 地址是由「⽹络标识」和「主机标识」这两个部分组\n成的，所以实际能够连接到⽹络的计算机个数更是少了很多。\n但可以根据⼀种可以更换IP地址的技术NAT，使得可连接计算机数超过43亿台。\n## IP地址分类\nIP地址被分为了五种类型：\n（1） A、B、C类地址\n最⼤主机数=2^主机号位数-2，其中有两个地址，全0和全1是⽐较特殊的：\n⼴播地址⽤于在同⼀个链路中相互连接的主机之间发送数据包。⼴播地址可以分为本地⼴播和直接⼴播两种。\n在本⽹络内⼴播的叫做本地⼴播。例如⽹络地址为 192.168.0.0/24 的情况下，⼴播地址是 192.168.0.255 。\n因为这个⼴播地址的 IP 包会被路由器屏蔽，所以不会到达\n以外的其他链路上。\n在不同⽹络之间的⼴播叫做直接⼴播。\n例如⽹络地址为 192.168.0.0/24 的主机向 192.168.1.255/24 的⽬标地址发送 IP 包。收到这个包的路由器，\n将数据转发给 192.168.1.0/24 从⽽使得所有  192.168.1.1~192.168.1.254 的主机都能收到这个包（由于直接\n⼴播有⼀定的安全问题，多数情况下会在路由  器上设置为不转发。）\n## /24\n（2） 什么是D、E类地址？\nD 类和 E 类地址是没有主机号的，所以不可⽤于主机 IP，D 类常被⽤于多播，E 类是预留的分类，暂时未使⽤。\n多播地址⽤于将包发送给特定组内的所有主机。由于⼴播⽆法穿透路由，若想给其他⽹段发送同样的包，就可以使\n⽤可以穿透路由的多播。\n多播使⽤的 D 类地址，其前四位是 1110 就表示是多播地址，⽽剩下的 28 位是多播的组编号。\n从 224.0.0.0 ~ 239.255.255.255 都是多播的可⽤范围，其划分为以下三类：\n## ~ 224.0.0.255 为预留的组播地址，只能在局域⽹中，路由器是不会进⾏转发的。\n## ~ 238.255.255.255 为⽤户可⽤的组播地址，可以⽤于 Internet 上。\n## ~ 239.255.255.255 为本地管理组播地址，可供内部⽹在内部使⽤，仅在特定的本地范围内有效。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1081,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000017",
    "content": "## ~ 239.255.255.255 为本地管理组播地址，可供内部⽹在内部使⽤，仅在特定的本地范围内有效。\n\n（3） IP分类的优缺点\n可以根据IP地址的前四位来判别IP地址属于哪个类别。简单明了，选路简单。\n同⼀⽹络下没有地址层次，⽐如⼀个公司⾥⽤了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划\n分地址层次，⽽这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。\nB、C类有个尴尬处境，就是不能很好的与现实⽹络匹配。\nC 类地址能包含的最⼤主机数量实在太少了，只有 254 个，估计⼀个⽹吧都不够⽤。\n⽽ B 类地址能包含的最⼤主机数量⼜太多了，6 万多台机器放在⼀个⽹络下⾯，⼀般的企业基本达不到这个规模，\n闲着的地址就是浪费。这两个缺点，都可以在 CIDR ⽆分类地址解决。\n（4） CIDR⽆分类地址\n这种⽅式不再有分类地址的概念，32 ⽐特的 IP 地址被划分为两部分，前⾯是⽹络号，后⾯是主机号。\n(i)如何划分⽹络号和主机号呢？\n表示形式 a.b.c.d/x ，其中 /x 表示前 x 位属于⽹络号， x 的范围是 0 ~ 32 ，这就使得 IP 地址更加具有灵活性。\n还有另⼀种划分⽹络号与主机号形式，那就是⼦⽹掩码，掩码的意思就是掩盖掉主机号，剩余的就是⽹络号。\n将⼦⽹掩码和 IP 地址按位计算 AND，就可得到⽹络号。\n（ii） 为什么要分离⽹络号和主机号？\n因为两台计算机要通讯，⾸先要判断是否处于同⼀个⼴播域内，即⽹络地址是否相同。如果⽹络地址相同，表明接\n受⽅在本⽹络上，那么可以把数据包直接发送到⽬标主机。\n路由器寻址⼯作中，也就是通过这样的⽅式来找到对应的⽹络号的，进⽽把数据包转发给对应的⽹络内。\n（iii） 如何进⾏⼦⽹划分？\n通过⼦⽹掩码划分出⽹络号和主机号，那实际上⼦⽹掩码还有⼀个作⽤，那就是划分⼦⽹。\n⼦⽹划分实际上是将主机地址分为两个部分：⼦⽹⽹络地址和⼦⽹主机地址。形式如下：\n假设对 C 类地址进⾏⼦⽹划分，⽹络地址 192.168.1.0，使⽤⼦⽹掩码 255.255.255.192 对其进⾏⼦⽹划分。\nC 类地址中前 24 位是⽹络号，最后 8 位是主机号，根据⼦⽹掩码可知从 8 位主机号中借⽤ 2 位作为⼦⽹号（对应\n4个⼦⽹）。\n划分后的4个⼦⽹如下：",
    "question": "## ~ 239.255.255.255 为本地管理组播地址，可供内部⽹在内部使⽤，仅在特定的本地范围内有效。",
    "answer": "（3） IP分类的优缺点\n可以根据IP地址的前四位来判别IP地址属于哪个类别。简单明了，选路简单。\n同⼀⽹络下没有地址层次，⽐如⼀个公司⾥⽤了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划\n分地址层次，⽽这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。\nB、C类有个尴尬处境，就是不能很好的与现实⽹络匹配。\nC 类地址能包含的最⼤主机数量实在太少了，只有 254 个，估计⼀个⽹吧都不够⽤。\n⽽ B 类地址能包含的最⼤主机数量⼜太多了，6 万多台机器放在⼀个⽹络下⾯，⼀般的企业基本达不到这个规模，\n闲着的地址就是浪费。这两个缺点，都可以在 CIDR ⽆分类地址解决。\n（4） CIDR⽆分类地址\n这种⽅式不再有分类地址的概念，32 ⽐特的 IP 地址被划分为两部分，前⾯是⽹络号，后⾯是主机号。\n(i)如何划分⽹络号和主机号呢？\n表示形式 a.b.c.d/x ，其中 /x 表示前 x 位属于⽹络号， x 的范围是 0 ~ 32 ，这就使得 IP 地址更加具有灵活性。\n还有另⼀种划分⽹络号与主机号形式，那就是⼦⽹掩码，掩码的意思就是掩盖掉主机号，剩余的就是⽹络号。\n将⼦⽹掩码和 IP 地址按位计算 AND，就可得到⽹络号。\n（ii） 为什么要分离⽹络号和主机号？\n因为两台计算机要通讯，⾸先要判断是否处于同⼀个⼴播域内，即⽹络地址是否相同。如果⽹络地址相同，表明接\n受⽅在本⽹络上，那么可以把数据包直接发送到⽬标主机。\n路由器寻址⼯作中，也就是通过这样的⽅式来找到对应的⽹络号的，进⽽把数据包转发给对应的⽹络内。\n（iii） 如何进⾏⼦⽹划分？\n通过⼦⽹掩码划分出⽹络号和主机号，那实际上⼦⽹掩码还有⼀个作⽤，那就是划分⼦⽹。\n⼦⽹划分实际上是将主机地址分为两个部分：⼦⽹⽹络地址和⼦⽹主机地址。形式如下：\n假设对 C 类地址进⾏⼦⽹划分，⽹络地址 192.168.1.0，使⽤⼦⽹掩码 255.255.255.192 对其进⾏⼦⽹划分。\nC 类地址中前 24 位是⽹络号，最后 8 位是主机号，根据⼦⽹掩码可知从 8 位主机号中借⽤ 2 位作为⼦⽹号（对应\n4个⼦⽹）。\n划分后的4个⼦⽹如下：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 976,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000018",
    "content": "（3） IP分类的优缺点\n\n可以根据IP地址的前四位来判别IP地址属于哪个类别。简单明了，选路简单。\n同⼀⽹络下没有地址层次，⽐如⼀个公司⾥⽤了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划\n分地址层次，⽽这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。\nB、C类有个尴尬处境，就是不能很好的与现实⽹络匹配。\nC 类地址能包含的最⼤主机数量实在太少了，只有 254 个，估计⼀个⽹吧都不够⽤。\n⽽ B 类地址能包含的最⼤主机数量⼜太多了，6 万多台机器放在⼀个⽹络下⾯，⼀般的企业基本达不到这个规模，\n闲着的地址就是浪费。这两个缺点，都可以在 CIDR ⽆分类地址解决。\n（4） CIDR⽆分类地址\n这种⽅式不再有分类地址的概念，32 ⽐特的 IP 地址被划分为两部分，前⾯是⽹络号，后⾯是主机号。\n(i)如何划分⽹络号和主机号呢？\n表示形式 a.b.c.d/x ，其中 /x 表示前 x 位属于⽹络号， x 的范围是 0 ~ 32 ，这就使得 IP 地址更加具有灵活性。\n还有另⼀种划分⽹络号与主机号形式，那就是⼦⽹掩码，掩码的意思就是掩盖掉主机号，剩余的就是⽹络号。\n将⼦⽹掩码和 IP 地址按位计算 AND，就可得到⽹络号。\n（ii） 为什么要分离⽹络号和主机号？\n因为两台计算机要通讯，⾸先要判断是否处于同⼀个⼴播域内，即⽹络地址是否相同。如果⽹络地址相同，表明接\n受⽅在本⽹络上，那么可以把数据包直接发送到⽬标主机。\n路由器寻址⼯作中，也就是通过这样的⽅式来找到对应的⽹络号的，进⽽把数据包转发给对应的⽹络内。\n（iii） 如何进⾏⼦⽹划分？\n通过⼦⽹掩码划分出⽹络号和主机号，那实际上⼦⽹掩码还有⼀个作⽤，那就是划分⼦⽹。\n⼦⽹划分实际上是将主机地址分为两个部分：⼦⽹⽹络地址和⼦⽹主机地址。形式如下：\n假设对 C 类地址进⾏⼦⽹划分，⽹络地址 192.168.1.0，使⽤⼦⽹掩码 255.255.255.192 对其进⾏⼦⽹划分。\nC 类地址中前 24 位是⽹络号，最后 8 位是主机号，根据⼦⽹掩码可知从 8 位主机号中借⽤ 2 位作为⼦⽹号（对应\n4个⼦⽹）。\n划分后的4个⼦⽹如下：\n## 公有IP地址与私有IP地址\n在A、B、C分类地址，实际⼜分公有IP地址和私有IP地址。\n平时我们办公室、家⾥、学校⽤的 IP 地址，⼀般都是私有 IP 地址。因为这些地址允许组织内部的 IT ⼈员⾃⼰管\n理、⾃⼰分配，⽽且可以重复。\n因此，你学校的某个私有 IP 地址和我学校的可以是⼀样的。 就像每个⼩区都有⾃⼰的楼编号和⻔牌号，你⼩区家可\n以叫 1 栋 101 号，我⼩区家也可以叫 1 栋 101，没有任何问题。但⼀旦出了⼩区，就需要带上中⼭路 666 号\n（公⽹ IP 地址），是国家统⼀分配的，不能两个⼩区都叫中⼭路 666。\n所以，公有 IP 地址是有个组织统⼀分配的，假设你要开⼀个博客⽹站，那么你就需要去申请购买⼀个公有 IP，这样\n全世界的⼈才能访问。并且公有 IP 地址基本上要在整个互联⽹范围内保持唯⼀\n那么公有IP地址由谁管理呢？\n私有 IP 地址通常是内部的 IT ⼈员管理，公有 IP 地址是由 ICANN 组织管理，中⽂叫「互联⽹名称与数字地址分配\n机构」。 IANA 是 ICANN 的其中⼀个机构，它负责分配互联⽹ IP 地址，是按州的⽅式层层分配。\n## IP地址与路由控制\nIP地址的⽹络地址这⼀部分是⽤于进⾏路由控制。路由控制表中记录着⽹络地址与下⼀步应该发送⾄路由器的地\n址。在主机和路由器上都会有各⾃的路由器控制表。\n在发送 IP 包时，⾸先要确定 IP 包⾸部中的⽬标地址，再从路由控制表中找到与该地址具有相同⽹络地址的记录，\n根据该记录将 IP 包转发给相应的下⼀个路由器。如果路由控制表中存在多条相同⽹络地址的记录，就选择相同位\n数最多的⽹络地址，也就是最⻓匹配。\n举例说明：\n环回地址是不会流向⽹络：\n环回地址是在同⼀台计算机上的程序之间进⾏⽹络通信时所使⽤的⼀个默认地址。 计算机使⽤⼀个特殊的 IP 地址\n## 作为环回地址。\n与该地址具有相同意义的是⼀个叫做 localhost 的主机名。使⽤这个 IP 或主机名时，数据包不会流向⽹络\n## IP分⽚与重组\n每种数据链路的最⼤传输单元 MTU 都是不相同的，如 FDDI 数据链路 MTU 4352、以太⽹的 MTU 是 1500 字节\n每种数据链路的  MTU  之所以不同，是因为每个不同类型的数据链路的使⽤⽬的不同。使⽤⽬的不同，可承载的\nMTU 也就不同。\n其中，我们最常⻅数据链路是以太⽹，它的 MTU 是 1500 字节。 那么当 IP 数据包⼤⼩⼤于 MTU 时， IP 数据包就\n会被分⽚。 经过分⽚之后的 IP 数据报在被重组的时候，只能由⽬标主机进⾏，路由器是不会进⾏重组的。\n在分⽚传输中，⼀旦某个分⽚丢失，则会造成整个 IP 数据报作废，所以 TCP 引⼊了 MSS 也就是在 TCP 层进⾏分\n⽚不由 IP 层分⽚，那么对于 UDP 我们尽量不要发送⼀个⼤于 MTU 的数据报⽂。\n## IPV6基本认识\nIPV6:更多的地址，更好的安全性和扩展性。\n但IPV4和IPV6不能兼容。所以不但要我们电脑、⼿机之类的设备⽀持，还需要⽹络运营商对现有的设备进⾏升级，\n所以这可能是 IPv6 普及率⽐较慢的⼀个原因。\n（1） IPV6的亮点\n可分配地址变多\nIPv6 可⾃动配置，即使没有 DHCP 服务器也可以实现⾃动分配IP地址，真是便捷到即插即⽤啊。\nIPv6 包头包⾸部⻓度采⽤固定的值 40 字节，去掉了包头校验和，简化了⾸部结构，减轻了路由器负荷，⼤ ⼤提⾼了\n传输的性能。\nIPv6 有应对伪造 IP 地址的⽹络安全功能以及防⽌线路窃听的功能，⼤⼤提升了安全性。\n（2） IPV6地址的标识⽅法\nIPv4 地址⻓度共 32 位，是以每 8 位作为⼀组，并⽤点分⼗进制的表示⽅式。\nIPv6 地址⻓度是 128 位，是以每 16 位作为⼀组，每组⽤冒号 「:」 隔开。\n如果出现连续的 0 时还可以将这些 0 省略，并⽤两个冒号 「::」隔开。但是，⼀个 IP 地址中只允许出现⼀次两个\n连续的冒号。\n（3） IPV6地址的结构\nIPv6 类似 IPv4，也是通过 IP 地址的前⼏位标识 IP 地址的种类。 IPv6 的地址主要有以下类型地址：\n单播地址：⽤于⼀对⼀的通信；\n组播地址：⽤于⼀对多的通信；\n任播地址：⽤于通信最近的节点，最近的节点是由路由协议决定；\n没有⼴播地址。\nIPV6单播地址类型：\n对于⼀对⼀通信的 IPv6 地址，主要划分了三类单播地址，每类地址的有效范围都不同。\n在同⼀链路单播通信，不经过路由器，可以使⽤链路本地单播地址，IPv4  没有此类型\n在内⽹⾥单播通信，可以使⽤唯⼀本地地址，相当于 IPv4 的私有 IP\n在互联⽹通信，可以使⽤全局单播地址，相当于 IPv4 的公有 IP\n## IPV4⾸部与IPV6⾸部\nIPv4 ⾸部与 IPv6 ⾸部 IPv4 ⾸部与 IPv6 ⾸部的差异如下图：\n其中：\nIPV6相⽐IPV4的⾸部改进\n取消了⾸部校验和字段：\n因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。\n取消了分⽚/重新组装相关字段：\n分⽚与重组是耗时的过程，IPv6 不允许在中间路由器进⾏分⽚与重组，这 种操作只能在源与⽬标主机，这将⼤⼤\n提⾼了路由器转发的速度。\n取消选项字段：\n选项字段不再是标准 IP ⾸部的⼀部分了，但它并没有消失，⽽是可能出现在 IPv6 ⾸部中的 「下⼀个⾸部」指出的\n位置上。删除该选项字段使的 IPv6 的⾸部成为固定⻓度的 40 字节。\n## ARP与RARP协议\n（1） ARP协议\n在传输⼀个 IP 数据报的时候，确定了源 IP 地址和⽬标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下⼀\n跳。然⽽，⽹络层的下⼀层是数据链路层，所以我们还要知道「下⼀跳」的 MAC 地址。\n由于主机的路由表中可以找到下⼀跳的 IP 地址，所以可以通过 ARP 协议（Address Resolution Protocol，地址解\n析协议），求得下⼀跳的 MAC 地址。\nARP是如何知道对⽅的MAC地址的呢？ARP 是借助 ARP 请求与 ARP 响应两种类型的包确定 MAC 地址的。\n主机会通过⼴播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。\n当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包⾥的内容，如果 ARP 请求包中的⽬标 IP 地址与\n⾃⼰的 IP 地址⼀致，那么这个设备就将⾃⼰的 MAC 地址塞⼊ ARP 响应包返回给主机。\n操作系统通常会把第⼀次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地\n址。 不过，MAC 地址的缓存是有⼀定期限的，超过这个期限，缓存的内容将被清除。\n（2） RARP协议\nARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是已知 MAC 地址求 IP 地址。\n例如将打印机服务器等⼩型嵌⼊式设备接⼊到⽹络时就经常会⽤得到。通常这需要架设⼀台 RARP 服务器，在这个\n服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接⼊到⽹络\n接着：\n## DHCP动态获取IP地址\nDHCP(Dynamic Host Configuration Protocol,动态主机配置协议)。我们的电脑通常都是通过 DHCP 动态获取 IP\n地址，⼤⼤省去了配 IP 信息繁琐的过程。\n接下来，我们来看看我们的电脑是如何通过 4 个步骤的过程，获取到 IP 的：\n说明： DHCP 客户端进程监听的是 68 端⼝号，DHCP 服务端进程监听的是 67 端⼝号。\n如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报⽂：\n服务器如果同意继续租⽤：\n则⽤ DHCP ACK 报⽂进⾏应答，客户端就会延⻓租期。\n服务器如果不同意继续租⽤：\n则⽤ DHCP NACK 报⽂，客户端就要停⽌使⽤租约的 IP 地址。 可以发现，DHCP 交互中，全程都是使⽤ UDP ⼴\n播通信。\n疑问：\n咦，⽤的是⼴播，那如果 DHCP 服务器和客户端不是在同⼀个局域⽹内，路由器⼜不会转发⼴播包，那不是每个⽹\n络 都要配⼀个 DHCP 服务器？\n为了解决这⼀问题，就出现了 DHCP 中继代理。有了 DHCP 中继代理以后，对不同⽹段的 IP 地址分配也 可以由⼀\n个 DHCP 服务器统⼀进⾏管理。\nDHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，⽽ DHCP 中继代理在收到这个⼴播包以后，再以单播的形\n式发给 DHCP 服务器。\n服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包⼴播给 DHCP 客户端 。\n因此，DHCP 服务器即使不在同⼀个链路上也可以实现统⼀分配和管理IP地址。\n## NAT( Network Address Translation, ⽹络地址转换)\nIPv4 的地址是⾮常紧缺的，在前⾯我们也提到可以通过⽆分类地址来减缓 IPv4 地址耗尽的速度，但是互联⽹的⽤\n户增速是⾮常惊⼈的，所以 IPv4 地址依然有被耗尽的危险。\n于是，提出了⼀种⽹络地址转换 NAT 的⽅法，再次缓解了 IPv4 地址耗尽的问题。 简单的来说 NAT 就是同个公\n司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。\n疑问：\n那不是 N 个私有 IP 地址，你就要 N 个公有 IP 地址？这怎么就缓解了 IPv4 地址耗尽的问题？这不瞎扯吗？\n确实是，普通的 NAT 转换没什么意义。 由于绝⼤多数的⽹络应⽤都是使⽤传输层协议 TCP 或 UDP 来传输数据\n的。 因此，可以把 IP 地址 + 端⼝号⼀起进⾏转换。 这样，就⽤⼀个全球 IP 地址就可以了，这种转换技术就叫⽹\n络地址与端⼝转换 NAPT。\n来看看下⾯的图解：\n图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进⾏通信，并且这两个客户端的\n本地端⼝都是 1025。 此时，两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端⼝号\n作为区分。\n于是，⽣成⼀个 NAPT 路由器的转换表，就可以正确地转换地址跟端⼝的组合，令客户端 A、B 能同时与服务器之\n间进⾏通信。 这种转换表在 NAT 路由器上⾃动⽣成。例如，在 TCP 的情况下，建⽴ TCP 连接⾸次握⼿时的 SYN\n包⼀经发出， 就会⽣成这个表。⽽后⼜随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。\n（1） NAT有缺点吗？\n由于 NAT/NAPT 都依赖于⾃⼰的转换表，因此会有以下的问题：\n外部⽆法主动与 NAT 内部服务器建⽴连接，因为 NAPT 转换表没有转换记录。\n转换表的⽣成与转换操作都会产⽣性能开销。\n通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。\n（2） 如何解决NAT潜在的问题呢？\n改⽤IPV6：\nIPv6 可⽤范围⾮常⼤，以⾄于每台设备都可以配置⼀个公有 IP 地址，就不搞那么多花⾥胡哨的地址转换了，但是\nIPv6 普及速度还需要⼀些时间。\nNAT 穿透技术：\nNAT 穿越技术能够让⽹络应⽤程序主动发现⾃⼰位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为⾃\n⼰建⽴端⼝映射条⽬，注意这些都是 NAT设备后的应⽤程序⾃动完成的。 也就是说，客户端主动从 NAT 设备获取\n公有 IP 地址，然后⾃⼰建⽴端⼝映射条⽬，然后⽤这个条⽬对外通信， 就不需要 NAT 设备来进⾏转换了。\n## ICMP互联⽹控制报⽂协议\nICMP（ Internet Control Message Protocol，也就是互联⽹控制报⽂协议）。\n⽹络包在复杂的⽹络传输环境⾥，常常会遇到各种问题。   当遇到问题的时候，总不能死个不明不⽩，没头没脑的作\n⻛不是计算机⽹络的⻛格。所以需要传出消息，报告遇到  了什么问题，这样才可以调整传输策略，以此来控制整个局\n（1） ICMP功能都有啥\nICMP的主要功能包括：确认 IP 包是否成功送达⽬标地址、报告发送过程中 IP 包被废弃的原因和改善⽹络设置等。\n在 IP 通信中如果某个 IP 包因为某种原因未能达到⽬标地址，那么这个具体的原因将由 ICMP 负责通知。\nICMP 的这种通知消息会使⽤IP进⾏发送 。 因此，从路由器 2 返回的 ICMP 包会按照往常的路由控制先经过路由器\n1 再转发给主机A 。收到该 ICMP 包的主机 A 则分解 ICMP 的⾸部和数据域以后得知具体发⽣问题的原因。\n（2） ICMP的类型\nICMP⼤致可以分为两⼤类：\n⼀类是⽤于诊断的查询消息，也就是「查询报⽂类型」\n⼀类是通知出错原因的错误消息，也就是「差错报⽂类型」\n## IGMP因特⽹组管理协议\n在前⾯我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有⼀组的主机能收到数据包，不在⼀组的\n主机不能收到数组包，怎么管理是否是在⼀组呢？\n那么，就需要 IGMP 协议了。\nIGMP  是因特⽹组管理协议，⼯作在主机（组播成员）和最后⼀跳路由之间，如上图中的蓝⾊部分。\nIGMP 报⽂向路由器申请加⼊和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除⾮主机通过\nIGMP 加⼊到组播组，主机申请加⼊到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转 发组播包到对\n应的主机了。\nIGMP 报⽂采⽤ IP 封装，IP 头部的协议号为 2，⽽且 TTL 字段值通常为 1，因为 IGMP 是⼯作在主机与连接的路由\n器之间。\n（1） IGMP的⼯作机制\nIGMP 分为了三个版本分别是，IGMPv1、IGMPv2、IGMPv3。 接下来，以 IGMPv2 作为例⼦，说说常规查询与响\n应和离开组播组这两个⼯作机制。\n常规查询与响应机制：\n（i） 路由器会周期性发送⽬的地址为 224.0.0.1 （表示同⼀⽹段内所有主机和路由器） IGMP 常规查询报⽂。\n（ii） 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10\n秒，计时器超时后主机就会发送 IGMP 成员关系报告报⽂（源 IP 地址为⾃⼰主机的 IP 地址，⽬的 IP 地址为组播地\n址）。如果在定时器超时之前，收到同⼀个组内的其他主机发送的成员关系报告报⽂，则⾃⼰不再发  送，这样可以减\n少⽹络中多余的 IGMP 报⽂数。\n（iii） 路由器收到主机的成员关系报⽂后，就会在 IGMP 路由表中加⼊该组播组，后续⽹络中⼀旦该组播地址的数\n据到达路由器，它会把数据包转发出去\n离开组播组⼯作机制：\n情况1：\n⽹段中仍有该组播组\n（i） 主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报⽂，报⽂的⽬的地址是 224.0.0.2（表示发向⽹段内的所有\n路由器）\n（ii） 路由器 收到该报⽂后，以 1 秒为间隔连续发送 IGMP 特定组查询报⽂（共计发送 2 个），以便确认该⽹络是\n否还有 224.1.1.1 组的其他成员。\n（iii） 主机 3 仍然是组 224.1.1.1 的成员，因此它⽴即响应这个特定组查询。路由器知道该⽹络中仍然存在该组播\n组的成员，于是继续向该⽹络转发 224.1.1.1 的组播数据包。\n情况2：\n⽹段中没有该组播组\n（i） 主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报⽂。\n（ii） 路由器收到该报⽂后，以 1 秒为间隔连续发送 IGMP 特定组查询报⽂（共计发送 2 个）。此时在该⽹段内，\n组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。\n（iii） ⼀定时间后，路由器认为该⽹段中已经没有 224.1.1.1 组播组成员了，将不会再向这个⽹段转发该组播地址\n的 数据包。\n注：组播地址不是⽤于机器ip地址的，因为组播地址没有⽹络号和主机号，所以跟dhcp没关系。组播地址⼀般是⽤",
    "question": "（3） IP分类的优缺点",
    "answer": "可以根据IP地址的前四位来判别IP地址属于哪个类别。简单明了，选路简单。\n同⼀⽹络下没有地址层次，⽐如⼀个公司⾥⽤了 B 类地址，但是可能需要根据⽣产环境、测试环境、开发环境来划\n分地址层次，⽽这种 IP 分类是没有地址层次划分的功能，所以这就缺少地址的灵活性。\nB、C类有个尴尬处境，就是不能很好的与现实⽹络匹配。\nC 类地址能包含的最⼤主机数量实在太少了，只有 254 个，估计⼀个⽹吧都不够⽤。\n⽽ B 类地址能包含的最⼤主机数量⼜太多了，6 万多台机器放在⼀个⽹络下⾯，⼀般的企业基本达不到这个规模，\n闲着的地址就是浪费。这两个缺点，都可以在 CIDR ⽆分类地址解决。\n（4） CIDR⽆分类地址\n这种⽅式不再有分类地址的概念，32 ⽐特的 IP 地址被划分为两部分，前⾯是⽹络号，后⾯是主机号。\n(i)如何划分⽹络号和主机号呢？\n表示形式 a.b.c.d/x ，其中 /x 表示前 x 位属于⽹络号， x 的范围是 0 ~ 32 ，这就使得 IP 地址更加具有灵活性。\n还有另⼀种划分⽹络号与主机号形式，那就是⼦⽹掩码，掩码的意思就是掩盖掉主机号，剩余的就是⽹络号。\n将⼦⽹掩码和 IP 地址按位计算 AND，就可得到⽹络号。\n（ii） 为什么要分离⽹络号和主机号？\n因为两台计算机要通讯，⾸先要判断是否处于同⼀个⼴播域内，即⽹络地址是否相同。如果⽹络地址相同，表明接\n受⽅在本⽹络上，那么可以把数据包直接发送到⽬标主机。\n路由器寻址⼯作中，也就是通过这样的⽅式来找到对应的⽹络号的，进⽽把数据包转发给对应的⽹络内。\n（iii） 如何进⾏⼦⽹划分？\n通过⼦⽹掩码划分出⽹络号和主机号，那实际上⼦⽹掩码还有⼀个作⽤，那就是划分⼦⽹。\n⼦⽹划分实际上是将主机地址分为两个部分：⼦⽹⽹络地址和⼦⽹主机地址。形式如下：\n假设对 C 类地址进⾏⼦⽹划分，⽹络地址 192.168.1.0，使⽤⼦⽹掩码 255.255.255.192 对其进⾏⼦⽹划分。\nC 类地址中前 24 位是⽹络号，最后 8 位是主机号，根据⼦⽹掩码可知从 8 位主机号中借⽤ 2 位作为⼦⽹号（对应\n4个⼦⽹）。\n划分后的4个⼦⽹如下：\n## 公有IP地址与私有IP地址\n在A、B、C分类地址，实际⼜分公有IP地址和私有IP地址。\n平时我们办公室、家⾥、学校⽤的 IP 地址，⼀般都是私有 IP 地址。因为这些地址允许组织内部的 IT ⼈员⾃⼰管\n理、⾃⼰分配，⽽且可以重复。\n因此，你学校的某个私有 IP 地址和我学校的可以是⼀样的。 就像每个⼩区都有⾃⼰的楼编号和⻔牌号，你⼩区家可\n以叫 1 栋 101 号，我⼩区家也可以叫 1 栋 101，没有任何问题。但⼀旦出了⼩区，就需要带上中⼭路 666 号\n（公⽹ IP 地址），是国家统⼀分配的，不能两个⼩区都叫中⼭路 666。\n所以，公有 IP 地址是有个组织统⼀分配的，假设你要开⼀个博客⽹站，那么你就需要去申请购买⼀个公有 IP，这样\n全世界的⼈才能访问。并且公有 IP 地址基本上要在整个互联⽹范围内保持唯⼀\n那么公有IP地址由谁管理呢？\n私有 IP 地址通常是内部的 IT ⼈员管理，公有 IP 地址是由 ICANN 组织管理，中⽂叫「互联⽹名称与数字地址分配\n机构」。 IANA 是 ICANN 的其中⼀个机构，它负责分配互联⽹ IP 地址，是按州的⽅式层层分配。\n## IP地址与路由控制\nIP地址的⽹络地址这⼀部分是⽤于进⾏路由控制。路由控制表中记录着⽹络地址与下⼀步应该发送⾄路由器的地\n址。在主机和路由器上都会有各⾃的路由器控制表。\n在发送 IP 包时，⾸先要确定 IP 包⾸部中的⽬标地址，再从路由控制表中找到与该地址具有相同⽹络地址的记录，\n根据该记录将 IP 包转发给相应的下⼀个路由器。如果路由控制表中存在多条相同⽹络地址的记录，就选择相同位\n数最多的⽹络地址，也就是最⻓匹配。\n举例说明：\n环回地址是不会流向⽹络：\n环回地址是在同⼀台计算机上的程序之间进⾏⽹络通信时所使⽤的⼀个默认地址。 计算机使⽤⼀个特殊的 IP 地址\n## 作为环回地址。\n与该地址具有相同意义的是⼀个叫做 localhost 的主机名。使⽤这个 IP 或主机名时，数据包不会流向⽹络\n## IP分⽚与重组\n每种数据链路的最⼤传输单元 MTU 都是不相同的，如 FDDI 数据链路 MTU 4352、以太⽹的 MTU 是 1500 字节\n每种数据链路的  MTU  之所以不同，是因为每个不同类型的数据链路的使⽤⽬的不同。使⽤⽬的不同，可承载的\nMTU 也就不同。\n其中，我们最常⻅数据链路是以太⽹，它的 MTU 是 1500 字节。 那么当 IP 数据包⼤⼩⼤于 MTU 时， IP 数据包就\n会被分⽚。 经过分⽚之后的 IP 数据报在被重组的时候，只能由⽬标主机进⾏，路由器是不会进⾏重组的。\n在分⽚传输中，⼀旦某个分⽚丢失，则会造成整个 IP 数据报作废，所以 TCP 引⼊了 MSS 也就是在 TCP 层进⾏分\n⽚不由 IP 层分⽚，那么对于 UDP 我们尽量不要发送⼀个⼤于 MTU 的数据报⽂。\n## IPV6基本认识\nIPV6:更多的地址，更好的安全性和扩展性。\n但IPV4和IPV6不能兼容。所以不但要我们电脑、⼿机之类的设备⽀持，还需要⽹络运营商对现有的设备进⾏升级，\n所以这可能是 IPv6 普及率⽐较慢的⼀个原因。\n（1） IPV6的亮点\n可分配地址变多\nIPv6 可⾃动配置，即使没有 DHCP 服务器也可以实现⾃动分配IP地址，真是便捷到即插即⽤啊。\nIPv6 包头包⾸部⻓度采⽤固定的值 40 字节，去掉了包头校验和，简化了⾸部结构，减轻了路由器负荷，⼤ ⼤提⾼了\n传输的性能。\nIPv6 有应对伪造 IP 地址的⽹络安全功能以及防⽌线路窃听的功能，⼤⼤提升了安全性。\n（2） IPV6地址的标识⽅法\nIPv4 地址⻓度共 32 位，是以每 8 位作为⼀组，并⽤点分⼗进制的表示⽅式。\nIPv6 地址⻓度是 128 位，是以每 16 位作为⼀组，每组⽤冒号 「:」 隔开。\n如果出现连续的 0 时还可以将这些 0 省略，并⽤两个冒号 「::」隔开。但是，⼀个 IP 地址中只允许出现⼀次两个\n连续的冒号。\n（3） IPV6地址的结构\nIPv6 类似 IPv4，也是通过 IP 地址的前⼏位标识 IP 地址的种类。 IPv6 的地址主要有以下类型地址：\n单播地址：⽤于⼀对⼀的通信；\n组播地址：⽤于⼀对多的通信；\n任播地址：⽤于通信最近的节点，最近的节点是由路由协议决定；\n没有⼴播地址。\nIPV6单播地址类型：\n对于⼀对⼀通信的 IPv6 地址，主要划分了三类单播地址，每类地址的有效范围都不同。\n在同⼀链路单播通信，不经过路由器，可以使⽤链路本地单播地址，IPv4  没有此类型\n在内⽹⾥单播通信，可以使⽤唯⼀本地地址，相当于 IPv4 的私有 IP\n在互联⽹通信，可以使⽤全局单播地址，相当于 IPv4 的公有 IP\n## IPV4⾸部与IPV6⾸部\nIPv4 ⾸部与 IPv6 ⾸部 IPv4 ⾸部与 IPv6 ⾸部的差异如下图：\n其中：\nIPV6相⽐IPV4的⾸部改进\n取消了⾸部校验和字段：\n因为在数据链路层和传输层都会校验，因此 IPv6 直接取消了 IP 的校验。\n取消了分⽚/重新组装相关字段：\n分⽚与重组是耗时的过程，IPv6 不允许在中间路由器进⾏分⽚与重组，这 种操作只能在源与⽬标主机，这将⼤⼤\n提⾼了路由器转发的速度。\n取消选项字段：\n选项字段不再是标准 IP ⾸部的⼀部分了，但它并没有消失，⽽是可能出现在 IPv6 ⾸部中的 「下⼀个⾸部」指出的\n位置上。删除该选项字段使的 IPv6 的⾸部成为固定⻓度的 40 字节。\n## ARP与RARP协议\n（1） ARP协议\n在传输⼀个 IP 数据报的时候，确定了源 IP 地址和⽬标 IP 地址后，就会通过主机「路由表」确定 IP 数据包下⼀\n跳。然⽽，⽹络层的下⼀层是数据链路层，所以我们还要知道「下⼀跳」的 MAC 地址。\n由于主机的路由表中可以找到下⼀跳的 IP 地址，所以可以通过 ARP 协议（Address Resolution Protocol，地址解\n析协议），求得下⼀跳的 MAC 地址。\nARP是如何知道对⽅的MAC地址的呢？ARP 是借助 ARP 请求与 ARP 响应两种类型的包确定 MAC 地址的。\n主机会通过⼴播发送 ARP 请求，这个包中包含了想要知道的 MAC 地址的主机 IP 地址。\n当同个链路中的所有设备收到 ARP 请求时，会去拆开 ARP 请求包⾥的内容，如果 ARP 请求包中的⽬标 IP 地址与\n⾃⼰的 IP 地址⼀致，那么这个设备就将⾃⼰的 MAC 地址塞⼊ ARP 响应包返回给主机。\n操作系统通常会把第⼀次通过 ARP 获取的 MAC 地址缓存起来，以便下次直接从缓存中找到对应 IP 地址的 MAC 地\n址。 不过，MAC 地址的缓存是有⼀定期限的，超过这个期限，缓存的内容将被清除。\n（2） RARP协议\nARP 协议是已知 IP 地址求 MAC 地址，那 RARP 协议正好相反，它是已知 MAC 地址求 IP 地址。\n例如将打印机服务器等⼩型嵌⼊式设备接⼊到⽹络时就经常会⽤得到。通常这需要架设⼀台 RARP 服务器，在这个\n服务器上注册设备的 MAC 地址及其 IP 地址。然后再将这个设备接⼊到⽹络\n接着：\n## DHCP动态获取IP地址\nDHCP(Dynamic Host Configuration Protocol,动态主机配置协议)。我们的电脑通常都是通过 DHCP 动态获取 IP\n地址，⼤⼤省去了配 IP 信息繁琐的过程。\n接下来，我们来看看我们的电脑是如何通过 4 个步骤的过程，获取到 IP 的：\n说明： DHCP 客户端进程监听的是 68 端⼝号，DHCP 服务端进程监听的是 67 端⼝号。\n如果租约的 DHCP IP 地址快期后，客户端会向服务器发送 DHCP 请求报⽂：\n服务器如果同意继续租⽤：\n则⽤ DHCP ACK 报⽂进⾏应答，客户端就会延⻓租期。\n服务器如果不同意继续租⽤：\n则⽤ DHCP NACK 报⽂，客户端就要停⽌使⽤租约的 IP 地址。 可以发现，DHCP 交互中，全程都是使⽤ UDP ⼴\n播通信。\n疑问：\n咦，⽤的是⼴播，那如果 DHCP 服务器和客户端不是在同⼀个局域⽹内，路由器⼜不会转发⼴播包，那不是每个⽹\n络 都要配⼀个 DHCP 服务器？\n为了解决这⼀问题，就出现了 DHCP 中继代理。有了 DHCP 中继代理以后，对不同⽹段的 IP 地址分配也 可以由⼀\n个 DHCP 服务器统⼀进⾏管理。\nDHCP 客户端会向 DHCP 中继代理发送 DHCP 请求包，⽽ DHCP 中继代理在收到这个⼴播包以后，再以单播的形\n式发给 DHCP 服务器。\n服务器端收到该包以后再向 DHCP 中继代理返回应答，并由 DHCP 中继代理将此包⼴播给 DHCP 客户端 。\n因此，DHCP 服务器即使不在同⼀个链路上也可以实现统⼀分配和管理IP地址。\n## NAT( Network Address Translation, ⽹络地址转换)\nIPv4 的地址是⾮常紧缺的，在前⾯我们也提到可以通过⽆分类地址来减缓 IPv4 地址耗尽的速度，但是互联⽹的⽤\n户增速是⾮常惊⼈的，所以 IPv4 地址依然有被耗尽的危险。\n于是，提出了⼀种⽹络地址转换 NAT 的⽅法，再次缓解了 IPv4 地址耗尽的问题。 简单的来说 NAT 就是同个公\n司、家庭、教室内的主机对外部通信时，把私有 IP 地址转换成公有 IP 地址。\n疑问：\n那不是 N 个私有 IP 地址，你就要 N 个公有 IP 地址？这怎么就缓解了 IPv4 地址耗尽的问题？这不瞎扯吗？\n确实是，普通的 NAT 转换没什么意义。 由于绝⼤多数的⽹络应⽤都是使⽤传输层协议 TCP 或 UDP 来传输数据\n的。 因此，可以把 IP 地址 + 端⼝号⼀起进⾏转换。 这样，就⽤⼀个全球 IP 地址就可以了，这种转换技术就叫⽹\n络地址与端⼝转换 NAPT。\n来看看下⾯的图解：\n图中有两个客户端 192.168.1.10 和 192.168.1.11 同时与服务器 183.232.231.172 进⾏通信，并且这两个客户端的\n本地端⼝都是 1025。 此时，两个私有 IP 地址都转换 IP 地址为公有地址 120.229.175.121，但是以不同的端⼝号\n作为区分。\n于是，⽣成⼀个 NAPT 路由器的转换表，就可以正确地转换地址跟端⼝的组合，令客户端 A、B 能同时与服务器之\n间进⾏通信。 这种转换表在 NAT 路由器上⾃动⽣成。例如，在 TCP 的情况下，建⽴ TCP 连接⾸次握⼿时的 SYN\n包⼀经发出， 就会⽣成这个表。⽽后⼜随着收到关闭连接时发出 FIN 包的确认应答从表中被删除。\n（1） NAT有缺点吗？\n由于 NAT/NAPT 都依赖于⾃⼰的转换表，因此会有以下的问题：\n外部⽆法主动与 NAT 内部服务器建⽴连接，因为 NAPT 转换表没有转换记录。\n转换表的⽣成与转换操作都会产⽣性能开销。\n通信过程中，如果 NAT 路由器重启了，所有的 TCP 连接都将被重置。\n（2） 如何解决NAT潜在的问题呢？\n改⽤IPV6：\nIPv6 可⽤范围⾮常⼤，以⾄于每台设备都可以配置⼀个公有 IP 地址，就不搞那么多花⾥胡哨的地址转换了，但是\nIPv6 普及速度还需要⼀些时间。\nNAT 穿透技术：\nNAT 穿越技术能够让⽹络应⽤程序主动发现⾃⼰位于 NAT 设备之后，并且会主动获得 NAT 设备的公有 IP，并为⾃\n⼰建⽴端⼝映射条⽬，注意这些都是 NAT设备后的应⽤程序⾃动完成的。 也就是说，客户端主动从 NAT 设备获取\n公有 IP 地址，然后⾃⼰建⽴端⼝映射条⽬，然后⽤这个条⽬对外通信， 就不需要 NAT 设备来进⾏转换了。\n## ICMP互联⽹控制报⽂协议\nICMP（ Internet Control Message Protocol，也就是互联⽹控制报⽂协议）。\n⽹络包在复杂的⽹络传输环境⾥，常常会遇到各种问题。   当遇到问题的时候，总不能死个不明不⽩，没头没脑的作\n⻛不是计算机⽹络的⻛格。所以需要传出消息，报告遇到  了什么问题，这样才可以调整传输策略，以此来控制整个局\n（1） ICMP功能都有啥\nICMP的主要功能包括：确认 IP 包是否成功送达⽬标地址、报告发送过程中 IP 包被废弃的原因和改善⽹络设置等。\n在 IP 通信中如果某个 IP 包因为某种原因未能达到⽬标地址，那么这个具体的原因将由 ICMP 负责通知。\nICMP 的这种通知消息会使⽤IP进⾏发送 。 因此，从路由器 2 返回的 ICMP 包会按照往常的路由控制先经过路由器\n1 再转发给主机A 。收到该 ICMP 包的主机 A 则分解 ICMP 的⾸部和数据域以后得知具体发⽣问题的原因。\n（2） ICMP的类型\nICMP⼤致可以分为两⼤类：\n⼀类是⽤于诊断的查询消息，也就是「查询报⽂类型」\n⼀类是通知出错原因的错误消息，也就是「差错报⽂类型」\n## IGMP因特⽹组管理协议\n在前⾯我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有⼀组的主机能收到数据包，不在⼀组的\n主机不能收到数组包，怎么管理是否是在⼀组呢？\n那么，就需要 IGMP 协议了。\nIGMP  是因特⽹组管理协议，⼯作在主机（组播成员）和最后⼀跳路由之间，如上图中的蓝⾊部分。\nIGMP 报⽂向路由器申请加⼊和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除⾮主机通过\nIGMP 加⼊到组播组，主机申请加⼊到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转 发组播包到对\n应的主机了。\nIGMP 报⽂采⽤ IP 封装，IP 头部的协议号为 2，⽽且 TTL 字段值通常为 1，因为 IGMP 是⼯作在主机与连接的路由\n器之间。\n（1） IGMP的⼯作机制\nIGMP 分为了三个版本分别是，IGMPv1、IGMPv2、IGMPv3。 接下来，以 IGMPv2 作为例⼦，说说常规查询与响\n应和离开组播组这两个⼯作机制。\n常规查询与响应机制：\n（i） 路由器会周期性发送⽬的地址为 224.0.0.1 （表示同⼀⽹段内所有主机和路由器） IGMP 常规查询报⽂。\n（ii） 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10\n秒，计时器超时后主机就会发送 IGMP 成员关系报告报⽂（源 IP 地址为⾃⼰主机的 IP 地址，⽬的 IP 地址为组播地\n址）。如果在定时器超时之前，收到同⼀个组内的其他主机发送的成员关系报告报⽂，则⾃⼰不再发  送，这样可以减\n少⽹络中多余的 IGMP 报⽂数。\n（iii） 路由器收到主机的成员关系报⽂后，就会在 IGMP 路由表中加⼊该组播组，后续⽹络中⼀旦该组播地址的数\n据到达路由器，它会把数据包转发出去\n离开组播组⼯作机制：\n情况1：\n⽹段中仍有该组播组\n（i） 主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报⽂，报⽂的⽬的地址是 224.0.0.2（表示发向⽹段内的所有\n路由器）\n（ii） 路由器 收到该报⽂后，以 1 秒为间隔连续发送 IGMP 特定组查询报⽂（共计发送 2 个），以便确认该⽹络是\n否还有 224.1.1.1 组的其他成员。\n（iii） 主机 3 仍然是组 224.1.1.1 的成员，因此它⽴即响应这个特定组查询。路由器知道该⽹络中仍然存在该组播\n组的成员，于是继续向该⽹络转发 224.1.1.1 的组播数据包。\n情况2：\n⽹段中没有该组播组\n（i） 主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报⽂。\n（ii） 路由器收到该报⽂后，以 1 秒为间隔连续发送 IGMP 特定组查询报⽂（共计发送 2 个）。此时在该⽹段内，\n组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。\n（iii） ⼀定时间后，路由器认为该⽹段中已经没有 224.1.1.1 组播组成员了，将不会再向这个⽹段转发该组播地址\n的 数据包。\n注：组播地址不是⽤于机器ip地址的，因为组播地址没有⽹络号和主机号，所以跟dhcp没关系。组播地址⼀般是⽤",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 7624,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000019",
    "content": "## IGMP因特⽹组管理协议\n\n在前⾯我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有⼀组的主机能收到数据包，不在⼀组的\n主机不能收到数组包，怎么管理是否是在⼀组呢？\n那么，就需要 IGMP 协议了。\nIGMP  是因特⽹组管理协议，⼯作在主机（组播成员）和最后⼀跳路由之间，如上图中的蓝⾊部分。\nIGMP 报⽂向路由器申请加⼊和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除⾮主机通过\nIGMP 加⼊到组播组，主机申请加⼊到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转 发组播包到对\n应的主机了。\nIGMP 报⽂采⽤ IP 封装，IP 头部的协议号为 2，⽽且 TTL 字段值通常为 1，因为 IGMP 是⼯作在主机与连接的路由\n器之间。\n（1） IGMP的⼯作机制\nIGMP 分为了三个版本分别是，IGMPv1、IGMPv2、IGMPv3。 接下来，以 IGMPv2 作为例⼦，说说常规查询与响\n应和离开组播组这两个⼯作机制。\n常规查询与响应机制：\n（i） 路由器会周期性发送⽬的地址为 224.0.0.1 （表示同⼀⽹段内所有主机和路由器） IGMP 常规查询报⽂。\n（ii） 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10\n秒，计时器超时后主机就会发送 IGMP 成员关系报告报⽂（源 IP 地址为⾃⼰主机的 IP 地址，⽬的 IP 地址为组播地\n址）。如果在定时器超时之前，收到同⼀个组内的其他主机发送的成员关系报告报⽂，则⾃⼰不再发  送，这样可以减\n少⽹络中多余的 IGMP 报⽂数。\n（iii） 路由器收到主机的成员关系报⽂后，就会在 IGMP 路由表中加⼊该组播组，后续⽹络中⼀旦该组播地址的数\n据到达路由器，它会把数据包转发出去\n离开组播组⼯作机制：\n情况1：\n⽹段中仍有该组播组\n（i） 主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报⽂，报⽂的⽬的地址是 224.0.0.2（表示发向⽹段内的所有\n路由器）\n（ii） 路由器 收到该报⽂后，以 1 秒为间隔连续发送 IGMP 特定组查询报⽂（共计发送 2 个），以便确认该⽹络是\n否还有 224.1.1.1 组的其他成员。\n（iii） 主机 3 仍然是组 224.1.1.1 的成员，因此它⽴即响应这个特定组查询。路由器知道该⽹络中仍然存在该组播\n组的成员，于是继续向该⽹络转发 224.1.1.1 的组播数据包。\n情况2：\n⽹段中没有该组播组\n（i） 主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报⽂。\n（ii） 路由器收到该报⽂后，以 1 秒为间隔连续发送 IGMP 特定组查询报⽂（共计发送 2 个）。此时在该⽹段内，\n组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。\n（iii） ⼀定时间后，路由器认为该⽹段中已经没有 224.1.1.1 组播组成员了，将不会再向这个⽹段转发该组播地址\n的 数据包。\n注：组播地址不是⽤于机器ip地址的，因为组播地址没有⽹络号和主机号，所以跟dhcp没关系。组播地址⼀般是⽤\n于 udp协议，机器发送UDP组播数据时，⽬标地址填的是组播地址，那么在组播组内的机器都能收到数据包。 是否\n加⼊组播组和离开组播组，是由socket⼀个接⼝实现的，主机ip是不⽤改变的。\n在浏览器中输⼊URL并按下回⻋之后会发⽣什么\n经过了上⾯内容的学习之后，再看这道题⽬的剖析\nURL，⽣成发送给WEB服务器的请求信息。",
    "question": "## IGMP因特⽹组管理协议",
    "answer": "在前⾯我们知道了组播地址，也就是 D 类地址，既然是组播，那就说明是只有⼀组的主机能收到数据包，不在⼀组的\n主机不能收到数组包，怎么管理是否是在⼀组呢？\n那么，就需要 IGMP 协议了。\nIGMP  是因特⽹组管理协议，⼯作在主机（组播成员）和最后⼀跳路由之间，如上图中的蓝⾊部分。\nIGMP 报⽂向路由器申请加⼊和退出组播组，默认情况下路由器是不会转发组播包到连接中的主机，除⾮主机通过\nIGMP 加⼊到组播组，主机申请加⼊到组播组时，路由器就会记录 IGMP 路由器表，路由器后续就会转 发组播包到对\n应的主机了。\nIGMP 报⽂采⽤ IP 封装，IP 头部的协议号为 2，⽽且 TTL 字段值通常为 1，因为 IGMP 是⼯作在主机与连接的路由\n器之间。\n（1） IGMP的⼯作机制\nIGMP 分为了三个版本分别是，IGMPv1、IGMPv2、IGMPv3。 接下来，以 IGMPv2 作为例⼦，说说常规查询与响\n应和离开组播组这两个⼯作机制。\n常规查询与响应机制：\n（i） 路由器会周期性发送⽬的地址为 224.0.0.1 （表示同⼀⽹段内所有主机和路由器） IGMP 常规查询报⽂。\n（ii） 主机1 和 主机 3 收到这个查询，随后会启动「报告延迟计时器」，计时器的时间是随机的，通常是 0~10\n秒，计时器超时后主机就会发送 IGMP 成员关系报告报⽂（源 IP 地址为⾃⼰主机的 IP 地址，⽬的 IP 地址为组播地\n址）。如果在定时器超时之前，收到同⼀个组内的其他主机发送的成员关系报告报⽂，则⾃⼰不再发  送，这样可以减\n少⽹络中多余的 IGMP 报⽂数。\n（iii） 路由器收到主机的成员关系报⽂后，就会在 IGMP 路由表中加⼊该组播组，后续⽹络中⼀旦该组播地址的数\n据到达路由器，它会把数据包转发出去\n离开组播组⼯作机制：\n情况1：\n⽹段中仍有该组播组\n（i） 主机 1 要离开组 224.1.1.1，发送 IGMPv2 离组报⽂，报⽂的⽬的地址是 224.0.0.2（表示发向⽹段内的所有\n路由器）\n（ii） 路由器 收到该报⽂后，以 1 秒为间隔连续发送 IGMP 特定组查询报⽂（共计发送 2 个），以便确认该⽹络是\n否还有 224.1.1.1 组的其他成员。\n（iii） 主机 3 仍然是组 224.1.1.1 的成员，因此它⽴即响应这个特定组查询。路由器知道该⽹络中仍然存在该组播\n组的成员，于是继续向该⽹络转发 224.1.1.1 的组播数据包。\n情况2：\n⽹段中没有该组播组\n（i） 主机 1 要离开组播组 224.1.1.1，发送 IGMP 离组报⽂。\n（ii） 路由器收到该报⽂后，以 1 秒为间隔连续发送 IGMP 特定组查询报⽂（共计发送 2 个）。此时在该⽹段内，\n组 224.1.1.1 已经没有其他成员了，因此没有主机响应这个查询。\n（iii） ⼀定时间后，路由器认为该⽹段中已经没有 224.1.1.1 组播组成员了，将不会再向这个⽹段转发该组播地址\n的 数据包。\n注：组播地址不是⽤于机器ip地址的，因为组播地址没有⽹络号和主机号，所以跟dhcp没关系。组播地址⼀般是⽤\n于 udp协议，机器发送UDP组播数据时，⽬标地址填的是组播地址，那么在组播组内的机器都能收到数据包。 是否\n加⼊组播组和离开组播组，是由socket⼀个接⼝实现的，主机ip是不⽤改变的。\n在浏览器中输⼊URL并按下回⻋之后会发⽣什么\n经过了上⾯内容的学习之后，再看这道题⽬的剖析\nURL，⽣成发送给WEB服务器的请求信息。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1494,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000020",
    "content": "于 udp协议，机器发送UDP组播数据时，⽬标地址填的是组播地址，那么在组播组内的机器都能收到数据包。 是否\n\n加⼊组播组和离开组播组，是由socket⼀个接⼝实现的，主机ip是不⽤改变的。",
    "question": "于 udp协议，机器发送UDP组播数据时，⽬标地址填的是组播地址，那么在组播组内的机器都能收到数据包。 是否",
    "answer": "加⼊组播组和离开组播组，是由socket⼀个接⼝实现的，主机ip是不⽤改变的。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 95,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000021",
    "content": "在浏览器中输⼊URL并按下回⻋之后会发⽣什么\n\n经过了上⾯内容的学习之后，再看这道题⽬的剖析\nURL，⽣成发送给WEB服务器的请求信息。\n## 解析URL\n所以⻓⻓的 URL 实际上是请求服务器⾥的⽂件资源。\n当图（a）示意图中的蓝⾊部分元素省略后（即：没有路径名），代表访问根⽬录下事先设置的默认⽂件，也就是\n/index.html 或者/default.html 这些⽂件，这样就不会发⽣混乱了。\n## ⽣成HTTP请求信息\n对 URL 进⾏解析之后，浏览器确定了 Web 服务器和⽂件名，接下来就是根据这些信息来⽣成 HTTP 请求消息了。\n## DNS域名解析\n通过浏览器解析 URL 并⽣成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。\n但在发送之前，还有⼀项⼯作需要完成，那就是查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，\n必须提供通信对象的 IP 地址。\n有⼀种服务器就专⻔保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器。\n（1）域名的层级关系\n根域的 DNS 服务器信息保存在互联⽹中所有的 DNS 服务器中。这样⼀来，任何 DNS 服务器就都可以找到并访问\n根域 DNS 服务器了。 因此，客户端只要能够找到任意⼀台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然\n后再⼀路顺藤摸⽠找到位于下层的某台⽬标 DNS 服务器。\n如下图所示：\n## 协议栈：如何发送数据包\n数据包表示：“DNS   ⽼⼤哥厉害呀，找到了⽬的地了！我还是很迷茫呀，我要发出去，接下来我需要谁的帮助呢?”\nSocket\n通过 DNS 获取到 IP 后，就可以把 HTTP 的传输⼯作交给操作系统中的协议栈。协议栈的内部分为⼏个部分，分别\n承担不同的⼯作。上下关系是有⼀定的规则的，上⾯的部分会向下⾯的部分委托⼯作，下⾯的部分收到委托的⼯作\n并执⾏。\n应⽤程序（浏览器）通过调⽤\n库，来委托协议栈⼯作。协议栈的上半部分有两块，分别是负责收发数据的\nTCP 和 UDP 协议，它们两会接受应⽤层的委托执⾏收发数据的操作。\n协议栈的下⾯⼀半是⽤ IP 协议控制⽹络包收发操作，在互联⽹上传数据时，数据会被切分成⼀块块的⽹络包，⽽\n将⽹络包发送给对⽅的操作就是由 IP 负责的。 此外 IP 中还包括 ICMP 协议和 ARP 协议。\nICMP  ⽤于告知⽹络包传送过程中产⽣的错误以及各种控制信息\nARP ⽤于根据 IP 地址查询相应的以太⽹ MAC 地址\nIP   下⾯的⽹卡驱动程序负责控制⽹卡硬件，⽽最下⾯的⽹卡则负责完成实际的收发操作，也就是对⽹线中的信号执\n⾏发送和接收操作。\n## 可靠传输—TCP\n数据包看了这份指南表示：“原来我需要那么多⼤佬的协助啊，那我先去找找 TCP ⼤佬！”\n（1） TCP包头格式\nHTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议。\nTCP包头格式：\n⾸先，源端⼝号 和 ⽬标端⼝号是不可少的，如果没有这两个端⼝号，数据就不知道应该发给哪个应⽤。接\n下来有包的序号，这个是为了解决包乱序的问题。\n还有应该有的是确认号，⽬的是确认发出去对⽅是否有收到。如果没有收到就应该重新发送，直到送达，这个是为\n了解决不丢包的问题。\n接下来还有⼀些状态位。例如 SYN 是发起⼀个连接， ACK 是回复， RST 是重新连接， FIN 是结束连接等。TCP 是\n⾯向连接的，因⽽双⽅要维护连接的状态，这些带状态位的包的发送，会引起双⽅的状态变更。\n还有⼀个重要的就是窗⼝⼤⼩。TCP 要做流量控制，通信双⽅各声明⼀个窗⼝（缓存⼤⼩），标识⾃⼰当前能够的\n处理能⼒，别发送的太快，撑死我，也别发的太慢，饿死我。\n除了做流量控制以外，TCP还会做拥塞控制，对于真正的通路堵⻋不堵⻋，它⽆能为⼒，唯⼀能做的就是控制⾃\n⼰，也即控制发送的速度。不能改变世界，就改变⾃⼰嘛。\n（2） TCP 传输数据之前，要先三次握⼿建⽴连接\n这个所谓的「连接」，只是双⽅计算机⾥维护⼀个状态机，在连接建⽴的过程中，双⽅的状态变化时序图就像这\n⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端⼝，处于 LISTEN 状态。\n然后客户端主动发起连接 SYN ，之后处于 SYN-SENT 状态。\n服务端收到发起的连接，返回 SYN ，并且 ACK 客户端的 SYN ，之后处于 SYN-RCVD 状态。\n客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK ，之后处于 ESTABLISHED 状态， 因为它⼀发⼀收\n成功了。\n服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也⼀发⼀收了。\n所以三次握⼿⽬的是保证双⽅都有发送和接收的能⼒。\n（3） 如何查看TCP的连接状态？\nTCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。\n（4） TCP分割数据\n如果 HTTP 请求消息⽐较⻓，超过了 MSS 的⻓度，这时 TCP 就需要把 HTTP 的数据拆解成⼀块块的数据发送，⽽\n不是⼀次性发送所有数据。\n数据会被以 MSS 的⻓度为单位进⾏拆分，拆分出来的每⼀块数据都会被放进单独的⽹络包中。也就是在每个被拆\n分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。\n（5） TCP报⽂⽣成\nTCP 协议⾥⾯会有两个端⼝，⼀个是浏览器监听的端⼝（通常是随机⽣成的），⼀个是 Web 服务器监听的端⼝\n（HTTP 默认端⼝号是 80 ， HTTPS 默认端⼝号是 443 ）。\n在双⽅建⽴了连接后，TCP 报⽂中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报⽂之后，就需交给下⾯\n的⽹络层处理。⽹络包的报⽂如下图：\n此时，遇上了 TCP 的数据包激动表示：“太好了，碰到了可靠传输的 TCP 传输，它给我加上 TCP 头部，我不再孤单\n了，安全感⼗⾜啊！有⼤佬可以保护我的可靠送达！但我应该往哪⾛呢？”（ 远程定位—IP ）\n## IP包头格式\nTCP 模块在执⾏连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成⽹络包发送给通信对象。\n（1） IP包头格式如下：\n在 IP 协议⾥⾯需要有源地址 IP 和 ⽬标地址 IP：\n源地址IP：即是客户端输出的 IP 地址\n⽬标地址：即通过 DNS 域名解析得到的 Web 服务器 IP\n因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06 （⼗六进制），表示协议为 TCP。\n（2） 假设客户端有多个⽹卡\n就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？\n当存在多个⽹卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块⽹卡中判断\n应该使⽤哪个⼀块⽹卡来发送包。这个时候就需要根据路由表规则，来判断哪⼀个⽹卡作为源地址 IP。\n在 Linux 操作系统，我们可以使⽤ route -n 命令查看当前系统的路由表。\n第三条⽬⽐较特殊，它⽬标地址和⼦⽹掩码都是  0.0.0.0  ，这表示默认⽹关，如果其他所有条⽬都⽆法匹配，就会\n⾃动匹配这⼀⾏。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。\n（3） IP报⽂⽣成\n## 两点传输-MAC\n此时，加上了 IP 头部的数据包表示 ：“有 IP ⼤佬给我指路了，感谢 IP 层给我加上了 IP 包头，让我有了远程定位的\n能⼒！不会害怕在浩瀚的互联⽹迷茫了！可是⽬的地好远啊，我下⼀站应该去哪呢？”\n⽣成了 IP 头部之后，接下来⽹络包还需要在 IP 头部的前⾯加上 MAC 头部。\n（1） MAC包头格式\nMAC 头部是以太⽹使⽤的头部，它包含了接收⽅和发送⽅的 MAC 地址等信息。\n⼀般在 TCP/IP 通信⾥，MAC 包头的协议类型只使⽤：",
    "question": "在浏览器中输⼊URL并按下回⻋之后会发⽣什么",
    "answer": "经过了上⾯内容的学习之后，再看这道题⽬的剖析\nURL，⽣成发送给WEB服务器的请求信息。\n## 解析URL\n所以⻓⻓的 URL 实际上是请求服务器⾥的⽂件资源。\n当图（a）示意图中的蓝⾊部分元素省略后（即：没有路径名），代表访问根⽬录下事先设置的默认⽂件，也就是\n/index.html 或者/default.html 这些⽂件，这样就不会发⽣混乱了。\n## ⽣成HTTP请求信息\n对 URL 进⾏解析之后，浏览器确定了 Web 服务器和⽂件名，接下来就是根据这些信息来⽣成 HTTP 请求消息了。\n## DNS域名解析\n通过浏览器解析 URL 并⽣成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。\n但在发送之前，还有⼀项⼯作需要完成，那就是查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，\n必须提供通信对象的 IP 地址。\n有⼀种服务器就专⻔保存了 Web 服务器域名与 IP 的对应关系，它就是 DNS 服务器。\n（1）域名的层级关系\n根域的 DNS 服务器信息保存在互联⽹中所有的 DNS 服务器中。这样⼀来，任何 DNS 服务器就都可以找到并访问\n根域 DNS 服务器了。 因此，客户端只要能够找到任意⼀台 DNS 服务器，就可以通过它找到根域 DNS 服务器，然\n后再⼀路顺藤摸⽠找到位于下层的某台⽬标 DNS 服务器。\n如下图所示：\n## 协议栈：如何发送数据包\n数据包表示：“DNS   ⽼⼤哥厉害呀，找到了⽬的地了！我还是很迷茫呀，我要发出去，接下来我需要谁的帮助呢?”\nSocket\n通过 DNS 获取到 IP 后，就可以把 HTTP 的传输⼯作交给操作系统中的协议栈。协议栈的内部分为⼏个部分，分别\n承担不同的⼯作。上下关系是有⼀定的规则的，上⾯的部分会向下⾯的部分委托⼯作，下⾯的部分收到委托的⼯作\n并执⾏。\n应⽤程序（浏览器）通过调⽤\n库，来委托协议栈⼯作。协议栈的上半部分有两块，分别是负责收发数据的\nTCP 和 UDP 协议，它们两会接受应⽤层的委托执⾏收发数据的操作。\n协议栈的下⾯⼀半是⽤ IP 协议控制⽹络包收发操作，在互联⽹上传数据时，数据会被切分成⼀块块的⽹络包，⽽\n将⽹络包发送给对⽅的操作就是由 IP 负责的。 此外 IP 中还包括 ICMP 协议和 ARP 协议。\nICMP  ⽤于告知⽹络包传送过程中产⽣的错误以及各种控制信息\nARP ⽤于根据 IP 地址查询相应的以太⽹ MAC 地址\nIP   下⾯的⽹卡驱动程序负责控制⽹卡硬件，⽽最下⾯的⽹卡则负责完成实际的收发操作，也就是对⽹线中的信号执\n⾏发送和接收操作。\n## 可靠传输—TCP\n数据包看了这份指南表示：“原来我需要那么多⼤佬的协助啊，那我先去找找 TCP ⼤佬！”\n（1） TCP包头格式\nHTTP 是基于 TCP 协议传输的，所以在这我们先了解下 TCP 协议。\nTCP包头格式：\n⾸先，源端⼝号 和 ⽬标端⼝号是不可少的，如果没有这两个端⼝号，数据就不知道应该发给哪个应⽤。接\n下来有包的序号，这个是为了解决包乱序的问题。\n还有应该有的是确认号，⽬的是确认发出去对⽅是否有收到。如果没有收到就应该重新发送，直到送达，这个是为\n了解决不丢包的问题。\n接下来还有⼀些状态位。例如 SYN 是发起⼀个连接， ACK 是回复， RST 是重新连接， FIN 是结束连接等。TCP 是\n⾯向连接的，因⽽双⽅要维护连接的状态，这些带状态位的包的发送，会引起双⽅的状态变更。\n还有⼀个重要的就是窗⼝⼤⼩。TCP 要做流量控制，通信双⽅各声明⼀个窗⼝（缓存⼤⼩），标识⾃⼰当前能够的\n处理能⼒，别发送的太快，撑死我，也别发的太慢，饿死我。\n除了做流量控制以外，TCP还会做拥塞控制，对于真正的通路堵⻋不堵⻋，它⽆能为⼒，唯⼀能做的就是控制⾃\n⼰，也即控制发送的速度。不能改变世界，就改变⾃⼰嘛。\n（2） TCP 传输数据之前，要先三次握⼿建⽴连接\n这个所谓的「连接」，只是双⽅计算机⾥维护⼀个状态机，在连接建⽴的过程中，双⽅的状态变化时序图就像这\n⼀开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端⼝，处于 LISTEN 状态。\n然后客户端主动发起连接 SYN ，之后处于 SYN-SENT 状态。\n服务端收到发起的连接，返回 SYN ，并且 ACK 客户端的 SYN ，之后处于 SYN-RCVD 状态。\n客户端收到服务端发送的 SYN 和 ACK 之后，发送 ACK 的 ACK ，之后处于 ESTABLISHED 状态， 因为它⼀发⼀收\n成功了。\n服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也⼀发⼀收了。\n所以三次握⼿⽬的是保证双⽅都有发送和接收的能⼒。\n（3） 如何查看TCP的连接状态？\nTCP 的连接状态查看，在 Linux 可以通过 netstat -napt 命令查看。\n（4） TCP分割数据\n如果 HTTP 请求消息⽐较⻓，超过了 MSS 的⻓度，这时 TCP 就需要把 HTTP 的数据拆解成⼀块块的数据发送，⽽\n不是⼀次性发送所有数据。\n数据会被以 MSS 的⻓度为单位进⾏拆分，拆分出来的每⼀块数据都会被放进单独的⽹络包中。也就是在每个被拆\n分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。\n（5） TCP报⽂⽣成\nTCP 协议⾥⾯会有两个端⼝，⼀个是浏览器监听的端⼝（通常是随机⽣成的），⼀个是 Web 服务器监听的端⼝\n（HTTP 默认端⼝号是 80 ， HTTPS 默认端⼝号是 443 ）。\n在双⽅建⽴了连接后，TCP 报⽂中的数据部分就是存放 HTTP 头部 + 数据，组装好 TCP 报⽂之后，就需交给下⾯\n的⽹络层处理。⽹络包的报⽂如下图：\n此时，遇上了 TCP 的数据包激动表示：“太好了，碰到了可靠传输的 TCP 传输，它给我加上 TCP 头部，我不再孤单\n了，安全感⼗⾜啊！有⼤佬可以保护我的可靠送达！但我应该往哪⾛呢？”（ 远程定位—IP ）\n## IP包头格式\nTCP 模块在执⾏连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成⽹络包发送给通信对象。\n（1） IP包头格式如下：\n在 IP 协议⾥⾯需要有源地址 IP 和 ⽬标地址 IP：\n源地址IP：即是客户端输出的 IP 地址\n⽬标地址：即通过 DNS 域名解析得到的 Web 服务器 IP\n因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06 （⼗六进制），表示协议为 TCP。\n（2） 假设客户端有多个⽹卡\n就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？\n当存在多个⽹卡时，在填写源地址 IP 时，就需要判断到底应该填写哪个地址。这个判断相当于在多块⽹卡中判断\n应该使⽤哪个⼀块⽹卡来发送包。这个时候就需要根据路由表规则，来判断哪⼀个⽹卡作为源地址 IP。\n在 Linux 操作系统，我们可以使⽤ route -n 命令查看当前系统的路由表。\n第三条⽬⽐较特殊，它⽬标地址和⼦⽹掩码都是  0.0.0.0  ，这表示默认⽹关，如果其他所有条⽬都⽆法匹配，就会\n⾃动匹配这⼀⾏。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。\n（3） IP报⽂⽣成\n## 两点传输-MAC\n此时，加上了 IP 头部的数据包表示 ：“有 IP ⼤佬给我指路了，感谢 IP 层给我加上了 IP 包头，让我有了远程定位的\n能⼒！不会害怕在浩瀚的互联⽹迷茫了！可是⽬的地好远啊，我下⼀站应该去哪呢？”\n⽣成了 IP 头部之后，接下来⽹络包还需要在 IP 头部的前⾯加上 MAC 头部。\n（1） MAC包头格式\nMAC 头部是以太⽹使⽤的头部，它包含了接收⽅和发送⽅的 MAC 地址等信息。\n⼀般在 TCP/IP 通信⾥，MAC 包头的协议类型只使⽤：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3290,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000022",
    "content": "## 两点传输-MAC\n\n此时，加上了 IP 头部的数据包表示 ：“有 IP ⼤佬给我指路了，感谢 IP 层给我加上了 IP 包头，让我有了远程定位的\n能⼒！不会害怕在浩瀚的互联⽹迷茫了！可是⽬的地好远啊，我下⼀站应该去哪呢？”\n⽣成了 IP 头部之后，接下来⽹络包还需要在 IP 头部的前⾯加上 MAC 头部。\n（1） MAC包头格式\nMAC 头部是以太⽹使⽤的头部，它包含了接收⽅和发送⽅的 MAC 地址等信息。\n⼀般在 TCP/IP 通信⾥，MAC 包头的协议类型只使⽤：\n0800：IP 协议\n0806：ARP 协议\n（2） MAC发送⽅和接收⽅如何确认\n发送⽅的 MAC 地址获取就⽐较简单了，MAC 地址是在⽹卡⽣产时写⼊到 ROM ⾥的，只要将这个值读取出来写⼊\n到 MAC 头部就可以了。\n接收⽅的 MAC 地址就有点复杂了，只要告诉以太⽹对⽅的 MAC 的地址，以太⽹就会帮我们把包发送过去，那么\n很显然这⾥应该填写对⽅的 MAC 地址。\n所以先得搞清楚应该把包发给谁，这个只要查⼀下路由表就知道了。在路由表中找到相匹配的条⽬，然后把包发给\nGateway 列中的 IP 地址就可以了。\n（3） 既然知道要发给谁，按如何获取对⽅的 MAC 地址\n不知道对⽅ MAC 地址？不知道就喊呗。此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。\n（4） 如果每次都要⼴播获取，那不是很麻烦吗？\n后续操作系统会把本次查询结果放到⼀块叫做 ARP 缓存的内存空间留着以后⽤，不过缓存的时间就⼏分钟。也就\n是说，在发包时：\n先查询 ARP 缓存，如果其中已经保存了对⽅的 MAC 地址，就不需要发送 ARP 查询，直接使⽤ ARP 缓存中\n的地址。\n⽽当 ARP 缓存中不存在对⽅ MAC 地址时，则发送 ARP ⼴播查询。\n（5） 查看ARP缓存内容\n在 Linux 系统中，我们可以使⽤ arp -a 命令来查看 ARP 缓存的内容。\n（6） MAC报⽂⽣成",
    "question": "## 两点传输-MAC",
    "answer": "此时，加上了 IP 头部的数据包表示 ：“有 IP ⼤佬给我指路了，感谢 IP 层给我加上了 IP 包头，让我有了远程定位的\n能⼒！不会害怕在浩瀚的互联⽹迷茫了！可是⽬的地好远啊，我下⼀站应该去哪呢？”\n⽣成了 IP 头部之后，接下来⽹络包还需要在 IP 头部的前⾯加上 MAC 头部。\n（1） MAC包头格式\nMAC 头部是以太⽹使⽤的头部，它包含了接收⽅和发送⽅的 MAC 地址等信息。\n⼀般在 TCP/IP 通信⾥，MAC 包头的协议类型只使⽤：\n0800：IP 协议\n0806：ARP 协议\n（2） MAC发送⽅和接收⽅如何确认\n发送⽅的 MAC 地址获取就⽐较简单了，MAC 地址是在⽹卡⽣产时写⼊到 ROM ⾥的，只要将这个值读取出来写⼊\n到 MAC 头部就可以了。\n接收⽅的 MAC 地址就有点复杂了，只要告诉以太⽹对⽅的 MAC 的地址，以太⽹就会帮我们把包发送过去，那么\n很显然这⾥应该填写对⽅的 MAC 地址。\n所以先得搞清楚应该把包发给谁，这个只要查⼀下路由表就知道了。在路由表中找到相匹配的条⽬，然后把包发给\nGateway 列中的 IP 地址就可以了。\n（3） 既然知道要发给谁，按如何获取对⽅的 MAC 地址\n不知道对⽅ MAC 地址？不知道就喊呗。此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。\n（4） 如果每次都要⼴播获取，那不是很麻烦吗？\n后续操作系统会把本次查询结果放到⼀块叫做 ARP 缓存的内存空间留着以后⽤，不过缓存的时间就⼏分钟。也就\n是说，在发包时：\n先查询 ARP 缓存，如果其中已经保存了对⽅的 MAC 地址，就不需要发送 ARP 查询，直接使⽤ ARP 缓存中\n的地址。\n⽽当 ARP 缓存中不存在对⽅ MAC 地址时，则发送 ARP ⼴播查询。\n（5） 查看ARP缓存内容\n在 Linux 系统中，我们可以使⽤ arp -a 命令来查看 ARP 缓存的内容。\n（6） MAC报⽂⽣成",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 837,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000023",
    "content": "0806：ARP 协议\n\n（2） MAC发送⽅和接收⽅如何确认\n发送⽅的 MAC 地址获取就⽐较简单了，MAC 地址是在⽹卡⽣产时写⼊到 ROM ⾥的，只要将这个值读取出来写⼊\n到 MAC 头部就可以了。\n接收⽅的 MAC 地址就有点复杂了，只要告诉以太⽹对⽅的 MAC 的地址，以太⽹就会帮我们把包发送过去，那么\n很显然这⾥应该填写对⽅的 MAC 地址。\n所以先得搞清楚应该把包发给谁，这个只要查⼀下路由表就知道了。在路由表中找到相匹配的条⽬，然后把包发给\nGateway 列中的 IP 地址就可以了。\n（3） 既然知道要发给谁，按如何获取对⽅的 MAC 地址\n不知道对⽅ MAC 地址？不知道就喊呗。此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。\n（4） 如果每次都要⼴播获取，那不是很麻烦吗？\n后续操作系统会把本次查询结果放到⼀块叫做 ARP 缓存的内存空间留着以后⽤，不过缓存的时间就⼏分钟。也就\n是说，在发包时：\n先查询 ARP 缓存，如果其中已经保存了对⽅的 MAC 地址，就不需要发送 ARP 查询，直接使⽤ ARP 缓存中\n的地址。\n⽽当 ARP 缓存中不存在对⽅ MAC 地址时，则发送 ARP ⼴播查询。\n（5） 查看ARP缓存内容\n在 Linux 系统中，我们可以使⽤ arp -a 命令来查看 ARP 缓存的内容。\n（6） MAC报⽂⽣成\n## 出⼝-⽹卡\n此时，加上了 MAC 头部的数据包万分感谢，说道 ：“感谢 MAC ⼤佬，我知道我下⼀步要去哪了！我现在有很多头\n部兄弟，相信我可以到达最终的⽬的地！”。带着众多头部兄弟的数据包，终于准备要出⻔了。\n⽹络包只是存放在内存中的⼀串⼆进制数字信息，没有办法直接发送给对⽅。因此，我们需要将数字信息转换为电\n信号，才能在⽹线上传输，也就是说，这才是真正的数据发送过程。负责执⾏这⼀操作的是⽹卡，要控制⽹卡还需\n要靠⽹卡驱动程序。\n⽹卡驱动从 IP 模块获取到包之后，会将其复制到⽹卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，\n在末尾加上⽤于检测错误的帧校验序列。\n起始帧分界符是⼀个⽤来表示包起始位置的标记\n末尾的 FCS （帧校验序列）⽤来检查包传输过程是否有损坏\n最后⽹卡会将包转为电信号，通过⽹线发送出去。\n## 送别者—交换机\n唉，真是不容易，发⼀个包，真是历经千⾟万苦。致此，⼀个带有许多头部的数据终于踏上寻找⽬的地的征途了！\n下⾯来看⼀下包是如何通过交换机的？交换机的设计是将⽹络包原样转发到⽬的地。交换机⼯作在 MAC 层，也称\n为⼆层⽹络设备。\n（1） 交换机的包接收操作\n⾸先，电信号到达⽹线接⼝，交换机⾥的模块进⾏接收，接下来交换机⾥的模块将电信号转换为数字信号。\n然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的⽹卡相同，但交换机的⼯\n作⽅式和⽹卡不同。\n计算机的⽹卡本身具有 MAC 地址，并通过核对收到的包的接收⽅ MAC 地址判断是不是发给⾃⼰的，如果不是发\n给⾃⼰的则丢弃；相对地，交换机的端⼝不核对接收⽅ MAC 地址，⽽是直接接收所有的包并存放到缓冲区中。\n因此，和⽹卡不同，交换机的端⼝不具有 MAC 地址。\n将包存⼊缓冲区后，接下来需要查询⼀下这个包的接收⽅ MAC 地址是否已经在 MAC 地址表中有记录了。\n交换机的 MAC 地址表主要包含两个信息：\n⼀个是设备的 MAC 地址\n⼀个是该设备连接在交换机的哪个端⼝上\n交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端⼝。\n（2） 当 MAC 地址表找不到指定的 MAC 地址会怎么样？、\n地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备⼀段\n时间没有⼯作导致地址被从地址表中删除了。\n这种情况下，交换机⽆法判断应该把包转发到哪个端⼝，只能将包转发到除了源端⼝之外的所有端⼝上，⽆论该设\n备连接在哪个端⼝上都能收到这个包。\n这样做不会产⽣什么问题，因为以太⽹的设计本来就是将包发送到整个⽹络的，然后只有相应的接收者才接收包，\n⽽其他设备则会忽略这个包。\n发送了包之后⽬标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写⼊ MAC 地址表，下次也就不\n需要把包发到所有端⼝了。\n此外，如果接收⽅ MAC 地址是⼀个⼴播地址，那么交换机会将包发送到除源端⼝之外的所有端⼝。\n以下两个属于⼴播地址：\nMAC 地址中的 FF:FF:FF:FF:FF:FF\nIP 地址中的 255.255.255.255\n## 出境⼤⻔—路由器\n数据包通过交换机转发抵达了路由器，准备要离开⼟⽣⼟⻓的⼦⽹了。此时，数据包和交换机离别时说道：“感谢\n交换机兄弟，帮我转发到出境的⼤⻔，我要出远⻔啦！”",
    "question": "0806：ARP 协议",
    "answer": "（2） MAC发送⽅和接收⽅如何确认\n发送⽅的 MAC 地址获取就⽐较简单了，MAC 地址是在⽹卡⽣产时写⼊到 ROM ⾥的，只要将这个值读取出来写⼊\n到 MAC 头部就可以了。\n接收⽅的 MAC 地址就有点复杂了，只要告诉以太⽹对⽅的 MAC 的地址，以太⽹就会帮我们把包发送过去，那么\n很显然这⾥应该填写对⽅的 MAC 地址。\n所以先得搞清楚应该把包发给谁，这个只要查⼀下路由表就知道了。在路由表中找到相匹配的条⽬，然后把包发给\nGateway 列中的 IP 地址就可以了。\n（3） 既然知道要发给谁，按如何获取对⽅的 MAC 地址\n不知道对⽅ MAC 地址？不知道就喊呗。此时就需要 ARP 协议帮我们找到路由器的 MAC 地址。\n（4） 如果每次都要⼴播获取，那不是很麻烦吗？\n后续操作系统会把本次查询结果放到⼀块叫做 ARP 缓存的内存空间留着以后⽤，不过缓存的时间就⼏分钟。也就\n是说，在发包时：\n先查询 ARP 缓存，如果其中已经保存了对⽅的 MAC 地址，就不需要发送 ARP 查询，直接使⽤ ARP 缓存中\n的地址。\n⽽当 ARP 缓存中不存在对⽅ MAC 地址时，则发送 ARP ⼴播查询。\n（5） 查看ARP缓存内容\n在 Linux 系统中，我们可以使⽤ arp -a 命令来查看 ARP 缓存的内容。\n（6） MAC报⽂⽣成\n## 出⼝-⽹卡\n此时，加上了 MAC 头部的数据包万分感谢，说道 ：“感谢 MAC ⼤佬，我知道我下⼀步要去哪了！我现在有很多头\n部兄弟，相信我可以到达最终的⽬的地！”。带着众多头部兄弟的数据包，终于准备要出⻔了。\n⽹络包只是存放在内存中的⼀串⼆进制数字信息，没有办法直接发送给对⽅。因此，我们需要将数字信息转换为电\n信号，才能在⽹线上传输，也就是说，这才是真正的数据发送过程。负责执⾏这⼀操作的是⽹卡，要控制⽹卡还需\n要靠⽹卡驱动程序。\n⽹卡驱动从 IP 模块获取到包之后，会将其复制到⽹卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，\n在末尾加上⽤于检测错误的帧校验序列。\n起始帧分界符是⼀个⽤来表示包起始位置的标记\n末尾的 FCS （帧校验序列）⽤来检查包传输过程是否有损坏\n最后⽹卡会将包转为电信号，通过⽹线发送出去。\n## 送别者—交换机\n唉，真是不容易，发⼀个包，真是历经千⾟万苦。致此，⼀个带有许多头部的数据终于踏上寻找⽬的地的征途了！\n下⾯来看⼀下包是如何通过交换机的？交换机的设计是将⽹络包原样转发到⽬的地。交换机⼯作在 MAC 层，也称\n为⼆层⽹络设备。\n（1） 交换机的包接收操作\n⾸先，电信号到达⽹线接⼝，交换机⾥的模块进⾏接收，接下来交换机⾥的模块将电信号转换为数字信号。\n然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的⽹卡相同，但交换机的⼯\n作⽅式和⽹卡不同。\n计算机的⽹卡本身具有 MAC 地址，并通过核对收到的包的接收⽅ MAC 地址判断是不是发给⾃⼰的，如果不是发\n给⾃⼰的则丢弃；相对地，交换机的端⼝不核对接收⽅ MAC 地址，⽽是直接接收所有的包并存放到缓冲区中。\n因此，和⽹卡不同，交换机的端⼝不具有 MAC 地址。\n将包存⼊缓冲区后，接下来需要查询⼀下这个包的接收⽅ MAC 地址是否已经在 MAC 地址表中有记录了。\n交换机的 MAC 地址表主要包含两个信息：\n⼀个是设备的 MAC 地址\n⼀个是该设备连接在交换机的哪个端⼝上\n交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端⼝。\n（2） 当 MAC 地址表找不到指定的 MAC 地址会怎么样？、\n地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备⼀段\n时间没有⼯作导致地址被从地址表中删除了。\n这种情况下，交换机⽆法判断应该把包转发到哪个端⼝，只能将包转发到除了源端⼝之外的所有端⼝上，⽆论该设\n备连接在哪个端⼝上都能收到这个包。\n这样做不会产⽣什么问题，因为以太⽹的设计本来就是将包发送到整个⽹络的，然后只有相应的接收者才接收包，\n⽽其他设备则会忽略这个包。\n发送了包之后⽬标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写⼊ MAC 地址表，下次也就不\n需要把包发到所有端⼝了。\n此外，如果接收⽅ MAC 地址是⼀个⼴播地址，那么交换机会将包发送到除源端⼝之外的所有端⼝。\n以下两个属于⼴播地址：\nMAC 地址中的 FF:FF:FF:FF:FF:FF\nIP 地址中的 255.255.255.255\n## 出境⼤⻔—路由器\n数据包通过交换机转发抵达了路由器，准备要离开⼟⽣⼟⻓的⼦⽹了。此时，数据包和交换机离别时说道：“感谢\n交换机兄弟，帮我转发到出境的⼤⻔，我要出远⻔啦！”",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": 806,
    "char_count": 1990,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000024",
    "content": "## 出境⼤⻔—路由器\n\n数据包通过交换机转发抵达了路由器，准备要离开⼟⽣⼟⻓的⼦⽹了。此时，数据包和交换机离别时说道：“感谢\n交换机兄弟，帮我转发到出境的⼤⻔，我要出远⻔啦！”\n（1） 路由器与交换机的区别\n⽹络包经过交换机之后，现在到达了路由器，并在此被转发到下⼀个路由器或⽬标设备。\n这⼀步转发的⼯作原理和交换机类似，也是通过查表判断包转发的⽬标。  不过在具体的操作过程上，路由器和交换机\n是有区别的。\n因为路由器是基于 IP 设计的，俗称三层⽹络设备，路由器的各个端⼝都具有 MAC 地址和 IP 地址；\n⽽交换机是基于以太⽹设计的，俗称⼆层⽹络设备，交换机的端⼝不具有 MAC 地址。\n（2） 路由器的基本原理\n路由器的端⼝具有 MAC 地址，因此它就能够成为以太⽹的发送⽅和接收⽅；同时还具有 IP 地址，从这个意义上来\n说，它和计算机的⽹卡是⼀样的。\n当转发包时，⾸先路由器端⼝会接收发给⾃⼰的以太⽹包，然后路由表查询转发⽬标，再由相应的端⼝作为发送⽅\n将以太⽹包发送出去。\n（3） 路由器的包接收操作\n⾸先，电信号到达⽹线接⼝部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进⾏错误校\n验。如果没问题则检查 MAC 头部中的接收⽅ MAC 地址，看看是不是发给⾃⼰的包，如果是就放到接收缓冲区中，\n否则就否则就丢弃这个包。\n总的来说，路由器的端⼝都具有  MAC  地址，只接收与⾃身地址匹配的包，遇到不匹配的包则直接丢弃。\n（4） 查询路由表确定输出端⼝\n完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。 MAC 头部的作⽤就是将包送达路由器，其中的接收\n⽅ MAC 地址就是路由器端⼝的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC\n头部就会被丢弃。\n接下来，路由器会根据 MAC 头部后⽅的 IP 头部中的内容进⾏包的转发操作。转发操作分为⼏个阶段，⾸先是查询\n路由表判断转发⽬标。\n（5） 路由器的发送操作\n⾸先，我们需要根据路由表的⽹关列判断对⽅的地址。\n如果⽹关是⼀个 IP 地址：\n则这个IP  地址就是我们要转发到的⽬标地址，还未抵达终点，还需继续需要路由器转发。\n如果⽹关为空：\n则 IP 头部中的接收⽅ IP 地址就是要转发到的⽬标地址，也是就终于找到 IP 包头⾥的⽬标地址了，说明已抵达终\n知道对⽅的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收⽅ MAC\n地址。\n路由器也有 ARP 缓存，因此⾸先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。\n接下来是发送⽅ MAC 地址字段，这⾥填写输出端⼝的 MAC 地址。还有⼀个以太类型字段，填写 0800 （⼗六进\n制）表示 IP 协议。\n⽹络包完成后，接下来会将其转换成电信号并通过端⼝发送出去。这⼀步的⼯作过程和计算机也是相同的。\n发送出去的⽹络包会通过交换机到达下⼀个路由器。由于接收⽅ MAC 地址就是下⼀个路由器的地址，所以交换机\n会根据这⼀地址将包传输到下⼀个路由器。\n接下来，下⼀个路由器会将包转发给再下⼀个路由器，经过层层转发之后，⽹络包就到达了最终的⽬的地。\n不知你发现了没有，在⽹络包传输的过程中，源 IP 和⽬标 IP 始终是不会变的，⼀直变化的是 MAC 地址，因为需\n要 MAC 地址在以太⽹内进⾏两个设备之间的包传输。",
    "question": "## 出境⼤⻔—路由器",
    "answer": "数据包通过交换机转发抵达了路由器，准备要离开⼟⽣⼟⻓的⼦⽹了。此时，数据包和交换机离别时说道：“感谢\n交换机兄弟，帮我转发到出境的⼤⻔，我要出远⻔啦！”\n（1） 路由器与交换机的区别\n⽹络包经过交换机之后，现在到达了路由器，并在此被转发到下⼀个路由器或⽬标设备。\n这⼀步转发的⼯作原理和交换机类似，也是通过查表判断包转发的⽬标。  不过在具体的操作过程上，路由器和交换机\n是有区别的。\n因为路由器是基于 IP 设计的，俗称三层⽹络设备，路由器的各个端⼝都具有 MAC 地址和 IP 地址；\n⽽交换机是基于以太⽹设计的，俗称⼆层⽹络设备，交换机的端⼝不具有 MAC 地址。\n（2） 路由器的基本原理\n路由器的端⼝具有 MAC 地址，因此它就能够成为以太⽹的发送⽅和接收⽅；同时还具有 IP 地址，从这个意义上来\n说，它和计算机的⽹卡是⼀样的。\n当转发包时，⾸先路由器端⼝会接收发给⾃⼰的以太⽹包，然后路由表查询转发⽬标，再由相应的端⼝作为发送⽅\n将以太⽹包发送出去。\n（3） 路由器的包接收操作\n⾸先，电信号到达⽹线接⼝部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进⾏错误校\n验。如果没问题则检查 MAC 头部中的接收⽅ MAC 地址，看看是不是发给⾃⼰的包，如果是就放到接收缓冲区中，\n否则就否则就丢弃这个包。\n总的来说，路由器的端⼝都具有  MAC  地址，只接收与⾃身地址匹配的包，遇到不匹配的包则直接丢弃。\n（4） 查询路由表确定输出端⼝\n完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。 MAC 头部的作⽤就是将包送达路由器，其中的接收\n⽅ MAC 地址就是路由器端⼝的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC\n头部就会被丢弃。\n接下来，路由器会根据 MAC 头部后⽅的 IP 头部中的内容进⾏包的转发操作。转发操作分为⼏个阶段，⾸先是查询\n路由表判断转发⽬标。\n（5） 路由器的发送操作\n⾸先，我们需要根据路由表的⽹关列判断对⽅的地址。\n如果⽹关是⼀个 IP 地址：\n则这个IP  地址就是我们要转发到的⽬标地址，还未抵达终点，还需继续需要路由器转发。\n如果⽹关为空：\n则 IP 头部中的接收⽅ IP 地址就是要转发到的⽬标地址，也是就终于找到 IP 包头⾥的⽬标地址了，说明已抵达终\n知道对⽅的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收⽅ MAC\n地址。\n路由器也有 ARP 缓存，因此⾸先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。\n接下来是发送⽅ MAC 地址字段，这⾥填写输出端⼝的 MAC 地址。还有⼀个以太类型字段，填写 0800 （⼗六进\n制）表示 IP 协议。\n⽹络包完成后，接下来会将其转换成电信号并通过端⼝发送出去。这⼀步的⼯作过程和计算机也是相同的。\n发送出去的⽹络包会通过交换机到达下⼀个路由器。由于接收⽅ MAC 地址就是下⼀个路由器的地址，所以交换机\n会根据这⼀地址将包传输到下⼀个路由器。\n接下来，下⼀个路由器会将包转发给再下⼀个路由器，经过层层转发之后，⽹络包就到达了最终的⽬的地。\n不知你发现了没有，在⽹络包传输的过程中，源 IP 和⽬标 IP 始终是不会变的，⼀直变化的是 MAC 地址，因为需\n要 MAC 地址在以太⽹内进⾏两个设备之间的包传输。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1439,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000025",
    "content": "（1） 路由器与交换机的区别\n\n⽹络包经过交换机之后，现在到达了路由器，并在此被转发到下⼀个路由器或⽬标设备。\n这⼀步转发的⼯作原理和交换机类似，也是通过查表判断包转发的⽬标。  不过在具体的操作过程上，路由器和交换机\n是有区别的。\n因为路由器是基于 IP 设计的，俗称三层⽹络设备，路由器的各个端⼝都具有 MAC 地址和 IP 地址；\n⽽交换机是基于以太⽹设计的，俗称⼆层⽹络设备，交换机的端⼝不具有 MAC 地址。",
    "question": "（1） 路由器与交换机的区别",
    "answer": "⽹络包经过交换机之后，现在到达了路由器，并在此被转发到下⼀个路由器或⽬标设备。\n这⼀步转发的⼯作原理和交换机类似，也是通过查表判断包转发的⽬标。  不过在具体的操作过程上，路由器和交换机\n是有区别的。\n因为路由器是基于 IP 设计的，俗称三层⽹络设备，路由器的各个端⼝都具有 MAC 地址和 IP 地址；\n⽽交换机是基于以太⽹设计的，俗称⼆层⽹络设备，交换机的端⼝不具有 MAC 地址。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 209,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000026",
    "content": "（2） 路由器的基本原理\n\n路由器的端⼝具有 MAC 地址，因此它就能够成为以太⽹的发送⽅和接收⽅；同时还具有 IP 地址，从这个意义上来\n说，它和计算机的⽹卡是⼀样的。\n当转发包时，⾸先路由器端⼝会接收发给⾃⼰的以太⽹包，然后路由表查询转发⽬标，再由相应的端⼝作为发送⽅\n将以太⽹包发送出去。\n（3） 路由器的包接收操作\n⾸先，电信号到达⽹线接⼝部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进⾏错误校\n验。如果没问题则检查 MAC 头部中的接收⽅ MAC 地址，看看是不是发给⾃⼰的包，如果是就放到接收缓冲区中，\n否则就否则就丢弃这个包。\n总的来说，路由器的端⼝都具有  MAC  地址，只接收与⾃身地址匹配的包，遇到不匹配的包则直接丢弃。\n（4） 查询路由表确定输出端⼝\n完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。 MAC 头部的作⽤就是将包送达路由器，其中的接收\n⽅ MAC 地址就是路由器端⼝的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC\n头部就会被丢弃。\n接下来，路由器会根据 MAC 头部后⽅的 IP 头部中的内容进⾏包的转发操作。转发操作分为⼏个阶段，⾸先是查询\n路由表判断转发⽬标。\n（5） 路由器的发送操作\n⾸先，我们需要根据路由表的⽹关列判断对⽅的地址。\n如果⽹关是⼀个 IP 地址：\n则这个IP  地址就是我们要转发到的⽬标地址，还未抵达终点，还需继续需要路由器转发。\n如果⽹关为空：\n则 IP 头部中的接收⽅ IP 地址就是要转发到的⽬标地址，也是就终于找到 IP 包头⾥的⽬标地址了，说明已抵达终\n知道对⽅的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收⽅ MAC\n地址。\n路由器也有 ARP 缓存，因此⾸先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。\n接下来是发送⽅ MAC 地址字段，这⾥填写输出端⼝的 MAC 地址。还有⼀个以太类型字段，填写 0800 （⼗六进\n制）表示 IP 协议。\n⽹络包完成后，接下来会将其转换成电信号并通过端⼝发送出去。这⼀步的⼯作过程和计算机也是相同的。\n发送出去的⽹络包会通过交换机到达下⼀个路由器。由于接收⽅ MAC 地址就是下⼀个路由器的地址，所以交换机\n会根据这⼀地址将包传输到下⼀个路由器。\n接下来，下⼀个路由器会将包转发给再下⼀个路由器，经过层层转发之后，⽹络包就到达了最终的⽬的地。\n不知你发现了没有，在⽹络包传输的过程中，源 IP 和⽬标 IP 始终是不会变的，⼀直变化的是 MAC 地址，因为需\n要 MAC 地址在以太⽹内进⾏两个设备之间的包传输。\n## 交换机转发\n数据包通过多个路由器道友的帮助，在⽹络世界途经了很多路程，最终抵达了⽬的地的城⻔！城⻔值守的路由器，\n发 现了这个⼩兄弟数据包原来是找城内的⼈，于是它就将数据包送进了城内，再经由城内的交换机帮助下，最终转\n发到了⽬的地了。数据包感慨万千的说道：“多谢这⼀路上，各路⼤侠的相助！”\n数据包抵达了服务器，服务器肯定⾼兴呀，开始扒数据包的⽪!\n⼀个数据包臭不要脸的感受：\n我⼀开始我虽然孤单、不知所措，但没有停滞不前。我依然满怀信⼼和勇⽓开始了征途。\n我很庆幸遇到了各路神通⼴⼤的⼤佬，有可靠传输的 TCP、有远程定位功能的 IP、有指明下⼀站位置的 MAC 等\n这些⼤佬都给我前⾯加上了头部，使得我能在交换机和路由器的转发下，抵达到了⽬的地！\n这⼀路上的经历，让我认识到了⽹络世界中各路⼤侠协作的᯿要性，是他们维护了⽹络世界的秩序，感谢他们！\nTCP 抓包实践\n## 显形“不可⻅”的⽹络包\n（1） 最常⽤的⽹络抓包和分析⼯具：\ntcpdump和Wireshark，那这两者有什么区别呢？\n两者经常搭配使⽤，先⽤ tcpdump 命令在 Linux 服务器上抓包（保存成.pcap后缀格式的⽂件），接着把抓包的⽂\n件拖出到Windows 电脑后，⽤ Wireshark 可视化分析。\n（2） tcpdump在Linux下如何抓包？\n（3） Wireshark⼯具如何分析数据包？\n## TCP三次握⼿异常情况实战分析\n（1） 实验⼀：TCP第⼀次握⼿SYN 丢包\n（2） 实验⼆：TCP第⼆次握⼿SYN、ACK丢包\n客户端设置了防⽕墙，粗暴地将来⾃服务端的数据都丢弃\n（3） 实验三：TCP第三次握⼿ACK丢包\n在服务端配置防⽕墙，屏蔽客户端TCP报⽂中标志位是ACK的包。\n如果客户端不发送数据，什么时候才会断开处于ESTABLISHED状态的连接？这就需要提到TCP的保活机制了：\n## TCP快速建⽴连接\n使⽤TCP Fast Open功能，可以减少TCP连接建⽴的时延。\n## TCP流量控制\n发送窗⼝决定了⼀次能发多少字节的数据，⽽MSS决定了这些字节要分多少包才能发送完。\n## TCP延迟确认与Nagle算法\n当TCP报⽂承载的数据⾮常⼩的时候，整个⽹络的效率很低。就好像快递员开着⼤货⻋送⼀个⼩包裹⼀样浪费。所\n以就出现了常⻅的两种策略，来减少⼩报⽂的传输。\n## Nagle算法\n## 延迟确认\n（1） Nagle算法是如何避免⼤量TCP⼩数据报⽂的传输的 ？\n从上图可以看出：Nagle算法⼀定会有⼀个⼩报⽂，在最开始的时候。\n（2） 延迟确认：为解决ACK传输效率低的问题，⽽提出的。\n当延迟确认和Nagle混合使⽤时，会出现新的问题（导致时耗增⻓）\n要解决上述问题，只有两个办法：\n## 发送⽅关闭Nagle算法\n## 接收⽅关闭TCP延迟确认\nTCP连接与断开优化\n关于优化TCP握⼿的⼏个TCP参数：\n## 客户端的优化\n当客户端发起SYN包时，可以通过tcp_synb_retries控制其重传的次数。\n## 服务端的优化\n## 绕过三次握⼿\nTCP内核参数\n## TCP四次挥⼿的性能提升\nTCP四次挥⼿的状态变迁如下：\n注：主动关闭连接的⼀⽅才有TIME_WAIT状态。\n主动关闭⽅和被动关闭⽅的优化思路也不同，下⾯将进⾏分别讨论：\n主动⽅的优化\n关闭连接的⽅式通常有两种，分别是 RST 报⽂关闭和 FIN 报⽂关闭。\n如果进程异常退出了，内核就会发送  RST  报⽂来关闭，它可以不⾛四次挥⼿流程，是⼀个暴⼒关闭连接的⽅式。\n安全关闭连接的⽅式必须通过四次挥⼿，它由进程调⽤ close 和 shutdown 函数发起 FIN 报⽂（shutdown 参数须\n传⼊ SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。",
    "question": "（2） 路由器的基本原理",
    "answer": "路由器的端⼝具有 MAC 地址，因此它就能够成为以太⽹的发送⽅和接收⽅；同时还具有 IP 地址，从这个意义上来\n说，它和计算机的⽹卡是⼀样的。\n当转发包时，⾸先路由器端⼝会接收发给⾃⼰的以太⽹包，然后路由表查询转发⽬标，再由相应的端⼝作为发送⽅\n将以太⽹包发送出去。\n（3） 路由器的包接收操作\n⾸先，电信号到达⽹线接⼝部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进⾏错误校\n验。如果没问题则检查 MAC 头部中的接收⽅ MAC 地址，看看是不是发给⾃⼰的包，如果是就放到接收缓冲区中，\n否则就否则就丢弃这个包。\n总的来说，路由器的端⼝都具有  MAC  地址，只接收与⾃身地址匹配的包，遇到不匹配的包则直接丢弃。\n（4） 查询路由表确定输出端⼝\n完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。 MAC 头部的作⽤就是将包送达路由器，其中的接收\n⽅ MAC 地址就是路由器端⼝的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC\n头部就会被丢弃。\n接下来，路由器会根据 MAC 头部后⽅的 IP 头部中的内容进⾏包的转发操作。转发操作分为⼏个阶段，⾸先是查询\n路由表判断转发⽬标。\n（5） 路由器的发送操作\n⾸先，我们需要根据路由表的⽹关列判断对⽅的地址。\n如果⽹关是⼀个 IP 地址：\n则这个IP  地址就是我们要转发到的⽬标地址，还未抵达终点，还需继续需要路由器转发。\n如果⽹关为空：\n则 IP 头部中的接收⽅ IP 地址就是要转发到的⽬标地址，也是就终于找到 IP 包头⾥的⽬标地址了，说明已抵达终\n知道对⽅的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收⽅ MAC\n地址。\n路由器也有 ARP 缓存，因此⾸先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。\n接下来是发送⽅ MAC 地址字段，这⾥填写输出端⼝的 MAC 地址。还有⼀个以太类型字段，填写 0800 （⼗六进\n制）表示 IP 协议。\n⽹络包完成后，接下来会将其转换成电信号并通过端⼝发送出去。这⼀步的⼯作过程和计算机也是相同的。\n发送出去的⽹络包会通过交换机到达下⼀个路由器。由于接收⽅ MAC 地址就是下⼀个路由器的地址，所以交换机\n会根据这⼀地址将包传输到下⼀个路由器。\n接下来，下⼀个路由器会将包转发给再下⼀个路由器，经过层层转发之后，⽹络包就到达了最终的⽬的地。\n不知你发现了没有，在⽹络包传输的过程中，源 IP 和⽬标 IP 始终是不会变的，⼀直变化的是 MAC 地址，因为需\n要 MAC 地址在以太⽹内进⾏两个设备之间的包传输。\n## 交换机转发\n数据包通过多个路由器道友的帮助，在⽹络世界途经了很多路程，最终抵达了⽬的地的城⻔！城⻔值守的路由器，\n发 现了这个⼩兄弟数据包原来是找城内的⼈，于是它就将数据包送进了城内，再经由城内的交换机帮助下，最终转\n发到了⽬的地了。数据包感慨万千的说道：“多谢这⼀路上，各路⼤侠的相助！”\n数据包抵达了服务器，服务器肯定⾼兴呀，开始扒数据包的⽪!\n⼀个数据包臭不要脸的感受：\n我⼀开始我虽然孤单、不知所措，但没有停滞不前。我依然满怀信⼼和勇⽓开始了征途。\n我很庆幸遇到了各路神通⼴⼤的⼤佬，有可靠传输的 TCP、有远程定位功能的 IP、有指明下⼀站位置的 MAC 等\n这些⼤佬都给我前⾯加上了头部，使得我能在交换机和路由器的转发下，抵达到了⽬的地！\n这⼀路上的经历，让我认识到了⽹络世界中各路⼤侠协作的᯿要性，是他们维护了⽹络世界的秩序，感谢他们！\nTCP 抓包实践\n## 显形“不可⻅”的⽹络包\n（1） 最常⽤的⽹络抓包和分析⼯具：\ntcpdump和Wireshark，那这两者有什么区别呢？\n两者经常搭配使⽤，先⽤ tcpdump 命令在 Linux 服务器上抓包（保存成.pcap后缀格式的⽂件），接着把抓包的⽂\n件拖出到Windows 电脑后，⽤ Wireshark 可视化分析。\n（2） tcpdump在Linux下如何抓包？\n（3） Wireshark⼯具如何分析数据包？\n## TCP三次握⼿异常情况实战分析\n（1） 实验⼀：TCP第⼀次握⼿SYN 丢包\n（2） 实验⼆：TCP第⼆次握⼿SYN、ACK丢包\n客户端设置了防⽕墙，粗暴地将来⾃服务端的数据都丢弃\n（3） 实验三：TCP第三次握⼿ACK丢包\n在服务端配置防⽕墙，屏蔽客户端TCP报⽂中标志位是ACK的包。\n如果客户端不发送数据，什么时候才会断开处于ESTABLISHED状态的连接？这就需要提到TCP的保活机制了：\n## TCP快速建⽴连接\n使⽤TCP Fast Open功能，可以减少TCP连接建⽴的时延。\n## TCP流量控制\n发送窗⼝决定了⼀次能发多少字节的数据，⽽MSS决定了这些字节要分多少包才能发送完。\n## TCP延迟确认与Nagle算法\n当TCP报⽂承载的数据⾮常⼩的时候，整个⽹络的效率很低。就好像快递员开着⼤货⻋送⼀个⼩包裹⼀样浪费。所\n以就出现了常⻅的两种策略，来减少⼩报⽂的传输。\n## Nagle算法\n## 延迟确认\n（1） Nagle算法是如何避免⼤量TCP⼩数据报⽂的传输的 ？\n从上图可以看出：Nagle算法⼀定会有⼀个⼩报⽂，在最开始的时候。\n（2） 延迟确认：为解决ACK传输效率低的问题，⽽提出的。\n当延迟确认和Nagle混合使⽤时，会出现新的问题（导致时耗增⻓）\n要解决上述问题，只有两个办法：\n## 发送⽅关闭Nagle算法\n## 接收⽅关闭TCP延迟确认\nTCP连接与断开优化\n关于优化TCP握⼿的⼏个TCP参数：\n## 客户端的优化\n当客户端发起SYN包时，可以通过tcp_synb_retries控制其重传的次数。\n## 服务端的优化\n## 绕过三次握⼿\nTCP内核参数\n## TCP四次挥⼿的性能提升\nTCP四次挥⼿的状态变迁如下：\n注：主动关闭连接的⼀⽅才有TIME_WAIT状态。\n主动关闭⽅和被动关闭⽅的优化思路也不同，下⾯将进⾏分别讨论：\n主动⽅的优化\n关闭连接的⽅式通常有两种，分别是 RST 报⽂关闭和 FIN 报⽂关闭。\n如果进程异常退出了，内核就会发送  RST  报⽂来关闭，它可以不⾛四次挥⼿流程，是⼀个暴⼒关闭连接的⽅式。\n安全关闭连接的⽅式必须通过四次挥⼿，它由进程调⽤ close 和 shutdown 函数发起 FIN 报⽂（shutdown 参数须\n传⼊ SHUT_WR 或者 SHUT_RDWR 才会发送 FIN）。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2733,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000027",
    "content": "## close 和 shutdown 有什么区别\n\n调⽤了  close  函数意味着完全断开连接，完全断开不仅指⽆法接收数据，⽽且也不能发送数据。\n此时，调⽤了 close 函数的⼀⽅的连接叫做「孤⼉连接」，如果你⽤ netstat -p 命令，会发现连接对应的进程名为\n使⽤ close 函数关闭连接是不优雅的。于是，就出现了⼀种优雅关闭连接的 shutdown 函数，它可以控制只关闭\n⼀个⽅向的连接。\n其中第⼆个参数决定断开连接的⽅式，主要有三种：\n（1） SHUT_RD(0)\n关闭连接的「读」这个⽅向，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数\n据进⾏ ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。\n（2） SHUT_WR(1)\n关闭连接的「写」这个⽅向，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发送的数据，将被⽴即发\n送出去，并发送⼀个 FIN 报⽂给对端。\n（3） SHUT_RDWR(2)\n相当于 SHUT_RD 和 SHUT_WR 操作各⼀次，关闭套接字的读和写两个⽅向。\n## FIN_WAIT1状态的优化\n如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 tcp_orphan_retries 的值。当重传次数超过\ntcp_orphan_retries 时，连接就会直接关闭掉（即：新增的孤⼉连接将不再⾛四次挥⼿，⽽是直接发送  RST 复位报\n⽂强制关闭）。\n注：tcp_max_orphans  参数，定义了「孤⼉连接」的最⼤数量。\n## FIN_WAIT2状态的优化\n当主动⽅收到 ACK 报⽂后，会处于 FIN_WAIT2 状态，就表示主动⽅的发送通道已经关闭，接下来将等待对⽅发送\nFIN 报⽂，关闭对⽅的发送通道。\n这时，如果连接是⽤ shutdown 函数关闭的，主动⽅连接可以⼀直处于 FIN_WAIT2 状态，因为它可能还可以发送或\n接收数据。\n但对于 close 函数关闭的孤⼉连接，由于⽆法再发送和接收数据，所以这个状态不可以持续太久，⽽\ntcp_fin_timeout 控制了这个状态下连接的持续时⻓，默认值是 60 秒（与 TIME_WAIT 状态持续的时间是相同\n的）。它意味着对于孤⼉连接（调⽤ close 关闭的连接），如果在 60 秒后还没有收到 FIN 报⽂，连接就会直接关\n## TIME_WAIT状态的优化",
    "question": "## close 和 shutdown 有什么区别",
    "answer": "调⽤了  close  函数意味着完全断开连接，完全断开不仅指⽆法接收数据，⽽且也不能发送数据。\n此时，调⽤了 close 函数的⼀⽅的连接叫做「孤⼉连接」，如果你⽤ netstat -p 命令，会发现连接对应的进程名为\n使⽤ close 函数关闭连接是不优雅的。于是，就出现了⼀种优雅关闭连接的 shutdown 函数，它可以控制只关闭\n⼀个⽅向的连接。\n其中第⼆个参数决定断开连接的⽅式，主要有三种：\n（1） SHUT_RD(0)\n关闭连接的「读」这个⽅向，如果接收缓冲区有已接收的数据，则将会被丢弃，并且后续再收到新的数据，会对数\n据进⾏ ACK，然后悄悄地丢弃。也就是说，对端还是会接收到 ACK，在这种情况下根本不知道数据已经被丢弃了。\n（2） SHUT_WR(1)\n关闭连接的「写」这个⽅向，这就是常被称为「半关闭」的连接。如果发送缓冲区还有未发送的数据，将被⽴即发\n送出去，并发送⼀个 FIN 报⽂给对端。\n（3） SHUT_RDWR(2)\n相当于 SHUT_RD 和 SHUT_WR 操作各⼀次，关闭套接字的读和写两个⽅向。\n## FIN_WAIT1状态的优化\n如果 FIN_WAIT1 状态连接很多，我们就需要考虑降低 tcp_orphan_retries 的值。当重传次数超过\ntcp_orphan_retries 时，连接就会直接关闭掉（即：新增的孤⼉连接将不再⾛四次挥⼿，⽽是直接发送  RST 复位报\n⽂强制关闭）。\n注：tcp_max_orphans  参数，定义了「孤⼉连接」的最⼤数量。\n## FIN_WAIT2状态的优化\n当主动⽅收到 ACK 报⽂后，会处于 FIN_WAIT2 状态，就表示主动⽅的发送通道已经关闭，接下来将等待对⽅发送\nFIN 报⽂，关闭对⽅的发送通道。\n这时，如果连接是⽤ shutdown 函数关闭的，主动⽅连接可以⼀直处于 FIN_WAIT2 状态，因为它可能还可以发送或\n接收数据。\n但对于 close 函数关闭的孤⼉连接，由于⽆法再发送和接收数据，所以这个状态不可以持续太久，⽽\ntcp_fin_timeout 控制了这个状态下连接的持续时⻓，默认值是 60 秒（与 TIME_WAIT 状态持续的时间是相同\n的）。它意味着对于孤⼉连接（调⽤ close 关闭的连接），如果在 60 秒后还没有收到 FIN 报⽂，连接就会直接关\n## TIME_WAIT状态的优化",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1041,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000028",
    "content": "## TIME_WAIT状态的优化\n\nTIME_WAIT的状态尤其重要，主要是两个原因\n（1） 防⽌收到历史数据，从⽽导致数据错乱的问题\n若TIME_WAIT等待时间过短，被延迟的数据包抵达后会发⽣什么呢？\nTIME_WAIT设计为2MSL，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再\n出现的数据包⼀定都是新建⽴连接所产⽣的。\nMSL 全称是 Maximum Segment Lifetime，它定义了⼀个报⽂在⽹络中的最⻓⽣存时间（报⽂每经过⼀次路由器\n的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报⽂ 就被丢弃，这就限制了报⽂的最⻓存活时间）。\n（2） 为什么是 2 MSL 的时⻓呢？\n这其实是相当于⾄少允许报⽂丢失⼀次。⽐如，若 ACK 在⼀个 MSL 内丢失，这样被 动⽅᯿发的 FIN 会在第 2 个\nMSL 内到达，TIME_WAIT 状态的连接可以应对。\n在Linux系统中，MSL的值固定为30秒。\n等待⾜够的时间以确保最后的ACK能让被动关闭⽅接收，从⽽帮助其正确关闭\n（3） 假设TIME_WAIT没有等待或等待的时间过短，断开连接会造成什么？\n如上图红⾊框框客户端四次挥⼿的最后⼀个 ACK 报⽂如果在⽹络中被丢失了，此时如果客户端 TIMEWAIT 过短或\n没有，则就直接进⼊了 CLOSE 状态了，那么服务端则会⼀直处在 LAST-ACK 状态。\n当客户端发起建⽴连接的 SYN 请求报⽂后，服务端会发送 RST 报⽂给客户端，连接建⽴的过程就会被终⽌。\nLinux 提供了 tcp_max_tw_buckets 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历\nTIME_WAIT ⽽直接关闭。查看系统的TIME_WAIT的连接数量：\n但tcp_max_tw_buckets  也不是越⼤越好，毕竟内存和端⼝都是有限的。\n还有⼀种⽅式是复⽤处于TIME_WAIT状态的连接，那就是打开 tcp_tw_reuse 参数。\n但是需要注意，该参数是只⽤于客户端（建⽴连接的发起⽅），因为是在调⽤ connect() 时起作⽤的，⽽对于服务\n端（被动 连接⽅）是没有⽤的。\ntcp_tw_reuse 从协议⻆度理解是安全可控的，可以复⽤处于 TIME_WAIT 的端⼝为新的连接所⽤。\n什么是协议⻆度理解的安全可控呢？\n主要有两点：\n（1） 只适⽤于连接发起⽅，也就是 C/S 模型中的客户端；\n（2） 对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复⽤。\n使⽤这个选项，还有⼀个前提，需要打开对 TCP 时间戳的⽀持（对⽅也要打开 ）。\n由于引⼊了时间戳，带来了⼀些好处：",
    "question": "## TIME_WAIT状态的优化",
    "answer": "TIME_WAIT的状态尤其重要，主要是两个原因\n（1） 防⽌收到历史数据，从⽽导致数据错乱的问题\n若TIME_WAIT等待时间过短，被延迟的数据包抵达后会发⽣什么呢？\nTIME_WAIT设计为2MSL，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再\n出现的数据包⼀定都是新建⽴连接所产⽣的。\nMSL 全称是 Maximum Segment Lifetime，它定义了⼀个报⽂在⽹络中的最⻓⽣存时间（报⽂每经过⼀次路由器\n的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报⽂ 就被丢弃，这就限制了报⽂的最⻓存活时间）。\n（2） 为什么是 2 MSL 的时⻓呢？\n这其实是相当于⾄少允许报⽂丢失⼀次。⽐如，若 ACK 在⼀个 MSL 内丢失，这样被 动⽅᯿发的 FIN 会在第 2 个\nMSL 内到达，TIME_WAIT 状态的连接可以应对。\n在Linux系统中，MSL的值固定为30秒。\n等待⾜够的时间以确保最后的ACK能让被动关闭⽅接收，从⽽帮助其正确关闭\n（3） 假设TIME_WAIT没有等待或等待的时间过短，断开连接会造成什么？\n如上图红⾊框框客户端四次挥⼿的最后⼀个 ACK 报⽂如果在⽹络中被丢失了，此时如果客户端 TIMEWAIT 过短或\n没有，则就直接进⼊了 CLOSE 状态了，那么服务端则会⼀直处在 LAST-ACK 状态。\n当客户端发起建⽴连接的 SYN 请求报⽂后，服务端会发送 RST 报⽂给客户端，连接建⽴的过程就会被终⽌。\nLinux 提供了 tcp_max_tw_buckets 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历\nTIME_WAIT ⽽直接关闭。查看系统的TIME_WAIT的连接数量：\n但tcp_max_tw_buckets  也不是越⼤越好，毕竟内存和端⼝都是有限的。\n还有⼀种⽅式是复⽤处于TIME_WAIT状态的连接，那就是打开 tcp_tw_reuse 参数。\n但是需要注意，该参数是只⽤于客户端（建⽴连接的发起⽅），因为是在调⽤ connect() 时起作⽤的，⽽对于服务\n端（被动 连接⽅）是没有⽤的。\ntcp_tw_reuse 从协议⻆度理解是安全可控的，可以复⽤处于 TIME_WAIT 的端⼝为新的连接所⽤。\n什么是协议⻆度理解的安全可控呢？\n主要有两点：\n（1） 只适⽤于连接发起⽅，也就是 C/S 模型中的客户端；\n（2） 对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复⽤。\n使⽤这个选项，还有⼀个前提，需要打开对 TCP 时间戳的⽀持（对⽅也要打开 ）。\n由于引⼊了时间戳，带来了⼀些好处：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1146,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000029",
    "content": "TIME_WAIT的状态尤其重要，主要是两个原因\n\n（1） 防⽌收到历史数据，从⽽导致数据错乱的问题\n若TIME_WAIT等待时间过短，被延迟的数据包抵达后会发⽣什么呢？\nTIME_WAIT设计为2MSL，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再\n出现的数据包⼀定都是新建⽴连接所产⽣的。\nMSL 全称是 Maximum Segment Lifetime，它定义了⼀个报⽂在⽹络中的最⻓⽣存时间（报⽂每经过⼀次路由器\n的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报⽂ 就被丢弃，这就限制了报⽂的最⻓存活时间）。\n（2） 为什么是 2 MSL 的时⻓呢？\n这其实是相当于⾄少允许报⽂丢失⼀次。⽐如，若 ACK 在⼀个 MSL 内丢失，这样被 动⽅᯿发的 FIN 会在第 2 个\nMSL 内到达，TIME_WAIT 状态的连接可以应对。\n在Linux系统中，MSL的值固定为30秒。\n等待⾜够的时间以确保最后的ACK能让被动关闭⽅接收，从⽽帮助其正确关闭\n（3） 假设TIME_WAIT没有等待或等待的时间过短，断开连接会造成什么？\n如上图红⾊框框客户端四次挥⼿的最后⼀个 ACK 报⽂如果在⽹络中被丢失了，此时如果客户端 TIMEWAIT 过短或\n没有，则就直接进⼊了 CLOSE 状态了，那么服务端则会⼀直处在 LAST-ACK 状态。\n当客户端发起建⽴连接的 SYN 请求报⽂后，服务端会发送 RST 报⽂给客户端，连接建⽴的过程就会被终⽌。\nLinux 提供了 tcp_max_tw_buckets 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历\nTIME_WAIT ⽽直接关闭。查看系统的TIME_WAIT的连接数量：\n但tcp_max_tw_buckets  也不是越⼤越好，毕竟内存和端⼝都是有限的。\n还有⼀种⽅式是复⽤处于TIME_WAIT状态的连接，那就是打开 tcp_tw_reuse 参数。\n但是需要注意，该参数是只⽤于客户端（建⽴连接的发起⽅），因为是在调⽤ connect() 时起作⽤的，⽽对于服务\n端（被动 连接⽅）是没有⽤的。\ntcp_tw_reuse 从协议⻆度理解是安全可控的，可以复⽤处于 TIME_WAIT 的端⼝为新的连接所⽤。\n什么是协议⻆度理解的安全可控呢？\n主要有两点：\n（1） 只适⽤于连接发起⽅，也就是 C/S 模型中的客户端；\n（2） 对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复⽤。\n使⽤这个选项，还有⼀个前提，需要打开对 TCP 时间戳的⽀持（对⽅也要打开 ）。\n由于引⼊了时间戳，带来了⼀些好处：\n## 我们在前⾯提到的 2MSL 问题就不复存在了，因为᯿复的数据包会因为时间戳过期被⾃然丢弃；\n## 同时，它还可以防⽌序列号绕回，也是因为᯿复的数据包会由于时间戳过期被⾃然丢弃。\n时间戳是在 TCP 的选项字段⾥定义的，开启了时间戳功能，在 TCP 报⽂传输的时候会带上发送报⽂的时间戳。\n开启tcp_tw_reuse功能后，如果四次挥⼿中的最后⼀次ACK在⽹络中丢失了，会发⽣什么？\n被动⽅的优化",
    "question": "TIME_WAIT的状态尤其重要，主要是两个原因",
    "answer": "（1） 防⽌收到历史数据，从⽽导致数据错乱的问题\n若TIME_WAIT等待时间过短，被延迟的数据包抵达后会发⽣什么呢？\nTIME_WAIT设计为2MSL，⾜以让两个⽅向上的数据包都被丢弃，使得原来连接的数据包在⽹络中都⾃然消失，再\n出现的数据包⼀定都是新建⽴连接所产⽣的。\nMSL 全称是 Maximum Segment Lifetime，它定义了⼀个报⽂在⽹络中的最⻓⽣存时间（报⽂每经过⼀次路由器\n的转发，IP 头部的 TTL 字段就会减 1，减到 0 时报⽂ 就被丢弃，这就限制了报⽂的最⻓存活时间）。\n（2） 为什么是 2 MSL 的时⻓呢？\n这其实是相当于⾄少允许报⽂丢失⼀次。⽐如，若 ACK 在⼀个 MSL 内丢失，这样被 动⽅᯿发的 FIN 会在第 2 个\nMSL 内到达，TIME_WAIT 状态的连接可以应对。\n在Linux系统中，MSL的值固定为30秒。\n等待⾜够的时间以确保最后的ACK能让被动关闭⽅接收，从⽽帮助其正确关闭\n（3） 假设TIME_WAIT没有等待或等待的时间过短，断开连接会造成什么？\n如上图红⾊框框客户端四次挥⼿的最后⼀个 ACK 报⽂如果在⽹络中被丢失了，此时如果客户端 TIMEWAIT 过短或\n没有，则就直接进⼊了 CLOSE 状态了，那么服务端则会⼀直处在 LAST-ACK 状态。\n当客户端发起建⽴连接的 SYN 请求报⽂后，服务端会发送 RST 报⽂给客户端，连接建⽴的过程就会被终⽌。\nLinux 提供了 tcp_max_tw_buckets 参数，当 TIME_WAIT 的连接数量超过该参数时，新关闭的连接就不再经历\nTIME_WAIT ⽽直接关闭。查看系统的TIME_WAIT的连接数量：\n但tcp_max_tw_buckets  也不是越⼤越好，毕竟内存和端⼝都是有限的。\n还有⼀种⽅式是复⽤处于TIME_WAIT状态的连接，那就是打开 tcp_tw_reuse 参数。\n但是需要注意，该参数是只⽤于客户端（建⽴连接的发起⽅），因为是在调⽤ connect() 时起作⽤的，⽽对于服务\n端（被动 连接⽅）是没有⽤的。\ntcp_tw_reuse 从协议⻆度理解是安全可控的，可以复⽤处于 TIME_WAIT 的端⼝为新的连接所⽤。\n什么是协议⻆度理解的安全可控呢？\n主要有两点：\n（1） 只适⽤于连接发起⽅，也就是 C/S 模型中的客户端；\n（2） 对应的 TIME_WAIT 状态的连接创建时间超过 1 秒才可以被复⽤。\n使⽤这个选项，还有⼀个前提，需要打开对 TCP 时间戳的⽀持（对⽅也要打开 ）。\n由于引⼊了时间戳，带来了⼀些好处：\n## 我们在前⾯提到的 2MSL 问题就不复存在了，因为᯿复的数据包会因为时间戳过期被⾃然丢弃；\n## 同时，它还可以防⽌序列号绕回，也是因为᯿复的数据包会由于时间戳过期被⾃然丢弃。\n时间戳是在 TCP 的选项字段⾥定义的，开启了时间戳功能，在 TCP 报⽂传输的时候会带上发送报⽂的时间戳。\n开启tcp_tw_reuse功能后，如果四次挥⼿中的最后⼀次ACK在⽹络中丢失了，会发⽣什么？\n被动⽅的优化",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1330,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000030",
    "content": "## 如果连接双⽅同时关闭连接，会怎么样？\n\n由于 TCP 是双全⼯的协议，所以是会出现两⽅同时关闭连接的现象，也就是同时发送了 FIN 报⽂。\n此时，上⾯介绍的优化策略仍然适⽤。两⽅发送 FIN 报⽂时，都认为⾃⼰是主动⽅，所以都进⼊了 FIN_WAIT1 状\n态，FIN 报⽂的重发次数仍由 tcp_orphan_retries 参数控制。\n接下来，双⽅在等待 ACK 报⽂的过程中，都等来了 FIN 报⽂。这是⼀种新情况，所以连接会进⼊⼀种叫做\nCLOSING 的新状态，它替代了 FIN_WAIT2 状态。接着，双⽅内核回复 ACK 确认对⽅发送通道的关闭后，进⼊\nTIME_WAIT 状态，等待 2MSL 的时间后，连接⾃动关闭。\n⼩结：\n针对 TCP 四次挥⼿的优化，我们需要根据主动⽅和被动⽅四次挥⼿状态变化来调整系统 TCP 内核参数。\n## TCP数据传输性能的提升\nTCP  连接是由内核维护的，内核会为每个连接建⽴内存缓冲区：\n如果连接的内存配置过⼩，就⽆法充分使⽤⽹络带宽，TCP  传输效率就会降低；\n如果连接的内存配置过⼤，很容易把服务器资源耗尽，这样就会导致新连接⽆法建⽴；\n因此，我们必须理解 Linux 下 TCP 内存的⽤途，才能正确地配置内存⼤⼩。\n（1） 滑动窗⼝是如何影响传输速度的？\nTCP 会保证每⼀个报⽂都能够抵达对⽅，机制如下：报⽂发出去后，必须接收到对⽅返回的确认报⽂ ACK，如果迟迟\n未收到，就会超时᯿发该报⽂，直到收到对⽅的 ACK 为⽌。\n因此TCP报⽂发出去后，并不会⽴⻢从内存中删除，因为重传时还需要⽤到。由于TCP是由内核维护的，所以报⽂\n存放在内核缓冲区。\n应答：\n批量发送，批量应答：\n引发的问题：\n当接收⽅硬件不如发送⽅，或者系统繁忙、资源紧张时，是⽆法瞬间处理这么多报⽂的。于是，这些报⽂只能被丢\n掉，使得⽹络效率⾮常低。\n为了解决这种现象发⽣，TCP 提供⼀种机制可以让「发送⽅」根据「接收⽅」的实际接收能⼒控制发送的数据量，\n这就是滑动窗⼝的由来。\n接收⽅根据它的缓冲区，可以计算出后续能够接收多少字节的报⽂，这个数字叫做接收窗⼝。当内核接收到报⽂\n时，必须⽤缓冲区存放它们，这样剩余缓冲区空间变⼩，接收窗⼝也就变⼩了；当进程调⽤ read 函数后，数据被\n读⼊了⽤户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报⽂，接收窗⼝就会变⼤。\n因此，接收窗⼝并不是恒定不变的，接收⽅会把当前可接收的⼤⼩放在 TCP 报⽂头部中的窗⼝字段，这样就可以\n起到窗⼝⼤⼩通知的作⽤。\n从上图中可以看到，窗⼝字段只有 2 个字节，因此它最多能表达 65535 字节⼤⼩的窗⼝，也就是 64KB ⼤⼩。\n这个窗⼝⼤⼩最⼤值，在当今⾼速⽹络下，很明显是不够⽤的。\n所以后续有了扩充窗⼝的⽅法：\n在 TCP 选项字段定义了窗⼝扩⼤因⼦，⽤于扩⼤ TCP 通告窗⼝，其值⼤⼩是 2^14，这样就使 TCP 的窗⼝⼤⼩从\n16 位扩⼤为 30 位（2^16 * 2^ 14 = 2^30），所以此时窗⼝的最⼤值可以达到 1GB。\n⽹络的传输能⼒是有限的，当发送⽅依据发送窗⼝，发送超过⽹络处理能⼒的报⽂时，路由器会直接丢弃这些报\n⽂。因此，缓冲区的内存并不是越⼤越好。\n（2） 如何确定最⼤传输速度？\nTCP的传输速度，受限于发送窗⼝，接收窗⼝以及⽹络设备传输能⼒。\n其中，窗⼝⼤⼩由内核缓冲区⼤⼩决定。如果缓冲区与⽹络传输能⼒匹配，那么缓冲区的利⽤率就达到了最⼤化。\n（3） 如何计算⽹络传输能⼒呢？\n⽹络是有「带宽」限制的，带宽描述的是⽹络传输能⼒\n它与内核缓冲区的计量单位不同:\n带宽是单位时间内的流᯿，表达是「速度」，⽐如常⻅的带宽 100 MB/s；缓\n冲区单位是字节，当⽹络速度乘以时间才能得到字节数。\n带宽时延积BDP决定⽹络中⻜⾏报⽂的⼤⼩。所谓【⻜⾏】，是指它们就在⽹络线路、路由器等⽹络设备上。\n其中：RTT为⽹络时延。\n由于发送缓冲区⼤⼩决定了发送窗⼝的上限，⽽发送窗⼝⼜决定了「已发送未确认」的⻜⾏报⽂的上限。因此，发\n送缓冲区不能超过「带宽时延积」。\n发送缓冲区与带宽时延积的关系如下：\n如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的⽹络传输，同时导致⽹络过载，容易丢包；\n如果发送缓冲区「⼩于」带宽时延积，就不能很好的发挥出⽹络的传输效率。\n（4） 怎样调整缓冲区⼤⼩？\n发送缓冲区⼤⼩可⾃⾏调节，三个数值分别为：动态范围的最⼩值，初始默认值，动态范围的最⼤值。\n接收缓冲区范围调节\n接收缓冲区可以根据系统空闲内存的⼤⼩来调节接收窗⼝：\n如果系统的空闲内存很多，就可以⾃动把缓冲区增⼤⼀些，这样传给对⽅的接收窗⼝也会变⼤，因⽽提升发  送⽅发送\n的传输数据数\n反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常⼯作\n发送缓冲区的调节功能是⾃动开启的，⽽接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能\n调节TCP内存范围\n根据实际场景调节的策略\n⼩结：\nLinux是如何收发⽹络包的\nLinux⽹络协议栈\n从上述⽹络协议栈，可以看出：",
    "question": "## 如果连接双⽅同时关闭连接，会怎么样？",
    "answer": "由于 TCP 是双全⼯的协议，所以是会出现两⽅同时关闭连接的现象，也就是同时发送了 FIN 报⽂。\n此时，上⾯介绍的优化策略仍然适⽤。两⽅发送 FIN 报⽂时，都认为⾃⼰是主动⽅，所以都进⼊了 FIN_WAIT1 状\n态，FIN 报⽂的重发次数仍由 tcp_orphan_retries 参数控制。\n接下来，双⽅在等待 ACK 报⽂的过程中，都等来了 FIN 报⽂。这是⼀种新情况，所以连接会进⼊⼀种叫做\nCLOSING 的新状态，它替代了 FIN_WAIT2 状态。接着，双⽅内核回复 ACK 确认对⽅发送通道的关闭后，进⼊\nTIME_WAIT 状态，等待 2MSL 的时间后，连接⾃动关闭。\n⼩结：\n针对 TCP 四次挥⼿的优化，我们需要根据主动⽅和被动⽅四次挥⼿状态变化来调整系统 TCP 内核参数。\n## TCP数据传输性能的提升\nTCP  连接是由内核维护的，内核会为每个连接建⽴内存缓冲区：\n如果连接的内存配置过⼩，就⽆法充分使⽤⽹络带宽，TCP  传输效率就会降低；\n如果连接的内存配置过⼤，很容易把服务器资源耗尽，这样就会导致新连接⽆法建⽴；\n因此，我们必须理解 Linux 下 TCP 内存的⽤途，才能正确地配置内存⼤⼩。\n（1） 滑动窗⼝是如何影响传输速度的？\nTCP 会保证每⼀个报⽂都能够抵达对⽅，机制如下：报⽂发出去后，必须接收到对⽅返回的确认报⽂ ACK，如果迟迟\n未收到，就会超时᯿发该报⽂，直到收到对⽅的 ACK 为⽌。\n因此TCP报⽂发出去后，并不会⽴⻢从内存中删除，因为重传时还需要⽤到。由于TCP是由内核维护的，所以报⽂\n存放在内核缓冲区。\n应答：\n批量发送，批量应答：\n引发的问题：\n当接收⽅硬件不如发送⽅，或者系统繁忙、资源紧张时，是⽆法瞬间处理这么多报⽂的。于是，这些报⽂只能被丢\n掉，使得⽹络效率⾮常低。\n为了解决这种现象发⽣，TCP 提供⼀种机制可以让「发送⽅」根据「接收⽅」的实际接收能⼒控制发送的数据量，\n这就是滑动窗⼝的由来。\n接收⽅根据它的缓冲区，可以计算出后续能够接收多少字节的报⽂，这个数字叫做接收窗⼝。当内核接收到报⽂\n时，必须⽤缓冲区存放它们，这样剩余缓冲区空间变⼩，接收窗⼝也就变⼩了；当进程调⽤ read 函数后，数据被\n读⼊了⽤户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报⽂，接收窗⼝就会变⼤。\n因此，接收窗⼝并不是恒定不变的，接收⽅会把当前可接收的⼤⼩放在 TCP 报⽂头部中的窗⼝字段，这样就可以\n起到窗⼝⼤⼩通知的作⽤。\n从上图中可以看到，窗⼝字段只有 2 个字节，因此它最多能表达 65535 字节⼤⼩的窗⼝，也就是 64KB ⼤⼩。\n这个窗⼝⼤⼩最⼤值，在当今⾼速⽹络下，很明显是不够⽤的。\n所以后续有了扩充窗⼝的⽅法：\n在 TCP 选项字段定义了窗⼝扩⼤因⼦，⽤于扩⼤ TCP 通告窗⼝，其值⼤⼩是 2^14，这样就使 TCP 的窗⼝⼤⼩从\n16 位扩⼤为 30 位（2^16 * 2^ 14 = 2^30），所以此时窗⼝的最⼤值可以达到 1GB。\n⽹络的传输能⼒是有限的，当发送⽅依据发送窗⼝，发送超过⽹络处理能⼒的报⽂时，路由器会直接丢弃这些报\n⽂。因此，缓冲区的内存并不是越⼤越好。\n（2） 如何确定最⼤传输速度？\nTCP的传输速度，受限于发送窗⼝，接收窗⼝以及⽹络设备传输能⼒。\n其中，窗⼝⼤⼩由内核缓冲区⼤⼩决定。如果缓冲区与⽹络传输能⼒匹配，那么缓冲区的利⽤率就达到了最⼤化。\n（3） 如何计算⽹络传输能⼒呢？\n⽹络是有「带宽」限制的，带宽描述的是⽹络传输能⼒\n它与内核缓冲区的计量单位不同:\n带宽是单位时间内的流᯿，表达是「速度」，⽐如常⻅的带宽 100 MB/s；缓\n冲区单位是字节，当⽹络速度乘以时间才能得到字节数。\n带宽时延积BDP决定⽹络中⻜⾏报⽂的⼤⼩。所谓【⻜⾏】，是指它们就在⽹络线路、路由器等⽹络设备上。\n其中：RTT为⽹络时延。\n由于发送缓冲区⼤⼩决定了发送窗⼝的上限，⽽发送窗⼝⼜决定了「已发送未确认」的⻜⾏报⽂的上限。因此，发\n送缓冲区不能超过「带宽时延积」。\n发送缓冲区与带宽时延积的关系如下：\n如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的⽹络传输，同时导致⽹络过载，容易丢包；\n如果发送缓冲区「⼩于」带宽时延积，就不能很好的发挥出⽹络的传输效率。\n（4） 怎样调整缓冲区⼤⼩？\n发送缓冲区⼤⼩可⾃⾏调节，三个数值分别为：动态范围的最⼩值，初始默认值，动态范围的最⼤值。\n接收缓冲区范围调节\n接收缓冲区可以根据系统空闲内存的⼤⼩来调节接收窗⼝：\n如果系统的空闲内存很多，就可以⾃动把缓冲区增⼤⼀些，这样传给对⽅的接收窗⼝也会变⼤，因⽽提升发  送⽅发送\n的传输数据数\n反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常⼯作\n发送缓冲区的调节功能是⾃动开启的，⽽接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能\n调节TCP内存范围\n根据实际场景调节的策略\n⼩结：\nLinux是如何收发⽹络包的\nLinux⽹络协议栈\n从上述⽹络协议栈，可以看出：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2156,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000031",
    "content": "## TCP数据传输性能的提升\n\nTCP  连接是由内核维护的，内核会为每个连接建⽴内存缓冲区：\n如果连接的内存配置过⼩，就⽆法充分使⽤⽹络带宽，TCP  传输效率就会降低；\n如果连接的内存配置过⼤，很容易把服务器资源耗尽，这样就会导致新连接⽆法建⽴；\n因此，我们必须理解 Linux 下 TCP 内存的⽤途，才能正确地配置内存⼤⼩。\n（1） 滑动窗⼝是如何影响传输速度的？\nTCP 会保证每⼀个报⽂都能够抵达对⽅，机制如下：报⽂发出去后，必须接收到对⽅返回的确认报⽂ ACK，如果迟迟\n未收到，就会超时᯿发该报⽂，直到收到对⽅的 ACK 为⽌。\n因此TCP报⽂发出去后，并不会⽴⻢从内存中删除，因为重传时还需要⽤到。由于TCP是由内核维护的，所以报⽂\n存放在内核缓冲区。\n应答：\n批量发送，批量应答：\n引发的问题：\n当接收⽅硬件不如发送⽅，或者系统繁忙、资源紧张时，是⽆法瞬间处理这么多报⽂的。于是，这些报⽂只能被丢\n掉，使得⽹络效率⾮常低。\n为了解决这种现象发⽣，TCP 提供⼀种机制可以让「发送⽅」根据「接收⽅」的实际接收能⼒控制发送的数据量，\n这就是滑动窗⼝的由来。\n接收⽅根据它的缓冲区，可以计算出后续能够接收多少字节的报⽂，这个数字叫做接收窗⼝。当内核接收到报⽂\n时，必须⽤缓冲区存放它们，这样剩余缓冲区空间变⼩，接收窗⼝也就变⼩了；当进程调⽤ read 函数后，数据被\n读⼊了⽤户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报⽂，接收窗⼝就会变⼤。\n因此，接收窗⼝并不是恒定不变的，接收⽅会把当前可接收的⼤⼩放在 TCP 报⽂头部中的窗⼝字段，这样就可以\n起到窗⼝⼤⼩通知的作⽤。\n从上图中可以看到，窗⼝字段只有 2 个字节，因此它最多能表达 65535 字节⼤⼩的窗⼝，也就是 64KB ⼤⼩。\n这个窗⼝⼤⼩最⼤值，在当今⾼速⽹络下，很明显是不够⽤的。\n所以后续有了扩充窗⼝的⽅法：\n在 TCP 选项字段定义了窗⼝扩⼤因⼦，⽤于扩⼤ TCP 通告窗⼝，其值⼤⼩是 2^14，这样就使 TCP 的窗⼝⼤⼩从\n16 位扩⼤为 30 位（2^16 * 2^ 14 = 2^30），所以此时窗⼝的最⼤值可以达到 1GB。\n⽹络的传输能⼒是有限的，当发送⽅依据发送窗⼝，发送超过⽹络处理能⼒的报⽂时，路由器会直接丢弃这些报\n⽂。因此，缓冲区的内存并不是越⼤越好。\n（2） 如何确定最⼤传输速度？\nTCP的传输速度，受限于发送窗⼝，接收窗⼝以及⽹络设备传输能⼒。\n其中，窗⼝⼤⼩由内核缓冲区⼤⼩决定。如果缓冲区与⽹络传输能⼒匹配，那么缓冲区的利⽤率就达到了最⼤化。\n（3） 如何计算⽹络传输能⼒呢？\n⽹络是有「带宽」限制的，带宽描述的是⽹络传输能⼒\n它与内核缓冲区的计量单位不同:\n带宽是单位时间内的流᯿，表达是「速度」，⽐如常⻅的带宽 100 MB/s；缓\n冲区单位是字节，当⽹络速度乘以时间才能得到字节数。\n带宽时延积BDP决定⽹络中⻜⾏报⽂的⼤⼩。所谓【⻜⾏】，是指它们就在⽹络线路、路由器等⽹络设备上。\n其中：RTT为⽹络时延。\n由于发送缓冲区⼤⼩决定了发送窗⼝的上限，⽽发送窗⼝⼜决定了「已发送未确认」的⻜⾏报⽂的上限。因此，发\n送缓冲区不能超过「带宽时延积」。\n发送缓冲区与带宽时延积的关系如下：\n如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的⽹络传输，同时导致⽹络过载，容易丢包；\n如果发送缓冲区「⼩于」带宽时延积，就不能很好的发挥出⽹络的传输效率。\n（4） 怎样调整缓冲区⼤⼩？\n发送缓冲区⼤⼩可⾃⾏调节，三个数值分别为：动态范围的最⼩值，初始默认值，动态范围的最⼤值。\n接收缓冲区范围调节\n接收缓冲区可以根据系统空闲内存的⼤⼩来调节接收窗⼝：\n如果系统的空闲内存很多，就可以⾃动把缓冲区增⼤⼀些，这样传给对⽅的接收窗⼝也会变⼤，因⽽提升发  送⽅发送\n的传输数据数\n反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常⼯作\n发送缓冲区的调节功能是⾃动开启的，⽽接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能\n调节TCP内存范围\n根据实际场景调节的策略\n⼩结：\nLinux是如何收发⽹络包的\nLinux⽹络协议栈\n从上述⽹络协议栈，可以看出：\n收发流程\n⽹卡是计算机⾥的⼀个硬件，专⻔负责接收和发送⽹络包，当⽹卡接收到⼀个⽹络包后，会通过 DMA 技术，将⽹\n络包放⼊到 Ring Buffer，这个是⼀个环形缓冲区。",
    "question": "## TCP数据传输性能的提升",
    "answer": "TCP  连接是由内核维护的，内核会为每个连接建⽴内存缓冲区：\n如果连接的内存配置过⼩，就⽆法充分使⽤⽹络带宽，TCP  传输效率就会降低；\n如果连接的内存配置过⼤，很容易把服务器资源耗尽，这样就会导致新连接⽆法建⽴；\n因此，我们必须理解 Linux 下 TCP 内存的⽤途，才能正确地配置内存⼤⼩。\n（1） 滑动窗⼝是如何影响传输速度的？\nTCP 会保证每⼀个报⽂都能够抵达对⽅，机制如下：报⽂发出去后，必须接收到对⽅返回的确认报⽂ ACK，如果迟迟\n未收到，就会超时᯿发该报⽂，直到收到对⽅的 ACK 为⽌。\n因此TCP报⽂发出去后，并不会⽴⻢从内存中删除，因为重传时还需要⽤到。由于TCP是由内核维护的，所以报⽂\n存放在内核缓冲区。\n应答：\n批量发送，批量应答：\n引发的问题：\n当接收⽅硬件不如发送⽅，或者系统繁忙、资源紧张时，是⽆法瞬间处理这么多报⽂的。于是，这些报⽂只能被丢\n掉，使得⽹络效率⾮常低。\n为了解决这种现象发⽣，TCP 提供⼀种机制可以让「发送⽅」根据「接收⽅」的实际接收能⼒控制发送的数据量，\n这就是滑动窗⼝的由来。\n接收⽅根据它的缓冲区，可以计算出后续能够接收多少字节的报⽂，这个数字叫做接收窗⼝。当内核接收到报⽂\n时，必须⽤缓冲区存放它们，这样剩余缓冲区空间变⼩，接收窗⼝也就变⼩了；当进程调⽤ read 函数后，数据被\n读⼊了⽤户空间，内核缓冲区就被清空，这意味着主机可以接收更多的报⽂，接收窗⼝就会变⼤。\n因此，接收窗⼝并不是恒定不变的，接收⽅会把当前可接收的⼤⼩放在 TCP 报⽂头部中的窗⼝字段，这样就可以\n起到窗⼝⼤⼩通知的作⽤。\n从上图中可以看到，窗⼝字段只有 2 个字节，因此它最多能表达 65535 字节⼤⼩的窗⼝，也就是 64KB ⼤⼩。\n这个窗⼝⼤⼩最⼤值，在当今⾼速⽹络下，很明显是不够⽤的。\n所以后续有了扩充窗⼝的⽅法：\n在 TCP 选项字段定义了窗⼝扩⼤因⼦，⽤于扩⼤ TCP 通告窗⼝，其值⼤⼩是 2^14，这样就使 TCP 的窗⼝⼤⼩从\n16 位扩⼤为 30 位（2^16 * 2^ 14 = 2^30），所以此时窗⼝的最⼤值可以达到 1GB。\n⽹络的传输能⼒是有限的，当发送⽅依据发送窗⼝，发送超过⽹络处理能⼒的报⽂时，路由器会直接丢弃这些报\n⽂。因此，缓冲区的内存并不是越⼤越好。\n（2） 如何确定最⼤传输速度？\nTCP的传输速度，受限于发送窗⼝，接收窗⼝以及⽹络设备传输能⼒。\n其中，窗⼝⼤⼩由内核缓冲区⼤⼩决定。如果缓冲区与⽹络传输能⼒匹配，那么缓冲区的利⽤率就达到了最⼤化。\n（3） 如何计算⽹络传输能⼒呢？\n⽹络是有「带宽」限制的，带宽描述的是⽹络传输能⼒\n它与内核缓冲区的计量单位不同:\n带宽是单位时间内的流᯿，表达是「速度」，⽐如常⻅的带宽 100 MB/s；缓\n冲区单位是字节，当⽹络速度乘以时间才能得到字节数。\n带宽时延积BDP决定⽹络中⻜⾏报⽂的⼤⼩。所谓【⻜⾏】，是指它们就在⽹络线路、路由器等⽹络设备上。\n其中：RTT为⽹络时延。\n由于发送缓冲区⼤⼩决定了发送窗⼝的上限，⽽发送窗⼝⼜决定了「已发送未确认」的⻜⾏报⽂的上限。因此，发\n送缓冲区不能超过「带宽时延积」。\n发送缓冲区与带宽时延积的关系如下：\n如果发送缓冲区「超过」带宽时延积，超出的部分就没办法有效的⽹络传输，同时导致⽹络过载，容易丢包；\n如果发送缓冲区「⼩于」带宽时延积，就不能很好的发挥出⽹络的传输效率。\n（4） 怎样调整缓冲区⼤⼩？\n发送缓冲区⼤⼩可⾃⾏调节，三个数值分别为：动态范围的最⼩值，初始默认值，动态范围的最⼤值。\n接收缓冲区范围调节\n接收缓冲区可以根据系统空闲内存的⼤⼩来调节接收窗⼝：\n如果系统的空闲内存很多，就可以⾃动把缓冲区增⼤⼀些，这样传给对⽅的接收窗⼝也会变⼤，因⽽提升发  送⽅发送\n的传输数据数\n反之，如果系统的内存很紧张，就会减少缓冲区，这虽然会降低传输效率，可以保证更多的并发连接正常⼯作\n发送缓冲区的调节功能是⾃动开启的，⽽接收缓冲区则需要配置 tcp_moderate_rcvbuf 为 1 来开启调节功能\n调节TCP内存范围\n根据实际场景调节的策略\n⼩结：\nLinux是如何收发⽹络包的\nLinux⽹络协议栈\n从上述⽹络协议栈，可以看出：\n收发流程\n⽹卡是计算机⾥的⼀个硬件，专⻔负责接收和发送⽹络包，当⽹卡接收到⼀个⽹络包后，会通过 DMA 技术，将⽹\n络包放⼊到 Ring Buffer，这个是⼀个环形缓冲区。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1868,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000032",
    "content": "收发流程\n\n⽹卡是计算机⾥的⼀个硬件，专⻔负责接收和发送⽹络包，当⽹卡接收到⼀个⽹络包后，会通过 DMA 技术，将⽹\n络包放⼊到 Ring Buffer，这个是⼀个环形缓冲区。\n## 发送\n⾸先，应⽤程序会调⽤  Socket  发送数据包的接⼝，由于这个是系统调⽤，所以会从⽤户态陷⼊到内核态中的\nSocket 层，Socket 层会将应⽤层数据拷⻉到 Socket 发送缓冲区中。\n接下来，⽹络协议栈从 Socket 发送缓冲区中取出数据包，并按照 TCP/IP 协议栈从上到下逐层处理。\n如果使⽤的是 TCP 传输协议发送数据，那么会在传输层增加 TCP 包头，然后交给⽹络层；\n⽹络层会给数据包增加 IP 包，然后通过查询路由表确认下⼀跳的 IP，并按照 MTU ⼤⼩进⾏分⽚。 分⽚后的⽹络\n包，就会被送到⽹络接⼝层，在这⾥会通过 ARP 协议获得下⼀跳的 MAC 地址，然后增加帧头和帧尾，放到发包队\n列中。\n这⼀些准备好后，会触发软中断告诉⽹卡驱动程序，这⾥有新的⽹络包需要发送，最后驱动程序通过 DMA，从发\n包队列中读取⽹络包，将其放⼊到硬件⽹卡的队列中，随后物理⽹卡再将它发送出去。\n## 接收\n为了解决频繁中断带来的性能开销，Linux 内核在 2.6 版本中引⼊了 NAPI 机制，它是混合「中断和轮询」的⽅式\n来接收⽹络包，它的核⼼概念就是不采⽤中断的⽅式读取数据，⽽是⾸先采⽤中断唤醒数据接收的服务程序，然后\npoll 的⽅法来轮询数据。\n⽐如，当有⽹络包到达时，⽹卡发起硬件中断，于是会执⾏⽹卡硬件中断处理函数，中断处理函数处理完需要「暂\n时屏蔽中断」，然后唤醒「软中断」来轮询处理数据，直到没有新数据时才恢复中断，这样⼀次中断处理多个⽹络\n包，于是就可以降低⽹卡中断带来的性能开销。\n软中断会从 Ring Buffer 中拷⻉数据到内核 struct sk_buff 缓冲区中，从⽽可以作为⼀个⽹络包交给⽹络协议栈进\n⾏逐层处理。\n⾸先，会先进⼊到⽹络接⼝层，在这⼀层会检查报⽂的合法性，如果不合法则丢弃，合法则会找出该⽹络包的上层\n协议的类型，⽐如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给⽹络层。到了⽹络层，则取出 IP 包，判\n断⽹络包下⼀步的⾛向，⽐如是交给上层处理还是转发出去。\n当确认这个⽹络包要发送给本机后，就会从 IP 头⾥看看上⼀层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然\n后交给传输层。\n传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端⼝、⽬的 IP、⽬的端⼝」 作为标识，找出对应的\nSocket，并把数据拷⻉到 Socket 的接收缓冲区。\n最后，应⽤层程序调⽤ Socket 接⼝，从内核的 Socket 接收缓冲区读取新到来的数据到应⽤层。\n本部分⾯试题仅做参考，读者可以结合前⾯的基础知识讲解形成⾃⼰的答案。\nOSI 七层参考模型\nOSI（Open System Interconnection）模型，即开放式系统互联，是国际标准化组织（ISO）制定的⼀个⽤于计算\n机或通信系统间互联的标准体系，旨在将计算机⽹络通信划分为七个不同的层级，每个层级都负责特定的功能。每\n个层级都构建在其下⽅的层级之上，并为上⽅的层级提供服务。七层从下到上分别是物理层、数据链路层、⽹络 层、\n传输层、会话层、表示层和应⽤层。可以简称为“物数⽹传会表应”。\n## 物理层：负责物理传输媒介的传输，例如电缆、光纤或⽆线信号。主要作⽤是传输⽐特流（就是由 1、0 转化\n为电流强弱来进⾏传输，到达⽬的地后再转化为 1、0，也就是我们常说的数模转换与模数转换）。这⼀层的\n数据叫做⽐特。\n## 数据链路层：建⽴逻辑连接、进⾏硬件地址寻址、差错校验等功能。定义了如何让格式化数据以帧为单位进⾏\n传输，以及如何控制对物理介质的访问。将⽐特组合成字节进⽽组合成帧，⽤ MAC 地址访问介质，传输单位\n是桢。\n## ⽹络层：负责数据的路由和转发，选择最佳路径将数据从源主机传输到⽬标主机。它使⽤IP地址来标识不同主\n机和⽹络，并进⾏逻辑地址寻址。传输单位是数据报。常⻅的协议有ICMP、ARP、IP\n## 传输层：提供端到端的数据传输服务。它使⽤TCP（传输控制协议）和UDP（⽤户数据报协议）来管理数据传\n## 会话层：建⽴、管理和终⽌应⽤程序之间的会话连接。它处理会话建⽴、维护和终⽌，以及处理会话过程中的\n异常情况。\n## 表示层：负责数据的格式转换、加密和解密，确保数据在不同系统之间的正确解释和呈现，也就是把计算机能\n够识别的东⻄转换成⼈能够能识别的东⻄（如图⽚、声⾳等）。\n## 应⽤层：⽹络服务与最终⽤户的⼀个接⼝。这⼀层为⽤户的应⽤程序（例如电⼦邮件、⽂件传输和终端仿真）\n提供⽹络服务。常⻅的协议有：FTP、SMTP、HTTP、DNS。\nOSI七层⽹络模型为⽹络通信的不同功能提供了逻辑上的划分，为⽹络协议的设计和实现提供了标准化的框架。然\n⽽，在实际⽹络通信中，常⽤的TCP/IP协议栈更为⼴泛和普遍。\nTCP/IP四层⽹络模型\nTCP/IP模型是⼀种⽤于组织和描述计算机⽹络通信的标准模型，它是互联⽹最常⽤的协议栈。TCP/IP模型由两个主\n要协议组成：TCP（Transmission Control Protocol）和IP（Internet Protocol）。它是互联⽹通信的基础，也被\n⼴泛⽤于局域⽹和⼴域⽹等各种⽹络环境。\nTCP/IP模型分为四个层级，每个层级负责特定的⽹络功能。以下是TCP/IP模型的层级及其功能：\n## 应⽤层（Application Layer）：该层与OSI模型的应⽤层和表示层以及会话层类似，提供直接与⽤户应⽤程\n序交互的接⼝。它为⽹络上的各种应⽤程序提供服务，如电⼦邮件（SMTP）、⽹⻚浏览（HTTP）、⽂件传\n输（FTP）等。\n## 传输层（Transport Layer）：该层对应OSI模型的传输层。它负责端到端的数据传输，提供可靠的、⽆连接\n的数据传输服务。主要的传输层协议有TCP（Transmission Control Protocol）和UDP（User Datagram\nProtocol）。TCP提供可靠的数据传输，确保数据的正确性和完整性；⽽UDP则是⽆连接的，适⽤于不要求可\n靠性的传输，如实时⾳频和视频流。\n## ⽹际层（Internet Layer）：该层对应OSI模型的⽹络层。主要协议是IP（Internet Protocol），它负责数\n据包的路由和转发，选择最佳路径将数据从源主机传输到⽬标主机。IP协议使⽤IP地址来标识主机和⽹络，并\n进⾏逻辑地址寻址。\n## ⽹络接⼝层（Link Layer）：该层对应OSI模型的数据链路层和物理层。它负责物理传输媒介的传输，例如以\n太⽹、Wi-Fi等，并提供错误检测和纠正的功能。此外，⽹络接⼝层还包含硬件地址（MAC地址）的管理。\nTCP/IP模型和OSI七层⽹络模型有些相似，但并不完全⼀样。TCP/IP模型较为简洁，只分为四个层级，⽽OSI模型分\n为七个层级。虽然OSI模型在理论上更全⾯，但在实际⽹络通信中，TCP/IP模型更为实⽤，并且成为了互联⽹通信\n的主要参考模型。\n两种⽹络模型的对⽐\n对应的数据封装：\n五层⽹络体系结构\n五层⽹络体系结构是综合了OSI模型和TCP/IP模型所得来的。\n五层⽹络体系结构分别为：应⽤层、运输层、⽹络层、数据链路层、物理层。各层功能分别如下：\n## 应⽤层（Application Layer）：与直接为⽤户的应⽤进程提供服务，是操作系统中的⽤户态，常⻅的有⽀持\n万维⽹应⽤的HTTP协议、⽀持电⼦邮件的SMTP协议，⽀持⽂件传送的FTP协议等等。\n## 传输层（Transport Layer）：负责向两个主机中进程之间的通信提供服务，是端（端⼝）到端的通信。传输\n层有两个传输协议。\nTCP：⾯向连接的、可靠的传输控制协议\nUDP:  ⽆连接的，不提供可靠服务的⽤户数据报协议。\n## ⽹络层（Network   Layer）：负责数据的路由和转发。它选择最佳路径将数据从源主机传输到⽬标主机，并使\n⽤逻辑地址（如IP地址）来标识主机和⽹络。\n## 数据链路层（Data Link Layer）：在直连⽹络中传输数据帧。它提供错误检测和纠正的功能，并负责数据的\n帧同步、地址寻址和流量控制。在这⼀层级上，通常会使⽤MAC地址来标识⽹络设备。\n## 物理层（Physical Layer）：负责物理传输媒介的传输。这包括电缆、光纤、⽆线信号等。该层级定义了传输\n数据位的形式、电压级别、传输速率等特性。\n从输⼊URL到⻚⾯展示发⽣了什么？\n## URL 输⼊：⽤户在浏览器的地址栏中输⼊  URL，例如  \"https://www.example.com\"。\n## 域名解析：浏览器通过域名系统（DNS）将域名解析为  IP 地址，以确定要连接的服务器位置。\n## 建⽴连接：浏览器使⽤解析得到的 IP 地址，与服务器建⽴⽹络连接。这通常涉及使⽤ TCP 协议进⾏三次握\n## 发送请求：浏览器向服务器发送  HTTP  请求，请求服务器的⽹⻚内容。请求中包含了要访问的路径、⽅法\n（GET、POST等）、头部信息等。\n## 服务器处理：服务器接收到请求后，根据请求的内容和路径，处理请求并返回响应。服务器可能从数据库中获\n取数据，⽣成动态内容，然后将响应发送回浏览器。\n## 接收响应：浏览器接收到服务器的响应，响应包含了 HTTP 状态码、头部信息和⻚⾯内容等。\n## 解析和渲染：浏览器开始解析响应内容，构建⽂档对象模型（DOM）和渲染树。它解析 HTML、CSS 和\nJavaScript，并确定⻚⾯的结构、样式和⾏为。\n## ⻚⾯渲染：浏览器使⽤渲染树和样式信息，将⻚⾯内容绘制到屏幕上。这包括布局、绘制和显示⻚⾯元素。\n## 执⾏ JavaScript：如果⻚⾯包含 JavaScript，浏览器会执⾏ JavaScript 代码，添加交互和动态⾏为。\n## 加载资源：⻚⾯中可能包含外部资源，如图⽚、样式表、脚本⽂件等。浏览器会根据需要下载这些资源，以完\n整地呈现⻚⾯。\n## 完成⻚⾯加载：⻚⾯的所有内容和资源加载完成后，浏览器显示完整的⻚⾯。\nHTTP报⽂\nHTTP请求报⽂\n其主要由请求⾏、请求头、请求体构成\n## 请求⾏ ：(请求⽅法 URI 协议版本号)\n请求⽅法： GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE\nURL： <协议>：//<主机>：<端⼝>/<路径>?<参数>\nHost: example.com\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like\nGecko) Chrome/88.0.4324.96 Safari/537.36\nAccept:\ntext/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,\n*/*;q=0.8\nContent-Type: application/json\nAuthorization: Bearer <token>\nGET /example/index.html HTTP/1.1\nHost: example.com\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like\nGecko) Chrome/88.0.4324.96 Safari/537.36\nAccept:\ntext/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,\n*/*;q=0.8\n协议版本号： HTTP版本号\n例如： POST /chapter17/user.html HTTP/1.1\n## 请求头\n包含请求的附加信息，有key：value组成, 它可以包含很多不同的字段，⽤于告知服务器有关请求的详细信息。⼀\n些常⻅的请求头部字段包括：\nHost：指定服务器的主机名和端⼝号。\nUser-Agent：标识客户端的⽤户代理（浏览器或其他⼯具）。\nAccept：指定客户端可以接受的响应的MIME类型。 Content-\nType：指定请求主体的MIME类型。 Authorization：⽤于进\n⾏身份验证的凭据。\n## 空⾏：  空⾏是请求头部和请求主体之间的空⾏，⽤于分隔请求头部和请求主体。\n## 请求体\n承载多个请求参数的数据,  请求主体是可选的，通常在发送POST、PUT等请求时包含请求的实际数据。例如，在使\n⽤POST请求提交表单数据或上传⽂件时，请求主体会包含这些数据。\n⼀个完整的HTTP请求报⽂示例如下：\nHTTP响应报⽂\nHTTP响应报⽂是服务器向客户端返回的数据格式，⽤于传达服务器对客户端请求的处理结果以及相关的数据。⼀\n个标准的HTTP响应报⽂通常包含状态⾏、响应头、响应体：\n## 状态⾏（Status Line）： 状态⾏包括三个主要部分，⽤空格分隔：\nHTTP协议版本（通常是\"HTTP/1.1\"）\n状态码（表示服务器处理结果的三位数字代码）\n状态消息（对状态码的简要描述）\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=UTF-8\nContent-Length: 1234\nServer: Apache/2.4.38 (Unix)\nSet-Cookie: session_id=abcd1234; Expires=Wed, 11 Aug 2023 00:00:00 GMT\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=UTF-8\nContent-Length: 1234\nServer: Apache/2.4.38 (Unix)\nSet-Cookie: session id=abcd1234; Expires=Wed, 11 Aug 2023 00:00:00 GMT\n<!DOCTYPE html>\n<html>\n<head>\n<title>Example Page</title>\n</head>\n<body>\n<h1>Hello, World!</h1>\n</body>\n</html>\n例如： HTTP/1.1 200 OK\n## 响应头部（Response Headers）： 响应头部也是以键值对的形式提供的额外信息，类似于请求头部，⽤于告\n知客户端有关响应的详细信息。⼀些常⻅的响应头部字段包括：\nContent-Type：指定响应主体的MIME类型。\nContent-Length：指定响应主体的⻓度（字节数）。\nServer：指定服务器的信息。        Location：\n在重定向时指定新的资源位置。\nSet-Cookie：在响应中设置Cookie。\n## 空⾏（Empty Line）： 空⾏是响应头部和响应主体之间的空⾏，⽤于分隔响应头部和响应主体。\n## 响应主体（Response Body）： 响应主体包含服务器返回给客户端的实际数据。例如，当请求⼀个⽹⻚时，\n响应主体将包含HTML内容。响应主体的存在与否取决于请求的性质以及服务器的处理结果。\n⼀个完整的HTTP响应报⽂示例如下：\nHTTP常⻅字段\n通⽤头部字段（General Headers）：\nCache-Control：指定缓存策略。\nConnection：控制连接的⾏为。\nDate：指定⽇期和时间。\n请求头部字段（Request Headers）：\nAccept：指定客户端能够接受的响应的MIME类型。\nAccept-Encoding：指定客户端⽀持的内容编码⽅式。\nAuthorization：⽤于进⾏身份验证的凭据。   Host：\n指定请求的⽬标主机和端⼝。\nUser-Agent：标识客户端的⽤户代理（浏览器或其他⼯具）。\n什么是TCP粘包问题？如何解决TCP粘包问题？\nTCP粘包和拆包问题\nTCP是⼀个“流”协议，所谓流，就是没有界限的⼀⻓串⼆进制数据。TCP作为传输层协议并不了解上层业务数\n据的具体含义，它会根据TCP缓冲区的实际情况进⾏数据包的划分，所以在业务上认为是⼀个完整的包，可能\n会被TCP拆分成多个包进⾏发送，也有可能把多个⼩的包封装成⼀个⼤的数据包发送，这就是所谓的TCP粘包\n和拆包问题。",
    "question": "收发流程",
    "answer": "⽹卡是计算机⾥的⼀个硬件，专⻔负责接收和发送⽹络包，当⽹卡接收到⼀个⽹络包后，会通过 DMA 技术，将⽹\n络包放⼊到 Ring Buffer，这个是⼀个环形缓冲区。\n## 发送\n⾸先，应⽤程序会调⽤  Socket  发送数据包的接⼝，由于这个是系统调⽤，所以会从⽤户态陷⼊到内核态中的\nSocket 层，Socket 层会将应⽤层数据拷⻉到 Socket 发送缓冲区中。\n接下来，⽹络协议栈从 Socket 发送缓冲区中取出数据包，并按照 TCP/IP 协议栈从上到下逐层处理。\n如果使⽤的是 TCP 传输协议发送数据，那么会在传输层增加 TCP 包头，然后交给⽹络层；\n⽹络层会给数据包增加 IP 包，然后通过查询路由表确认下⼀跳的 IP，并按照 MTU ⼤⼩进⾏分⽚。 分⽚后的⽹络\n包，就会被送到⽹络接⼝层，在这⾥会通过 ARP 协议获得下⼀跳的 MAC 地址，然后增加帧头和帧尾，放到发包队\n列中。\n这⼀些准备好后，会触发软中断告诉⽹卡驱动程序，这⾥有新的⽹络包需要发送，最后驱动程序通过 DMA，从发\n包队列中读取⽹络包，将其放⼊到硬件⽹卡的队列中，随后物理⽹卡再将它发送出去。\n## 接收\n为了解决频繁中断带来的性能开销，Linux 内核在 2.6 版本中引⼊了 NAPI 机制，它是混合「中断和轮询」的⽅式\n来接收⽹络包，它的核⼼概念就是不采⽤中断的⽅式读取数据，⽽是⾸先采⽤中断唤醒数据接收的服务程序，然后\npoll 的⽅法来轮询数据。\n⽐如，当有⽹络包到达时，⽹卡发起硬件中断，于是会执⾏⽹卡硬件中断处理函数，中断处理函数处理完需要「暂\n时屏蔽中断」，然后唤醒「软中断」来轮询处理数据，直到没有新数据时才恢复中断，这样⼀次中断处理多个⽹络\n包，于是就可以降低⽹卡中断带来的性能开销。\n软中断会从 Ring Buffer 中拷⻉数据到内核 struct sk_buff 缓冲区中，从⽽可以作为⼀个⽹络包交给⽹络协议栈进\n⾏逐层处理。\n⾸先，会先进⼊到⽹络接⼝层，在这⼀层会检查报⽂的合法性，如果不合法则丢弃，合法则会找出该⽹络包的上层\n协议的类型，⽐如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给⽹络层。到了⽹络层，则取出 IP 包，判\n断⽹络包下⼀步的⾛向，⽐如是交给上层处理还是转发出去。\n当确认这个⽹络包要发送给本机后，就会从 IP 头⾥看看上⼀层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然\n后交给传输层。\n传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端⼝、⽬的 IP、⽬的端⼝」 作为标识，找出对应的\nSocket，并把数据拷⻉到 Socket 的接收缓冲区。\n最后，应⽤层程序调⽤ Socket 接⼝，从内核的 Socket 接收缓冲区读取新到来的数据到应⽤层。\n本部分⾯试题仅做参考，读者可以结合前⾯的基础知识讲解形成⾃⼰的答案。\nOSI 七层参考模型\nOSI（Open System Interconnection）模型，即开放式系统互联，是国际标准化组织（ISO）制定的⼀个⽤于计算\n机或通信系统间互联的标准体系，旨在将计算机⽹络通信划分为七个不同的层级，每个层级都负责特定的功能。每\n个层级都构建在其下⽅的层级之上，并为上⽅的层级提供服务。七层从下到上分别是物理层、数据链路层、⽹络 层、\n传输层、会话层、表示层和应⽤层。可以简称为“物数⽹传会表应”。\n## 物理层：负责物理传输媒介的传输，例如电缆、光纤或⽆线信号。主要作⽤是传输⽐特流（就是由 1、0 转化\n为电流强弱来进⾏传输，到达⽬的地后再转化为 1、0，也就是我们常说的数模转换与模数转换）。这⼀层的\n数据叫做⽐特。\n## 数据链路层：建⽴逻辑连接、进⾏硬件地址寻址、差错校验等功能。定义了如何让格式化数据以帧为单位进⾏\n传输，以及如何控制对物理介质的访问。将⽐特组合成字节进⽽组合成帧，⽤ MAC 地址访问介质，传输单位\n是桢。\n## ⽹络层：负责数据的路由和转发，选择最佳路径将数据从源主机传输到⽬标主机。它使⽤IP地址来标识不同主\n机和⽹络，并进⾏逻辑地址寻址。传输单位是数据报。常⻅的协议有ICMP、ARP、IP\n## 传输层：提供端到端的数据传输服务。它使⽤TCP（传输控制协议）和UDP（⽤户数据报协议）来管理数据传\n## 会话层：建⽴、管理和终⽌应⽤程序之间的会话连接。它处理会话建⽴、维护和终⽌，以及处理会话过程中的\n异常情况。\n## 表示层：负责数据的格式转换、加密和解密，确保数据在不同系统之间的正确解释和呈现，也就是把计算机能\n够识别的东⻄转换成⼈能够能识别的东⻄（如图⽚、声⾳等）。\n## 应⽤层：⽹络服务与最终⽤户的⼀个接⼝。这⼀层为⽤户的应⽤程序（例如电⼦邮件、⽂件传输和终端仿真）\n提供⽹络服务。常⻅的协议有：FTP、SMTP、HTTP、DNS。\nOSI七层⽹络模型为⽹络通信的不同功能提供了逻辑上的划分，为⽹络协议的设计和实现提供了标准化的框架。然\n⽽，在实际⽹络通信中，常⽤的TCP/IP协议栈更为⼴泛和普遍。\nTCP/IP四层⽹络模型\nTCP/IP模型是⼀种⽤于组织和描述计算机⽹络通信的标准模型，它是互联⽹最常⽤的协议栈。TCP/IP模型由两个主\n要协议组成：TCP（Transmission Control Protocol）和IP（Internet Protocol）。它是互联⽹通信的基础，也被\n⼴泛⽤于局域⽹和⼴域⽹等各种⽹络环境。\nTCP/IP模型分为四个层级，每个层级负责特定的⽹络功能。以下是TCP/IP模型的层级及其功能：\n## 应⽤层（Application Layer）：该层与OSI模型的应⽤层和表示层以及会话层类似，提供直接与⽤户应⽤程\n序交互的接⼝。它为⽹络上的各种应⽤程序提供服务，如电⼦邮件（SMTP）、⽹⻚浏览（HTTP）、⽂件传\n输（FTP）等。\n## 传输层（Transport Layer）：该层对应OSI模型的传输层。它负责端到端的数据传输，提供可靠的、⽆连接\n的数据传输服务。主要的传输层协议有TCP（Transmission Control Protocol）和UDP（User Datagram\nProtocol）。TCP提供可靠的数据传输，确保数据的正确性和完整性；⽽UDP则是⽆连接的，适⽤于不要求可\n靠性的传输，如实时⾳频和视频流。\n## ⽹际层（Internet Layer）：该层对应OSI模型的⽹络层。主要协议是IP（Internet Protocol），它负责数\n据包的路由和转发，选择最佳路径将数据从源主机传输到⽬标主机。IP协议使⽤IP地址来标识主机和⽹络，并\n进⾏逻辑地址寻址。\n## ⽹络接⼝层（Link Layer）：该层对应OSI模型的数据链路层和物理层。它负责物理传输媒介的传输，例如以\n太⽹、Wi-Fi等，并提供错误检测和纠正的功能。此外，⽹络接⼝层还包含硬件地址（MAC地址）的管理。\nTCP/IP模型和OSI七层⽹络模型有些相似，但并不完全⼀样。TCP/IP模型较为简洁，只分为四个层级，⽽OSI模型分\n为七个层级。虽然OSI模型在理论上更全⾯，但在实际⽹络通信中，TCP/IP模型更为实⽤，并且成为了互联⽹通信\n的主要参考模型。\n两种⽹络模型的对⽐\n对应的数据封装：\n五层⽹络体系结构\n五层⽹络体系结构是综合了OSI模型和TCP/IP模型所得来的。\n五层⽹络体系结构分别为：应⽤层、运输层、⽹络层、数据链路层、物理层。各层功能分别如下：\n## 应⽤层（Application Layer）：与直接为⽤户的应⽤进程提供服务，是操作系统中的⽤户态，常⻅的有⽀持\n万维⽹应⽤的HTTP协议、⽀持电⼦邮件的SMTP协议，⽀持⽂件传送的FTP协议等等。\n## 传输层（Transport Layer）：负责向两个主机中进程之间的通信提供服务，是端（端⼝）到端的通信。传输\n层有两个传输协议。\nTCP：⾯向连接的、可靠的传输控制协议\nUDP:  ⽆连接的，不提供可靠服务的⽤户数据报协议。\n## ⽹络层（Network   Layer）：负责数据的路由和转发。它选择最佳路径将数据从源主机传输到⽬标主机，并使\n⽤逻辑地址（如IP地址）来标识主机和⽹络。\n## 数据链路层（Data Link Layer）：在直连⽹络中传输数据帧。它提供错误检测和纠正的功能，并负责数据的\n帧同步、地址寻址和流量控制。在这⼀层级上，通常会使⽤MAC地址来标识⽹络设备。\n## 物理层（Physical Layer）：负责物理传输媒介的传输。这包括电缆、光纤、⽆线信号等。该层级定义了传输\n数据位的形式、电压级别、传输速率等特性。\n从输⼊URL到⻚⾯展示发⽣了什么？\n## URL 输⼊：⽤户在浏览器的地址栏中输⼊  URL，例如  \"https://www.example.com\"。\n## 域名解析：浏览器通过域名系统（DNS）将域名解析为  IP 地址，以确定要连接的服务器位置。\n## 建⽴连接：浏览器使⽤解析得到的 IP 地址，与服务器建⽴⽹络连接。这通常涉及使⽤ TCP 协议进⾏三次握\n## 发送请求：浏览器向服务器发送  HTTP  请求，请求服务器的⽹⻚内容。请求中包含了要访问的路径、⽅法\n（GET、POST等）、头部信息等。\n## 服务器处理：服务器接收到请求后，根据请求的内容和路径，处理请求并返回响应。服务器可能从数据库中获\n取数据，⽣成动态内容，然后将响应发送回浏览器。\n## 接收响应：浏览器接收到服务器的响应，响应包含了 HTTP 状态码、头部信息和⻚⾯内容等。\n## 解析和渲染：浏览器开始解析响应内容，构建⽂档对象模型（DOM）和渲染树。它解析 HTML、CSS 和\nJavaScript，并确定⻚⾯的结构、样式和⾏为。\n## ⻚⾯渲染：浏览器使⽤渲染树和样式信息，将⻚⾯内容绘制到屏幕上。这包括布局、绘制和显示⻚⾯元素。\n## 执⾏ JavaScript：如果⻚⾯包含 JavaScript，浏览器会执⾏ JavaScript 代码，添加交互和动态⾏为。\n## 加载资源：⻚⾯中可能包含外部资源，如图⽚、样式表、脚本⽂件等。浏览器会根据需要下载这些资源，以完\n整地呈现⻚⾯。\n## 完成⻚⾯加载：⻚⾯的所有内容和资源加载完成后，浏览器显示完整的⻚⾯。\nHTTP报⽂\nHTTP请求报⽂\n其主要由请求⾏、请求头、请求体构成\n## 请求⾏ ：(请求⽅法 URI 协议版本号)\n请求⽅法： GET、POST、PUT、DELETE、PATCH、HEAD、OPTIONS、TRACE\nURL： <协议>：//<主机>：<端⼝>/<路径>?<参数>\nHost: example.com\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like\nGecko) Chrome/88.0.4324.96 Safari/537.36\nAccept:\ntext/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,\n*/*;q=0.8\nContent-Type: application/json\nAuthorization: Bearer <token>\nGET /example/index.html HTTP/1.1\nHost: example.com\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like\nGecko) Chrome/88.0.4324.96 Safari/537.36\nAccept:\ntext/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,\n*/*;q=0.8\n协议版本号： HTTP版本号\n例如： POST /chapter17/user.html HTTP/1.1\n## 请求头\n包含请求的附加信息，有key：value组成, 它可以包含很多不同的字段，⽤于告知服务器有关请求的详细信息。⼀\n些常⻅的请求头部字段包括：\nHost：指定服务器的主机名和端⼝号。\nUser-Agent：标识客户端的⽤户代理（浏览器或其他⼯具）。\nAccept：指定客户端可以接受的响应的MIME类型。 Content-\nType：指定请求主体的MIME类型。 Authorization：⽤于进\n⾏身份验证的凭据。\n## 空⾏：  空⾏是请求头部和请求主体之间的空⾏，⽤于分隔请求头部和请求主体。\n## 请求体\n承载多个请求参数的数据,  请求主体是可选的，通常在发送POST、PUT等请求时包含请求的实际数据。例如，在使\n⽤POST请求提交表单数据或上传⽂件时，请求主体会包含这些数据。\n⼀个完整的HTTP请求报⽂示例如下：\nHTTP响应报⽂\nHTTP响应报⽂是服务器向客户端返回的数据格式，⽤于传达服务器对客户端请求的处理结果以及相关的数据。⼀\n个标准的HTTP响应报⽂通常包含状态⾏、响应头、响应体：\n## 状态⾏（Status Line）： 状态⾏包括三个主要部分，⽤空格分隔：\nHTTP协议版本（通常是\"HTTP/1.1\"）\n状态码（表示服务器处理结果的三位数字代码）\n状态消息（对状态码的简要描述）\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=UTF-8\nContent-Length: 1234\nServer: Apache/2.4.38 (Unix)\nSet-Cookie: session_id=abcd1234; Expires=Wed, 11 Aug 2023 00:00:00 GMT\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=UTF-8\nContent-Length: 1234\nServer: Apache/2.4.38 (Unix)\nSet-Cookie: session id=abcd1234; Expires=Wed, 11 Aug 2023 00:00:00 GMT\n<!DOCTYPE html>\n<html>\n<head>\n<title>Example Page</title>\n</head>\n<body>\n<h1>Hello, World!</h1>\n</body>\n</html>\n例如： HTTP/1.1 200 OK\n## 响应头部（Response Headers）： 响应头部也是以键值对的形式提供的额外信息，类似于请求头部，⽤于告\n知客户端有关响应的详细信息。⼀些常⻅的响应头部字段包括：\nContent-Type：指定响应主体的MIME类型。\nContent-Length：指定响应主体的⻓度（字节数）。\nServer：指定服务器的信息。        Location：\n在重定向时指定新的资源位置。\nSet-Cookie：在响应中设置Cookie。\n## 空⾏（Empty Line）： 空⾏是响应头部和响应主体之间的空⾏，⽤于分隔响应头部和响应主体。\n## 响应主体（Response Body）： 响应主体包含服务器返回给客户端的实际数据。例如，当请求⼀个⽹⻚时，\n响应主体将包含HTML内容。响应主体的存在与否取决于请求的性质以及服务器的处理结果。\n⼀个完整的HTTP响应报⽂示例如下：\nHTTP常⻅字段\n通⽤头部字段（General Headers）：\nCache-Control：指定缓存策略。\nConnection：控制连接的⾏为。\nDate：指定⽇期和时间。\n请求头部字段（Request Headers）：\nAccept：指定客户端能够接受的响应的MIME类型。\nAccept-Encoding：指定客户端⽀持的内容编码⽅式。\nAuthorization：⽤于进⾏身份验证的凭据。   Host：\n指定请求的⽬标主机和端⼝。\nUser-Agent：标识客户端的⽤户代理（浏览器或其他⼯具）。\n什么是TCP粘包问题？如何解决TCP粘包问题？\nTCP粘包和拆包问题\nTCP是⼀个“流”协议，所谓流，就是没有界限的⼀⻓串⼆进制数据。TCP作为传输层协议并不了解上层业务数\n据的具体含义，它会根据TCP缓冲区的实际情况进⾏数据包的划分，所以在业务上认为是⼀个完整的包，可能\n会被TCP拆分成多个包进⾏发送，也有可能把多个⼩的包封装成⼀个⼤的数据包发送，这就是所谓的TCP粘包\n和拆包问题。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 6952,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000033",
    "content": "## 响应主体（Response Body）： 响应主体包含服务器返回给客户端的实际数据。例如，当请求⼀个⽹⻚时，\n\n响应主体将包含HTML内容。响应主体的存在与否取决于请求的性质以及服务器的处理结果。\n⼀个完整的HTTP响应报⽂示例如下：\nHTTP常⻅字段\n通⽤头部字段（General Headers）：\nCache-Control：指定缓存策略。\nConnection：控制连接的⾏为。\nDate：指定⽇期和时间。\n请求头部字段（Request Headers）：\nAccept：指定客户端能够接受的响应的MIME类型。\nAccept-Encoding：指定客户端⽀持的内容编码⽅式。\nAuthorization：⽤于进⾏身份验证的凭据。   Host：\n指定请求的⽬标主机和端⼝。\nUser-Agent：标识客户端的⽤户代理（浏览器或其他⼯具）。\n什么是TCP粘包问题？如何解决TCP粘包问题？\nTCP粘包和拆包问题\nTCP是⼀个“流”协议，所谓流，就是没有界限的⼀⻓串⼆进制数据。TCP作为传输层协议并不了解上层业务数\n据的具体含义，它会根据TCP缓冲区的实际情况进⾏数据包的划分，所以在业务上认为是⼀个完整的包，可能\n会被TCP拆分成多个包进⾏发送，也有可能把多个⼩的包封装成⼀个⼤的数据包发送，这就是所谓的TCP粘包\n和拆包问题。\n产⽣TCP粘包和拆包的原因\n我们知道TCP是以流动的⽅式传输数据的，传输的最⼩单位为⼀个报⽂段（Segment）。TCP Header中有个\nOptions标识位。常⻅的标识位为MSS（Maximum Segment Size）指的是，连接层每次传输的数据有个最⼤\n限制MTU（Maximum Transmission Unit），⼀般是1500bit，超过这个量要分成多个报⽂段，MSS则是这个\n最⼤限制减去TCP的header，光是要传输的数据的⼤⼩，⼀般为1460bit。换算成字节，也就是180多字   节。\nTCP为提⾼性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了以后，再将缓冲中的数据发送到\n接收⽅。同理，接收⽅也有缓冲区这样的机制来接受数据。 发⽣TCP粘包、拆包主要是以下原因：\n（1）应⽤程序写⼊数据⼤于套接字缓冲区⼤⼩，会发⽣拆包；   （2）应⽤程序写⼊数据⼩于套接字缓冲区⼤\n⼩，⽹卡将应⽤多次写⼊的数据发送到⽹络上，这将会发送粘包； （3）进⾏MSS（最⼤报⽂⻓度）⼤⼩的\nTCP分段，当TCP报⽂⻓度——TCP header⻓度>MSS 的时候会发⽣拆包；  （4）接收⽅法不及时读取套接\n字缓冲区数据，这将发⽣粘包。\n如何处理粘包和拆包\n假设应⽤层协议是http\n我从浏览器中访问了⼀个⽹站，⽹站服务器给我发了200k的数据。建⽴连接的时候，通告的MSS是50k，所以\n为了防⽌ip层分⽚，tcp每次只会发送50k的数据，⼀共发了4个tcp数据包。如果我⼜访问了另⼀个⽹站，这个\n⽹站给我发了100k的数据，这次tcp会发出2个包，问题是，客户端收到6个包，怎么知道前4个包是⼀个⻚\n⾯，后两个是⼀个⻚⾯。既然是tcp将这些包分开了，那tcp会将这些包重组吗，它送给应⽤层的是什么？这是\n我⾃⼰想的⼀个场景，正式⼀点讲的话，这个现象叫拆包。\n我们再考虑⼀个问题。\ntcp中有⼀个negal算法，⽤途是这样的：通信两端有很多⼩的数据包要发送，虽然传送的数据很少，但是流程\n⼀点没少，也需要tcp的各种确认，校验。这样⼩的数据包如果很多，会造成⽹络资源很⼤的浪费，negal算法\n做了这样⼀件事，当来了⼀个很⼩的数据包，我不急于发送这个包，⽽是等来了更多的包，将这些⼩包组合成\n⼤包之后⼀并发送，不就提⾼了⽹络传输的效率的嘛。这个想法收到了很好的效果，但是我们想⼀下，如果是\n分属于两个不同⻚⾯的包，被合并在了⼀起，那客户那边如何区分它们呢？这就是粘包问题。\n从粘包问题我们更可以看出为什么tcp被称为流协议，因为它就跟⽔流⼀样，是没有边界的，没有消息的边界\n保护机制，所以tcp只有流的概念，没有包的概念。\n我们还需要有两个概念：\n（1） ⻓连接：  Client⽅与Server⽅先建⽴通讯连接，连接建⽴后不断开，  然后再进⾏报⽂发送和接收。\n（2） 短连接：Client⽅与Server每进⾏⼀次报⽂收发交易时才进⾏通讯连接，交易完毕后⽴即断开连接。此种⽅\n式常⽤于⼀点对多点 通讯，⽐如多个Client连接⼀个Server。\n实际，我想象的关于粘包的场景是不对的，http连接是短连接，请求之后，收到回答，⽴⻢断开连接，不会出现\n粘包。 拆包现象是有可能存在的。\n处理拆包这⾥提供两种⽅法：\n（1） 通过包头+包⻓+包体的协议形式，当服务器端获取到指定的包⻓时才说明获取完整。  （2） 指定包的结束\n标识，这样当我们获取到指定的标识时，说明包获取完整。\n处理粘包我们从上⾯的分析看到，虽然像http这样的短连接协议不会出现粘包的现象，但是⼀旦建⽴了⻓连接，\n粘包还是有可能会发⽣的。处理粘包的⽅法如下：\n（1） 发送⽅对于发送⽅造成的粘包问题，可以通过关闭Nagle算法来解决，使⽤TCP_NODELAY选项来关闭算\n（2） 接收⽅没有办法来处理粘包现象，只能将问题交给应⽤层来处理。应⽤层的解决办法简单可⾏，不仅能解决\n接收⽅的粘包问题，还可以解决发送⽅的粘包问题。解决办法：循环处理，应⽤程序从接收缓存中读取分组时，读\n完⼀条数据，就应该循环读取下⼀条数据，直到所有数据都被处理完成，判断每条数据的⻓度的⽅法有两种：\n格式化数据：每条数据有固定的格式（开始符，结束符），这种⽅法简单易⾏，但是选择开始符和结束符时⼀\n定要确保每条数据的内部不包含开始符和结束符。\nb. 发送⻓度：发送每条数据时，将数据的⻓度⼀并发送，例如规定数据的前4位是数据的⻓度，应⽤层在处理时\n可以根据⻓度来判断每个分组的开始和结束位置。\nUDP会不会产⽣粘包问题呢？\nTCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采⽤了基于流的传输，基于流的传输不认为消息\n是⼀条⼀条的，是⽆保护消息边界的（保护消息边界：指传输协议把数据当做⼀条独⽴的消息在⽹上传输，接收端\n⼀次只能接受⼀条独⽴的消息）。UDP则是⾯向消息传输的，是有保护消息边界的，接收⽅⼀次只接受⼀条独⽴的\n信息，所以不存在粘包问题。\n举个例⼦：有三个数据包，⼤⼩分别为2k、4k、6k，如果采⽤UDP发送的话，不管接受⽅的接收缓存有多⼤，我\n们必须要进⾏⾄少三次以上的发送才能把数据包发送完，但是使⽤TCP协议发送的话，我们只需要接受⽅的接收缓\n存有12k的⼤⼩，就可以⼀次把这3个数据包全部发送完毕。\nHTTP请求⽅法",
    "question": "## 响应主体（Response Body）： 响应主体包含服务器返回给客户端的实际数据。例如，当请求⼀个⽹⻚时，",
    "answer": "响应主体将包含HTML内容。响应主体的存在与否取决于请求的性质以及服务器的处理结果。\n⼀个完整的HTTP响应报⽂示例如下：\nHTTP常⻅字段\n通⽤头部字段（General Headers）：\nCache-Control：指定缓存策略。\nConnection：控制连接的⾏为。\nDate：指定⽇期和时间。\n请求头部字段（Request Headers）：\nAccept：指定客户端能够接受的响应的MIME类型。\nAccept-Encoding：指定客户端⽀持的内容编码⽅式。\nAuthorization：⽤于进⾏身份验证的凭据。   Host：\n指定请求的⽬标主机和端⼝。\nUser-Agent：标识客户端的⽤户代理（浏览器或其他⼯具）。\n什么是TCP粘包问题？如何解决TCP粘包问题？\nTCP粘包和拆包问题\nTCP是⼀个“流”协议，所谓流，就是没有界限的⼀⻓串⼆进制数据。TCP作为传输层协议并不了解上层业务数\n据的具体含义，它会根据TCP缓冲区的实际情况进⾏数据包的划分，所以在业务上认为是⼀个完整的包，可能\n会被TCP拆分成多个包进⾏发送，也有可能把多个⼩的包封装成⼀个⼤的数据包发送，这就是所谓的TCP粘包\n和拆包问题。\n产⽣TCP粘包和拆包的原因\n我们知道TCP是以流动的⽅式传输数据的，传输的最⼩单位为⼀个报⽂段（Segment）。TCP Header中有个\nOptions标识位。常⻅的标识位为MSS（Maximum Segment Size）指的是，连接层每次传输的数据有个最⼤\n限制MTU（Maximum Transmission Unit），⼀般是1500bit，超过这个量要分成多个报⽂段，MSS则是这个\n最⼤限制减去TCP的header，光是要传输的数据的⼤⼩，⼀般为1460bit。换算成字节，也就是180多字   节。\nTCP为提⾼性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了以后，再将缓冲中的数据发送到\n接收⽅。同理，接收⽅也有缓冲区这样的机制来接受数据。 发⽣TCP粘包、拆包主要是以下原因：\n（1）应⽤程序写⼊数据⼤于套接字缓冲区⼤⼩，会发⽣拆包；   （2）应⽤程序写⼊数据⼩于套接字缓冲区⼤\n⼩，⽹卡将应⽤多次写⼊的数据发送到⽹络上，这将会发送粘包； （3）进⾏MSS（最⼤报⽂⻓度）⼤⼩的\nTCP分段，当TCP报⽂⻓度——TCP header⻓度>MSS 的时候会发⽣拆包；  （4）接收⽅法不及时读取套接\n字缓冲区数据，这将发⽣粘包。\n如何处理粘包和拆包\n假设应⽤层协议是http\n我从浏览器中访问了⼀个⽹站，⽹站服务器给我发了200k的数据。建⽴连接的时候，通告的MSS是50k，所以\n为了防⽌ip层分⽚，tcp每次只会发送50k的数据，⼀共发了4个tcp数据包。如果我⼜访问了另⼀个⽹站，这个\n⽹站给我发了100k的数据，这次tcp会发出2个包，问题是，客户端收到6个包，怎么知道前4个包是⼀个⻚\n⾯，后两个是⼀个⻚⾯。既然是tcp将这些包分开了，那tcp会将这些包重组吗，它送给应⽤层的是什么？这是\n我⾃⼰想的⼀个场景，正式⼀点讲的话，这个现象叫拆包。\n我们再考虑⼀个问题。\ntcp中有⼀个negal算法，⽤途是这样的：通信两端有很多⼩的数据包要发送，虽然传送的数据很少，但是流程\n⼀点没少，也需要tcp的各种确认，校验。这样⼩的数据包如果很多，会造成⽹络资源很⼤的浪费，negal算法\n做了这样⼀件事，当来了⼀个很⼩的数据包，我不急于发送这个包，⽽是等来了更多的包，将这些⼩包组合成\n⼤包之后⼀并发送，不就提⾼了⽹络传输的效率的嘛。这个想法收到了很好的效果，但是我们想⼀下，如果是\n分属于两个不同⻚⾯的包，被合并在了⼀起，那客户那边如何区分它们呢？这就是粘包问题。\n从粘包问题我们更可以看出为什么tcp被称为流协议，因为它就跟⽔流⼀样，是没有边界的，没有消息的边界\n保护机制，所以tcp只有流的概念，没有包的概念。\n我们还需要有两个概念：\n（1） ⻓连接：  Client⽅与Server⽅先建⽴通讯连接，连接建⽴后不断开，  然后再进⾏报⽂发送和接收。\n（2） 短连接：Client⽅与Server每进⾏⼀次报⽂收发交易时才进⾏通讯连接，交易完毕后⽴即断开连接。此种⽅\n式常⽤于⼀点对多点 通讯，⽐如多个Client连接⼀个Server。\n实际，我想象的关于粘包的场景是不对的，http连接是短连接，请求之后，收到回答，⽴⻢断开连接，不会出现\n粘包。 拆包现象是有可能存在的。\n处理拆包这⾥提供两种⽅法：\n（1） 通过包头+包⻓+包体的协议形式，当服务器端获取到指定的包⻓时才说明获取完整。  （2） 指定包的结束\n标识，这样当我们获取到指定的标识时，说明包获取完整。\n处理粘包我们从上⾯的分析看到，虽然像http这样的短连接协议不会出现粘包的现象，但是⼀旦建⽴了⻓连接，\n粘包还是有可能会发⽣的。处理粘包的⽅法如下：\n（1） 发送⽅对于发送⽅造成的粘包问题，可以通过关闭Nagle算法来解决，使⽤TCP_NODELAY选项来关闭算\n（2） 接收⽅没有办法来处理粘包现象，只能将问题交给应⽤层来处理。应⽤层的解决办法简单可⾏，不仅能解决\n接收⽅的粘包问题，还可以解决发送⽅的粘包问题。解决办法：循环处理，应⽤程序从接收缓存中读取分组时，读\n完⼀条数据，就应该循环读取下⼀条数据，直到所有数据都被处理完成，判断每条数据的⻓度的⽅法有两种：\n格式化数据：每条数据有固定的格式（开始符，结束符），这种⽅法简单易⾏，但是选择开始符和结束符时⼀\n定要确保每条数据的内部不包含开始符和结束符。\nb. 发送⻓度：发送每条数据时，将数据的⻓度⼀并发送，例如规定数据的前4位是数据的⻓度，应⽤层在处理时\n可以根据⻓度来判断每个分组的开始和结束位置。\nUDP会不会产⽣粘包问题呢？\nTCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采⽤了基于流的传输，基于流的传输不认为消息\n是⼀条⼀条的，是⽆保护消息边界的（保护消息边界：指传输协议把数据当做⼀条独⽴的消息在⽹上传输，接收端\n⼀次只能接受⼀条独⽴的消息）。UDP则是⾯向消息传输的，是有保护消息边界的，接收⽅⼀次只接受⼀条独⽴的\n信息，所以不存在粘包问题。\n举个例⼦：有三个数据包，⼤⼩分别为2k、4k、6k，如果采⽤UDP发送的话，不管接受⽅的接收缓存有多⼤，我\n们必须要进⾏⾄少三次以上的发送才能把数据包发送完，但是使⽤TCP协议发送的话，我们只需要接受⽅的接收缓\n存有12k的⼤⼩，就可以⼀次把这3个数据包全部发送完毕。\nHTTP请求⽅法",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2784,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000034",
    "content": "产⽣TCP粘包和拆包的原因\n\n我们知道TCP是以流动的⽅式传输数据的，传输的最⼩单位为⼀个报⽂段（Segment）。TCP Header中有个\nOptions标识位。常⻅的标识位为MSS（Maximum Segment Size）指的是，连接层每次传输的数据有个最⼤\n限制MTU（Maximum Transmission Unit），⼀般是1500bit，超过这个量要分成多个报⽂段，MSS则是这个\n最⼤限制减去TCP的header，光是要传输的数据的⼤⼩，⼀般为1460bit。换算成字节，也就是180多字   节。\nTCP为提⾼性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了以后，再将缓冲中的数据发送到\n接收⽅。同理，接收⽅也有缓冲区这样的机制来接受数据。 发⽣TCP粘包、拆包主要是以下原因：\n（1）应⽤程序写⼊数据⼤于套接字缓冲区⼤⼩，会发⽣拆包；   （2）应⽤程序写⼊数据⼩于套接字缓冲区⼤\n⼩，⽹卡将应⽤多次写⼊的数据发送到⽹络上，这将会发送粘包； （3）进⾏MSS（最⼤报⽂⻓度）⼤⼩的\nTCP分段，当TCP报⽂⻓度——TCP header⻓度>MSS 的时候会发⽣拆包；  （4）接收⽅法不及时读取套接\n字缓冲区数据，这将发⽣粘包。\n如何处理粘包和拆包\n假设应⽤层协议是http\n我从浏览器中访问了⼀个⽹站，⽹站服务器给我发了200k的数据。建⽴连接的时候，通告的MSS是50k，所以\n为了防⽌ip层分⽚，tcp每次只会发送50k的数据，⼀共发了4个tcp数据包。如果我⼜访问了另⼀个⽹站，这个\n⽹站给我发了100k的数据，这次tcp会发出2个包，问题是，客户端收到6个包，怎么知道前4个包是⼀个⻚\n⾯，后两个是⼀个⻚⾯。既然是tcp将这些包分开了，那tcp会将这些包重组吗，它送给应⽤层的是什么？这是\n我⾃⼰想的⼀个场景，正式⼀点讲的话，这个现象叫拆包。\n我们再考虑⼀个问题。",
    "question": "产⽣TCP粘包和拆包的原因",
    "answer": "我们知道TCP是以流动的⽅式传输数据的，传输的最⼩单位为⼀个报⽂段（Segment）。TCP Header中有个\nOptions标识位。常⻅的标识位为MSS（Maximum Segment Size）指的是，连接层每次传输的数据有个最⼤\n限制MTU（Maximum Transmission Unit），⼀般是1500bit，超过这个量要分成多个报⽂段，MSS则是这个\n最⼤限制减去TCP的header，光是要传输的数据的⼤⼩，⼀般为1460bit。换算成字节，也就是180多字   节。\nTCP为提⾼性能，发送端会将需要发送的数据发送到缓冲区，等待缓冲区满了以后，再将缓冲中的数据发送到\n接收⽅。同理，接收⽅也有缓冲区这样的机制来接受数据。 发⽣TCP粘包、拆包主要是以下原因：\n（1）应⽤程序写⼊数据⼤于套接字缓冲区⼤⼩，会发⽣拆包；   （2）应⽤程序写⼊数据⼩于套接字缓冲区⼤\n⼩，⽹卡将应⽤多次写⼊的数据发送到⽹络上，这将会发送粘包； （3）进⾏MSS（最⼤报⽂⻓度）⼤⼩的\nTCP分段，当TCP报⽂⻓度——TCP header⻓度>MSS 的时候会发⽣拆包；  （4）接收⽅法不及时读取套接\n字缓冲区数据，这将发⽣粘包。\n如何处理粘包和拆包\n假设应⽤层协议是http\n我从浏览器中访问了⼀个⽹站，⽹站服务器给我发了200k的数据。建⽴连接的时候，通告的MSS是50k，所以\n为了防⽌ip层分⽚，tcp每次只会发送50k的数据，⼀共发了4个tcp数据包。如果我⼜访问了另⼀个⽹站，这个\n⽹站给我发了100k的数据，这次tcp会发出2个包，问题是，客户端收到6个包，怎么知道前4个包是⼀个⻚\n⾯，后两个是⼀个⻚⾯。既然是tcp将这些包分开了，那tcp会将这些包重组吗，它送给应⽤层的是什么？这是\n我⾃⼰想的⼀个场景，正式⼀点讲的话，这个现象叫拆包。\n我们再考虑⼀个问题。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 804,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000035",
    "content": "tcp中有⼀个negal算法，⽤途是这样的：通信两端有很多⼩的数据包要发送，虽然传送的数据很少，但是流程\n\n⼀点没少，也需要tcp的各种确认，校验。这样⼩的数据包如果很多，会造成⽹络资源很⼤的浪费，negal算法\n做了这样⼀件事，当来了⼀个很⼩的数据包，我不急于发送这个包，⽽是等来了更多的包，将这些⼩包组合成\n⼤包之后⼀并发送，不就提⾼了⽹络传输的效率的嘛。这个想法收到了很好的效果，但是我们想⼀下，如果是\n分属于两个不同⻚⾯的包，被合并在了⼀起，那客户那边如何区分它们呢？这就是粘包问题。\n从粘包问题我们更可以看出为什么tcp被称为流协议，因为它就跟⽔流⼀样，是没有边界的，没有消息的边界\n保护机制，所以tcp只有流的概念，没有包的概念。\n我们还需要有两个概念：\n（1） ⻓连接：  Client⽅与Server⽅先建⽴通讯连接，连接建⽴后不断开，  然后再进⾏报⽂发送和接收。\n（2） 短连接：Client⽅与Server每进⾏⼀次报⽂收发交易时才进⾏通讯连接，交易完毕后⽴即断开连接。此种⽅\n式常⽤于⼀点对多点 通讯，⽐如多个Client连接⼀个Server。\n实际，我想象的关于粘包的场景是不对的，http连接是短连接，请求之后，收到回答，⽴⻢断开连接，不会出现\n粘包。 拆包现象是有可能存在的。\n处理拆包这⾥提供两种⽅法：\n（1） 通过包头+包⻓+包体的协议形式，当服务器端获取到指定的包⻓时才说明获取完整。  （2） 指定包的结束\n标识，这样当我们获取到指定的标识时，说明包获取完整。\n处理粘包我们从上⾯的分析看到，虽然像http这样的短连接协议不会出现粘包的现象，但是⼀旦建⽴了⻓连接，\n粘包还是有可能会发⽣的。处理粘包的⽅法如下：\n（1） 发送⽅对于发送⽅造成的粘包问题，可以通过关闭Nagle算法来解决，使⽤TCP_NODELAY选项来关闭算\n（2） 接收⽅没有办法来处理粘包现象，只能将问题交给应⽤层来处理。应⽤层的解决办法简单可⾏，不仅能解决\n接收⽅的粘包问题，还可以解决发送⽅的粘包问题。解决办法：循环处理，应⽤程序从接收缓存中读取分组时，读\n完⼀条数据，就应该循环读取下⼀条数据，直到所有数据都被处理完成，判断每条数据的⻓度的⽅法有两种：\n格式化数据：每条数据有固定的格式（开始符，结束符），这种⽅法简单易⾏，但是选择开始符和结束符时⼀\n定要确保每条数据的内部不包含开始符和结束符。\nb. 发送⻓度：发送每条数据时，将数据的⻓度⼀并发送，例如规定数据的前4位是数据的⻓度，应⽤层在处理时\n可以根据⻓度来判断每个分组的开始和结束位置。\nUDP会不会产⽣粘包问题呢？\nTCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采⽤了基于流的传输，基于流的传输不认为消息\n是⼀条⼀条的，是⽆保护消息边界的（保护消息边界：指传输协议把数据当做⼀条独⽴的消息在⽹上传输，接收端\n⼀次只能接受⼀条独⽴的消息）。UDP则是⾯向消息传输的，是有保护消息边界的，接收⽅⼀次只接受⼀条独⽴的\n信息，所以不存在粘包问题。\n举个例⼦：有三个数据包，⼤⼩分别为2k、4k、6k，如果采⽤UDP发送的话，不管接受⽅的接收缓存有多⼤，我\n们必须要进⾏⾄少三次以上的发送才能把数据包发送完，但是使⽤TCP协议发送的话，我们只需要接受⽅的接收缓\n存有12k的⼤⼩，就可以⼀次把这3个数据包全部发送完毕。\nHTTP请求⽅法\n## GET：申请获取资源，不对服务器产⽣影响\n## POST：POST请求通常⽤于发送数据，例如提交表单数据、上传⽂件等，会影响服务器，服务器可能动态创建\n新的资源或更新原有资源。\n## HEAD：类似GET，仅要求服务器返回头部信息，不返回实际的资源内容。\n## PUT：⽤于更新服务器上的资源或创建新资源。\n## DELETE：请求服务器删除指定的资源。\n## TRACE：⽤于测试。要求⽬标服务器返回原始的HTTP请求内容\n## PATCH： ⽤于对资源进⾏部分更新。\n## CONNECT：⽤于代理服务器\n## OPTIONS：⽤于获取服务器⽀持的HTTP⽅法列表，以及针对指定资源⽀持的⽅法",
    "question": "tcp中有⼀个negal算法，⽤途是这样的：通信两端有很多⼩的数据包要发送，虽然传送的数据很少，但是流程",
    "answer": "⼀点没少，也需要tcp的各种确认，校验。这样⼩的数据包如果很多，会造成⽹络资源很⼤的浪费，negal算法\n做了这样⼀件事，当来了⼀个很⼩的数据包，我不急于发送这个包，⽽是等来了更多的包，将这些⼩包组合成\n⼤包之后⼀并发送，不就提⾼了⽹络传输的效率的嘛。这个想法收到了很好的效果，但是我们想⼀下，如果是\n分属于两个不同⻚⾯的包，被合并在了⼀起，那客户那边如何区分它们呢？这就是粘包问题。\n从粘包问题我们更可以看出为什么tcp被称为流协议，因为它就跟⽔流⼀样，是没有边界的，没有消息的边界\n保护机制，所以tcp只有流的概念，没有包的概念。\n我们还需要有两个概念：\n（1） ⻓连接：  Client⽅与Server⽅先建⽴通讯连接，连接建⽴后不断开，  然后再进⾏报⽂发送和接收。\n（2） 短连接：Client⽅与Server每进⾏⼀次报⽂收发交易时才进⾏通讯连接，交易完毕后⽴即断开连接。此种⽅\n式常⽤于⼀点对多点 通讯，⽐如多个Client连接⼀个Server。\n实际，我想象的关于粘包的场景是不对的，http连接是短连接，请求之后，收到回答，⽴⻢断开连接，不会出现\n粘包。 拆包现象是有可能存在的。\n处理拆包这⾥提供两种⽅法：\n（1） 通过包头+包⻓+包体的协议形式，当服务器端获取到指定的包⻓时才说明获取完整。  （2） 指定包的结束\n标识，这样当我们获取到指定的标识时，说明包获取完整。\n处理粘包我们从上⾯的分析看到，虽然像http这样的短连接协议不会出现粘包的现象，但是⼀旦建⽴了⻓连接，\n粘包还是有可能会发⽣的。处理粘包的⽅法如下：\n（1） 发送⽅对于发送⽅造成的粘包问题，可以通过关闭Nagle算法来解决，使⽤TCP_NODELAY选项来关闭算\n（2） 接收⽅没有办法来处理粘包现象，只能将问题交给应⽤层来处理。应⽤层的解决办法简单可⾏，不仅能解决\n接收⽅的粘包问题，还可以解决发送⽅的粘包问题。解决办法：循环处理，应⽤程序从接收缓存中读取分组时，读\n完⼀条数据，就应该循环读取下⼀条数据，直到所有数据都被处理完成，判断每条数据的⻓度的⽅法有两种：\n格式化数据：每条数据有固定的格式（开始符，结束符），这种⽅法简单易⾏，但是选择开始符和结束符时⼀\n定要确保每条数据的内部不包含开始符和结束符。\nb. 发送⻓度：发送每条数据时，将数据的⻓度⼀并发送，例如规定数据的前4位是数据的⻓度，应⽤层在处理时\n可以根据⻓度来判断每个分组的开始和结束位置。\nUDP会不会产⽣粘包问题呢？\nTCP为了保证可靠传输并减少额外的开销（每次发包都要验证），采⽤了基于流的传输，基于流的传输不认为消息\n是⼀条⼀条的，是⽆保护消息边界的（保护消息边界：指传输协议把数据当做⼀条独⽴的消息在⽹上传输，接收端\n⼀次只能接受⼀条独⽴的消息）。UDP则是⾯向消息传输的，是有保护消息边界的，接收⽅⼀次只接受⼀条独⽴的\n信息，所以不存在粘包问题。\n举个例⼦：有三个数据包，⼤⼩分别为2k、4k、6k，如果采⽤UDP发送的话，不管接受⽅的接收缓存有多⼤，我\n们必须要进⾏⾄少三次以上的发送才能把数据包发送完，但是使⽤TCP协议发送的话，我们只需要接受⽅的接收缓\n存有12k的⼤⼩，就可以⼀次把这3个数据包全部发送完毕。\nHTTP请求⽅法\n## GET：申请获取资源，不对服务器产⽣影响\n## POST：POST请求通常⽤于发送数据，例如提交表单数据、上传⽂件等，会影响服务器，服务器可能动态创建\n新的资源或更新原有资源。\n## HEAD：类似GET，仅要求服务器返回头部信息，不返回实际的资源内容。\n## PUT：⽤于更新服务器上的资源或创建新资源。\n## DELETE：请求服务器删除指定的资源。\n## TRACE：⽤于测试。要求⽬标服务器返回原始的HTTP请求内容\n## PATCH： ⽤于对资源进⾏部分更新。\n## CONNECT：⽤于代理服务器\n## OPTIONS：⽤于获取服务器⽀持的HTTP⽅法列表，以及针对指定资源⽀持的⽅法",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1710,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000036",
    "content": "## OPTIONS：⽤于获取服务器⽀持的HTTP⽅法列表，以及针对指定资源⽀持的⽅法\n\nGET和POST请求的区别\nGET和POST都是HTTP请求⽅法",
    "question": "## OPTIONS：⽤于获取服务器⽀持的HTTP⽅法列表，以及针对指定资源⽀持的⽅法",
    "answer": "GET和POST请求的区别\nGET和POST都是HTTP请求⽅法",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 77,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000037",
    "content": "GET和POST请求的区别\n\nGET和POST都是HTTP请求⽅法\n## GET\n申请获取资源，不对服务器产⽣影响\n## POST\n客户端向服务器提交数据，会影响服务器，服务器可能动态创建新的资源或更新原有资源\n请求数据：若为GET，则请求数据为空；其主要是在POST中进⾏使⽤，使⽤于需要填表单(Form)场景\n参数传递\nHTTP 协议没有 Body 和 URL 的⻓度限制，对 URL 限制的⼤多是浏览器和服务器的原因。\nGET请求的参数⼀般写在URL中，所以GET传送的数据量较⼩，不能⼤于2KB，且只接受ASCII字符\nPOST请求参数⼀般放在请求体中，所以其请求信息没有⻓度限制， 对于数据类型也没有限制\n请求报⽂\n## GET请求报⽂：\n## POST请求报⽂：\n请求⾏中请求⽅法为POST，URL为空，协议版本为HTTP1.1\n与GET不同在于它的请求参数是位于请求数据中，最后⼀⾏name...为请求数据，且，请求数据和请求头之间必须空\n出⼀⾏\n安全和幂等\n安全：HTTP协议中，安全是指请求⽅法不会破坏服务器上的资源\n幂等：多次执⾏相同的操作，结果都相同\nGET为安全幂等的，因为它为只读操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相\nPOST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创\n建多个资源，所以不是幂等的。\n缓存机制\nGET 请求会被浏览器主动cache，如果下⼀次传输的数据相同，那么就返回缓存中的内容，以求更快的展示数\n据，⽽ POST 不会，除⾮⼿动设置。\nGET 请求参数会被完整保留在浏览器历史记录⾥，⽽ POST 中的参数不会被保留。\nGET 产⽣的 URL 地址可以被 保存为书签，⽽ POST 不可以。\nGET 在浏览器回退时是⽆害的，⽽ POST 会再次提交请求。\n时间消耗\nGET 产⽣⼀个 TCP 数据包：浏览器会把 header 和 data ⼀并发送出去，服务器响应 200（返回数据）\nPOST 产⽣两个 TCP 数据包，对于 POST，浏览器先发送 Header，服务器响应 100 continue，浏览器再发送\ndata，服务器响应 200 ok（返回数据）\n编码⽅式\nGET 请求只能进⾏ URL 编码application/x-www-form-urlencoded\nPOST ⽀持多种编码⽅式application/x-www-form-urlencoded 或 multipart/form-data 。为⼆进制数据使\n⽤多种编码。）",
    "question": "GET和POST请求的区别",
    "answer": "GET和POST都是HTTP请求⽅法\n## GET\n申请获取资源，不对服务器产⽣影响\n## POST\n客户端向服务器提交数据，会影响服务器，服务器可能动态创建新的资源或更新原有资源\n请求数据：若为GET，则请求数据为空；其主要是在POST中进⾏使⽤，使⽤于需要填表单(Form)场景\n参数传递\nHTTP 协议没有 Body 和 URL 的⻓度限制，对 URL 限制的⼤多是浏览器和服务器的原因。\nGET请求的参数⼀般写在URL中，所以GET传送的数据量较⼩，不能⼤于2KB，且只接受ASCII字符\nPOST请求参数⼀般放在请求体中，所以其请求信息没有⻓度限制， 对于数据类型也没有限制\n请求报⽂\n## GET请求报⽂：\n## POST请求报⽂：\n请求⾏中请求⽅法为POST，URL为空，协议版本为HTTP1.1\n与GET不同在于它的请求参数是位于请求数据中，最后⼀⾏name...为请求数据，且，请求数据和请求头之间必须空\n出⼀⾏\n安全和幂等\n安全：HTTP协议中，安全是指请求⽅法不会破坏服务器上的资源\n幂等：多次执⾏相同的操作，结果都相同\nGET为安全幂等的，因为它为只读操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相\nPOST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创\n建多个资源，所以不是幂等的。\n缓存机制\nGET 请求会被浏览器主动cache，如果下⼀次传输的数据相同，那么就返回缓存中的内容，以求更快的展示数\n据，⽽ POST 不会，除⾮⼿动设置。\nGET 请求参数会被完整保留在浏览器历史记录⾥，⽽ POST 中的参数不会被保留。\nGET 产⽣的 URL 地址可以被 保存为书签，⽽ POST 不可以。\nGET 在浏览器回退时是⽆害的，⽽ POST 会再次提交请求。\n时间消耗\nGET 产⽣⼀个 TCP 数据包：浏览器会把 header 和 data ⼀并发送出去，服务器响应 200（返回数据）\nPOST 产⽣两个 TCP 数据包，对于 POST，浏览器先发送 Header，服务器响应 100 continue，浏览器再发送\ndata，服务器响应 200 ok（返回数据）\n编码⽅式\nGET 请求只能进⾏ URL 编码application/x-www-form-urlencoded\nPOST ⽀持多种编码⽅式application/x-www-form-urlencoded 或 multipart/form-data 。为⼆进制数据使\n⽤多种编码。）",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1087,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000038",
    "content": "## POST请求报⽂：\n\n请求⾏中请求⽅法为POST，URL为空，协议版本为HTTP1.1\n与GET不同在于它的请求参数是位于请求数据中，最后⼀⾏name...为请求数据，且，请求数据和请求头之间必须空\n出⼀⾏\n安全和幂等\n安全：HTTP协议中，安全是指请求⽅法不会破坏服务器上的资源\n幂等：多次执⾏相同的操作，结果都相同\nGET为安全幂等的，因为它为只读操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相\nPOST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创\n建多个资源，所以不是幂等的。\n缓存机制\nGET 请求会被浏览器主动cache，如果下⼀次传输的数据相同，那么就返回缓存中的内容，以求更快的展示数\n据，⽽ POST 不会，除⾮⼿动设置。\nGET 请求参数会被完整保留在浏览器历史记录⾥，⽽ POST 中的参数不会被保留。\nGET 产⽣的 URL 地址可以被 保存为书签，⽽ POST 不可以。\nGET 在浏览器回退时是⽆害的，⽽ POST 会再次提交请求。\n时间消耗\nGET 产⽣⼀个 TCP 数据包：浏览器会把 header 和 data ⼀并发送出去，服务器响应 200（返回数据）\nPOST 产⽣两个 TCP 数据包，对于 POST，浏览器先发送 Header，服务器响应 100 continue，浏览器再发送\ndata，服务器响应 200 ok（返回数据）\n编码⽅式\nGET 请求只能进⾏ URL 编码application/x-www-form-urlencoded\nPOST ⽀持多种编码⽅式application/x-www-form-urlencoded 或 multipart/form-data 。为⼆进制数据使\n⽤多种编码。）\n实际上本质都是⼀样的，并⽆区别",
    "question": "## POST请求报⽂：",
    "answer": "请求⾏中请求⽅法为POST，URL为空，协议版本为HTTP1.1\n与GET不同在于它的请求参数是位于请求数据中，最后⼀⾏name...为请求数据，且，请求数据和请求头之间必须空\n出⼀⾏\n安全和幂等\n安全：HTTP协议中，安全是指请求⽅法不会破坏服务器上的资源\n幂等：多次执⾏相同的操作，结果都相同\nGET为安全幂等的，因为它为只读操作，⽆论操作多少次，服务器上的数据都是安全的，且每次的结果都是相\nPOST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创\n建多个资源，所以不是幂等的。\n缓存机制\nGET 请求会被浏览器主动cache，如果下⼀次传输的数据相同，那么就返回缓存中的内容，以求更快的展示数\n据，⽽ POST 不会，除⾮⼿动设置。\nGET 请求参数会被完整保留在浏览器历史记录⾥，⽽ POST 中的参数不会被保留。\nGET 产⽣的 URL 地址可以被 保存为书签，⽽ POST 不可以。\nGET 在浏览器回退时是⽆害的，⽽ POST 会再次提交请求。\n时间消耗\nGET 产⽣⼀个 TCP 数据包：浏览器会把 header 和 data ⼀并发送出去，服务器响应 200（返回数据）\nPOST 产⽣两个 TCP 数据包，对于 POST，浏览器先发送 Header，服务器响应 100 continue，浏览器再发送\ndata，服务器响应 200 ok（返回数据）\n编码⽅式\nGET 请求只能进⾏ URL 编码application/x-www-form-urlencoded\nPOST ⽀持多种编码⽅式application/x-www-form-urlencoded 或 multipart/form-data 。为⼆进制数据使\n⽤多种编码。）\n实际上本质都是⼀样的，并⽆区别",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 779,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000039",
    "content": "实际上本质都是⼀样的，并⽆区别\n\n## 都是HTTP请求协议的请求⽅法，⽽HTTP⼜是基于TCP/IP的关于数据如何在万维⽹中如何通信的协议，所以\nGET/POST实际上都是TCP链接\n## 由于HTTP的规定以及浏览器/服务器的限制，导致它们在应⽤过程中可能会有所不同\nHTTP状态码",
    "question": "实际上本质都是⼀样的，并⽆区别",
    "answer": "## 都是HTTP请求协议的请求⽅法，⽽HTTP⼜是基于TCP/IP的关于数据如何在万维⽹中如何通信的协议，所以\nGET/POST实际上都是TCP链接\n## 由于HTTP的规定以及浏览器/服务器的限制，导致它们在应⽤过程中可能会有所不同\nHTTP状态码",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 143,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000040",
    "content": "## 由于HTTP的规定以及浏览器/服务器的限制，导致它们在应⽤过程中可能会有所不同\n\nHTTP状态码\n200：客户端请求成功\n206：partial content 服务器已经正确处理部分GET请求，实现断点续传或同时分⽚下载，该请求必须包含Range\n请求头来指示客户端期望得到的范围\n301（永久重定向）：该资源已被永久移动到新位置，将来任何对该资源的访问都要使⽤本响应返回的若⼲个URL\nIf-None-Match\n302（临时重定向）：请求的资源现在临时从不同的URI中获得\n304：如果客户端发送⼀个待条件的GET请求并且该请求以经被允许，⽽⽂档内容未被改变，则返回304,该响应不\n包含包体（即可直接使⽤缓存）\n400：请求报⽂语法有误，服务器⽆法识别\n401：请求需要认证\n403：请求的对应资源禁⽌被访问\n404：服务器⽆法找到对应资源\n500：服务器内部错误\n503：服务器正忙\nHTTP缓存有⼏种\n将资源（如⽹⻚、图像、脚本等）的副本存储在客户端或中间代理服务器上，以便将来的请求可以直接从缓存中获\n取，⽽不必重新从服务器下载资源。这有助于减少⽹络延迟，提⾼⻚⾯加载速度，并减轻服务器的负担。\n缓存可以解决什么问题\n减少不必要的⽹络传输，节约带宽\n更快的加载⻚⾯\n减少服务器负载，避免服务过载的情况出现\n强制缓存\n强缓存：浏览器判断请求的⽬标资源是否有效命中强缓存，如果命中，则可以直接从内存中读取⽬标资源，⽆需与\n服务器做任何通讯。\nExpires强缓存  ：设置⼀个强缓存时间，此时间范围内，从内存中读取缓存并返回。\nCache-Control强缓存 ： http1.1 中增加该字段，使⽤ max-age 指令，可以设置资源在缓存中的最⻓有效时\n间，单位为秒。例如， Cache-Control: max-age=3600 表示资源在缓存中保留 3600 秒\n协商缓存\n与强制缓存不同，协商缓存依赖于客户端和服务器之间的交互，在协商缓存中，服务器在响应中提供了资源的⼀些\n标识信息，客户端在后续请求中通过这些信息来判断资源是否发⽣了变化，进⽽判断是否需要重新传输资源。\n下⾯是常⽤于协商缓存的⼀些头部字段\nETag 和 If-None-Match：\n是服务器为资源⽣成的唯⼀标识符，可以是根据⽂件内容计算出的哈希值。\n客户端在请求头部的\n字段中携带上次响应的\n服务器⽐较请求中的 If-None-Match 值与当前资源的\n态码 304 Not Modified 。\nLast-Modified 和 If-Modified-Since：\n值，如果匹配，表示资源未发⽣变化，返回状\n是资源的最后修改时间，服务器在响应头部中返回。\nLast-Modified\nIf-Modified-Since\nAlive\nContent）\n客户端在请求头部的\n字段中携带上次响应的\n时间。\n服务器⽐较请求中的\n值与当前资源的  Last-Modified 值，如果请求时间早于资源的\n最后修改时间，表示资源未发⽣变化，返回状态码 304 Not Modified 。\nHTTP1.0和HTTP1.1的区别？\nHTTP1.1 ⽀持⻓连接，每⼀个TCP连接上可以传送多个HTTP请求和响应，默认开启 Connection:Keep-\nHTTP1.0 默认为短连接，每次请求都需要建⽴⼀个TCP连接。",
    "question": "## 由于HTTP的规定以及浏览器/服务器的限制，导致它们在应⽤过程中可能会有所不同",
    "answer": "HTTP状态码\n200：客户端请求成功\n206：partial content 服务器已经正确处理部分GET请求，实现断点续传或同时分⽚下载，该请求必须包含Range\n请求头来指示客户端期望得到的范围\n301（永久重定向）：该资源已被永久移动到新位置，将来任何对该资源的访问都要使⽤本响应返回的若⼲个URL\nIf-None-Match\n302（临时重定向）：请求的资源现在临时从不同的URI中获得\n304：如果客户端发送⼀个待条件的GET请求并且该请求以经被允许，⽽⽂档内容未被改变，则返回304,该响应不\n包含包体（即可直接使⽤缓存）\n400：请求报⽂语法有误，服务器⽆法识别\n401：请求需要认证\n403：请求的对应资源禁⽌被访问\n404：服务器⽆法找到对应资源\n500：服务器内部错误\n503：服务器正忙\nHTTP缓存有⼏种\n将资源（如⽹⻚、图像、脚本等）的副本存储在客户端或中间代理服务器上，以便将来的请求可以直接从缓存中获\n取，⽽不必重新从服务器下载资源。这有助于减少⽹络延迟，提⾼⻚⾯加载速度，并减轻服务器的负担。\n缓存可以解决什么问题\n减少不必要的⽹络传输，节约带宽\n更快的加载⻚⾯\n减少服务器负载，避免服务过载的情况出现\n强制缓存\n强缓存：浏览器判断请求的⽬标资源是否有效命中强缓存，如果命中，则可以直接从内存中读取⽬标资源，⽆需与\n服务器做任何通讯。\nExpires强缓存  ：设置⼀个强缓存时间，此时间范围内，从内存中读取缓存并返回。\nCache-Control强缓存 ： http1.1 中增加该字段，使⽤ max-age 指令，可以设置资源在缓存中的最⻓有效时\n间，单位为秒。例如， Cache-Control: max-age=3600 表示资源在缓存中保留 3600 秒\n协商缓存\n与强制缓存不同，协商缓存依赖于客户端和服务器之间的交互，在协商缓存中，服务器在响应中提供了资源的⼀些\n标识信息，客户端在后续请求中通过这些信息来判断资源是否发⽣了变化，进⽽判断是否需要重新传输资源。\n下⾯是常⽤于协商缓存的⼀些头部字段\nETag 和 If-None-Match：\n是服务器为资源⽣成的唯⼀标识符，可以是根据⽂件内容计算出的哈希值。\n客户端在请求头部的\n字段中携带上次响应的\n服务器⽐较请求中的 If-None-Match 值与当前资源的\n态码 304 Not Modified 。\nLast-Modified 和 If-Modified-Since：\n值，如果匹配，表示资源未发⽣变化，返回状\n是资源的最后修改时间，服务器在响应头部中返回。\nLast-Modified\nIf-Modified-Since\nAlive\nContent）\n客户端在请求头部的\n字段中携带上次响应的\n时间。\n服务器⽐较请求中的\n值与当前资源的  Last-Modified 值，如果请求时间早于资源的\n最后修改时间，表示资源未发⽣变化，返回状态码 304 Not Modified 。\nHTTP1.0和HTTP1.1的区别？\nHTTP1.1 ⽀持⻓连接，每⼀个TCP连接上可以传送多个HTTP请求和响应，默认开启 Connection:Keep-\nHTTP1.0 默认为短连接，每次请求都需要建⽴⼀个TCP连接。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1402,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000041",
    "content": "206：partial content 服务器已经正确处理部分GET请求，实现断点续传或同时分⽚下载，该请求必须包含Range\n\n请求头来指示客户端期望得到的范围\n301（永久重定向）：该资源已被永久移动到新位置，将来任何对该资源的访问都要使⽤本响应返回的若⼲个URL\nIf-None-Match\n302（临时重定向）：请求的资源现在临时从不同的URI中获得",
    "question": "206：partial content 服务器已经正确处理部分GET请求，实现断点续传或同时分⽚下载，该请求必须包含Range",
    "answer": "请求头来指示客户端期望得到的范围\n301（永久重定向）：该资源已被永久移动到新位置，将来任何对该资源的访问都要使⽤本响应返回的若⼲个URL\nIf-None-Match\n302（临时重定向）：请求的资源现在临时从不同的URI中获得",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": 206,
    "char_count": 179,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000042",
    "content": "503：服务器正忙\n\nHTTP缓存有⼏种\n将资源（如⽹⻚、图像、脚本等）的副本存储在客户端或中间代理服务器上，以便将来的请求可以直接从缓存中获\n取，⽽不必重新从服务器下载资源。这有助于减少⽹络延迟，提⾼⻚⾯加载速度，并减轻服务器的负担。\n缓存可以解决什么问题\n减少不必要的⽹络传输，节约带宽\n更快的加载⻚⾯\n减少服务器负载，避免服务过载的情况出现\n强制缓存\n强缓存：浏览器判断请求的⽬标资源是否有效命中强缓存，如果命中，则可以直接从内存中读取⽬标资源，⽆需与\n服务器做任何通讯。\nExpires强缓存  ：设置⼀个强缓存时间，此时间范围内，从内存中读取缓存并返回。\nCache-Control强缓存 ： http1.1 中增加该字段，使⽤ max-age 指令，可以设置资源在缓存中的最⻓有效时\n间，单位为秒。例如， Cache-Control: max-age=3600 表示资源在缓存中保留 3600 秒\n协商缓存\n与强制缓存不同，协商缓存依赖于客户端和服务器之间的交互，在协商缓存中，服务器在响应中提供了资源的⼀些\n标识信息，客户端在后续请求中通过这些信息来判断资源是否发⽣了变化，进⽽判断是否需要重新传输资源。\n下⾯是常⽤于协商缓存的⼀些头部字段\nETag 和 If-None-Match：\n是服务器为资源⽣成的唯⼀标识符，可以是根据⽂件内容计算出的哈希值。\n客户端在请求头部的\n字段中携带上次响应的\n服务器⽐较请求中的 If-None-Match 值与当前资源的\n态码 304 Not Modified 。\nLast-Modified 和 If-Modified-Since：\n值，如果匹配，表示资源未发⽣变化，返回状\n是资源的最后修改时间，服务器在响应头部中返回。\nLast-Modified\nIf-Modified-Since\nAlive\nContent）\n客户端在请求头部的\n字段中携带上次响应的\n时间。\n服务器⽐较请求中的\n值与当前资源的  Last-Modified 值，如果请求时间早于资源的\n最后修改时间，表示资源未发⽣变化，返回状态码 304 Not Modified 。\nHTTP1.0和HTTP1.1的区别？\nHTTP1.1 ⽀持⻓连接，每⼀个TCP连接上可以传送多个HTTP请求和响应，默认开启 Connection:Keep-\nHTTP1.0 默认为短连接，每次请求都需要建⽴⼀个TCP连接。\n## 缓存\nHTTP1.0 主要使⽤If-Modified-Since/Expires 来做为缓存判断的标准\nHTTP1.1 则引⼊了更多的缓存控制策略例如Entity tag / If-None-Match 等更多可供选择的缓存头来控\n制缓存策略。\n## 管道化\n基于HTTP1.1 的⻓连接，使得请求管线化成为可能。管线化使得请求能够“并⾏”传输，但是响应必须按照请\n求发出的顺序依次返回，性能在⼀定程度上得到了改善。\n## 增加Host字段\n使得⼀个服务器能够⽤来创建多个 Web 站点。\n## 状态码\n新增了24个错误状态响应码\n## 带宽优化\nHTTP1.0 中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送\n过来了，并且不⽀持断点续传功能\nHTTP1.1 则在请求头引⼊了range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial\nHTTP1.1有什么特性\n## 持久连接：只要客户端任意⼀端没有明确提出断开TCP连接，就⼀直保持连接，也称为“Keep-Alive”。\n## 管线化：允许客户端在不等待前⼀个响应返回的情况下发送多个请求\n## 增加了 PUT、DELETE、OPTIONS、PATCH 等新的⽅法\n## 新增了24个错误状态响应码\n## 新增了⼀些缓存的字段（ If-Modified-Since, If-None-Match ）\n## HTTP1.1 在请求头引⼊了range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content）\n## 允许响应数据分块（chunked），利于传输⼤⽂件\n## 增加Host 字段：使得⼀个服务器能够⽤来创建多个 Web 站点。\nIf-Modified-Since\nLast-Modified\nAlive\nContent）",
    "question": "503：服务器正忙",
    "answer": "HTTP缓存有⼏种\n将资源（如⽹⻚、图像、脚本等）的副本存储在客户端或中间代理服务器上，以便将来的请求可以直接从缓存中获\n取，⽽不必重新从服务器下载资源。这有助于减少⽹络延迟，提⾼⻚⾯加载速度，并减轻服务器的负担。\n缓存可以解决什么问题\n减少不必要的⽹络传输，节约带宽\n更快的加载⻚⾯\n减少服务器负载，避免服务过载的情况出现\n强制缓存\n强缓存：浏览器判断请求的⽬标资源是否有效命中强缓存，如果命中，则可以直接从内存中读取⽬标资源，⽆需与\n服务器做任何通讯。\nExpires强缓存  ：设置⼀个强缓存时间，此时间范围内，从内存中读取缓存并返回。\nCache-Control强缓存 ： http1.1 中增加该字段，使⽤ max-age 指令，可以设置资源在缓存中的最⻓有效时\n间，单位为秒。例如， Cache-Control: max-age=3600 表示资源在缓存中保留 3600 秒\n协商缓存\n与强制缓存不同，协商缓存依赖于客户端和服务器之间的交互，在协商缓存中，服务器在响应中提供了资源的⼀些\n标识信息，客户端在后续请求中通过这些信息来判断资源是否发⽣了变化，进⽽判断是否需要重新传输资源。\n下⾯是常⽤于协商缓存的⼀些头部字段\nETag 和 If-None-Match：\n是服务器为资源⽣成的唯⼀标识符，可以是根据⽂件内容计算出的哈希值。\n客户端在请求头部的\n字段中携带上次响应的\n服务器⽐较请求中的 If-None-Match 值与当前资源的\n态码 304 Not Modified 。\nLast-Modified 和 If-Modified-Since：\n值，如果匹配，表示资源未发⽣变化，返回状\n是资源的最后修改时间，服务器在响应头部中返回。\nLast-Modified\nIf-Modified-Since\nAlive\nContent）\n客户端在请求头部的\n字段中携带上次响应的\n时间。\n服务器⽐较请求中的\n值与当前资源的  Last-Modified 值，如果请求时间早于资源的\n最后修改时间，表示资源未发⽣变化，返回状态码 304 Not Modified 。\nHTTP1.0和HTTP1.1的区别？\nHTTP1.1 ⽀持⻓连接，每⼀个TCP连接上可以传送多个HTTP请求和响应，默认开启 Connection:Keep-\nHTTP1.0 默认为短连接，每次请求都需要建⽴⼀个TCP连接。\n## 缓存\nHTTP1.0 主要使⽤If-Modified-Since/Expires 来做为缓存判断的标准\nHTTP1.1 则引⼊了更多的缓存控制策略例如Entity tag / If-None-Match 等更多可供选择的缓存头来控\n制缓存策略。\n## 管道化\n基于HTTP1.1 的⻓连接，使得请求管线化成为可能。管线化使得请求能够“并⾏”传输，但是响应必须按照请\n求发出的顺序依次返回，性能在⼀定程度上得到了改善。\n## 增加Host字段\n使得⼀个服务器能够⽤来创建多个 Web 站点。\n## 状态码\n新增了24个错误状态响应码\n## 带宽优化\nHTTP1.0 中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送\n过来了，并且不⽀持断点续传功能\nHTTP1.1 则在请求头引⼊了range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial\nHTTP1.1有什么特性\n## 持久连接：只要客户端任意⼀端没有明确提出断开TCP连接，就⼀直保持连接，也称为“Keep-Alive”。\n## 管线化：允许客户端在不等待前⼀个响应返回的情况下发送多个请求\n## 增加了 PUT、DELETE、OPTIONS、PATCH 等新的⽅法\n## 新增了24个错误状态响应码\n## 新增了⼀些缓存的字段（ If-Modified-Since, If-None-Match ）\n## HTTP1.1 在请求头引⼊了range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial Content）\n## 允许响应数据分块（chunked），利于传输⼤⽂件\n## 增加Host 字段：使得⼀个服务器能够⽤来创建多个 Web 站点。\nIf-Modified-Since\nLast-Modified\nAlive\nContent）",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": 503,
    "char_count": 1804,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000043",
    "content": "## 增加Host 字段：使得⼀个服务器能够⽤来创建多个 Web 站点。\n\nIf-Modified-Since\nLast-Modified\nAlive\nContent）\nHTPP1.1和HTTP1.0有什么区别\nHTTP1.1 ⽀持⻓连接，每⼀个TCP连接上可以传送多个HTTP请求和响应，默认开启 Connection:Keep-\nHTTP1.0 默认为短连接，每次请求都需要建⽴⼀个TCP连接。",
    "question": "## 增加Host 字段：使得⼀个服务器能够⽤来创建多个 Web 站点。",
    "answer": "If-Modified-Since\nLast-Modified\nAlive\nContent）\nHTPP1.1和HTTP1.0有什么区别\nHTTP1.1 ⽀持⻓连接，每⼀个TCP连接上可以传送多个HTTP请求和响应，默认开启 Connection:Keep-\nHTTP1.0 默认为短连接，每次请求都需要建⽴⼀个TCP连接。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 199,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000044",
    "content": "HTPP1.1和HTTP1.0有什么区别\n\nHTTP1.1 ⽀持⻓连接，每⼀个TCP连接上可以传送多个HTTP请求和响应，默认开启 Connection:Keep-\nHTTP1.0 默认为短连接，每次请求都需要建⽴⼀个TCP连接。\n## 缓存\nHTTP1.0 主要使⽤If-Modified-Since/Expires 来做为缓存判断的标准\nHTTP1.1 则引⼊了更多的缓存控制策略例如Entity tag / If-None-Match 等更多可供选择的缓存头来控\n制缓存策略。\n## 管道化\n基于HTTP1.1 的⻓连接，使得请求管线化成为可能。管线化使得请求能够“并⾏”传输，但是响应必须按照请\n求发出的顺序依次返回，性能在⼀定程度上得到了改善。\n## 增加Host字段\n使得⼀个服务器能够⽤来创建多个 Web 站点。\n## 状态码\n新增了24个错误状态响应码\n## 带宽优化\nHTTP1.0 中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送\n过来了，并且不⽀持断点续传功能\nHTTP1.1 则在请求头引⼊了range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial",
    "question": "HTPP1.1和HTTP1.0有什么区别",
    "answer": "HTTP1.1 ⽀持⻓连接，每⼀个TCP连接上可以传送多个HTTP请求和响应，默认开启 Connection:Keep-\nHTTP1.0 默认为短连接，每次请求都需要建⽴⼀个TCP连接。\n## 缓存\nHTTP1.0 主要使⽤If-Modified-Since/Expires 来做为缓存判断的标准\nHTTP1.1 则引⼊了更多的缓存控制策略例如Entity tag / If-None-Match 等更多可供选择的缓存头来控\n制缓存策略。\n## 管道化\n基于HTTP1.1 的⻓连接，使得请求管线化成为可能。管线化使得请求能够“并⾏”传输，但是响应必须按照请\n求发出的顺序依次返回，性能在⼀定程度上得到了改善。\n## 增加Host字段\n使得⼀个服务器能够⽤来创建多个 Web 站点。\n## 状态码\n新增了24个错误状态响应码\n## 带宽优化\nHTTP1.0 中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送\n过来了，并且不⽀持断点续传功能\nHTTP1.1 则在请求头引⼊了range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 517,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000045",
    "content": "## 带宽优化\n\nHTTP1.0 中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送\n过来了，并且不⽀持断点续传功能\nHTTP1.1 则在请求头引⼊了range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial\nHTTP/2.0和HTTP1.1有什么区别",
    "question": "## 带宽优化",
    "answer": "HTTP1.0 中，存在⼀些浪费带宽的现象，例如客户端只是需要某个对象的⼀部分，⽽服务器却将整个对象送\n过来了，并且不⽀持断点续传功能\nHTTP1.1 则在请求头引⼊了range 头域，它允许只请求资源的某个部分，即返回码是 206（Partial\nHTTP/2.0和HTTP1.1有什么区别",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 155,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000046",
    "content": "HTTP/2.0和HTTP1.1有什么区别\n\n## 传输格式变化，采⽤了新的⼆进制格式\nHTTP1.X 的解析都是基于⽂本，⽂本的表现形式多样，不利于健壮性考虑\nHTTP2.0 采⽤⼆进制，只认0/1组合，实现更加快的⽅法，健壮性更加完善\n## 多路复⽤\n连接共享\n⼀个请求对应⼀个ID，每个连接都可以有多个请求\n接收⽅可以根据请求的ID将请求再归属到各⾃不同的服务端请求中\n可以极⼤的提⾼效率\n## header压缩\n在HTTP1.X中，header带有⼤量信息，⽽且每次都要重复发送\nHTTP2.0通过encoder减少header⼤⼩，通讯双⽅会各⾃缓存⼀份header字段表\n既可以避免重复header传输，⼜减⼩了需要传输的⼤⼩\n## 服务端推送",
    "question": "HTTP/2.0和HTTP1.1有什么区别",
    "answer": "## 传输格式变化，采⽤了新的⼆进制格式\nHTTP1.X 的解析都是基于⽂本，⽂本的表现形式多样，不利于健壮性考虑\nHTTP2.0 采⽤⼆进制，只认0/1组合，实现更加快的⽅法，健壮性更加完善\n## 多路复⽤\n连接共享\n⼀个请求对应⼀个ID，每个连接都可以有多个请求\n接收⽅可以根据请求的ID将请求再归属到各⾃不同的服务端请求中\n可以极⼤的提⾼效率\n## header压缩\n在HTTP1.X中，header带有⼤量信息，⽽且每次都要重复发送\nHTTP2.0通过encoder减少header⼤⼩，通讯双⽅会各⾃缓存⼀份header字段表\n既可以避免重复header传输，⼜减⼩了需要传输的⼤⼩\n## 服务端推送",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 328,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000047",
    "content": "## 服务端推送\n\n把客户端所需要的资源伴随着index.html⼀起发送到客户端，省去了客户端重复请求的步骤\n因为没有发起请求，建⽴连接等操作，所以静态资源通过服务器推送，可以极⼤的提升速度\nHTTP/3\nHTTPS和HTTP的区别\nHTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在\nTCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。\nHTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，\n还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。\n两者的默认端⼝不⼀样，HTTP 默认端⼝号是 80，HTTPS 默认端⼝号是 443。\nHTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。\nSSL/TLS是什么\nSSL：Secure Socket Layer 安全套接字\nTSL：Transport Layer Security 安全传输层协议\nHTTPS（HyperText Transfer Protocol Secure）是基于TLS/SSL的安全版本的HTTP协议\nSSL和TLS协议通过以下⽅式确保安全通信：\n加密：  使⽤加密算法对传输的数据进⾏加密，防⽌第三⽅截取和读取敏感信息。\n身份验证：  使⽤数字证书验证通信双⽅的身份，确保数据传输的可信性。\n数据完整性：  通过使⽤消息摘要算法，确保传输的数据在传输过程中没有被篡改或损坏。\n什么是对称加密和⾮对称加密\n对称加密\n对称加密也称为私钥加密，使⽤相同的密钥来进⾏加密和解密。\n在加密过程中，明⽂数据通过应⽤特定的算法和密钥进⾏加密，⽣成密⽂数据。解密过程则是将密⽂数据应⽤\n同样的算法和密钥进⾏解密，恢复为明⽂数据。\n由于加密和解密都使⽤相同的密钥，因此对称加密算法的速度通常较快，但密钥的安全性很重要。如果密钥泄\n漏，攻击者可以轻易地解密数据。\n⾮对称加密\n⾮对称加密也称为公钥加密，使⽤⼀对不同但相关的密钥：公钥和私钥。\n公钥⽤于加密数据，私钥⽤于解密数据。如果使⽤公钥加密数据，只有拥有相应私钥的⼈才能解密数据；如果\n使⽤私钥加密数据，可以使⽤相应公钥解密。\n除了加密和解密，⾮对称加密还⽤于【数字签名】，可以验证消息的来源和完整性。\nHTTPS是如何建⽴连接的\nHTTPS建⽴连接的⼀般过程：",
    "question": "## 服务端推送",
    "answer": "把客户端所需要的资源伴随着index.html⼀起发送到客户端，省去了客户端重复请求的步骤\n因为没有发起请求，建⽴连接等操作，所以静态资源通过服务器推送，可以极⼤的提升速度\nHTTP/3\nHTTPS和HTTP的区别\nHTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在\nTCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。\nHTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，\n还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。\n两者的默认端⼝不⼀样，HTTP 默认端⼝号是 80，HTTPS 默认端⼝号是 443。\nHTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。\nSSL/TLS是什么\nSSL：Secure Socket Layer 安全套接字\nTSL：Transport Layer Security 安全传输层协议\nHTTPS（HyperText Transfer Protocol Secure）是基于TLS/SSL的安全版本的HTTP协议\nSSL和TLS协议通过以下⽅式确保安全通信：\n加密：  使⽤加密算法对传输的数据进⾏加密，防⽌第三⽅截取和读取敏感信息。\n身份验证：  使⽤数字证书验证通信双⽅的身份，确保数据传输的可信性。\n数据完整性：  通过使⽤消息摘要算法，确保传输的数据在传输过程中没有被篡改或损坏。\n什么是对称加密和⾮对称加密\n对称加密\n对称加密也称为私钥加密，使⽤相同的密钥来进⾏加密和解密。\n在加密过程中，明⽂数据通过应⽤特定的算法和密钥进⾏加密，⽣成密⽂数据。解密过程则是将密⽂数据应⽤\n同样的算法和密钥进⾏解密，恢复为明⽂数据。\n由于加密和解密都使⽤相同的密钥，因此对称加密算法的速度通常较快，但密钥的安全性很重要。如果密钥泄\n漏，攻击者可以轻易地解密数据。\n⾮对称加密\n⾮对称加密也称为公钥加密，使⽤⼀对不同但相关的密钥：公钥和私钥。\n公钥⽤于加密数据，私钥⽤于解密数据。如果使⽤公钥加密数据，只有拥有相应私钥的⼈才能解密数据；如果\n使⽤私钥加密数据，可以使⽤相应公钥解密。\n除了加密和解密，⾮对称加密还⽤于【数字签名】，可以验证消息的来源和完整性。\nHTTPS是如何建⽴连接的\nHTTPS建⽴连接的⼀般过程：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1041,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000048",
    "content": "把客户端所需要的资源伴随着index.html⼀起发送到客户端，省去了客户端重复请求的步骤\n\n因为没有发起请求，建⽴连接等操作，所以静态资源通过服务器推送，可以极⼤的提升速度\nHTTP/3",
    "question": "把客户端所需要的资源伴随着index.html⼀起发送到客户端，省去了客户端重复请求的步骤",
    "answer": "因为没有发起请求，建⽴连接等操作，所以静态资源通过服务器推送，可以极⼤的提升速度\nHTTP/3",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 94,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000049",
    "content": "HTTPS和HTTP的区别\n\nHTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在\nTCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。\nHTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，\n还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。\n两者的默认端⼝不⼀样，HTTP 默认端⼝号是 80，HTTPS 默认端⼝号是 443。\nHTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。",
    "question": "HTTPS和HTTP的区别",
    "answer": "HTTP 是超⽂本传输协议，信息是明⽂传输，存在安全⻛险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在\nTCP 和 HTTP ⽹络层之间加⼊了 SSL/TLS 安全协议，使得报⽂能够加密传输。\nHTTP 连接建⽴相对简单， TCP 三次握⼿之后便可进⾏ HTTP 的报⽂传输。⽽ HTTPS 在 TCP 三次握⼿之后，\n还需进⾏ SSL/TLS 的握⼿过程，才可进⼊加密报⽂传输。\n两者的默认端⼝不⼀样，HTTP 默认端⼝号是 80，HTTPS 默认端⼝号是 443。\nHTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 297,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000050",
    "content": "SSL/TLS是什么\n\nSSL：Secure Socket Layer 安全套接字\nTSL：Transport Layer Security 安全传输层协议\nHTTPS（HyperText Transfer Protocol Secure）是基于TLS/SSL的安全版本的HTTP协议\nSSL和TLS协议通过以下⽅式确保安全通信：\n加密：  使⽤加密算法对传输的数据进⾏加密，防⽌第三⽅截取和读取敏感信息。\n身份验证：  使⽤数字证书验证通信双⽅的身份，确保数据传输的可信性。\n数据完整性：  通过使⽤消息摘要算法，确保传输的数据在传输过程中没有被篡改或损坏。\n什么是对称加密和⾮对称加密\n对称加密\n对称加密也称为私钥加密，使⽤相同的密钥来进⾏加密和解密。\n在加密过程中，明⽂数据通过应⽤特定的算法和密钥进⾏加密，⽣成密⽂数据。解密过程则是将密⽂数据应⽤\n同样的算法和密钥进⾏解密，恢复为明⽂数据。\n由于加密和解密都使⽤相同的密钥，因此对称加密算法的速度通常较快，但密钥的安全性很重要。如果密钥泄\n漏，攻击者可以轻易地解密数据。\n⾮对称加密\n⾮对称加密也称为公钥加密，使⽤⼀对不同但相关的密钥：公钥和私钥。\n公钥⽤于加密数据，私钥⽤于解密数据。如果使⽤公钥加密数据，只有拥有相应私钥的⼈才能解密数据；如果\n使⽤私钥加密数据，可以使⽤相应公钥解密。\n除了加密和解密，⾮对称加密还⽤于【数字签名】，可以验证消息的来源和完整性。\nHTTPS是如何建⽴连接的\nHTTPS建⽴连接的⼀般过程：\n## 客户端发送连接请求：\n当客户端想要与服务器建⽴HTTPS连接时，它会发送⼀个连接请求到服务器的443端⼝，表明它想要使\n⽤HTTPS进⾏通信。\n## 服务器响应：\n服务器收到连接请求后，会发送⼀个CA数字证书 给客户端。这个证书包含了服务器的公钥、证书的颁发\n者信息以及其他相关信息。\n## 客户端验证证书：\n客户端接收到服务器发送的数字证书后，会验证证书的合法性。这个过程包括验证证书的签名、证书是\n否过期、是否与预期域名匹配等。\n## ⽣成会话密钥：\n如果证书验证成功，客户端会⽣成⼀个⽤于该连接的随机会话密钥（对称密钥）。这个密钥将⽤于加密\n通信数据。\n## ⽤公钥加密会话密钥：\n客户端使⽤服务器的公钥，将⽣成的会话密钥进⾏加密，并将加密后的会话密钥发送给服务器。\n## 服务器解密会话密钥：\n服务器使⽤⾃⼰的私钥对客户端发送的加密会话密钥进⾏解密，获得会话密钥。\n## 建⽴安全通信：\n从此时开始，客户端和服务器都有了相同的会话密钥，他们使⽤对称加密算法（如AES）来加密和解密\n通信数据，保证了通信的隐私性和完整性。",
    "question": "SSL/TLS是什么",
    "answer": "SSL：Secure Socket Layer 安全套接字\nTSL：Transport Layer Security 安全传输层协议\nHTTPS（HyperText Transfer Protocol Secure）是基于TLS/SSL的安全版本的HTTP协议\nSSL和TLS协议通过以下⽅式确保安全通信：\n加密：  使⽤加密算法对传输的数据进⾏加密，防⽌第三⽅截取和读取敏感信息。\n身份验证：  使⽤数字证书验证通信双⽅的身份，确保数据传输的可信性。\n数据完整性：  通过使⽤消息摘要算法，确保传输的数据在传输过程中没有被篡改或损坏。\n什么是对称加密和⾮对称加密\n对称加密\n对称加密也称为私钥加密，使⽤相同的密钥来进⾏加密和解密。\n在加密过程中，明⽂数据通过应⽤特定的算法和密钥进⾏加密，⽣成密⽂数据。解密过程则是将密⽂数据应⽤\n同样的算法和密钥进⾏解密，恢复为明⽂数据。\n由于加密和解密都使⽤相同的密钥，因此对称加密算法的速度通常较快，但密钥的安全性很重要。如果密钥泄\n漏，攻击者可以轻易地解密数据。\n⾮对称加密\n⾮对称加密也称为公钥加密，使⽤⼀对不同但相关的密钥：公钥和私钥。\n公钥⽤于加密数据，私钥⽤于解密数据。如果使⽤公钥加密数据，只有拥有相应私钥的⼈才能解密数据；如果\n使⽤私钥加密数据，可以使⽤相应公钥解密。\n除了加密和解密，⾮对称加密还⽤于【数字签名】，可以验证消息的来源和完整性。\nHTTPS是如何建⽴连接的\nHTTPS建⽴连接的⼀般过程：\n## 客户端发送连接请求：\n当客户端想要与服务器建⽴HTTPS连接时，它会发送⼀个连接请求到服务器的443端⼝，表明它想要使\n⽤HTTPS进⾏通信。\n## 服务器响应：\n服务器收到连接请求后，会发送⼀个CA数字证书 给客户端。这个证书包含了服务器的公钥、证书的颁发\n者信息以及其他相关信息。\n## 客户端验证证书：\n客户端接收到服务器发送的数字证书后，会验证证书的合法性。这个过程包括验证证书的签名、证书是\n否过期、是否与预期域名匹配等。\n## ⽣成会话密钥：\n如果证书验证成功，客户端会⽣成⼀个⽤于该连接的随机会话密钥（对称密钥）。这个密钥将⽤于加密\n通信数据。\n## ⽤公钥加密会话密钥：\n客户端使⽤服务器的公钥，将⽣成的会话密钥进⾏加密，并将加密后的会话密钥发送给服务器。\n## 服务器解密会话密钥：\n服务器使⽤⾃⼰的私钥对客户端发送的加密会话密钥进⾏解密，获得会话密钥。\n## 建⽴安全通信：\n从此时开始，客户端和服务器都有了相同的会话密钥，他们使⽤对称加密算法（如AES）来加密和解密\n通信数据，保证了通信的隐私性和完整性。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1109,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000051",
    "content": "## 建⽴安全通信：\n\n从此时开始，客户端和服务器都有了相同的会话密钥，他们使⽤对称加密算法（如AES）来加密和解密\n通信数据，保证了通信的隐私性和完整性。\nURL和URI是什么\nURI（Uniform Resource Identifier）：统⼀资源标识符， URI是⼀个通⽤的术语，⽤于标识任何互联⽹上的资\n源，⽆论资源是什么类型。\nURL（Uniform Resource Locator）：统⼀资源定位符， URL是URI的⼀种特殊形式，它不仅标识资源，还提供\n了资源的位置信息，即如何定位和获取资源。URL由以下⼏部分组成：",
    "question": "## 建⽴安全通信：",
    "answer": "从此时开始，客户端和服务器都有了相同的会话密钥，他们使⽤对称加密算法（如AES）来加密和解密\n通信数据，保证了通信的隐私性和完整性。\nURL和URI是什么\nURI（Uniform Resource Identifier）：统⼀资源标识符， URI是⼀个通⽤的术语，⽤于标识任何互联⽹上的资\n源，⽆论资源是什么类型。\nURL（Uniform Resource Locator）：统⼀资源定位符， URL是URI的⼀种特殊形式，它不仅标识资源，还提供\n了资源的位置信息，即如何定位和获取资源。URL由以下⼏部分组成：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 268,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000052",
    "content": "URL和URI是什么\n\nURI（Uniform Resource Identifier）：统⼀资源标识符， URI是⼀个通⽤的术语，⽤于标识任何互联⽹上的资\n源，⽆论资源是什么类型。\nURL（Uniform Resource Locator）：统⼀资源定位符， URL是URI的⼀种特殊形式，它不仅标识资源，还提供\n了资源的位置信息，即如何定位和获取资源。URL由以下⼏部分组成：\n## 协议（Protocol）： 指定了访问资源的协议，例如HTTP、HTTPS、FTP等。\n## 域名或IP地址（Domain Name or IP Address）： 标识了资源所在的主机或服务器的名称或IP地址。\n## 端⼝号（Port Number）： 指定了服务器上监听资源请求的端⼝号，通常根据协议的默认端⼝。\n## 路径（Path）：  描述了服务器上资源的具体路径或位置。\n## 查询参数（Query Parameters）： ⽤于向服务器传递参数，以影响资源的获取或显示。\n## ⽚段标识（Fragment Identifier）： 标识资源中的特定⽚段或位置。\n以下是⼀个示例URL：https://www.example.com:8080/path/resource?param=value#section\n在这个示例URL中，协议是HTTPS，域名是www.example.com，端⼝号是8080，路径是/path/resource，查询参\n数是param=value，⽚段标识是section。",
    "question": "URL和URI是什么",
    "answer": "URI（Uniform Resource Identifier）：统⼀资源标识符， URI是⼀个通⽤的术语，⽤于标识任何互联⽹上的资\n源，⽆论资源是什么类型。\nURL（Uniform Resource Locator）：统⼀资源定位符， URL是URI的⼀种特殊形式，它不仅标识资源，还提供\n了资源的位置信息，即如何定位和获取资源。URL由以下⼏部分组成：\n## 协议（Protocol）： 指定了访问资源的协议，例如HTTP、HTTPS、FTP等。\n## 域名或IP地址（Domain Name or IP Address）： 标识了资源所在的主机或服务器的名称或IP地址。\n## 端⼝号（Port Number）： 指定了服务器上监听资源请求的端⼝号，通常根据协议的默认端⼝。\n## 路径（Path）：  描述了服务器上资源的具体路径或位置。\n## 查询参数（Query Parameters）： ⽤于向服务器传递参数，以影响资源的获取或显示。\n## ⽚段标识（Fragment Identifier）： 标识资源中的特定⽚段或位置。\n以下是⼀个示例URL：https://www.example.com:8080/path/resource?param=value#section\n在这个示例URL中，协议是HTTPS，域名是www.example.com，端⼝号是8080，路径是/path/resource，查询参\n数是param=value，⽚段标识是section。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 652,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000053",
    "content": "## ⽚段标识（Fragment Identifier）： 标识资源中的特定⽚段或位置。\n\n以下是⼀个示例URL：https://www.example.com:8080/path/resource?param=value#section\n在这个示例URL中，协议是HTTPS，域名是www.example.com，端⼝号是8080，路径是/path/resource，查询参\n数是param=value，⽚段标识是section。\nDNS是什么\nDNS(Domain Name System) 是域名“系统”的英⽂缩写,它作⽤于TCP/IP⽹络，它所提供的服务是⽤来将主机名和域\n名（⽐如www.baidu.com 转换为IP地址 128.13.45.56 的⼯作。\nDNS解析过程",
    "question": "## ⽚段标识（Fragment Identifier）： 标识资源中的特定⽚段或位置。",
    "answer": "以下是⼀个示例URL：https://www.example.com:8080/path/resource?param=value#section\n在这个示例URL中，协议是HTTPS，域名是www.example.com，端⼝号是8080，路径是/path/resource，查询参\n数是param=value，⽚段标识是section。\nDNS是什么\nDNS(Domain Name System) 是域名“系统”的英⽂缩写,它作⽤于TCP/IP⽹络，它所提供的服务是⽤来将主机名和域\n名（⽐如www.baidu.com 转换为IP地址 128.13.45.56 的⼯作。\nDNS解析过程",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 342,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000054",
    "content": "DNS是什么\n\nDNS(Domain Name System) 是域名“系统”的英⽂缩写,它作⽤于TCP/IP⽹络，它所提供的服务是⽤来将主机名和域\n名（⽐如www.baidu.com 转换为IP地址 128.13.45.56 的⼯作。\nDNS解析过程\n## 先查询浏览器缓存是否有该域名对应的IP地址。\n## 如果浏览器缓存中没有，会去计算机本地的Host⽂件中查询是否有对应的缓存。\n## 如果Host⽂件中也没有则会向本地的DNS服务器（通常由你的互联⽹服务提供商（ISP）提供， ⽐如中国移\n动）发送⼀个DNS查询请求。\n## 如果本地DNS解析器有该域名的ip地址，就会直接返回，如果没有缓存该域名的解析记录，它会向根DNS服\n务器发出查询请求。根DNS服务器并不负责解析域名，但它能告诉本地DNS解析器应该向哪个顶级域\n（.com/.net/.org）的DNS服务器继续查询。\n## 本地DNS解析器接着向指定的顶级域名DNS服务器发出查询请求。顶级域DNS服务器也不负责具体的域名解\n析，但它能告诉本地DNS解析器应该前往哪个权威DNS服务器查询下⼀步的信息。\n## 本地DNS解析器最后向权威DNS服务器发送查询请求。 权威DNS服务器是负责存储特定域名和IP地址映射的\n服务器。当权威DNS服务器收到查询请求时，它会查找\"example.com\"域名对应的IP地址，并将结果返回给本\n地DNS解析器。\n## 本地DNS解析器将收到的IP地址返回给浏览器，并且还会将域名解析结果缓存在本地，以便下次访问时更快地\n## 浏览器发起连接： 本地DNS解析器已经将IP地址返回给您的计算机，您的浏览器可以使⽤该IP地址与⽬标服\n务器建⽴连接，开始获取⽹⻚内容。\n递归查询和迭代查询\n递归查询和迭代查询是在DNS解析过程中⽤于获取域名解析信息的两种不同⽅法。\n## 递归查询\n在递归查询中，DNS客户端（通常是本地DNS解析器）向上层DNS服务器（如根域名服务器、顶级域名服务器）发\n起查询请求，并要求这些服务器直接提供完整的解析结果。递归查询的特点是，DNS客户端只需要发送⼀个查询请\n求，然后等待完整的解析结果。上层DNS服务器会⾃⾏查询下⼀级的服务器，并将最终结果返回给DNS客户端。\n## 迭代查询\n在迭代查询中，DNS客户端向上层DNS服务器发起查询请求，但不要求直接提供完整的解析结果。相反，DNS客户\n端只是询问上层服务器⼀个更⾼级的域名服务器的地址，然后再⾃⾏向那个更⾼级的服务器发起查询请求，以此类\n推，直到获取完整的解析结果为⽌。\n递归查询适合普通⽤户和客户端，⽽迭代查询适⽤于DNS服务器之间的通信。",
    "question": "DNS是什么",
    "answer": "DNS(Domain Name System) 是域名“系统”的英⽂缩写,它作⽤于TCP/IP⽹络，它所提供的服务是⽤来将主机名和域\n名（⽐如www.baidu.com 转换为IP地址 128.13.45.56 的⼯作。\nDNS解析过程\n## 先查询浏览器缓存是否有该域名对应的IP地址。\n## 如果浏览器缓存中没有，会去计算机本地的Host⽂件中查询是否有对应的缓存。\n## 如果Host⽂件中也没有则会向本地的DNS服务器（通常由你的互联⽹服务提供商（ISP）提供， ⽐如中国移\n动）发送⼀个DNS查询请求。\n## 如果本地DNS解析器有该域名的ip地址，就会直接返回，如果没有缓存该域名的解析记录，它会向根DNS服\n务器发出查询请求。根DNS服务器并不负责解析域名，但它能告诉本地DNS解析器应该向哪个顶级域\n（.com/.net/.org）的DNS服务器继续查询。\n## 本地DNS解析器接着向指定的顶级域名DNS服务器发出查询请求。顶级域DNS服务器也不负责具体的域名解\n析，但它能告诉本地DNS解析器应该前往哪个权威DNS服务器查询下⼀步的信息。\n## 本地DNS解析器最后向权威DNS服务器发送查询请求。 权威DNS服务器是负责存储特定域名和IP地址映射的\n服务器。当权威DNS服务器收到查询请求时，它会查找\"example.com\"域名对应的IP地址，并将结果返回给本\n地DNS解析器。\n## 本地DNS解析器将收到的IP地址返回给浏览器，并且还会将域名解析结果缓存在本地，以便下次访问时更快地\n## 浏览器发起连接： 本地DNS解析器已经将IP地址返回给您的计算机，您的浏览器可以使⽤该IP地址与⽬标服\n务器建⽴连接，开始获取⽹⻚内容。\n递归查询和迭代查询\n递归查询和迭代查询是在DNS解析过程中⽤于获取域名解析信息的两种不同⽅法。\n## 递归查询\n在递归查询中，DNS客户端（通常是本地DNS解析器）向上层DNS服务器（如根域名服务器、顶级域名服务器）发\n起查询请求，并要求这些服务器直接提供完整的解析结果。递归查询的特点是，DNS客户端只需要发送⼀个查询请\n求，然后等待完整的解析结果。上层DNS服务器会⾃⾏查询下⼀级的服务器，并将最终结果返回给DNS客户端。\n## 迭代查询\n在迭代查询中，DNS客户端向上层DNS服务器发起查询请求，但不要求直接提供完整的解析结果。相反，DNS客户\n端只是询问上层服务器⼀个更⾼级的域名服务器的地址，然后再⾃⾏向那个更⾼级的服务器发起查询请求，以此类\n推，直到获取完整的解析结果为⽌。\n递归查询适合普通⽤户和客户端，⽽迭代查询适⽤于DNS服务器之间的通信。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1115,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000055",
    "content": "## 迭代查询\n\n在迭代查询中，DNS客户端向上层DNS服务器发起查询请求，但不要求直接提供完整的解析结果。相反，DNS客户\n端只是询问上层服务器⼀个更⾼级的域名服务器的地址，然后再⾃⾏向那个更⾼级的服务器发起查询请求，以此类\n推，直到获取完整的解析结果为⽌。\n递归查询适合普通⽤户和客户端，⽽迭代查询适⽤于DNS服务器之间的通信。\nTCP和UDP的概念和特点\nTCP和UDP是两种常⻅的传输层协议，⽤于在计算机⽹络中进⾏数据传输。",
    "question": "## 迭代查询",
    "answer": "在迭代查询中，DNS客户端向上层DNS服务器发起查询请求，但不要求直接提供完整的解析结果。相反，DNS客户\n端只是询问上层服务器⼀个更⾼级的域名服务器的地址，然后再⾃⾏向那个更⾼级的服务器发起查询请求，以此类\n推，直到获取完整的解析结果为⽌。\n递归查询适合普通⽤户和客户端，⽽迭代查询适⽤于DNS服务器之间的通信。\nTCP和UDP的概念和特点\nTCP和UDP是两种常⻅的传输层协议，⽤于在计算机⽹络中进⾏数据传输。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 216,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000056",
    "content": "TCP和UDP的概念和特点\n\nTCP和UDP是两种常⻅的传输层协议，⽤于在计算机⽹络中进⾏数据传输。\n## TCP：TCP 是⾯向连接的、可靠的、基于字节流的传输层通信协议。\nTCP是⼀种⾯向连接的协议，在通信之前，TCP需要在发送和接收⽅之间建⽴连接，然后在通信完成后关闭连\n接。这种连接的建⽴和关闭过程称为“三次握⼿”和“四次挥⼿”，确保可靠的数据传输。\n可靠性：TCP提供可靠的数据传输。它使⽤序列号和确认机制来确保数据包的有序性和完整性。如果数据包丢\n失或损坏，TCP会重新发送丢失的数据包，直到接收⽅正确接收为⽌。\n流量控制和拥塞控制：TCP使⽤流量控制和拥塞控制算法，确保数据发送的速率不会超过接收⽅的处理能⼒，\n并防⽌⽹络拥塞。\n有序传输：TCP确保数据包按照发送的顺序到达接收⽅，并在接收⽅重新组装成正确的顺序。\n适⽤于可靠数据传输的场景：TCP适⽤于那些对数据传输可靠性要求较⾼的应⽤，如⽂件传输、电⼦邮件、⽹\n⻚浏览等。\n## UDP\nUDP是⼀种⽆连接的协议：与TCP不同，UDP在通信之前不需要建⽴连接，直接发送数据包。这使得UDP⽐\nTCP更加轻量级。\n不可靠性：UDP不提供可靠的数据传输。它发送数据包后不会关⼼数据包是否成功到达接收⽅。因此，如果\n数据包丢失或损坏，UDP不会重新发送，也不会提供确认机制。\n速度较快：由于没有连接建⽴和确认过程，UDP传输速度较快，适⽤于实时传输，如实时⾳频和视频流。\n⽆序传输：UDP不保证数据包的有序性，因此接收⽅接收到的数据包可能是⽆序的。\n适⽤于实时传输的场景：UDP适⽤于对数据传输可靠性要求不⾼的场景，如实时游戏、流媒体等，其中实时\n性⽐数据的准确性更为重要。",
    "question": "TCP和UDP的概念和特点",
    "answer": "TCP和UDP是两种常⻅的传输层协议，⽤于在计算机⽹络中进⾏数据传输。\n## TCP：TCP 是⾯向连接的、可靠的、基于字节流的传输层通信协议。\nTCP是⼀种⾯向连接的协议，在通信之前，TCP需要在发送和接收⽅之间建⽴连接，然后在通信完成后关闭连\n接。这种连接的建⽴和关闭过程称为“三次握⼿”和“四次挥⼿”，确保可靠的数据传输。\n可靠性：TCP提供可靠的数据传输。它使⽤序列号和确认机制来确保数据包的有序性和完整性。如果数据包丢\n失或损坏，TCP会重新发送丢失的数据包，直到接收⽅正确接收为⽌。\n流量控制和拥塞控制：TCP使⽤流量控制和拥塞控制算法，确保数据发送的速率不会超过接收⽅的处理能⼒，\n并防⽌⽹络拥塞。\n有序传输：TCP确保数据包按照发送的顺序到达接收⽅，并在接收⽅重新组装成正确的顺序。\n适⽤于可靠数据传输的场景：TCP适⽤于那些对数据传输可靠性要求较⾼的应⽤，如⽂件传输、电⼦邮件、⽹\n⻚浏览等。\n## UDP\nUDP是⼀种⽆连接的协议：与TCP不同，UDP在通信之前不需要建⽴连接，直接发送数据包。这使得UDP⽐\nTCP更加轻量级。\n不可靠性：UDP不提供可靠的数据传输。它发送数据包后不会关⼼数据包是否成功到达接收⽅。因此，如果\n数据包丢失或损坏，UDP不会重新发送，也不会提供确认机制。\n速度较快：由于没有连接建⽴和确认过程，UDP传输速度较快，适⽤于实时传输，如实时⾳频和视频流。\n⽆序传输：UDP不保证数据包的有序性，因此接收⽅接收到的数据包可能是⽆序的。\n适⽤于实时传输的场景：UDP适⽤于对数据传输可靠性要求不⾼的场景，如实时游戏、流媒体等，其中实时\n性⽐数据的准确性更为重要。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 718,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000057",
    "content": "## UDP\n\nUDP是⼀种⽆连接的协议：与TCP不同，UDP在通信之前不需要建⽴连接，直接发送数据包。这使得UDP⽐\nTCP更加轻量级。\n不可靠性：UDP不提供可靠的数据传输。它发送数据包后不会关⼼数据包是否成功到达接收⽅。因此，如果\n数据包丢失或损坏，UDP不会重新发送，也不会提供确认机制。\n速度较快：由于没有连接建⽴和确认过程，UDP传输速度较快，适⽤于实时传输，如实时⾳频和视频流。\n⽆序传输：UDP不保证数据包的有序性，因此接收⽅接收到的数据包可能是⽆序的。\n适⽤于实时传输的场景：UDP适⽤于对数据传输可靠性要求不⾼的场景，如实时游戏、流媒体等，其中实时\n性⽐数据的准确性更为重要。\nTCP与UDP的区别",
    "question": "## UDP",
    "answer": "UDP是⼀种⽆连接的协议：与TCP不同，UDP在通信之前不需要建⽴连接，直接发送数据包。这使得UDP⽐\nTCP更加轻量级。\n不可靠性：UDP不提供可靠的数据传输。它发送数据包后不会关⼼数据包是否成功到达接收⽅。因此，如果\n数据包丢失或损坏，UDP不会重新发送，也不会提供确认机制。\n速度较快：由于没有连接建⽴和确认过程，UDP传输速度较快，适⽤于实时传输，如实时⾳频和视频流。\n⽆序传输：UDP不保证数据包的有序性，因此接收⽅接收到的数据包可能是⽆序的。\n适⽤于实时传输的场景：UDP适⽤于对数据传输可靠性要求不⾼的场景，如实时游戏、流媒体等，其中实时\n性⽐数据的准确性更为重要。\nTCP与UDP的区别",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 309,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000058",
    "content": "TCP与UDP的区别\n\n## 连接\nTCP是⾯向连接的，在传输前需要三次握⼿建⽴连接。\nUDP不需要连接，直接发送数据包，没有连接建⽴和关闭的过程。\n## 服务形式\nTCP是⼀对⼀的通信。在TCP连接中，⼀台客户端与⼀台服务器之间建⽴⼀条连接，进⾏双向通信。\nUDP可以是⼀对⼀、⼀对多或多对多的通信。UDP是⽆连接的，⼀个UDP包可以被⼴播到多个⽬标主机，或\n者从多个源主机接收UDP包。这使得UDP适⽤于多播和⼴播应⽤。\n## 可靠性\nTCP保证数据可靠交付，拥有确认应答和重传机制，⽆重复、不丢失、按序到达;\nUDP尽可能交付，发送数据后不会关⼼数据包是否成功到达接收⽅，不会进⾏重传，不保证可靠性。\n## 流量控制和拥塞控制\nTCP拥有流量控制、拥塞控制，确保数据发送的速率不会超过接收⽅的处理能⼒，并防⽌⽹络拥塞。\nUDP不进⾏流量控制和拥塞控制，数据发送的速率不受限制。\n## ⾸部开销\nTCP的⾸部⼤⼩通常为20字节，但在选项字段被使⽤的情况下，可能会更⼤。TCP⾸部包含源端⼝号、⽬标端\n⼝号、序列号、确认号、窗⼝⼤⼩、校验和等字段。\nUDP的⾸部⼤⼩固定为8字节。UDP⾸部包含源端⼝号、⽬标端⼝号、包⻓度和校验和字段（各16位）。\n## 传输⽅式\nTCP基于字节流，没有边界，但是保证传输顺序和可靠性;\nUDP继承了IP层特性，基于数据包，有边界可能出现乱序和丢包。\n## 分⽚⽅式\nTCP数据⼤于MSS时会在TCP层将数据进⾏分⽚传输，到达⽬的地后同样在传输层进⾏合并，如果有某个⽚丢失则\n只需要重传丢失的分⽚即可;\nUDP数据⼤于MTU时会在IP层分⽚，则会在IP层合并，如果某个IP分⽚丢失，⽬标主机收到后，在 IP 层组装完数据，\n接着再传给传输层。\nTCP和UDP分别在什么场景使⽤？\nUDP适⽤于实时传输的场景：UDP适⽤于对数据传输可靠性要求不⾼的场景，如实时游戏、流媒体等，其中\n实时性⽐数据的准确性更为重要。\nTCP适⽤于可靠数据传输的场景：TCP适⽤于那些对数据传输可靠性要求较⾼的应⽤，如⽂件传输、电⼦邮\n件、⽹⻚浏览等。\nTCP连接如何确保可靠性\nTCP协议保证数据传输可靠性的⽅式主要有：校验和、序列号、确认应答、超时重传、连接管理、流量控制、拥塞\n控制。\n序列号和确认应答：TCP通过给每个发送的数据段分配⼀个序列号，以及使⽤确认（ACK）机制来跟踪数据的\n传输和接收。接收⽅会确认已成功接收的数据，发送⽅则根据收到的确认来确定哪些数据已经被成功传输，以\n及哪些需要重新发送。\n超时和重传： TCP使⽤超时机制来检测是否发⽣了数据包的丢失。如果发送⽅在⼀定时间内未收到确认，它\n会认为数据包丢失，并触发相应的重传。这确保了即使某个数据包在传输过程中丢失，它最终仍能够被成功传\n流量控制： TCP使⽤滑动窗⼝机制来进⾏流量控制，确保发送⽅不会以⾼于接收⽅处理速度的速率发送数\n据。这有助于防⽌接收⽅缓冲区溢出，并提⾼整个通信链路的效率。\n拥塞控制： TCP还具有拥塞控制机制，通过动态调整发送速率以适应⽹络状况。当⽹络出现拥塞时，TCP会减缓\n发送速率，以防⽌进⼀步加剧拥塞。\n怎么⽤UDP实现可靠传输\n## 为什么需要可靠的UDP\n在弱⽹（2G、3G、信号不好）环境下，使⽤ TCP 连接的延迟很⾼，影响体验。使⽤ UDP 是很好的解决⽅\n案，既然把 UDP 作为弱⽹⾥⾯的 TCP 来使⽤，就必须保证数据传输能像 TCP ⼀样可靠\n## 如何实现可靠的UDP\nUDP它不属于连接型协议，因⽽具有资源消耗⼩，处理速度快的优点，所以通常⾳频、视频和普通数据在传\n送时使⽤UDP较多，因为它们即使偶尔丢失⼀两个数据包，也不会对接收结果产⽣太⼤影响。传输层⽆法保\n证数据的可靠传输，只能通过应⽤层来实现了。实现的⽅式可以参照tcp可靠性传输的⽅式，只是实现不在传\n输层，实现转移到了应⽤层。关键在于两点，从应⽤层⻆度考虑：\n（1） 提供超时重传，能避免数据报丢失。\n（2） 提供确认序列号，可以对数据报进⾏确认和排序。\n本端：⾸先在UDP数据报定义⼀个⾸部，⾸部包含确认序列号和时间戳，时间戳是⽤来计算RTT(数据报传输\n的往返时间)，计算出合适的RTO(重传的超时时间)。然后以等-停的⽅式发送数据报，即收到对端的确认之后\n才发送下⼀个的数据报。当时间超时，本端重传数据报，同时RTO扩⼤为原来的两倍，重新开始计时。\n对端：接受到⼀个数据报之后取下该数据报⾸部的时间戳和确认序列号，并添加本端的确认数据报⾸部之后\n发送给对端。根据此序列号对已收到的数据报进⾏排序并丢弃重复的数据报。\n## 已经实现的可靠UDP：\n（1） RUDP 可靠数据报传输协议；\n（2） RTP 实时传输协议\n为数据提供了具有实时特征的端对端传送服务；\nEg：组播或单播⽹络服务下的交互式视频、⾳频或模拟数据\n（3） UDT\n基于UDP的数据传输协议，是⼀种互联⽹传输协议；\n主要⽬的是⽀持⾼速⼴域⽹上的海量数据传输，引⼊了新的拥塞控制和数据可靠性控制机制（互联⽹上的标准数\n据传输协议TCP在⾼带宽⻓距离的⽹络上性能很差）；\nUDT是⾯向连接的双向的应⽤层协议，同时⽀持可靠的数据流传输和部分可靠的数据报服务；\n应⽤：⾼速数据传输，点到点技术(P2P)，防⽕墙穿透，多媒体数据传输；\n三次握⼿的过程\nTCP（传输控制协议）的三次握⼿是建⽴⽹络连接的过程，确保通信双⽅能够正确地进⾏数据传输。\n## 第⼀次握⼿（SYN）：\n客户端（Client）向服务器（Server）发送⼀个带有 SYN（同步）标志位的包，表示客户端希望建⽴连接。该包同\n时指定客户端的初始序列号（Client Sequence Number）。\n## 第⼆次握⼿（SYN + ACK）：\n服务器收到客户端的 SYN 包后，会回复⼀个带有 SYN 和 ACK（确认）标志位的包，表示服务器接受了客户端的请\n求，并希望建⽴连接。服务器也会指定⾃⼰的初始序列号，以及对客户端序列号的确认。\n## 第三次握⼿（ACK）：\n客户端收到服务器的 SYN+ACK 包后，会发送⼀个带有 ACK 标志位的包作为确认回复。这个包的序列号会加⼀，表\n示客户端已经准备好与服务器进⾏数据传输。\n此时，TCP  连接已经建⽴起来，通信双⽅可以开始进⾏数据传输。\n四次挥⼿的过程\n四次挥⼿是指在TCP连接的断开过程中，由客户端先断开，然后由服务器进⾏最后的断开。\n具体的四次挥⼿步骤如下：\n## 客户端发送⼀个FIN（终⽌）报⽂给服务器，表示客户端不再发送数据。\n## 服务器收到FIN报⽂后，发送⼀个ACK（确认）报⽂给客户端，表示收到了客户端的终⽌请求。\n## 服务器发送⼀个FIN报⽂给客户端，表示服务器也不再发送数据。\n## 客户端收到服务器的FIN报⽂后，发送⼀个ACK报⽂给服务器，确认收到了服务器的终⽌请求，然后关闭连\n这样，经过四次挥⼿，TCP连接才会完全关闭。因为TCP是全双⼯连接，双⽅都需要通知对⽅停⽌数据传输，所以\n需要四次握⼿来完成断开连接的过程。",
    "question": "TCP与UDP的区别",
    "answer": "## 连接\nTCP是⾯向连接的，在传输前需要三次握⼿建⽴连接。\nUDP不需要连接，直接发送数据包，没有连接建⽴和关闭的过程。\n## 服务形式\nTCP是⼀对⼀的通信。在TCP连接中，⼀台客户端与⼀台服务器之间建⽴⼀条连接，进⾏双向通信。\nUDP可以是⼀对⼀、⼀对多或多对多的通信。UDP是⽆连接的，⼀个UDP包可以被⼴播到多个⽬标主机，或\n者从多个源主机接收UDP包。这使得UDP适⽤于多播和⼴播应⽤。\n## 可靠性\nTCP保证数据可靠交付，拥有确认应答和重传机制，⽆重复、不丢失、按序到达;\nUDP尽可能交付，发送数据后不会关⼼数据包是否成功到达接收⽅，不会进⾏重传，不保证可靠性。\n## 流量控制和拥塞控制\nTCP拥有流量控制、拥塞控制，确保数据发送的速率不会超过接收⽅的处理能⼒，并防⽌⽹络拥塞。\nUDP不进⾏流量控制和拥塞控制，数据发送的速率不受限制。\n## ⾸部开销\nTCP的⾸部⼤⼩通常为20字节，但在选项字段被使⽤的情况下，可能会更⼤。TCP⾸部包含源端⼝号、⽬标端\n⼝号、序列号、确认号、窗⼝⼤⼩、校验和等字段。\nUDP的⾸部⼤⼩固定为8字节。UDP⾸部包含源端⼝号、⽬标端⼝号、包⻓度和校验和字段（各16位）。\n## 传输⽅式\nTCP基于字节流，没有边界，但是保证传输顺序和可靠性;\nUDP继承了IP层特性，基于数据包，有边界可能出现乱序和丢包。\n## 分⽚⽅式\nTCP数据⼤于MSS时会在TCP层将数据进⾏分⽚传输，到达⽬的地后同样在传输层进⾏合并，如果有某个⽚丢失则\n只需要重传丢失的分⽚即可;\nUDP数据⼤于MTU时会在IP层分⽚，则会在IP层合并，如果某个IP分⽚丢失，⽬标主机收到后，在 IP 层组装完数据，\n接着再传给传输层。\nTCP和UDP分别在什么场景使⽤？\nUDP适⽤于实时传输的场景：UDP适⽤于对数据传输可靠性要求不⾼的场景，如实时游戏、流媒体等，其中\n实时性⽐数据的准确性更为重要。\nTCP适⽤于可靠数据传输的场景：TCP适⽤于那些对数据传输可靠性要求较⾼的应⽤，如⽂件传输、电⼦邮\n件、⽹⻚浏览等。\nTCP连接如何确保可靠性\nTCP协议保证数据传输可靠性的⽅式主要有：校验和、序列号、确认应答、超时重传、连接管理、流量控制、拥塞\n控制。\n序列号和确认应答：TCP通过给每个发送的数据段分配⼀个序列号，以及使⽤确认（ACK）机制来跟踪数据的\n传输和接收。接收⽅会确认已成功接收的数据，发送⽅则根据收到的确认来确定哪些数据已经被成功传输，以\n及哪些需要重新发送。\n超时和重传： TCP使⽤超时机制来检测是否发⽣了数据包的丢失。如果发送⽅在⼀定时间内未收到确认，它\n会认为数据包丢失，并触发相应的重传。这确保了即使某个数据包在传输过程中丢失，它最终仍能够被成功传\n流量控制： TCP使⽤滑动窗⼝机制来进⾏流量控制，确保发送⽅不会以⾼于接收⽅处理速度的速率发送数\n据。这有助于防⽌接收⽅缓冲区溢出，并提⾼整个通信链路的效率。\n拥塞控制： TCP还具有拥塞控制机制，通过动态调整发送速率以适应⽹络状况。当⽹络出现拥塞时，TCP会减缓\n发送速率，以防⽌进⼀步加剧拥塞。\n怎么⽤UDP实现可靠传输\n## 为什么需要可靠的UDP\n在弱⽹（2G、3G、信号不好）环境下，使⽤ TCP 连接的延迟很⾼，影响体验。使⽤ UDP 是很好的解决⽅\n案，既然把 UDP 作为弱⽹⾥⾯的 TCP 来使⽤，就必须保证数据传输能像 TCP ⼀样可靠\n## 如何实现可靠的UDP\nUDP它不属于连接型协议，因⽽具有资源消耗⼩，处理速度快的优点，所以通常⾳频、视频和普通数据在传\n送时使⽤UDP较多，因为它们即使偶尔丢失⼀两个数据包，也不会对接收结果产⽣太⼤影响。传输层⽆法保\n证数据的可靠传输，只能通过应⽤层来实现了。实现的⽅式可以参照tcp可靠性传输的⽅式，只是实现不在传\n输层，实现转移到了应⽤层。关键在于两点，从应⽤层⻆度考虑：\n（1） 提供超时重传，能避免数据报丢失。\n（2） 提供确认序列号，可以对数据报进⾏确认和排序。\n本端：⾸先在UDP数据报定义⼀个⾸部，⾸部包含确认序列号和时间戳，时间戳是⽤来计算RTT(数据报传输\n的往返时间)，计算出合适的RTO(重传的超时时间)。然后以等-停的⽅式发送数据报，即收到对端的确认之后\n才发送下⼀个的数据报。当时间超时，本端重传数据报，同时RTO扩⼤为原来的两倍，重新开始计时。\n对端：接受到⼀个数据报之后取下该数据报⾸部的时间戳和确认序列号，并添加本端的确认数据报⾸部之后\n发送给对端。根据此序列号对已收到的数据报进⾏排序并丢弃重复的数据报。\n## 已经实现的可靠UDP：\n（1） RUDP 可靠数据报传输协议；\n（2） RTP 实时传输协议\n为数据提供了具有实时特征的端对端传送服务；\nEg：组播或单播⽹络服务下的交互式视频、⾳频或模拟数据\n（3） UDT\n基于UDP的数据传输协议，是⼀种互联⽹传输协议；\n主要⽬的是⽀持⾼速⼴域⽹上的海量数据传输，引⼊了新的拥塞控制和数据可靠性控制机制（互联⽹上的标准数\n据传输协议TCP在⾼带宽⻓距离的⽹络上性能很差）；\nUDT是⾯向连接的双向的应⽤层协议，同时⽀持可靠的数据流传输和部分可靠的数据报服务；\n应⽤：⾼速数据传输，点到点技术(P2P)，防⽕墙穿透，多媒体数据传输；\n三次握⼿的过程\nTCP（传输控制协议）的三次握⼿是建⽴⽹络连接的过程，确保通信双⽅能够正确地进⾏数据传输。\n## 第⼀次握⼿（SYN）：\n客户端（Client）向服务器（Server）发送⼀个带有 SYN（同步）标志位的包，表示客户端希望建⽴连接。该包同\n时指定客户端的初始序列号（Client Sequence Number）。\n## 第⼆次握⼿（SYN + ACK）：\n服务器收到客户端的 SYN 包后，会回复⼀个带有 SYN 和 ACK（确认）标志位的包，表示服务器接受了客户端的请\n求，并希望建⽴连接。服务器也会指定⾃⼰的初始序列号，以及对客户端序列号的确认。\n## 第三次握⼿（ACK）：\n客户端收到服务器的 SYN+ACK 包后，会发送⼀个带有 ACK 标志位的包作为确认回复。这个包的序列号会加⼀，表\n示客户端已经准备好与服务器进⾏数据传输。\n此时，TCP  连接已经建⽴起来，通信双⽅可以开始进⾏数据传输。\n四次挥⼿的过程\n四次挥⼿是指在TCP连接的断开过程中，由客户端先断开，然后由服务器进⾏最后的断开。\n具体的四次挥⼿步骤如下：\n## 客户端发送⼀个FIN（终⽌）报⽂给服务器，表示客户端不再发送数据。\n## 服务器收到FIN报⽂后，发送⼀个ACK（确认）报⽂给客户端，表示收到了客户端的终⽌请求。\n## 服务器发送⼀个FIN报⽂给客户端，表示服务器也不再发送数据。\n## 客户端收到服务器的FIN报⽂后，发送⼀个ACK报⽂给服务器，确认收到了服务器的终⽌请求，然后关闭连\n这样，经过四次挥⼿，TCP连接才会完全关闭。因为TCP是全双⼯连接，双⽅都需要通知对⽅停⽌数据传输，所以\n需要四次握⼿来完成断开连接的过程。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2919,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000059",
    "content": "## 客户端收到服务器的FIN报⽂后，发送⼀个ACK报⽂给服务器，确认收到了服务器的终⽌请求，然后关闭连\n\n这样，经过四次挥⼿，TCP连接才会完全关闭。因为TCP是全双⼯连接，双⽅都需要通知对⽅停⽌数据传输，所以\n需要四次握⼿来完成断开连接的过程。\nKeep-Alive是什么\nHTTP1.0中需要配置⻓连接，在请求头中配置Connection: Keep-Alive , ⽽HTTP1.1中默认开启了⻓连接\nKeep-Alive 是⼀种 HTTP 协议的机制，也被称为HTTP⻓连接\n在启⽤ Keep-alive 的情况下，客户端和服务器在完成⼀个 HTTP 请求和响应后，并不⽴即关闭连接，⽽是继续保持\n连接处于打开状态。在连接保持打开的情况下，客户端可以继续发送其他请求，服务器可以继续发送响应，⽽⽆需\n重新建⽴连接，减少了连接的建⽴和关闭的开销，从⽽提⾼性能和效率。\nKeep-Alive的优缺点\nTCP 连接的建⽴和关闭需要时间和资源，通过保持连接打开，可以减少这些开销，从⽽提⾼性能和效率。\n客户端可以在同⼀个连接上同时发送多个请求，服务器可以并⾏地处理这些请求，提⾼并发性能。\nKeep-alive 连接中的多个请求共享同⼀个连接的头部信息（如⽤户代理、Cookie 等），减少了头部信息的重\n复传输。\n⻓时间的持久连接可能会占⽤服务器资源，特别是在⾼并发的情况下。为了平衡资源利⽤和性能，服务器和客\n户端通常会设置 Keep-alive 的超时时间，以便在⼀段时间内保持连接打开，超过该时间则关闭连接。\nTCP KeepAlive是什么\nTCP  Keep-Alive 是在操作系统和⽹络协议栈级别实现的，它通过发送特定的探测数据包来维护连接的活跃性。",
    "question": "## 客户端收到服务器的FIN报⽂后，发送⼀个ACK报⽂给服务器，确认收到了服务器的终⽌请求，然后关闭连",
    "answer": "这样，经过四次挥⼿，TCP连接才会完全关闭。因为TCP是全双⼯连接，双⽅都需要通知对⽅停⽌数据传输，所以\n需要四次握⼿来完成断开连接的过程。\nKeep-Alive是什么\nHTTP1.0中需要配置⻓连接，在请求头中配置Connection: Keep-Alive , ⽽HTTP1.1中默认开启了⻓连接\nKeep-Alive 是⼀种 HTTP 协议的机制，也被称为HTTP⻓连接\n在启⽤ Keep-alive 的情况下，客户端和服务器在完成⼀个 HTTP 请求和响应后，并不⽴即关闭连接，⽽是继续保持\n连接处于打开状态。在连接保持打开的情况下，客户端可以继续发送其他请求，服务器可以继续发送响应，⽽⽆需\n重新建⽴连接，减少了连接的建⽴和关闭的开销，从⽽提⾼性能和效率。\nKeep-Alive的优缺点\nTCP 连接的建⽴和关闭需要时间和资源，通过保持连接打开，可以减少这些开销，从⽽提⾼性能和效率。\n客户端可以在同⼀个连接上同时发送多个请求，服务器可以并⾏地处理这些请求，提⾼并发性能。\nKeep-alive 连接中的多个请求共享同⼀个连接的头部信息（如⽤户代理、Cookie 等），减少了头部信息的重\n复传输。\n⻓时间的持久连接可能会占⽤服务器资源，特别是在⾼并发的情况下。为了平衡资源利⽤和性能，服务器和客\n户端通常会设置 Keep-alive 的超时时间，以便在⼀段时间内保持连接打开，超过该时间则关闭连接。\nTCP KeepAlive是什么\nTCP  Keep-Alive 是在操作系统和⽹络协议栈级别实现的，它通过发送特定的探测数据包来维护连接的活跃性。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 734,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000060",
    "content": "Keep-Alive是什么\n\nHTTP1.0中需要配置⻓连接，在请求头中配置Connection: Keep-Alive , ⽽HTTP1.1中默认开启了⻓连接\nKeep-Alive 是⼀种 HTTP 协议的机制，也被称为HTTP⻓连接\n在启⽤ Keep-alive 的情况下，客户端和服务器在完成⼀个 HTTP 请求和响应后，并不⽴即关闭连接，⽽是继续保持\n连接处于打开状态。在连接保持打开的情况下，客户端可以继续发送其他请求，服务器可以继续发送响应，⽽⽆需\n重新建⽴连接，减少了连接的建⽴和关闭的开销，从⽽提⾼性能和效率。",
    "question": "Keep-Alive是什么",
    "answer": "HTTP1.0中需要配置⻓连接，在请求头中配置Connection: Keep-Alive , ⽽HTTP1.1中默认开启了⻓连接\nKeep-Alive 是⼀种 HTTP 协议的机制，也被称为HTTP⻓连接\n在启⽤ Keep-alive 的情况下，客户端和服务器在完成⼀个 HTTP 请求和响应后，并不⽴即关闭连接，⽽是继续保持\n连接处于打开状态。在连接保持打开的情况下，客户端可以继续发送其他请求，服务器可以继续发送响应，⽽⽆需\n重新建⽴连接，减少了连接的建⽴和关闭的开销，从⽽提⾼性能和效率。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 263,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000061",
    "content": "Keep-Alive的优缺点\n\nTCP 连接的建⽴和关闭需要时间和资源，通过保持连接打开，可以减少这些开销，从⽽提⾼性能和效率。\n客户端可以在同⼀个连接上同时发送多个请求，服务器可以并⾏地处理这些请求，提⾼并发性能。\nKeep-alive 连接中的多个请求共享同⼀个连接的头部信息（如⽤户代理、Cookie 等），减少了头部信息的重\n复传输。\n⻓时间的持久连接可能会占⽤服务器资源，特别是在⾼并发的情况下。为了平衡资源利⽤和性能，服务器和客\n户端通常会设置 Keep-alive 的超时时间，以便在⼀段时间内保持连接打开，超过该时间则关闭连接。",
    "question": "Keep-Alive的优缺点",
    "answer": "TCP 连接的建⽴和关闭需要时间和资源，通过保持连接打开，可以减少这些开销，从⽽提⾼性能和效率。\n客户端可以在同⼀个连接上同时发送多个请求，服务器可以并⾏地处理这些请求，提⾼并发性能。\nKeep-alive 连接中的多个请求共享同⼀个连接的头部信息（如⽤户代理、Cookie 等），减少了头部信息的重\n复传输。\n⻓时间的持久连接可能会占⽤服务器资源，特别是在⾼并发的情况下。为了平衡资源利⽤和性能，服务器和客\n户端通常会设置 Keep-alive 的超时时间，以便在⼀段时间内保持连接打开，超过该时间则关闭连接。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 272,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000062",
    "content": "TCP KeepAlive是什么\n\nTCP  Keep-Alive 是在操作系统和⽹络协议栈级别实现的，它通过发送特定的探测数据包来维护连接的活跃性。\n## 在启⽤ TCP Keep-Alive 的情况下，操作系统会定期发送⼀些特定的探测数据包到连接的另⼀端。这些数据包\n通常是空的，没有实际的数据内容。\n## 如果⼀端收到了探测数据包，它会回复⼀个确认（ACK）数据包。如果⼀段时间内没有收到确认数据包，发送\n端将认为连接可能已经断开，从⽽触发连接关闭。\n## TCP Keep-Alive 的主要⽬的是检测连接是否处于空闲状态，即没有实际数据传输。它不仅可以检测到连接断\n开，还可以在空闲连接超过⼀定时间时释放连接，从⽽释放资源。\nTCP的TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是⼀个东⻄吗？\n## HTTP 的 Keep-Alive，是由应⽤层实现的，称为 HTTP ⻓连接\n每次请求都要经历这样的过程：建⽴ TCP -> 请求资源 -> 响应资源 -> 释放连接，这就是HTTP短连接，但是这样每\n次建⽴连接都只能请求⼀次资源，所以HTTP 的 Keep-Alive 实现了使⽤同⼀个 TCP 连接来发送和接收多个 HTTP\n请求/应答，避免了连接建⽴和释放的开销，就就是 HTTP ⻓连接。\n## TCP 的 Keepalive，是由TCP 层（内核态）实现的，称为 TCP 保活机制，是⼀种⽤于在 TCP 连接上检测空闲\n连接状态的机制\n通俗地说，就是TCP有⼀个定时任务做倒计时，超时后会触发任务，内容是发送⼀个探测报⽂给对端，⽤来判断对\n端是否存活。",
    "question": "TCP KeepAlive是什么",
    "answer": "TCP  Keep-Alive 是在操作系统和⽹络协议栈级别实现的，它通过发送特定的探测数据包来维护连接的活跃性。\n## 在启⽤ TCP Keep-Alive 的情况下，操作系统会定期发送⼀些特定的探测数据包到连接的另⼀端。这些数据包\n通常是空的，没有实际的数据内容。\n## 如果⼀端收到了探测数据包，它会回复⼀个确认（ACK）数据包。如果⼀段时间内没有收到确认数据包，发送\n端将认为连接可能已经断开，从⽽触发连接关闭。\n## TCP Keep-Alive 的主要⽬的是检测连接是否处于空闲状态，即没有实际数据传输。它不仅可以检测到连接断\n开，还可以在空闲连接超过⼀定时间时释放连接，从⽽释放资源。\nTCP的TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是⼀个东⻄吗？\n## HTTP 的 Keep-Alive，是由应⽤层实现的，称为 HTTP ⻓连接\n每次请求都要经历这样的过程：建⽴ TCP -> 请求资源 -> 响应资源 -> 释放连接，这就是HTTP短连接，但是这样每\n次建⽴连接都只能请求⼀次资源，所以HTTP 的 Keep-Alive 实现了使⽤同⼀个 TCP 连接来发送和接收多个 HTTP\n请求/应答，避免了连接建⽴和释放的开销，就就是 HTTP ⻓连接。\n## TCP 的 Keepalive，是由TCP 层（内核态）实现的，称为 TCP 保活机制，是⼀种⽤于在 TCP 连接上检测空闲\n连接状态的机制\n通俗地说，就是TCP有⼀个定时任务做倒计时，超时后会触发任务，内容是发送⼀个探测报⽂给对端，⽤来判断对\n端是否存活。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 700,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000063",
    "content": "## TCP 的 Keepalive，是由TCP 层（内核态）实现的，称为 TCP 保活机制，是⼀种⽤于在 TCP 连接上检测空闲\n\n连接状态的机制\n通俗地说，就是TCP有⼀个定时任务做倒计时，超时后会触发任务，内容是发送⼀个探测报⽂给对端，⽤来判断对\n端是否存活。\nCDN是什么\nCDN，全称为内容分发⽹络（Content Delivery Network） , 过将内容存储在分布式的服务器上，使⽤户可以从\n距离较近的服务器获取所需的内容，从⽽减少数据传输的时间和距离，提⾼内容的传输速度、减少延迟和提升⽤户\n体验。\nCDN的⼯作流程",
    "question": "## TCP 的 Keepalive，是由TCP 层（内核态）实现的，称为 TCP 保活机制，是⼀种⽤于在 TCP 连接上检测空闲",
    "answer": "连接状态的机制\n通俗地说，就是TCP有⼀个定时任务做倒计时，超时后会触发任务，内容是发送⼀个探测报⽂给对端，⽤来判断对\n端是否存活。\nCDN是什么\nCDN，全称为内容分发⽹络（Content Delivery Network） , 过将内容存储在分布式的服务器上，使⽤户可以从\n距离较近的服务器获取所需的内容，从⽽减少数据传输的时间和距离，提⾼内容的传输速度、减少延迟和提升⽤户\n体验。\nCDN的⼯作流程",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 269,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000064",
    "content": "CDN是什么\n\nCDN，全称为内容分发⽹络（Content Delivery Network） , 过将内容存储在分布式的服务器上，使⽤户可以从\n距离较近的服务器获取所需的内容，从⽽减少数据传输的时间和距离，提⾼内容的传输速度、减少延迟和提升⽤户\n体验。",
    "question": "CDN是什么",
    "answer": "CDN，全称为内容分发⽹络（Content Delivery Network） , 过将内容存储在分布式的服务器上，使⽤户可以从\n距离较近的服务器获取所需的内容，从⽽减少数据传输的时间和距离，提⾼内容的传输速度、减少延迟和提升⽤户\n体验。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 127,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000065",
    "content": "CDN的⼯作流程\n\n## 当⽤户输⼊⼀个域名或点击⼀个链接时，⾸先会进⾏域名解析。如果⽹站启⽤了  CDN，DNS  解析会返回距离\n⽤户最近的 CDN 节点的 IP 地址，⽽不是原始源服务器的 IP 地址。\n## ⽤户的请求会被路由到距离最近的 CDN 节点，并且CDN 节点可以根据服务器的负载和可⽤性，动态地将请\n求分发到最适合的服务器节点上。\n## CDN 会⾸先检查是否已经缓存了该资源。如果有缓存，CDN 节点会直接返回缓存的资源，如果没有缓存所需\n资源，它会从源服务器（原始服务器）回源获取资源，并将资源缓存到节点中，以便以后的请求。\nCDN是如何加速的\n## 就近访问：CDN 在全球范围内部署了多个服务器节点，当⽤户请求访问⼀个⽹站时，CDN 会选择距离⽤户最\n近的节点来提供内容。这减少了数据传输的距离和时间，从⽽降低了延迟。\n## 内容缓存：CDN 节点会缓存静态资源，如图⽚、样式表、脚本等。当⽤户请求访问这些资源时，CDN 可以直\n接从缓存中返回，避免了从源服务器获取资源的延迟。\n## 前置缓存：CDN  可以根据⽹站的配置，提前将热⻔的内容缓存在节点中，以备⽤户请求时快速响应。\n## 智能负载均衡：CDN 会根据服务器的负载和可⽤性，动态地将请求分发到合适的服务器节点上，确保资源的\n快速获取。\n## 压缩技术：CDN  使⽤压缩技术对内容进⾏压缩，减少传输数据的⼤⼩，从⽽加快内容的传输速度。\n## 并⾏下载：由于 CDN ⽀持多路复⽤，⽤户可以在同⼀个连接上同时下载多个资源，从⽽提⾼并⾏下载的效\nCookie和Session是什么？\nCookie 和 Session 都⽤于管理⽤户的状态和身份,  Cookie 通过在客户端记录信息确定⽤户身份， Session 通过\n在服务器端记录信息确定⽤户身份。\n## Cookie\nCookie 是存储在⽤户浏览器中的⼩型⽂本⽂件，⽤于在⽤户和服务器之间传递数据。通常，服务器会将⼀个\n或多个 Cookie 发送到⽤户浏览器，然后浏览器将这些 Cookie 存储在本地。\n服务器在接收到来⾃客户端浏览器的请求之后，就能够通过分析存放于请求头的Cookie得到客户端特有的信\n息，从⽽动态⽣成与该客户端相对应的内容。\n## Session\n客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session 。Session 主\n要⽤于维护⽤户登录状态、存储⽤户的临时数据和上下⽂信息等。",
    "question": "CDN的⼯作流程",
    "answer": "## 当⽤户输⼊⼀个域名或点击⼀个链接时，⾸先会进⾏域名解析。如果⽹站启⽤了  CDN，DNS  解析会返回距离\n⽤户最近的 CDN 节点的 IP 地址，⽽不是原始源服务器的 IP 地址。\n## ⽤户的请求会被路由到距离最近的 CDN 节点，并且CDN 节点可以根据服务器的负载和可⽤性，动态地将请\n求分发到最适合的服务器节点上。\n## CDN 会⾸先检查是否已经缓存了该资源。如果有缓存，CDN 节点会直接返回缓存的资源，如果没有缓存所需\n资源，它会从源服务器（原始服务器）回源获取资源，并将资源缓存到节点中，以便以后的请求。\nCDN是如何加速的\n## 就近访问：CDN 在全球范围内部署了多个服务器节点，当⽤户请求访问⼀个⽹站时，CDN 会选择距离⽤户最\n近的节点来提供内容。这减少了数据传输的距离和时间，从⽽降低了延迟。\n## 内容缓存：CDN 节点会缓存静态资源，如图⽚、样式表、脚本等。当⽤户请求访问这些资源时，CDN 可以直\n接从缓存中返回，避免了从源服务器获取资源的延迟。\n## 前置缓存：CDN  可以根据⽹站的配置，提前将热⻔的内容缓存在节点中，以备⽤户请求时快速响应。\n## 智能负载均衡：CDN 会根据服务器的负载和可⽤性，动态地将请求分发到合适的服务器节点上，确保资源的\n快速获取。\n## 压缩技术：CDN  使⽤压缩技术对内容进⾏压缩，减少传输数据的⼤⼩，从⽽加快内容的传输速度。\n## 并⾏下载：由于 CDN ⽀持多路复⽤，⽤户可以在同⼀个连接上同时下载多个资源，从⽽提⾼并⾏下载的效\nCookie和Session是什么？\nCookie 和 Session 都⽤于管理⽤户的状态和身份,  Cookie 通过在客户端记录信息确定⽤户身份， Session 通过\n在服务器端记录信息确定⽤户身份。\n## Cookie\nCookie 是存储在⽤户浏览器中的⼩型⽂本⽂件，⽤于在⽤户和服务器之间传递数据。通常，服务器会将⼀个\n或多个 Cookie 发送到⽤户浏览器，然后浏览器将这些 Cookie 存储在本地。\n服务器在接收到来⾃客户端浏览器的请求之后，就能够通过分析存放于请求头的Cookie得到客户端特有的信\n息，从⽽动态⽣成与该客户端相对应的内容。\n## Session\n客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session 。Session 主\n要⽤于维护⽤户登录状态、存储⽤户的临时数据和上下⽂信息等。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1048,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000066",
    "content": "## Session\n\n客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session 。Session 主\n要⽤于维护⽤户登录状态、存储⽤户的临时数据和上下⽂信息等。\nCookie的⼯作原理\n通过服务器在 HTTP 响应中设置 \"Set-Cookie\" 标头，然后浏览器将这些 Cookie 存储并在后续的请求中发送\n给服务器。这样服务器可以通过 Cookie 实现⽤户状态管理和数据传递。",
    "question": "## Session",
    "answer": "客户端浏览器访问服务器的时候，服务器把客户端信息以某种形式记录在服务器上。这就是Session 。Session 主\n要⽤于维护⽤户登录状态、存储⽤户的临时数据和上下⽂信息等。\nCookie的⼯作原理\n通过服务器在 HTTP 响应中设置 \"Set-Cookie\" 标头，然后浏览器将这些 Cookie 存储并在后续的请求中发送\n给服务器。这样服务器可以通过 Cookie 实现⽤户状态管理和数据传递。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 212,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000067",
    "content": "Cookie的⼯作原理\n\n通过服务器在 HTTP 响应中设置 \"Set-Cookie\" 标头，然后浏览器将这些 Cookie 存储并在后续的请求中发送\n给服务器。这样服务器可以通过 Cookie 实现⽤户状态管理和数据传递。\n## 客户端（浏览器）第⼀次发送请求到服务器\n## 服务器可以通过 HTTP 响应的头部信息中的 \"Set-Cookie\" 标头来创建⼀个 Cookie。这个标头指定了\nCookie 的名称、值和其他参数，如过期时间、域名、路径等。\n## 浏览器接收到 \"Set-Cookie\" 标头后，会将 Cookie 存储在⽤户的本地计算机上。\n## 当⽤户再次访问同⼀个⽹站时，浏览器会将与该域名相关的 Cookie 信息包括在 HTTP 请求的头部中。\n## 服务器收到包含 Cookie 的 HTTP 请求后，可以读取 Cookie 的值，根据其中的数据来判断⽤户的状态、偏好\n等，并根据需要做出相应的响应，如根据⽤户登录状态提供个性化内容。\n## 服务器可以通过发送新的 \"Set-Cookie\" 标头来更新 Cookie 的值或设置新的参数。\n## Cookie 可以设置过期时间，可以是会话级的（浏览器关闭时失效）或持久性的（在⼀段时间后失效）。当过\n期时间到达后，浏览器不再发送该 Cookie。",
    "question": "Cookie的⼯作原理",
    "answer": "通过服务器在 HTTP 响应中设置 \"Set-Cookie\" 标头，然后浏览器将这些 Cookie 存储并在后续的请求中发送\n给服务器。这样服务器可以通过 Cookie 实现⽤户状态管理和数据传递。\n## 客户端（浏览器）第⼀次发送请求到服务器\n## 服务器可以通过 HTTP 响应的头部信息中的 \"Set-Cookie\" 标头来创建⼀个 Cookie。这个标头指定了\nCookie 的名称、值和其他参数，如过期时间、域名、路径等。\n## 浏览器接收到 \"Set-Cookie\" 标头后，会将 Cookie 存储在⽤户的本地计算机上。\n## 当⽤户再次访问同⼀个⽹站时，浏览器会将与该域名相关的 Cookie 信息包括在 HTTP 请求的头部中。\n## 服务器收到包含 Cookie 的 HTTP 请求后，可以读取 Cookie 的值，根据其中的数据来判断⽤户的状态、偏好\n等，并根据需要做出相应的响应，如根据⽤户登录状态提供个性化内容。\n## 服务器可以通过发送新的 \"Set-Cookie\" 标头来更新 Cookie 的值或设置新的参数。\n## Cookie 可以设置过期时间，可以是会话级的（浏览器关闭时失效）或持久性的（在⼀段时间后失效）。当过\n期时间到达后，浏览器不再发送该 Cookie。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 563,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000068",
    "content": "## Cookie 可以设置过期时间，可以是会话级的（浏览器关闭时失效）或持久性的（在⼀段时间后失效）。当过\n\n期时间到达后，浏览器不再发送该 Cookie。\nSession的⼯作原理\nSession  是⼀种在服务器端存储和管理⽤户状态和数据的机制，通常基于会话标识符（Session  ID）进⾏操作。",
    "question": "## Cookie 可以设置过期时间，可以是会话级的（浏览器关闭时失效）或持久性的（在⼀段时间后失效）。当过",
    "answer": "期时间到达后，浏览器不再发送该 Cookie。\nSession的⼯作原理\nSession  是⼀种在服务器端存储和管理⽤户状态和数据的机制，通常基于会话标识符（Session  ID）进⾏操作。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 153,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000069",
    "content": "Session的⼯作原理\n\nSession  是⼀种在服务器端存储和管理⽤户状态和数据的机制，通常基于会话标识符（Session  ID）进⾏操作。\n## ⽤户⾸次访问⽹站时，服务器会为该⽤户创建⼀个唯⼀的会话标识符（Session ID）。这个标识符可以是⼀个\n加密的字符串，通常以 Cookie 的形式存储在⽤户的浏览器中。\n## 每个会话标识符对应着服务器上的⼀个会话存储空间。这个存储空间⽤于存储该⽤户在会话期间的状态和数\n## 当⽤户与服务器交互时，服务器可以通过会话标识符来访问对应的会话存储空间。服务器可以将数据存储在会\n话中，如⽤户的登录状态、购物⻋内容、⽤户偏好等。\n## 服务器为每个会话设置⼀个超时时间，如果⽤户在⼀段时间内没有活动，会话会⾃动过期。⼀旦会话过期，会\n话数据将被清除。\n## ⽤户可以⼿动终⽌会话，例如通过退出登录操作。这会导致服务器删除与该⽤户相关的会话数据。\nCookie和Session有什么区别？\n存储位置：Cookie 数据存储在⽤户的浏览器中，⽽ Session 数据存储在服务器上。\n数据容量：Cookie 存储容量较⼩，⼀般为⼏ KB。Session 存储容量较⼤，通常没有固定限制，取决于服务器\n的配置和资源。\n安全性：由于 Cookie 存储在⽤户浏览器中，因此可以被⽤户读取和篡改。相⽐之下，Session 数据存储在服\n务器上，更难被⽤户访问和修改。\n传输⽅式：Cookie 在每次 HTTP 请求中都会被⾃动发送到服务器，⽽ Session ID 通常通过 Cookie 或 URL 参\n数传递。\nTCP重传机制是怎么实现的？\n当发送⽅的数据在传输过程中丢失、损坏或延迟，接收⽅可以请求发送⽅重新传输这些数据。\n## 序号与确认号：在 TCP 通信中，每个发送的字节都有⼀个唯⼀的序号，⽽每个接收的字节都有⼀个确认号。\n发送⽅维护了⼀个发送窗⼝，接收⽅维护了⼀个接收窗⼝。发送⽅会持续发送数据，并等待接收⽅的确认。\n## 超时检测：发送⽅为每个发送的数据段设置⼀个定时器，这个定时器的时⻓称为超时时间。发送⽅假设在这个\n超时时间内，数据能够到达接收⽅并得到确认。如果在超时时间内没有收到确认，发送⽅会认为数据丢失或损\n坏，触发重传。\n## 重传策略：当发送⽅在超时时间内没有收到确认，它会认为数据丢失，然后重新发送相应的数据段。如果只有\n⼀个数据段丢失，发送⽅只会重传丢失的数据段。如果有多个数据段丢失，发送⽅可能会使⽤更复杂的算法来\n决定哪些数据需要重传。\n## 快速重传和快速恢复：为了更快地发现丢失的数据，接收⽅可以使⽤快速重传策略。当接收⽅连续接收到相同\n的确认号时，它会⽴即向发送⽅发送冗余的确认，以触发发送⽅进⾏重传。此外，发送⽅在接收到快速重传的\n确认后，不需要等到超时再次发送，⽽是可以使⽤快速恢复算法继续发送未丢失的数据。\nTCP流量控制是怎么实现的？\n流量控制就是让发送发送速率不要过快，让接收⽅来得及接收。利⽤滑动窗⼝机制就可以实施流量控制，主要⽅法\n就是动态调整发送⽅和接收⽅之间数据传输速率。\n滑动窗⼝⼤⼩： 在TCP通信中，每个TCP报⽂段都包含⼀个窗⼝字段，该字段指示发送⽅可以发送多少字节的数\n据⽽不等待确认。这个窗⼝⼤⼩是动态调整的。\n接收⽅窗⼝⼤⼩： 接收⽅通过TCP报⽂中的窗⼝字段告诉发送⽅⾃⼰当前的可接收窗⼝⼤⼩。这是接收⽅缓\n冲区中还有多少可⽤空间。\n流量控制的⽬标：  流量控制的⽬标是确保发送⽅不要发送超过接收⽅缓冲区容量的数据。如果接收⽅的缓冲区\n快满了，它会减⼩窗⼝⼤⼩，通知发送⽅暂停发送，以防⽌溢出。\n动态调整：  发送⽅会根据接收⽅的窗⼝⼤⼩动态调整发送数据的速率。如果接收⽅的窗⼝⼤⼩增加，发送⽅可\n以加速发送数据。如果窗⼝⼤⼩减⼩，发送⽅将减缓发送数据的速率。\n确认机制： 接收⽅会定期发送确认（ACK）报⽂，告知发送⽅已成功接收数据。这也与流量控制密切相关，\n因为接收⽅可以通过ACK报⽂中的窗⼝字段来通知发送⽅它的当前窗⼝⼤⼩。\nTCP拥塞控制是怎么实现的？\nTCP拥塞控制可以在⽹络出现拥塞时动态地调整数据传输的速率，以防⽌⽹络过载。TCP拥塞控制的主要机制包括\n以下⼏个⽅⾯：\n## 慢启动（Slow Start）： 初始阶段，TCP发送⽅会以较⼩的发送窗⼝开始传输数据。随着每次成功收到确认的\n数据，发送⽅逐渐增加发送窗⼝的⼤⼩，实现指数级的增⻓，这称为慢启动。这有助于在⽹络刚开始传输时谨\n慎地逐步增加速率，以避免引发拥塞。\n## 拥塞避免（Congestion Avoidance）： ⼀旦达到⼀定的阈值（通常是慢启动阈值），TCP发送⽅就会进⼊\n拥塞避免阶段。在拥塞避免阶段，发送⽅以线性增加的⽅式增加发送窗⼝的⼤⼩，⽽不再是指数级的增⻓。这\n有助于控制发送速率，以避免引起⽹络拥塞。\n## 快速重传（Fast Retransmit）： 如果发送⽅连续收到相同的确认，它会认为发⽣了数据包的丢失，并会快\n速重传未确认的数据包，⽽不必等待超时。这有助于更快地恢复由于拥塞引起的数据包丢失。\n## 快速恢复（Fast Recovery）： 在发⽣快速重传后，TCP进⼊快速恢复阶段。在这个阶段，发送⽅不会回到慢\n启动阶段，⽽是将慢启动阈值设置为当前窗⼝的⼀半，并将拥塞窗⼝⼤⼩设置为慢启动阈值加上已确认但未被\n快速重传的数据块的数量。这有助于更快地从拥塞中恢复。\n什么是SS0\n普通的登录认证机制\n普通登录认证机制在登录认证成功后，服务器把⽤户的登录信息写⼊ session，并为该⽤户⽣成⼀个 cookie，返回\n并写⼊浏览器；当⽤户再次访问这个系统的时候，请求中会带上这个 cookie，服务端会根据这个 cookie 找到对应\n的 session，通过session来判断这个⽤户是否已经登录。\n普通的登录认证机制在多系统的环境下，在操作不同的系统时，需要多次登录，会变得很不⽅便。\n单点登录（ Single sign-on ，缩写为 SSO），允许⽤户在⼀次登录后访问多个关联的应⽤程序或服务，⽽⽆需\n再次输⼊其凭据。简⽽⾔之，⽤户只需⼀次登录，就能够⽆缝地访问多个应⽤。\nSSO的优点\n降低密码重⽤⻛险：  因为⽤户只需⼀个凭据，不再需要在多个应⽤程序间重复使⽤相同的密码，从⽽减少了因\n密码泄露⽽引发的安全⻛险。\n⽅便的⽤户体验：  ⽤户只需要在⼀次登录过程中提供凭据，然后就可以⽆缝地访问多个应⽤程序，⽆需为每个\n应⽤程序输⼊⽤户名和密码。这⼤⼤简化了⽤户的登录过程，提供了更流畅的体验。\n简化应⽤开发： 对于应⽤程序开发⼈员来说，他们可以将认证和授权的责任交给SSO系统，从⽽减少了在每\n个应⽤中实现这些功能的⼯作量。\nHTTP请求过程\n## ⾸先，我们在浏览器地址栏中，输⼊要查找⻚⾯的URL，按下Enter\n## 浏览器依次在 浏览器缓存 -->>系统缓存 -->>路由器缓存中去寻找匹配的URL，若有，就会直接在屏幕中显示出\n⻚⾯内容。若没有，则跳到第三步操作\n## 发送HTTP请求前，浏览器需要先进⾏域名解析(即DNS解析)，以获取相应的IP地址;（浏览器DNS缓存、路由\n器缓存、DNS缓存）\n## 获取到IP地址之后，浏览器向服务器发起TCP连接，与浏览器建⽴TCP三次握⼿\n## 握⼿成功之后，浏览器就会向服务器发送HTTP请求，来请求服务器端的数据包\n## 服务器处理从浏览器端收到的请求，接着将数据返回给浏览器\n## 浏览器收到HTTP响应\n## 查询状态，状态成功则进⾏下⼀步，不成功则弹出相应指示\n## 再读取⻚⾯内容、进⾏浏览器渲染、解析HTML源码;（⽣成DOM树、解析CCS样式、处理JS交互，客户端和\n服务器交互）进⾏展示\n## 关闭TCP连接（四次挥⼿）\nHTTP优化⽅案\n## TCP复⽤\n将多个客户端的HTTP请求复⽤到⼀个服务端的TCP连接上\n## HTTP复⽤\n将⼀个客户端的多个HTTP请求复⽤到⼀个TCP连接进⾏处理\n## 内容缓存\n将经常⽤到的内容进⾏缓存，在下⼀次获取的时候，就可以直接在内存中获取相应的数据了\n## 压缩\n⽂本数据压缩，减少带宽\n## SSL加速\n## TCP缓冲\n通过采⽤TCP缓冲技术，提⾼服务端响应时间和处理效率",
    "question": "Session的⼯作原理",
    "answer": "Session  是⼀种在服务器端存储和管理⽤户状态和数据的机制，通常基于会话标识符（Session  ID）进⾏操作。\n## ⽤户⾸次访问⽹站时，服务器会为该⽤户创建⼀个唯⼀的会话标识符（Session ID）。这个标识符可以是⼀个\n加密的字符串，通常以 Cookie 的形式存储在⽤户的浏览器中。\n## 每个会话标识符对应着服务器上的⼀个会话存储空间。这个存储空间⽤于存储该⽤户在会话期间的状态和数\n## 当⽤户与服务器交互时，服务器可以通过会话标识符来访问对应的会话存储空间。服务器可以将数据存储在会\n话中，如⽤户的登录状态、购物⻋内容、⽤户偏好等。\n## 服务器为每个会话设置⼀个超时时间，如果⽤户在⼀段时间内没有活动，会话会⾃动过期。⼀旦会话过期，会\n话数据将被清除。\n## ⽤户可以⼿动终⽌会话，例如通过退出登录操作。这会导致服务器删除与该⽤户相关的会话数据。\nCookie和Session有什么区别？\n存储位置：Cookie 数据存储在⽤户的浏览器中，⽽ Session 数据存储在服务器上。\n数据容量：Cookie 存储容量较⼩，⼀般为⼏ KB。Session 存储容量较⼤，通常没有固定限制，取决于服务器\n的配置和资源。\n安全性：由于 Cookie 存储在⽤户浏览器中，因此可以被⽤户读取和篡改。相⽐之下，Session 数据存储在服\n务器上，更难被⽤户访问和修改。\n传输⽅式：Cookie 在每次 HTTP 请求中都会被⾃动发送到服务器，⽽ Session ID 通常通过 Cookie 或 URL 参\n数传递。\nTCP重传机制是怎么实现的？\n当发送⽅的数据在传输过程中丢失、损坏或延迟，接收⽅可以请求发送⽅重新传输这些数据。\n## 序号与确认号：在 TCP 通信中，每个发送的字节都有⼀个唯⼀的序号，⽽每个接收的字节都有⼀个确认号。\n发送⽅维护了⼀个发送窗⼝，接收⽅维护了⼀个接收窗⼝。发送⽅会持续发送数据，并等待接收⽅的确认。\n## 超时检测：发送⽅为每个发送的数据段设置⼀个定时器，这个定时器的时⻓称为超时时间。发送⽅假设在这个\n超时时间内，数据能够到达接收⽅并得到确认。如果在超时时间内没有收到确认，发送⽅会认为数据丢失或损\n坏，触发重传。\n## 重传策略：当发送⽅在超时时间内没有收到确认，它会认为数据丢失，然后重新发送相应的数据段。如果只有\n⼀个数据段丢失，发送⽅只会重传丢失的数据段。如果有多个数据段丢失，发送⽅可能会使⽤更复杂的算法来\n决定哪些数据需要重传。\n## 快速重传和快速恢复：为了更快地发现丢失的数据，接收⽅可以使⽤快速重传策略。当接收⽅连续接收到相同\n的确认号时，它会⽴即向发送⽅发送冗余的确认，以触发发送⽅进⾏重传。此外，发送⽅在接收到快速重传的\n确认后，不需要等到超时再次发送，⽽是可以使⽤快速恢复算法继续发送未丢失的数据。\nTCP流量控制是怎么实现的？\n流量控制就是让发送发送速率不要过快，让接收⽅来得及接收。利⽤滑动窗⼝机制就可以实施流量控制，主要⽅法\n就是动态调整发送⽅和接收⽅之间数据传输速率。\n滑动窗⼝⼤⼩： 在TCP通信中，每个TCP报⽂段都包含⼀个窗⼝字段，该字段指示发送⽅可以发送多少字节的数\n据⽽不等待确认。这个窗⼝⼤⼩是动态调整的。\n接收⽅窗⼝⼤⼩： 接收⽅通过TCP报⽂中的窗⼝字段告诉发送⽅⾃⼰当前的可接收窗⼝⼤⼩。这是接收⽅缓\n冲区中还有多少可⽤空间。\n流量控制的⽬标：  流量控制的⽬标是确保发送⽅不要发送超过接收⽅缓冲区容量的数据。如果接收⽅的缓冲区\n快满了，它会减⼩窗⼝⼤⼩，通知发送⽅暂停发送，以防⽌溢出。\n动态调整：  发送⽅会根据接收⽅的窗⼝⼤⼩动态调整发送数据的速率。如果接收⽅的窗⼝⼤⼩增加，发送⽅可\n以加速发送数据。如果窗⼝⼤⼩减⼩，发送⽅将减缓发送数据的速率。\n确认机制： 接收⽅会定期发送确认（ACK）报⽂，告知发送⽅已成功接收数据。这也与流量控制密切相关，\n因为接收⽅可以通过ACK报⽂中的窗⼝字段来通知发送⽅它的当前窗⼝⼤⼩。\nTCP拥塞控制是怎么实现的？\nTCP拥塞控制可以在⽹络出现拥塞时动态地调整数据传输的速率，以防⽌⽹络过载。TCP拥塞控制的主要机制包括\n以下⼏个⽅⾯：\n## 慢启动（Slow Start）： 初始阶段，TCP发送⽅会以较⼩的发送窗⼝开始传输数据。随着每次成功收到确认的\n数据，发送⽅逐渐增加发送窗⼝的⼤⼩，实现指数级的增⻓，这称为慢启动。这有助于在⽹络刚开始传输时谨\n慎地逐步增加速率，以避免引发拥塞。\n## 拥塞避免（Congestion Avoidance）： ⼀旦达到⼀定的阈值（通常是慢启动阈值），TCP发送⽅就会进⼊\n拥塞避免阶段。在拥塞避免阶段，发送⽅以线性增加的⽅式增加发送窗⼝的⼤⼩，⽽不再是指数级的增⻓。这\n有助于控制发送速率，以避免引起⽹络拥塞。\n## 快速重传（Fast Retransmit）： 如果发送⽅连续收到相同的确认，它会认为发⽣了数据包的丢失，并会快\n速重传未确认的数据包，⽽不必等待超时。这有助于更快地恢复由于拥塞引起的数据包丢失。\n## 快速恢复（Fast Recovery）： 在发⽣快速重传后，TCP进⼊快速恢复阶段。在这个阶段，发送⽅不会回到慢\n启动阶段，⽽是将慢启动阈值设置为当前窗⼝的⼀半，并将拥塞窗⼝⼤⼩设置为慢启动阈值加上已确认但未被\n快速重传的数据块的数量。这有助于更快地从拥塞中恢复。\n什么是SS0\n普通的登录认证机制\n普通登录认证机制在登录认证成功后，服务器把⽤户的登录信息写⼊ session，并为该⽤户⽣成⼀个 cookie，返回\n并写⼊浏览器；当⽤户再次访问这个系统的时候，请求中会带上这个 cookie，服务端会根据这个 cookie 找到对应\n的 session，通过session来判断这个⽤户是否已经登录。\n普通的登录认证机制在多系统的环境下，在操作不同的系统时，需要多次登录，会变得很不⽅便。\n单点登录（ Single sign-on ，缩写为 SSO），允许⽤户在⼀次登录后访问多个关联的应⽤程序或服务，⽽⽆需\n再次输⼊其凭据。简⽽⾔之，⽤户只需⼀次登录，就能够⽆缝地访问多个应⽤。\nSSO的优点\n降低密码重⽤⻛险：  因为⽤户只需⼀个凭据，不再需要在多个应⽤程序间重复使⽤相同的密码，从⽽减少了因\n密码泄露⽽引发的安全⻛险。\n⽅便的⽤户体验：  ⽤户只需要在⼀次登录过程中提供凭据，然后就可以⽆缝地访问多个应⽤程序，⽆需为每个\n应⽤程序输⼊⽤户名和密码。这⼤⼤简化了⽤户的登录过程，提供了更流畅的体验。\n简化应⽤开发： 对于应⽤程序开发⼈员来说，他们可以将认证和授权的责任交给SSO系统，从⽽减少了在每\n个应⽤中实现这些功能的⼯作量。\nHTTP请求过程\n## ⾸先，我们在浏览器地址栏中，输⼊要查找⻚⾯的URL，按下Enter\n## 浏览器依次在 浏览器缓存 -->>系统缓存 -->>路由器缓存中去寻找匹配的URL，若有，就会直接在屏幕中显示出\n⻚⾯内容。若没有，则跳到第三步操作\n## 发送HTTP请求前，浏览器需要先进⾏域名解析(即DNS解析)，以获取相应的IP地址;（浏览器DNS缓存、路由\n器缓存、DNS缓存）\n## 获取到IP地址之后，浏览器向服务器发起TCP连接，与浏览器建⽴TCP三次握⼿\n## 握⼿成功之后，浏览器就会向服务器发送HTTP请求，来请求服务器端的数据包\n## 服务器处理从浏览器端收到的请求，接着将数据返回给浏览器\n## 浏览器收到HTTP响应\n## 查询状态，状态成功则进⾏下⼀步，不成功则弹出相应指示\n## 再读取⻚⾯内容、进⾏浏览器渲染、解析HTML源码;（⽣成DOM树、解析CCS样式、处理JS交互，客户端和\n服务器交互）进⾏展示\n## 关闭TCP连接（四次挥⼿）\nHTTP优化⽅案\n## TCP复⽤\n将多个客户端的HTTP请求复⽤到⼀个服务端的TCP连接上\n## HTTP复⽤\n将⼀个客户端的多个HTTP请求复⽤到⼀个TCP连接进⾏处理\n## 内容缓存\n将经常⽤到的内容进⾏缓存，在下⼀次获取的时候，就可以直接在内存中获取相应的数据了\n## 压缩\n⽂本数据压缩，减少带宽\n## SSL加速\n## TCP缓冲\n通过采⽤TCP缓冲技术，提⾼服务端响应时间和处理效率",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3420,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000070",
    "content": "## TCP缓冲\n\n通过采⽤TCP缓冲技术，提⾼服务端响应时间和处理效率\n浏览器地址栏输⼊URL回⻋后涉及到的流程",
    "question": "## TCP缓冲",
    "answer": "通过采⽤TCP缓冲技术，提⾼服务端响应时间和处理效率\n浏览器地址栏输⼊URL回⻋后涉及到的流程",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 57,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000071",
    "content": "浏览器地址栏输⼊URL回⻋后涉及到的流程\n\n## 查找DNS缓存\n## 先查找浏览器DNS缓存，看是否存放⽬标⽹络的IP地址;\n## 如果不在浏览器缓存，则浏览器将对操纵系统发起系统调⽤，查询操作系统本地缓存;\n## 如果不在操作系统本地缓存，则浏览器会查询与之相连的路由器缓存;\n## 如果不在路由器缓存，则浏览器会检查ISP【本地通信服务商】缓存;\n若以上四步均没有查询到⽬标⽹络的IP地址，则发起DNS查询。\n## 发起DNS查询\n判断DNS服务器和我们的主机是否在同⼀⼦⽹内\n## 在同⼀⼦⽹，则采⽤ ARP 地址解析协议对 DNS 服务器进⾏ ARP 查询\n## 不在同⼀⼦⽹，则采⽤ ARP 地址解析协议对默认⽹关进⾏查询\n若此时还是查询不到 IP 地址，则根据拿到 DNS 服务器或者默认⽹关的 IP 地址，继续进⾏ DNS 请求\n使⽤53端⼝先向本地 DNS 服务器发送 UDP 请求包，此处⼀般使⽤ UDP 协议（如果响应包太⼤，则使⽤ TCP 协\n没有查询到 IP 地址：\n则它会发送⼀个递归查询请求，⼀层⼀层向⾼层DNS服务器查询，直到查询到  IP  地址，则将结果返回\n【解释：DNS 是分布式域名服务器，每台服务器只维护⼀部分 IP 地址到⽹络地址的映射，没有任何⼀台服务器能够\n维持全部的映射关系】。\n## 封装TCP数据包\n拿到 IP 地址后，根据 URL 中的端⼝可知端⼝号【HTTP：80；HTTPS：443】，⼀般先会先尝试建⽴ HTTP 连接;\n准备 TCP 数据包：\n步骤：\n## 将应⽤层传递下来的实际数据，在传输层添加TCP⾸部;\n## 将传输层传下来的数据在⽹络层添加IP⾸部;\n## 将⽹络层传输下来的数据，在数据链路层添加以太⽹⾸部，并在传输介质中进⾏传输。\n## 浏览器与⽬标服务器建⽴TCP连接\n经过上述DNS和ARP查询流程后，浏览器会收到⽬标服务器的IP和MAC地址，然后经过三次握⼿后建⽴TCP连接;\n## 使⽤HTTP协议\n浏览器发送请求到服务器，如果使⽤的是HTTP协议，则服务器直接返回结果;\n## 使⽤HTTPS协议\n如果不是 HTTP 协议，则服务器会返回⼀个以 3 开头的重定向消息，告诉浏览器使⽤的 HTTPS，IP 没变，只是端\n⼝号变成 443；完成四次挥⼿；\n重新建⽴ TCP 连接，将端⼝号修改为 443，同时沟通好双⽅的使⽤的认证算法、加密和解密算法，在次过程中也会\n检查对⽅的 CA 安全证书，采⽤ SSL 加密技术进⾏传输数据。\n## 浏览器发送HTTP/HTTPS请求到web服务器\n主要使⽤两种请求⽅式：\n## 浏览器发送get请求，要求⽬标服务器提供输⼊的⽹⻚;\n## 浏览器发送post请求，表示填写的是表单。\n## 服务器处理请求并发挥⼀个响应\n服务器会从浏览器接受请求并将其传递给请求处理程序并响应;\n## 服务器发回⼀个HTTP响应\n⼀般响应包包含：请求的⽹⻚以及状态码，压缩类型，如何缓存的⻚⾯，设置的cookie;\n## 浏览器显示HTML⻚⾯\n## 渲染HTML⻣架；涉及到Ajax技术;\n## 检查HTML标记并发送GET请求以获取⽹⻚上的其他元素【图像、CSS样式、JS⽂件等】，该静态⽂件⼀般由\n浏览器缓存，再次访问，不⽤重新请求;\n## 最后会看到请求⾊彩斑斓的⽹⻚。",
    "question": "浏览器地址栏输⼊URL回⻋后涉及到的流程",
    "answer": "## 查找DNS缓存\n## 先查找浏览器DNS缓存，看是否存放⽬标⽹络的IP地址;\n## 如果不在浏览器缓存，则浏览器将对操纵系统发起系统调⽤，查询操作系统本地缓存;\n## 如果不在操作系统本地缓存，则浏览器会查询与之相连的路由器缓存;\n## 如果不在路由器缓存，则浏览器会检查ISP【本地通信服务商】缓存;\n若以上四步均没有查询到⽬标⽹络的IP地址，则发起DNS查询。\n## 发起DNS查询\n判断DNS服务器和我们的主机是否在同⼀⼦⽹内\n## 在同⼀⼦⽹，则采⽤ ARP 地址解析协议对 DNS 服务器进⾏ ARP 查询\n## 不在同⼀⼦⽹，则采⽤ ARP 地址解析协议对默认⽹关进⾏查询\n若此时还是查询不到 IP 地址，则根据拿到 DNS 服务器或者默认⽹关的 IP 地址，继续进⾏ DNS 请求\n使⽤53端⼝先向本地 DNS 服务器发送 UDP 请求包，此处⼀般使⽤ UDP 协议（如果响应包太⼤，则使⽤ TCP 协\n没有查询到 IP 地址：\n则它会发送⼀个递归查询请求，⼀层⼀层向⾼层DNS服务器查询，直到查询到  IP  地址，则将结果返回\n【解释：DNS 是分布式域名服务器，每台服务器只维护⼀部分 IP 地址到⽹络地址的映射，没有任何⼀台服务器能够\n维持全部的映射关系】。\n## 封装TCP数据包\n拿到 IP 地址后，根据 URL 中的端⼝可知端⼝号【HTTP：80；HTTPS：443】，⼀般先会先尝试建⽴ HTTP 连接;\n准备 TCP 数据包：\n步骤：\n## 将应⽤层传递下来的实际数据，在传输层添加TCP⾸部;\n## 将传输层传下来的数据在⽹络层添加IP⾸部;\n## 将⽹络层传输下来的数据，在数据链路层添加以太⽹⾸部，并在传输介质中进⾏传输。\n## 浏览器与⽬标服务器建⽴TCP连接\n经过上述DNS和ARP查询流程后，浏览器会收到⽬标服务器的IP和MAC地址，然后经过三次握⼿后建⽴TCP连接;\n## 使⽤HTTP协议\n浏览器发送请求到服务器，如果使⽤的是HTTP协议，则服务器直接返回结果;\n## 使⽤HTTPS协议\n如果不是 HTTP 协议，则服务器会返回⼀个以 3 开头的重定向消息，告诉浏览器使⽤的 HTTPS，IP 没变，只是端\n⼝号变成 443；完成四次挥⼿；\n重新建⽴ TCP 连接，将端⼝号修改为 443，同时沟通好双⽅的使⽤的认证算法、加密和解密算法，在次过程中也会\n检查对⽅的 CA 安全证书，采⽤ SSL 加密技术进⾏传输数据。\n## 浏览器发送HTTP/HTTPS请求到web服务器\n主要使⽤两种请求⽅式：\n## 浏览器发送get请求，要求⽬标服务器提供输⼊的⽹⻚;\n## 浏览器发送post请求，表示填写的是表单。\n## 服务器处理请求并发挥⼀个响应\n服务器会从浏览器接受请求并将其传递给请求处理程序并响应;\n## 服务器发回⼀个HTTP响应\n⼀般响应包包含：请求的⽹⻚以及状态码，压缩类型，如何缓存的⻚⾯，设置的cookie;\n## 浏览器显示HTML⻚⾯\n## 渲染HTML⻣架；涉及到Ajax技术;\n## 检查HTML标记并发送GET请求以获取⽹⻚上的其他元素【图像、CSS样式、JS⽂件等】，该静态⽂件⼀般由\n浏览器缓存，再次访问，不⽤重新请求;\n## 最后会看到请求⾊彩斑斓的⽹⻚。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1393,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000072",
    "content": "## 原理\n\n攻击者伪造不同IP地址的SYN报⽂请求连接，服务端收到连接请求后分配资源，回复ACK+SYN包，但是由于IP地址\n是伪造的，⽆法收到回应，久⽽久之造成服务端半连接队列被占满，⽆法正常⼯作。\n## 避免⽅式\n（1） 修改半连接队列⼤⼩\n使服务端能够容纳更多半连接。此外还可以修改服务端超时重传次数，使服务端尽早丢弃⽆⽤连接\n（2） 正常服务端⾏为是收到客户端SYN报⽂后\n将其加⼊到内核半连接队列，接着发送ACK+SYN报⽂给客户端，当收到客户端ACK报⽂后把连接从半连接队列移动\n到accept队列。\n当半连接队列满时，启动syn cookie,后续连接不进⼊半连接队列，⽽是计算⼀个cookie值，作为请求报⽂序列号发\n送给客户端，如果服务端收到客户端确认报⽂，会检查ack包合法性，如果合法直接加⼊到accept队列\nTCP保活机制",
    "question": "## 原理",
    "answer": "攻击者伪造不同IP地址的SYN报⽂请求连接，服务端收到连接请求后分配资源，回复ACK+SYN包，但是由于IP地址\n是伪造的，⽆法收到回应，久⽽久之造成服务端半连接队列被占满，⽆法正常⼯作。\n## 避免⽅式\n（1） 修改半连接队列⼤⼩\n使服务端能够容纳更多半连接。此外还可以修改服务端超时重传次数，使服务端尽早丢弃⽆⽤连接\n（2） 正常服务端⾏为是收到客户端SYN报⽂后\n将其加⼊到内核半连接队列，接着发送ACK+SYN报⽂给客户端，当收到客户端ACK报⽂后把连接从半连接队列移动\n到accept队列。\n当半连接队列满时，启动syn cookie,后续连接不进⼊半连接队列，⽽是计算⼀个cookie值，作为请求报⽂序列号发\n送给客户端，如果服务端收到客户端确认报⽂，会检查ack包合法性，如果合法直接加⼊到accept队列\nTCP保活机制",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 375,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000073",
    "content": "## 概念\n\n在⼀个定义的时间段内TCP连接⽆任何活动时，会启动TCP保活机制，每隔⼀定时间间隔发送⼀个探测报⽂，等待\n## 机制\n## 对端正常响应，重置保活时间;\n## 对端程序崩溃，响应⼀个RTS报⽂，将TCP连接重置;\n## 保活报⽂不可达，等待达到保活探测次数后关闭连接。\n## TCP为啥需要流量控制\n## 由于通讯双⽅⽹速不同，通讯⽅任意⼀⽅发送过快都会导致对⽅详细处理不过来，所以就需要把数据放到缓冲\n## 如果缓冲区满了，发送⽅还在疯狂发送，那接收⽅只能把数据包丢弃。因此我们需要控制发送速率\n## 我们缓冲区剩余⼤⼩称之为接收窗⼝，⽤变量win表示。如果win=0，则发送⽅停⽌发送\n操作系统\n操作系统基础\n本部分是⼀些基础的概念，仅做了解使⽤。\n什么是操作系统\n操作系统(Operating System)，是介于硬件资源和应⽤程序之间的⼀个系统软件 ，能控制和管理整个计算机系统的\n硬件和软件资源，调度计算机的⼯作与资源的分配，进⽽为⽤户和其他软件提供服务，操作系统是计算机系统中最\n基本的系统软件。\n如果将它理解为“掌控计算机的系统”是否更能精确的描述OS所做的事情呢？\n如果要更深⼊的掌握这个问题，可以问⼀问：如果没有了操作系统，你使⽤的PC机还能⼲什么？或者说，你能够使\n⽤你的PC机做什么呢？\n操作系统的特征：\n并发：并发指的是两个或多个事件在同⼀时间间隔内发⽣，计算机系统中同时存在多个运⾏的程序，因此具有\n处理和调度多个程序同时执⾏的能⼒。\n注意：并⾏和并发的区别：并发指的是同⼀时间间隔，并⾏指的是同⼀时刻。\n共享：系统中的资源可以供内存中多个并发执⾏的进程共同使⽤。\n互斥共享：⼀段时间内只允许⼀个进程访问该资源。⼀段时间内只允许⼀个进程访问的资源称为临界资\n同时访问：⼀段时间内允许多个进程“同时”访问，“同时”通常是宏观的，实际上是交替的对该资源进⾏访\n虚拟：把⼀个物理上的实体变为若⼲逻辑上的对应物。\n异步：进程的执⾏并不是⼀贯到底的，⽽是以不可预知的速度向前推进。\n操作系统的功能\n操作系统位于硬件资源之上，管理硬件资源;  应⽤程序之下，为应⽤程序提供服务，同时管理应⽤程序\n## 资源分配，资源回收\n计算机必要重要的硬件资源⽆⾮就是  CPU、内存、硬盘、I/O设备。\n⽽这些资源总是有限的，因此需要有效管理，资源管理最终只有两个问题：资源分配、资源回收。\n资源分配： 体现在CPU上，⽐如进程调度，多个进程同时请求CPU下，应该给哪⼀个进程呢？再⽐如内存分配，内\n存不够了怎么办？A进程⾮法访问了B进程的内存地址怎么办？内存内、外碎⽚问题等。\n资源回收：  考虑内存回收后的合并等等。\n## 为应⽤程序提供服务\n操作系统将硬件资源的操作封装起来，提供相对统⼀的接⼝（系统调⽤）供开发者调⽤。\n如果没有操作系统，应⽤程序将直接⾯对硬件，除去给开发者带来的编程困难不说，直接访问硬件，使⽤不当极有\n可能直接损坏硬件资源。\n## 管理应⽤程序\n即控制进程的⽣命周期：进程开始时的环境配置和资源分配、进程结束后的资源回收、进程调度等。\n## 操作系统内核的功能\n（1） 进程调度能⼒：  管理进程、线程，决定哪个进程、线程使⽤CPU。\n（2） 内存管理能⼒：  决定内存的分配和回收。\n（3） 硬件通信能⼒：  管理硬件，为进程和硬件之间提供通信。\n（4） 系统调⽤能⼒：   应⽤程序进⾏更⾼限权运⾏的服务，需要系统调⽤，⽤户程序和操作系统之间的接⼝。\n操作系统的⻆⾊\n## 管理者\n主要分为：CPU管理、内存管理、外存管理、IO管理；以及⾃⼰的健壮性和安全性管理。\n健壮性，⼜称鲁棒性，即使很粗鲁的对待程序，它还是可以很好的运⾏。\n## 魔术师:\n⽐如操作系统会让每个进程都觉得⾃⼰独占CPU、独占整⽚物理内存，⽽实际上每个进程都只是在某⼀时间段内占\n⽤CPU，仅仅只是占⽤实际⼀点点物理内存。\n⽤户程序与操作系统的关系\n⽤户程序和操作系统之间是相互调⽤的关系\n## 操作系统的⻆度\n计算机启动后启动的第⼀个软件就是操作系统，随后启动的所有进程都运⾏在操作系统之上，使⽤操作系统提供的\n服务，同时被操作系统监控，进程结束后也由操作系统回收。\n## 进程⻆度\n调⽤操作系统提供的服务，实现⾃⼰的功能。\n进程和线程\n进程基础",
    "question": "## 概念",
    "answer": "在⼀个定义的时间段内TCP连接⽆任何活动时，会启动TCP保活机制，每隔⼀定时间间隔发送⼀个探测报⽂，等待\n## 机制\n## 对端正常响应，重置保活时间;\n## 对端程序崩溃，响应⼀个RTS报⽂，将TCP连接重置;\n## 保活报⽂不可达，等待达到保活探测次数后关闭连接。\n## TCP为啥需要流量控制\n## 由于通讯双⽅⽹速不同，通讯⽅任意⼀⽅发送过快都会导致对⽅详细处理不过来，所以就需要把数据放到缓冲\n## 如果缓冲区满了，发送⽅还在疯狂发送，那接收⽅只能把数据包丢弃。因此我们需要控制发送速率\n## 我们缓冲区剩余⼤⼩称之为接收窗⼝，⽤变量win表示。如果win=0，则发送⽅停⽌发送\n操作系统\n操作系统基础\n本部分是⼀些基础的概念，仅做了解使⽤。\n什么是操作系统\n操作系统(Operating System)，是介于硬件资源和应⽤程序之间的⼀个系统软件 ，能控制和管理整个计算机系统的\n硬件和软件资源，调度计算机的⼯作与资源的分配，进⽽为⽤户和其他软件提供服务，操作系统是计算机系统中最\n基本的系统软件。\n如果将它理解为“掌控计算机的系统”是否更能精确的描述OS所做的事情呢？\n如果要更深⼊的掌握这个问题，可以问⼀问：如果没有了操作系统，你使⽤的PC机还能⼲什么？或者说，你能够使\n⽤你的PC机做什么呢？\n操作系统的特征：\n并发：并发指的是两个或多个事件在同⼀时间间隔内发⽣，计算机系统中同时存在多个运⾏的程序，因此具有\n处理和调度多个程序同时执⾏的能⼒。\n注意：并⾏和并发的区别：并发指的是同⼀时间间隔，并⾏指的是同⼀时刻。\n共享：系统中的资源可以供内存中多个并发执⾏的进程共同使⽤。\n互斥共享：⼀段时间内只允许⼀个进程访问该资源。⼀段时间内只允许⼀个进程访问的资源称为临界资\n同时访问：⼀段时间内允许多个进程“同时”访问，“同时”通常是宏观的，实际上是交替的对该资源进⾏访\n虚拟：把⼀个物理上的实体变为若⼲逻辑上的对应物。\n异步：进程的执⾏并不是⼀贯到底的，⽽是以不可预知的速度向前推进。\n操作系统的功能\n操作系统位于硬件资源之上，管理硬件资源;  应⽤程序之下，为应⽤程序提供服务，同时管理应⽤程序\n## 资源分配，资源回收\n计算机必要重要的硬件资源⽆⾮就是  CPU、内存、硬盘、I/O设备。\n⽽这些资源总是有限的，因此需要有效管理，资源管理最终只有两个问题：资源分配、资源回收。\n资源分配： 体现在CPU上，⽐如进程调度，多个进程同时请求CPU下，应该给哪⼀个进程呢？再⽐如内存分配，内\n存不够了怎么办？A进程⾮法访问了B进程的内存地址怎么办？内存内、外碎⽚问题等。\n资源回收：  考虑内存回收后的合并等等。\n## 为应⽤程序提供服务\n操作系统将硬件资源的操作封装起来，提供相对统⼀的接⼝（系统调⽤）供开发者调⽤。\n如果没有操作系统，应⽤程序将直接⾯对硬件，除去给开发者带来的编程困难不说，直接访问硬件，使⽤不当极有\n可能直接损坏硬件资源。\n## 管理应⽤程序\n即控制进程的⽣命周期：进程开始时的环境配置和资源分配、进程结束后的资源回收、进程调度等。\n## 操作系统内核的功能\n（1） 进程调度能⼒：  管理进程、线程，决定哪个进程、线程使⽤CPU。\n（2） 内存管理能⼒：  决定内存的分配和回收。\n（3） 硬件通信能⼒：  管理硬件，为进程和硬件之间提供通信。\n（4） 系统调⽤能⼒：   应⽤程序进⾏更⾼限权运⾏的服务，需要系统调⽤，⽤户程序和操作系统之间的接⼝。\n操作系统的⻆⾊\n## 管理者\n主要分为：CPU管理、内存管理、外存管理、IO管理；以及⾃⼰的健壮性和安全性管理。\n健壮性，⼜称鲁棒性，即使很粗鲁的对待程序，它还是可以很好的运⾏。\n## 魔术师:\n⽐如操作系统会让每个进程都觉得⾃⼰独占CPU、独占整⽚物理内存，⽽实际上每个进程都只是在某⼀时间段内占\n⽤CPU，仅仅只是占⽤实际⼀点点物理内存。\n⽤户程序与操作系统的关系\n⽤户程序和操作系统之间是相互调⽤的关系\n## 操作系统的⻆度\n计算机启动后启动的第⼀个软件就是操作系统，随后启动的所有进程都运⾏在操作系统之上，使⽤操作系统提供的\n服务，同时被操作系统监控，进程结束后也由操作系统回收。\n## 进程⻆度\n调⽤操作系统提供的服务，实现⾃⼰的功能。\n进程和线程\n进程基础",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1785,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000074",
    "content": "## 进程的概念\n\n我们编写的代码只是⼀个存储在硬盘的静态⽂件，通过编译后就会⽣成⼆进制可执⾏⽂件，当我们运⾏这个可执⾏\n⽂件后，它会被装载到内存中，接着 CPU 会执⾏程序中的每⼀条指令，那么这个运⾏中的程序，就被称为「进\n程」（Process）。\n根据上⾯的过程，我们可以得到进程的其中⼀个定义：进程是具有独⽴功能的程序在⼀个数据集合上运⾏的过程，\n是系统进⾏资源分配和调度的⼀个独⽴单位。\n## 进程控制块（PCB）\n系统通过进程控制块PCB 来描述进程的基本情况和运⾏状态，就进⽽控制和管理进程，它是进程存在的唯⼀标识，\n其包括以下信息：\n## 进程描述信息：  进程标识符、⽤户标识符\n## 进程控制和管理信息：  进程当前状态，进程优先级\n## 进程资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的 I/O 设备信\n## CPU相关信息： 当进程切换时，CPU寄存器的值都被保存在相应PCB中，以便CPU重新执⾏该进程时能从断\n点处继续执⾏;\nPCB  通常是通过链表的⽅式进⾏组织，把具有相同状态的进程链在⼀起，组成各种队列。\n## 并发与并⾏\n## 单个处理核在很短时间内分别执⾏多个进程，称为并发\n## 多个处理核同时执⾏多个进程称为并⾏\n## 对于并发来说，CPU需要从⼀个进程切换到另⼀个进程，在切换前必须要记录当前进程中运⾏的状态信息，以\n备下次切换回来的时候可以恢复执⾏。\n## 进程的状态切换\n我们知道了并发会执⾏进程的切换，这就需要进程有运⾏状态和停⽌状态，实际上某个进程在某个时刻所处的状态\n分为以下⼏种状态：\n运⾏态： 该时刻进程占⽤CPU\n就绪态：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏\n阻塞态：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏\n当然，进程还有另外两个基本状态：\n创建状态（new）：进程正在被创建时的状态；\n结束状态（Exit）：进程正在从系统中消失时的状态；\n如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，所以系统通常会把阻塞状态的进程的物理内存\n空间换出到硬盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存，那么，就需要⼀个新的状态，来描述进程没\n有占⽤实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不⼀样，阻塞状态是等待某个事件的\n返回。\n挂起状态可以分为两种：\n阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；\n就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏；\n## 只有就绪态和运⾏态可以相互转换，其它的都是单向转换。就绪态的进程通过调度算法从⽽获得CPU 时间，\n转为运⾏状态；\n## 运⾏态的进程，在分配给它的 CPU 时间⽚⽤完之后就会转为就绪状态，等待下⼀次调度。\n## 阻塞态是因缺少需要的资源从⽽由运⾏态转换⽽来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运⾏态\n转换为就绪态。\n## 当进程等待的外部事件发⽣时（如⼀些输⼊到达），则由阻塞态转换为就绪态，如果此时没有其他进程运⾏，\n则转换为运⾏态，否则该进程将处于就绪态，等待CPU空闲轮到它运⾏。\n## 进程的上下⽂切换\n⼀个进程切换到另⼀个进程运⾏，称为进程的上下⽂切换, 进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量\n等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。\n发⽣进程上下⽂切换有哪些场景？\n进程的时间⽚耗尽\n阻塞等待\n⾼优先级进程运⾏\n中断处理\n进程通过睡眠函数 sleep 这样的⽅法将⾃⼰主动挂起\n## 进程的创建\n⼀个进程可以创建另⼀个进程，此时创建者为⽗进程，被创建的进程为⼦进程，操作系统创建⼀个新进程的过程如\n为新进程分配⼀个独特的进程控制块（PCB）\n为新进程分配所需要的资源，⽐如内存、CPU时间\n初始化进程控制块（PCB）的各种字段，包括状态、优先级、寄存器初始值等。\n将其状态设置为就绪状态，使其能够被调度执⾏。进程进⼊就绪队列，等待分配处理器时间。\n## 进程的终⽌\n根据标识符，查找需要终⽌的进程的 PCB；\n如果进程处于执⾏状态，则⽴即终⽌该进程的执⾏，然后将处理器资源分配给其他进程；\n如果其还有⼦进程，则应将该进程的⼦进程交给 1 号进程接管；\n将该进程所拥有的全部资源都归还给操作系统；\n将其从 PCB 所在队列中删除；\n## 进程的阻塞\n找到被阻塞进程的标识符对应的PCB\n如果该进程为运⾏状态，则保护其现场，将其状态转为阻塞状态，停⽌运⾏；\n将该 PCB 插⼊到等待队列中，将处理机资源调度给其他就绪进程\n## 进程的唤醒\n在该事件的阻塞队列中找到相应进程的  PCB；\n将其从阻塞队列中移出，并置其状态为就绪状态；\n把该 PCB 插⼊到就绪队列中，等待调度程序调度；\n线程基础",
    "question": "## 进程的概念",
    "answer": "我们编写的代码只是⼀个存储在硬盘的静态⽂件，通过编译后就会⽣成⼆进制可执⾏⽂件，当我们运⾏这个可执⾏\n⽂件后，它会被装载到内存中，接着 CPU 会执⾏程序中的每⼀条指令，那么这个运⾏中的程序，就被称为「进\n程」（Process）。\n根据上⾯的过程，我们可以得到进程的其中⼀个定义：进程是具有独⽴功能的程序在⼀个数据集合上运⾏的过程，\n是系统进⾏资源分配和调度的⼀个独⽴单位。\n## 进程控制块（PCB）\n系统通过进程控制块PCB 来描述进程的基本情况和运⾏状态，就进⽽控制和管理进程，它是进程存在的唯⼀标识，\n其包括以下信息：\n## 进程描述信息：  进程标识符、⽤户标识符\n## 进程控制和管理信息：  进程当前状态，进程优先级\n## 进程资源分配清单： 有关内存地址空间或虚拟地址空间的信息，所打开⽂件的列表和所使⽤的 I/O 设备信\n## CPU相关信息： 当进程切换时，CPU寄存器的值都被保存在相应PCB中，以便CPU重新执⾏该进程时能从断\n点处继续执⾏;\nPCB  通常是通过链表的⽅式进⾏组织，把具有相同状态的进程链在⼀起，组成各种队列。\n## 并发与并⾏\n## 单个处理核在很短时间内分别执⾏多个进程，称为并发\n## 多个处理核同时执⾏多个进程称为并⾏\n## 对于并发来说，CPU需要从⼀个进程切换到另⼀个进程，在切换前必须要记录当前进程中运⾏的状态信息，以\n备下次切换回来的时候可以恢复执⾏。\n## 进程的状态切换\n我们知道了并发会执⾏进程的切换，这就需要进程有运⾏状态和停⽌状态，实际上某个进程在某个时刻所处的状态\n分为以下⼏种状态：\n运⾏态： 该时刻进程占⽤CPU\n就绪态：可运⾏，由于其他进程处于运⾏状态⽽暂时停⽌运⾏\n阻塞态：该进程正在等待某⼀事件发⽣（如等待输⼊/输出操作的完成）⽽暂时停⽌运⾏\n当然，进程还有另外两个基本状态：\n创建状态（new）：进程正在被创建时的状态；\n结束状态（Exit）：进程正在从系统中消失时的状态；\n如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，所以系统通常会把阻塞状态的进程的物理内存\n空间换出到硬盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存，那么，就需要⼀个新的状态，来描述进程没\n有占⽤实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不⼀样，阻塞状态是等待某个事件的\n返回。\n挂起状态可以分为两种：\n阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；\n就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏；\n## 只有就绪态和运⾏态可以相互转换，其它的都是单向转换。就绪态的进程通过调度算法从⽽获得CPU 时间，\n转为运⾏状态；\n## 运⾏态的进程，在分配给它的 CPU 时间⽚⽤完之后就会转为就绪状态，等待下⼀次调度。\n## 阻塞态是因缺少需要的资源从⽽由运⾏态转换⽽来，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运⾏态\n转换为就绪态。\n## 当进程等待的外部事件发⽣时（如⼀些输⼊到达），则由阻塞态转换为就绪态，如果此时没有其他进程运⾏，\n则转换为运⾏态，否则该进程将处于就绪态，等待CPU空闲轮到它运⾏。\n## 进程的上下⽂切换\n⼀个进程切换到另⼀个进程运⾏，称为进程的上下⽂切换, 进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量\n等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。\n发⽣进程上下⽂切换有哪些场景？\n进程的时间⽚耗尽\n阻塞等待\n⾼优先级进程运⾏\n中断处理\n进程通过睡眠函数 sleep 这样的⽅法将⾃⼰主动挂起\n## 进程的创建\n⼀个进程可以创建另⼀个进程，此时创建者为⽗进程，被创建的进程为⼦进程，操作系统创建⼀个新进程的过程如\n为新进程分配⼀个独特的进程控制块（PCB）\n为新进程分配所需要的资源，⽐如内存、CPU时间\n初始化进程控制块（PCB）的各种字段，包括状态、优先级、寄存器初始值等。\n将其状态设置为就绪状态，使其能够被调度执⾏。进程进⼊就绪队列，等待分配处理器时间。\n## 进程的终⽌\n根据标识符，查找需要终⽌的进程的 PCB；\n如果进程处于执⾏状态，则⽴即终⽌该进程的执⾏，然后将处理器资源分配给其他进程；\n如果其还有⼦进程，则应将该进程的⼦进程交给 1 号进程接管；\n将该进程所拥有的全部资源都归还给操作系统；\n将其从 PCB 所在队列中删除；\n## 进程的阻塞\n找到被阻塞进程的标识符对应的PCB\n如果该进程为运⾏状态，则保护其现场，将其状态转为阻塞状态，停⽌运⾏；\n将该 PCB 插⼊到等待队列中，将处理机资源调度给其他就绪进程\n## 进程的唤醒\n在该事件的阻塞队列中找到相应进程的  PCB；\n将其从阻塞队列中移出，并置其状态为就绪状态；\n把该 PCB 插⼊到就绪队列中，等待调度程序调度；\n线程基础",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2000,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000075",
    "content": "## 什么是线程？\n\n线程是“轻量级线程”，是进程中的⼀个实体，是程序执⾏的最⼩单元，也是被系统独⽴调度和分配的基本单位。\n线程是进程当中的⼀条执⾏流程，同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每\n个线程各⾃都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独⽴的。",
    "question": "## 什么是线程？",
    "answer": "线程是“轻量级线程”，是进程中的⼀个实体，是程序执⾏的最⼩单元，也是被系统独⽴调度和分配的基本单位。\n线程是进程当中的⼀条执⾏流程，同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每\n个线程各⾃都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独⽴的。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 150,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000076",
    "content": "## 线程的特点\n\n线程是⼀个“轻量级线程”，⼀个进程中可以有多个线程，线程不拥有系统资源，但是也有PCB，创建线程使⽤\n的底层函数和进程⼀样，都是clone\n各个线程之间可以并发执⾏\n同⼀个进程中的各个线程共享该进程所拥有的资源。\n进程可以蜕变成线程;\n实际上，⽆论是创建进程的fork，还是创建线程的 pthread_create ，底层实现都是调⽤同⼀个内核函数 clone 。\n## 如果复制对⽅的地址空间，那么就产出⼀个“进程”;\n## 如果共享对⽅的地址空间，就产⽣⼀个“线程”。\nLinux内核是不区分进程和线程的,  只在⽤户层⾯上进⾏区分。所以，线程所有操作函数  pthread_* 是库函数，⽽\n⾮系统调⽤。\n## 进程和线程的⽐较\n进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；\n资源：进程是系统中拥有资源的基本单位，⽽线程不拥有系统资源（仅有⼀点必不可少的能保证运⾏的资源，\n⽐如寄存器和栈），但线程可以访问⾪属进程的系统资源。\n调度：线程切换的代价远低于进程，在同⼀个进程中，线程的切换不会引起进程切换，⽽从⼀个进程中的线程\n切换到另⼀个进程中的线程中，会引起进程切换。\n并发：进程可以并发执⾏，⽽⼀个进程中的多个线程之间也能并发执⾏，甚⾄不同进程中的线程也能并发执\n⾏，从⽽使得操作系统拥有更好的并发性，提⾼了系统资源的利⽤率和系统的吞吐量。\n独⽴性：每个进程都拥有独⽴的地址空间和资源、除了共享全局变量，不允许其他进程访问。某进程中的线程\n对其他进程都不可⻅，同⼀进程中的不同线程是为了提⾼并发性以及进⾏相互之间的合作⽽创建的，它们共享\n进程的地址空间和资源。\n系统开销：线程所需要的开销⽐进程⼩\n线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件\n管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们；\n线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；\n同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同\n⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换\n的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的；\n由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核\n了，这就使得线程之间的数据交互效率更⾼了；\n所以，不管是时间效率，还是空间效率线程⽐进程都要⾼。\n## 线程的状态：\n执⾏状态：线程获得处理机正在执⾏\n就绪状态：线程已经具备执⾏条件，只需要获得CPU就可以执⾏\n阻塞状态：线程在执⾏中因事件受阻⽽处于暂停状态\n## 线程的实现\n（1） ⽤户线程 （ULT）\n⽤户线程是在⽤户空间实现的线程，不是由内核管理的线程，整个线程管理和调度，操作系统是不直接参与的，⽽\n是由⽤户级线程库函数来完成线程的管理，包括线程的创建、终⽌、同步和调度等。\n## 线程切换不需要切换到内核空间中，节省了模式切换的开销。\n## 调度算法可以是进程专⽤的，不同的进程可根据⾃身的需要，对⾃⼰的线程选择不同的调度算法。\n## ⽤户级线程的实现与操作系统平台⽆关，对线程管理的代码是属于⽤户程序的⼀部分。\n## 由于不由操作系统调度，⼀旦⽤户线程发起系统调⽤⽽阻塞，那么此进程下⽤户线程都⽆法运⾏;\n## ⼀旦某个⽤户线程正在运⾏，只有当其交出CPU执⾏权，其他⽤户线程才可以运⾏，⽆法被打断，因为只有操\n作系统才有权限打断运⾏，但是操作系统不直接参与调度;\n## 由于时间⽚分配给进程，故与其他进程⽐，在多线程执⾏时，每个线程得到的时间⽚较少，执⾏会⽐较慢；\n（2） 内核线程（KLT）\n由操作系统管理、调度，其对应的TCB是存放在内核中，这样线程的创建、终⽌和管理都是由操作系统负责。\n## 当⼀个内核线程发起系统调⽤阻塞时不会影响其它内核线程的执⾏;\n## 分配给线程，多线程的进程获得更多的 CPU 运⾏时间；\n## 在⽀持内核线程的操作系统中，由内核来维护进程和线程的上下⽂信息，如 PCB 和 TCB；\n## 线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤；\n（3） 轻量级线程 (LWP)：\n轻量级进程是内核⽀持的⽤户线程，⼀个进程可有⼀个或多个 LWP，每个 LWP 是跟内核线程⼀对⼀映射的，也就\n是 LWP 都是由⼀个内核线程⽀持，⽽且 LWP 是由内核管理并像普通进程⼀样被调度。\n## 线程共享资源\n⽂件描述符表\n每种信号的处理⽅式\n当前⼯作⽬录\n⽤户ID和组ID\n## 线程⾮共享资源\n线程id\n处理器现场和栈指针(内核栈)\n独⽴的栈空间(⽤户空间栈)\nerrno变量\n信号屏蔽字\n调度优先级",
    "question": "## 线程的特点",
    "answer": "线程是⼀个“轻量级线程”，⼀个进程中可以有多个线程，线程不拥有系统资源，但是也有PCB，创建线程使⽤\n的底层函数和进程⼀样，都是clone\n各个线程之间可以并发执⾏\n同⼀个进程中的各个线程共享该进程所拥有的资源。\n进程可以蜕变成线程;\n实际上，⽆论是创建进程的fork，还是创建线程的 pthread_create ，底层实现都是调⽤同⼀个内核函数 clone 。\n## 如果复制对⽅的地址空间，那么就产出⼀个“进程”;\n## 如果共享对⽅的地址空间，就产⽣⼀个“线程”。\nLinux内核是不区分进程和线程的,  只在⽤户层⾯上进⾏区分。所以，线程所有操作函数  pthread_* 是库函数，⽽\n⾮系统调⽤。\n## 进程和线程的⽐较\n进程是资源（包括内存、打开的⽂件等）分配的单位，线程是 CPU 调度的单位；\n资源：进程是系统中拥有资源的基本单位，⽽线程不拥有系统资源（仅有⼀点必不可少的能保证运⾏的资源，\n⽐如寄存器和栈），但线程可以访问⾪属进程的系统资源。\n调度：线程切换的代价远低于进程，在同⼀个进程中，线程的切换不会引起进程切换，⽽从⼀个进程中的线程\n切换到另⼀个进程中的线程中，会引起进程切换。\n并发：进程可以并发执⾏，⽽⼀个进程中的多个线程之间也能并发执⾏，甚⾄不同进程中的线程也能并发执\n⾏，从⽽使得操作系统拥有更好的并发性，提⾼了系统资源的利⽤率和系统的吞吐量。\n独⽴性：每个进程都拥有独⽴的地址空间和资源、除了共享全局变量，不允许其他进程访问。某进程中的线程\n对其他进程都不可⻅，同⼀进程中的不同线程是为了提⾼并发性以及进⾏相互之间的合作⽽创建的，它们共享\n进程的地址空间和资源。\n系统开销：线程所需要的开销⽐进程⼩\n线程的创建时间⽐进程快，因为进程在创建的过程中，还需要资源管理信息，⽐如内存管理信息、⽂件\n管理信息，⽽线程在创建的过程中，不会涉及这些资源管理信息，⽽是共享它们；\n线程的终⽌时间⽐进程快，因为线程释放的资源相⽐进程少很多；\n同⼀个进程内的线程切换⽐进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同\n⼀个进程的线程都具有同⼀个⻚表，那么在切换的时候不需要切换⻚表。⽽对于进程之间的切换，切换\n的时候要把⻚表给切换掉，⽽⻚表的切换过程开销是⽐较⼤的；\n由于同⼀进程的各线程间共享内存和⽂件资源，那么在线程之间数据传递的时候，就不需要经过内核\n了，这就使得线程之间的数据交互效率更⾼了；\n所以，不管是时间效率，还是空间效率线程⽐进程都要⾼。\n## 线程的状态：\n执⾏状态：线程获得处理机正在执⾏\n就绪状态：线程已经具备执⾏条件，只需要获得CPU就可以执⾏\n阻塞状态：线程在执⾏中因事件受阻⽽处于暂停状态\n## 线程的实现\n（1） ⽤户线程 （ULT）\n⽤户线程是在⽤户空间实现的线程，不是由内核管理的线程，整个线程管理和调度，操作系统是不直接参与的，⽽\n是由⽤户级线程库函数来完成线程的管理，包括线程的创建、终⽌、同步和调度等。\n## 线程切换不需要切换到内核空间中，节省了模式切换的开销。\n## 调度算法可以是进程专⽤的，不同的进程可根据⾃身的需要，对⾃⼰的线程选择不同的调度算法。\n## ⽤户级线程的实现与操作系统平台⽆关，对线程管理的代码是属于⽤户程序的⼀部分。\n## 由于不由操作系统调度，⼀旦⽤户线程发起系统调⽤⽽阻塞，那么此进程下⽤户线程都⽆法运⾏;\n## ⼀旦某个⽤户线程正在运⾏，只有当其交出CPU执⾏权，其他⽤户线程才可以运⾏，⽆法被打断，因为只有操\n作系统才有权限打断运⾏，但是操作系统不直接参与调度;\n## 由于时间⽚分配给进程，故与其他进程⽐，在多线程执⾏时，每个线程得到的时间⽚较少，执⾏会⽐较慢；\n（2） 内核线程（KLT）\n由操作系统管理、调度，其对应的TCB是存放在内核中，这样线程的创建、终⽌和管理都是由操作系统负责。\n## 当⼀个内核线程发起系统调⽤阻塞时不会影响其它内核线程的执⾏;\n## 分配给线程，多线程的进程获得更多的 CPU 运⾏时间；\n## 在⽀持内核线程的操作系统中，由内核来维护进程和线程的上下⽂信息，如 PCB 和 TCB；\n## 线程的创建、终⽌和切换都是通过系统调⽤的⽅式来进⾏，因此对于系统来说，系统开销⽐较⼤；\n（3） 轻量级线程 (LWP)：\n轻量级进程是内核⽀持的⽤户线程，⼀个进程可有⼀个或多个 LWP，每个 LWP 是跟内核线程⼀对⼀映射的，也就\n是 LWP 都是由⼀个内核线程⽀持，⽽且 LWP 是由内核管理并像普通进程⼀样被调度。\n## 线程共享资源\n⽂件描述符表\n每种信号的处理⽅式\n当前⼯作⽬录\n⽤户ID和组ID\n## 线程⾮共享资源\n线程id\n处理器现场和栈指针(内核栈)\n独⽴的栈空间(⽤户空间栈)\nerrno变量\n信号屏蔽字\n调度优先级",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1997,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000077",
    "content": "## 线程的优缺点\n\n提⾼程序并发性\n开销⼩\n数据通信、共享数据⽅便\n库函数，不稳定\n调试、编写困难、gdb不⽀持\n对信号⽀持不好\n## 线程如何减少开销\n## 线程创建快，进程创建需要资源管理信息，⽐如内存管理信息和⽂件管理信息，⽽线程创建后是共享其所属进\n程的资源管理信息;\n## 线程终⽌时间快，需要回收的仅有少量寄存器和私有的栈区;\n## 线程切换快，因为线程切换仅涉及到少量寄存器和栈区，⽽进程上下⽂切换有CPU寄存器和程序计数器(CPU\n上下⽂)、虚拟内存空间、⻚表切换等;\n## 线程因为创建时共享了其所属进程绝⼤多数资源，因此天⽣具有很好的线程间通信交互效率。\n进程调度\n当⼀个进程的状态发⽣改变时，操作系统需要考虑是否要换⼀个进程执⾏，这就需要⽤到“进程调度算法”\n调度⽬标\n不同的调度算法具有不同的特性，因为使⽤以下标准⽐较处理机调度算法的性能：\nCPU利⽤率：CPU是计算机系统中最重要和昂贵的资源之⼀，应该使CPU保持“忙碌”状态\n系统吞吐量：单位时间内CPU完成作业的数量。\n周转时间：作业从提交到作业完成所需要的时间，是作业等待、在就绪队列中排队、在处理机上运⾏及输⼊输\n出操作所花费时间的总和。\n等待时间：进程处于等处理机（处于就绪队列）的时间之和，等待时间越⻓，⽤户满意度越低。\n响应时间：⽤户提交请求到系统⾸次产⽣响应所需要的时间。\n进程调度⽅式\n⾮抢占调度⽅式：当⼀个进程正在处理中，即使有更为重要的进程进⼊到就绪队列中，仍然让正在执⾏的进程\n继续执⾏。\n抢占调度⽅式：当⼀个进程正在处理中，如果有更为重要的进程进⼊到就绪队列中，则允许调度程序根据某种\n原则去暂停正在执⾏的进程，将处理机分配给这个更为重要或紧迫的进程。\n调度算法\n## 先来先服务调度算法(FCFS)\n每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个\n进程接着运⾏。\n这种算法虽然看上去公平，但是如果有⼀个⻓作业需要处理，则后⾯的短作业需要处理很⻓时间。\n先来先调度算法的特点是算法简单，对⻓作业⽐较有利，对短作业不利，适⽤于  CPU  繁忙型作业的系统，⽽不适\n⽤于 I/O 繁忙型作业的系统。\n## 最短作业优先调度算法（SJF）\n最短作业优先调度算法从就绪队列中选择⼀个估计运⾏时间最短的作业，将之调⼊到内存中运⾏，这有利于提⾼系\n统的吞吐量。\n但是这对⻓作业⼗分不利，由于调度程序总是优先调度短作业，将会导致⻓作业⻓期不被调度，此外该算法也没有\n考虑到作业的紧迫程度，因此不能保证紧迫性作业会被及时处理。\n## ⾼响应⽐优先调度算法\n每次进⾏进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最⾼的进程投⼊运⾏\n根据公式可以知道：\n20ms~50ms\n作业的等待时间相同时，如果要求服务时间越短，则响应⽐更⾼，有利于短作业执⾏\n当要求服务时间相同时，响应⽐由等待时间决定，如果等待时间越⻓，则响应⽐越⾼\n对于⻓作业，作业的响应⽐可以随着等待时间的增加⽽提⾼\n## 时间⽚轮转调度算法\n每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏。\n如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外⼀个进程；\n如果该进程在时间⽚结束前阻塞或结束，则 CPU ⽴即进⾏切换；\n另外，时间⽚的⻓度就是⼀个很关键的点：\n如果时间⽚设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率；\n如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓。将\n⼀般来说，时间⽚设为\n通常是⼀个⽐较合理的折中值。\n## 最⾼优先级调度算法\n从就绪队列中选择最⾼优先级的进程进⾏运⾏，但进程的优先级可以分为静态优先级和动态优先级\n静态优先级：优先级在创建进程时已经确定，在进程运⾏期间保持不变，确定静态优先级的主要依据有进程类\n型，对资源的要求，⽤户要求。\n动态优先级：进程运⾏过程中，根据进程运⾏时间和等待时间等因素调整进程的优先级\n但是这种算法可能会导致低优先级的进程永远不被执⾏。\n## 多级队列调度算法\n上⾯的各种调度算法是固定且单⼀的，⽆法满⾜系统中不同⽤户对进程调度策略的不同要求，多级队列调度算法在\n系统中设置多个就绪队列，将不同类型或性质的进程固定分配到不同的就绪队列，每个队列可以实施不同的调度算\n## 多级反馈队列调度算法\n多级反馈队列调度算法融合了时间⽚轮转调度算法和优先级调度算法，通过动态调整进程的优先级和时间⽚⼤⼩，\n多级反馈队列调度算法可以兼顾多⽅⾯的系统⽬标\n多级反馈队列调度算法的实现思想如下：\n设置多个就绪队列，并为每个队列赋予不同的优先级。第1级队列的优先级最⾼，第2级队列的优先级次之，\n其余队列的优先级逐个降低。\n赋予各个队列的进程运⾏时间⽚的⼤⼩各不相同。在优先级越⾼的队列中，每个进程的时间⽚就越⼩。例如，\n第i+1 级队列的时间⽚要⽐第i级队列的时间⽚⻓1倍。\n每个队列都采⽤FCFS算法。当新进程进⼊内存后，⾸先将它放⼊第1级队列的末尾，按FCFS原则等待调度。当\n轮到该进程执⾏时，如它能在该时间⽚内完成，便可撤离系统。若它在⼀个时间⽚结束时尚未完成，调度程序\n将其转⼊第2级队列的末尾等待调度：若它在第2级队列中运⾏⼀个时间⽚后仍未完成，再将它放⼊第3级队\n列…，依此类推。当进程最后被降到第n级队列后，在第n级队列中便采⽤时间⽚轮转⽅式运⾏。\n按队列优先级调度。仅当第1级队列为空时，才调度第2级队列中的进程运⾏；仅当第 1~i-1 级队列均为空 时，\n才会调度第i级队列中的进程运⾏。若处理机正在执⾏第i级队列中的某进程时，⼜有新进程进⼊任⼀优先级较\n⾼的队列，此时须⽴即把正在运⾏的进程放回到第级队列的末尾，⽽把处理机分配给新到的⾼优先级进程。\n多级反馈队列的优势有以下⼏点：\n终端型作业⽤户：短作业优先。\n短批处理作业⽤户：周转时间较短。\n⻓批处理作业⽤户：经过前⾯⼏个队列得到部分执⾏，不会⻓期得不到处理。\n进程通信\n进程通信指的是进程之间的信息交换，进程之间⼀般是相互独⽴的，但内核空间是每个进程都共享的，所以进程之\n间要通信必须通过内核。\n共享存储\n在通信的进程之间存在⼀块可直接访问的共享空间，通过对这⽚共享空间进⾏写/读操作实现进程之间的信息交\n消息传递（消息队列）\n若通信的进程之间不存在可直接访问的共享空间，则必须利⽤操作系统提供的消息传递⽅法进⾏进程通信，进程通\n过系统提供的发送消息和接收消息两个原语进⾏数据交换。\n直接通信⽅式：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消\n息缓冲队列中取得消息。\n间接通信⽅式：发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。这种中间实体⼀般称为\n信箱。\n因为在内核中每个消息体都有⼀个最⼤⻓度的限制，所以消息队列不适合⽐较⼤数据的传输，⽽且通信也不是很及\n管道是指⽤于连接⼀个读进程和⼀个写进程以实现它们之间的通信的⼀个共享⽂件，⼜名pipe⽂件，向管道（共享\n⽂件）提供输⼊的发送进程（写进程），以字符流形式将⼤量的数据送⼊（写）管道：⽽接收管道输出的接收进程\n（即读进程）则从管道中接收（读）数据。\n管道传输数据是半双⼯通信，某⼀时刻只能单向传输。\n写⼊管道中的数据遵循先⼊先出的规则\n管道所传送的数据是⽆格式的，这要求管道的读出⽅与写⼊⽅必须事先约定好数据的格式，如多少字节算⼀个\n消息等\n管道不是普通的⽂件，不属于某个⽂件系统，其只存在于内存中\n管道在内存中对应⼀个缓冲区, 不同的系统其⼤⼩不⼀定相同\n从管道读数据是⼀次性操作，数据⼀旦被读⾛，它就从管道中被抛弃，释放空间以便写更多的数据\n通信效率低，不适合进程间频繁地交换数据。",
    "question": "## 线程的优缺点",
    "answer": "提⾼程序并发性\n开销⼩\n数据通信、共享数据⽅便\n库函数，不稳定\n调试、编写困难、gdb不⽀持\n对信号⽀持不好\n## 线程如何减少开销\n## 线程创建快，进程创建需要资源管理信息，⽐如内存管理信息和⽂件管理信息，⽽线程创建后是共享其所属进\n程的资源管理信息;\n## 线程终⽌时间快，需要回收的仅有少量寄存器和私有的栈区;\n## 线程切换快，因为线程切换仅涉及到少量寄存器和栈区，⽽进程上下⽂切换有CPU寄存器和程序计数器(CPU\n上下⽂)、虚拟内存空间、⻚表切换等;\n## 线程因为创建时共享了其所属进程绝⼤多数资源，因此天⽣具有很好的线程间通信交互效率。\n进程调度\n当⼀个进程的状态发⽣改变时，操作系统需要考虑是否要换⼀个进程执⾏，这就需要⽤到“进程调度算法”\n调度⽬标\n不同的调度算法具有不同的特性，因为使⽤以下标准⽐较处理机调度算法的性能：\nCPU利⽤率：CPU是计算机系统中最重要和昂贵的资源之⼀，应该使CPU保持“忙碌”状态\n系统吞吐量：单位时间内CPU完成作业的数量。\n周转时间：作业从提交到作业完成所需要的时间，是作业等待、在就绪队列中排队、在处理机上运⾏及输⼊输\n出操作所花费时间的总和。\n等待时间：进程处于等处理机（处于就绪队列）的时间之和，等待时间越⻓，⽤户满意度越低。\n响应时间：⽤户提交请求到系统⾸次产⽣响应所需要的时间。\n进程调度⽅式\n⾮抢占调度⽅式：当⼀个进程正在处理中，即使有更为重要的进程进⼊到就绪队列中，仍然让正在执⾏的进程\n继续执⾏。\n抢占调度⽅式：当⼀个进程正在处理中，如果有更为重要的进程进⼊到就绪队列中，则允许调度程序根据某种\n原则去暂停正在执⾏的进程，将处理机分配给这个更为重要或紧迫的进程。\n调度算法\n## 先来先服务调度算法(FCFS)\n每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个\n进程接着运⾏。\n这种算法虽然看上去公平，但是如果有⼀个⻓作业需要处理，则后⾯的短作业需要处理很⻓时间。\n先来先调度算法的特点是算法简单，对⻓作业⽐较有利，对短作业不利，适⽤于  CPU  繁忙型作业的系统，⽽不适\n⽤于 I/O 繁忙型作业的系统。\n## 最短作业优先调度算法（SJF）\n最短作业优先调度算法从就绪队列中选择⼀个估计运⾏时间最短的作业，将之调⼊到内存中运⾏，这有利于提⾼系\n统的吞吐量。\n但是这对⻓作业⼗分不利，由于调度程序总是优先调度短作业，将会导致⻓作业⻓期不被调度，此外该算法也没有\n考虑到作业的紧迫程度，因此不能保证紧迫性作业会被及时处理。\n## ⾼响应⽐优先调度算法\n每次进⾏进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最⾼的进程投⼊运⾏\n根据公式可以知道：\n20ms~50ms\n作业的等待时间相同时，如果要求服务时间越短，则响应⽐更⾼，有利于短作业执⾏\n当要求服务时间相同时，响应⽐由等待时间决定，如果等待时间越⻓，则响应⽐越⾼\n对于⻓作业，作业的响应⽐可以随着等待时间的增加⽽提⾼\n## 时间⽚轮转调度算法\n每个进程被分配⼀个时间段，称为时间⽚（Quantum），即允许该进程在该时间段中运⾏。\n如果时间⽚⽤完，进程还在运⾏，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外⼀个进程；\n如果该进程在时间⽚结束前阻塞或结束，则 CPU ⽴即进⾏切换；\n另外，时间⽚的⻓度就是⼀个很关键的点：\n如果时间⽚设得太短会导致过多的进程上下⽂切换，降低了 CPU 效率；\n如果设得太⻓⼜可能引起对短作业进程的响应时间变⻓。将\n⼀般来说，时间⽚设为\n通常是⼀个⽐较合理的折中值。\n## 最⾼优先级调度算法\n从就绪队列中选择最⾼优先级的进程进⾏运⾏，但进程的优先级可以分为静态优先级和动态优先级\n静态优先级：优先级在创建进程时已经确定，在进程运⾏期间保持不变，确定静态优先级的主要依据有进程类\n型，对资源的要求，⽤户要求。\n动态优先级：进程运⾏过程中，根据进程运⾏时间和等待时间等因素调整进程的优先级\n但是这种算法可能会导致低优先级的进程永远不被执⾏。\n## 多级队列调度算法\n上⾯的各种调度算法是固定且单⼀的，⽆法满⾜系统中不同⽤户对进程调度策略的不同要求，多级队列调度算法在\n系统中设置多个就绪队列，将不同类型或性质的进程固定分配到不同的就绪队列，每个队列可以实施不同的调度算\n## 多级反馈队列调度算法\n多级反馈队列调度算法融合了时间⽚轮转调度算法和优先级调度算法，通过动态调整进程的优先级和时间⽚⼤⼩，\n多级反馈队列调度算法可以兼顾多⽅⾯的系统⽬标\n多级反馈队列调度算法的实现思想如下：\n设置多个就绪队列，并为每个队列赋予不同的优先级。第1级队列的优先级最⾼，第2级队列的优先级次之，\n其余队列的优先级逐个降低。\n赋予各个队列的进程运⾏时间⽚的⼤⼩各不相同。在优先级越⾼的队列中，每个进程的时间⽚就越⼩。例如，\n第i+1 级队列的时间⽚要⽐第i级队列的时间⽚⻓1倍。\n每个队列都采⽤FCFS算法。当新进程进⼊内存后，⾸先将它放⼊第1级队列的末尾，按FCFS原则等待调度。当\n轮到该进程执⾏时，如它能在该时间⽚内完成，便可撤离系统。若它在⼀个时间⽚结束时尚未完成，调度程序\n将其转⼊第2级队列的末尾等待调度：若它在第2级队列中运⾏⼀个时间⽚后仍未完成，再将它放⼊第3级队\n列…，依此类推。当进程最后被降到第n级队列后，在第n级队列中便采⽤时间⽚轮转⽅式运⾏。\n按队列优先级调度。仅当第1级队列为空时，才调度第2级队列中的进程运⾏；仅当第 1~i-1 级队列均为空 时，\n才会调度第i级队列中的进程运⾏。若处理机正在执⾏第i级队列中的某进程时，⼜有新进程进⼊任⼀优先级较\n⾼的队列，此时须⽴即把正在运⾏的进程放回到第级队列的末尾，⽽把处理机分配给新到的⾼优先级进程。\n多级反馈队列的优势有以下⼏点：\n终端型作业⽤户：短作业优先。\n短批处理作业⽤户：周转时间较短。\n⻓批处理作业⽤户：经过前⾯⼏个队列得到部分执⾏，不会⻓期得不到处理。\n进程通信\n进程通信指的是进程之间的信息交换，进程之间⼀般是相互独⽴的，但内核空间是每个进程都共享的，所以进程之\n间要通信必须通过内核。\n共享存储\n在通信的进程之间存在⼀块可直接访问的共享空间，通过对这⽚共享空间进⾏写/读操作实现进程之间的信息交\n消息传递（消息队列）\n若通信的进程之间不存在可直接访问的共享空间，则必须利⽤操作系统提供的消息传递⽅法进⾏进程通信，进程通\n过系统提供的发送消息和接收消息两个原语进⾏数据交换。\n直接通信⽅式：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消\n息缓冲队列中取得消息。\n间接通信⽅式：发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。这种中间实体⼀般称为\n信箱。\n因为在内核中每个消息体都有⼀个最⼤⻓度的限制，所以消息队列不适合⽐较⼤数据的传输，⽽且通信也不是很及\n管道是指⽤于连接⼀个读进程和⼀个写进程以实现它们之间的通信的⼀个共享⽂件，⼜名pipe⽂件，向管道（共享\n⽂件）提供输⼊的发送进程（写进程），以字符流形式将⼤量的数据送⼊（写）管道：⽽接收管道输出的接收进程\n（即读进程）则从管道中接收（读）数据。\n管道传输数据是半双⼯通信，某⼀时刻只能单向传输。\n写⼊管道中的数据遵循先⼊先出的规则\n管道所传送的数据是⽆格式的，这要求管道的读出⽅与写⼊⽅必须事先约定好数据的格式，如多少字节算⼀个\n消息等\n管道不是普通的⽂件，不属于某个⽂件系统，其只存在于内存中\n管道在内存中对应⼀个缓冲区, 不同的系统其⼤⼩不⼀定相同\n从管道读数据是⼀次性操作，数据⼀旦被读⾛，它就从管道中被抛弃，释放空间以便写更多的数据\n通信效率低，不适合进程间频繁地交换数据。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3212,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000078",
    "content": "## 多级反馈队列调度算法\n\n多级反馈队列调度算法融合了时间⽚轮转调度算法和优先级调度算法，通过动态调整进程的优先级和时间⽚⼤⼩，\n多级反馈队列调度算法可以兼顾多⽅⾯的系统⽬标\n多级反馈队列调度算法的实现思想如下：\n设置多个就绪队列，并为每个队列赋予不同的优先级。第1级队列的优先级最⾼，第2级队列的优先级次之，\n其余队列的优先级逐个降低。\n赋予各个队列的进程运⾏时间⽚的⼤⼩各不相同。在优先级越⾼的队列中，每个进程的时间⽚就越⼩。例如，\n第i+1 级队列的时间⽚要⽐第i级队列的时间⽚⻓1倍。\n每个队列都采⽤FCFS算法。当新进程进⼊内存后，⾸先将它放⼊第1级队列的末尾，按FCFS原则等待调度。当\n轮到该进程执⾏时，如它能在该时间⽚内完成，便可撤离系统。若它在⼀个时间⽚结束时尚未完成，调度程序\n将其转⼊第2级队列的末尾等待调度：若它在第2级队列中运⾏⼀个时间⽚后仍未完成，再将它放⼊第3级队\n列…，依此类推。当进程最后被降到第n级队列后，在第n级队列中便采⽤时间⽚轮转⽅式运⾏。\n按队列优先级调度。仅当第1级队列为空时，才调度第2级队列中的进程运⾏；仅当第 1~i-1 级队列均为空 时，\n才会调度第i级队列中的进程运⾏。若处理机正在执⾏第i级队列中的某进程时，⼜有新进程进⼊任⼀优先级较\n⾼的队列，此时须⽴即把正在运⾏的进程放回到第级队列的末尾，⽽把处理机分配给新到的⾼优先级进程。\n多级反馈队列的优势有以下⼏点：\n终端型作业⽤户：短作业优先。\n短批处理作业⽤户：周转时间较短。\n⻓批处理作业⽤户：经过前⾯⼏个队列得到部分执⾏，不会⻓期得不到处理。\n进程通信\n进程通信指的是进程之间的信息交换，进程之间⼀般是相互独⽴的，但内核空间是每个进程都共享的，所以进程之\n间要通信必须通过内核。\n共享存储\n在通信的进程之间存在⼀块可直接访问的共享空间，通过对这⽚共享空间进⾏写/读操作实现进程之间的信息交\n消息传递（消息队列）\n若通信的进程之间不存在可直接访问的共享空间，则必须利⽤操作系统提供的消息传递⽅法进⾏进程通信，进程通\n过系统提供的发送消息和接收消息两个原语进⾏数据交换。\n直接通信⽅式：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消\n息缓冲队列中取得消息。\n间接通信⽅式：发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。这种中间实体⼀般称为\n信箱。\n因为在内核中每个消息体都有⼀个最⼤⻓度的限制，所以消息队列不适合⽐较⼤数据的传输，⽽且通信也不是很及\n管道是指⽤于连接⼀个读进程和⼀个写进程以实现它们之间的通信的⼀个共享⽂件，⼜名pipe⽂件，向管道（共享\n⽂件）提供输⼊的发送进程（写进程），以字符流形式将⼤量的数据送⼊（写）管道：⽽接收管道输出的接收进程\n（即读进程）则从管道中接收（读）数据。\n管道传输数据是半双⼯通信，某⼀时刻只能单向传输。\n写⼊管道中的数据遵循先⼊先出的规则\n管道所传送的数据是⽆格式的，这要求管道的读出⽅与写⼊⽅必须事先约定好数据的格式，如多少字节算⼀个\n消息等\n管道不是普通的⽂件，不属于某个⽂件系统，其只存在于内存中\n管道在内存中对应⼀个缓冲区, 不同的系统其⼤⼩不⼀定相同\n从管道读数据是⼀次性操作，数据⼀旦被读⾛，它就从管道中被抛弃，释放空间以便写更多的数据\n通信效率低，不适合进程间频繁地交换数据。\n(1) 匿名管道和命名管道之间的区别\n匿名管道：没有名字的管道，⽤完就销毁， Linux 中的| 就是⼀个匿名管道，只适⽤于⽗⼦进程之间的通信。\n命名管道：提前创建了⼀个类型为管道的设备⽂件，在进程⾥只要使⽤这个设备⽂件，就可以相互通信，所以它可\n以在不相关的进程间进⾏通信。\n(2) pipe函数",
    "question": "## 多级反馈队列调度算法",
    "answer": "多级反馈队列调度算法融合了时间⽚轮转调度算法和优先级调度算法，通过动态调整进程的优先级和时间⽚⼤⼩，\n多级反馈队列调度算法可以兼顾多⽅⾯的系统⽬标\n多级反馈队列调度算法的实现思想如下：\n设置多个就绪队列，并为每个队列赋予不同的优先级。第1级队列的优先级最⾼，第2级队列的优先级次之，\n其余队列的优先级逐个降低。\n赋予各个队列的进程运⾏时间⽚的⼤⼩各不相同。在优先级越⾼的队列中，每个进程的时间⽚就越⼩。例如，\n第i+1 级队列的时间⽚要⽐第i级队列的时间⽚⻓1倍。\n每个队列都采⽤FCFS算法。当新进程进⼊内存后，⾸先将它放⼊第1级队列的末尾，按FCFS原则等待调度。当\n轮到该进程执⾏时，如它能在该时间⽚内完成，便可撤离系统。若它在⼀个时间⽚结束时尚未完成，调度程序\n将其转⼊第2级队列的末尾等待调度：若它在第2级队列中运⾏⼀个时间⽚后仍未完成，再将它放⼊第3级队\n列…，依此类推。当进程最后被降到第n级队列后，在第n级队列中便采⽤时间⽚轮转⽅式运⾏。\n按队列优先级调度。仅当第1级队列为空时，才调度第2级队列中的进程运⾏；仅当第 1~i-1 级队列均为空 时，\n才会调度第i级队列中的进程运⾏。若处理机正在执⾏第i级队列中的某进程时，⼜有新进程进⼊任⼀优先级较\n⾼的队列，此时须⽴即把正在运⾏的进程放回到第级队列的末尾，⽽把处理机分配给新到的⾼优先级进程。\n多级反馈队列的优势有以下⼏点：\n终端型作业⽤户：短作业优先。\n短批处理作业⽤户：周转时间较短。\n⻓批处理作业⽤户：经过前⾯⼏个队列得到部分执⾏，不会⻓期得不到处理。\n进程通信\n进程通信指的是进程之间的信息交换，进程之间⼀般是相互独⽴的，但内核空间是每个进程都共享的，所以进程之\n间要通信必须通过内核。\n共享存储\n在通信的进程之间存在⼀块可直接访问的共享空间，通过对这⽚共享空间进⾏写/读操作实现进程之间的信息交\n消息传递（消息队列）\n若通信的进程之间不存在可直接访问的共享空间，则必须利⽤操作系统提供的消息传递⽅法进⾏进程通信，进程通\n过系统提供的发送消息和接收消息两个原语进⾏数据交换。\n直接通信⽅式：发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消\n息缓冲队列中取得消息。\n间接通信⽅式：发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。这种中间实体⼀般称为\n信箱。\n因为在内核中每个消息体都有⼀个最⼤⻓度的限制，所以消息队列不适合⽐较⼤数据的传输，⽽且通信也不是很及\n管道是指⽤于连接⼀个读进程和⼀个写进程以实现它们之间的通信的⼀个共享⽂件，⼜名pipe⽂件，向管道（共享\n⽂件）提供输⼊的发送进程（写进程），以字符流形式将⼤量的数据送⼊（写）管道：⽽接收管道输出的接收进程\n（即读进程）则从管道中接收（读）数据。\n管道传输数据是半双⼯通信，某⼀时刻只能单向传输。\n写⼊管道中的数据遵循先⼊先出的规则\n管道所传送的数据是⽆格式的，这要求管道的读出⽅与写⼊⽅必须事先约定好数据的格式，如多少字节算⼀个\n消息等\n管道不是普通的⽂件，不属于某个⽂件系统，其只存在于内存中\n管道在内存中对应⼀个缓冲区, 不同的系统其⼤⼩不⼀定相同\n从管道读数据是⼀次性操作，数据⼀旦被读⾛，它就从管道中被抛弃，释放空间以便写更多的数据\n通信效率低，不适合进程间频繁地交换数据。\n(1) 匿名管道和命名管道之间的区别\n匿名管道：没有名字的管道，⽤完就销毁， Linux 中的| 就是⼀个匿名管道，只适⽤于⽗⼦进程之间的通信。\n命名管道：提前创建了⼀个类型为管道的设备⽂件，在进程⾥只要使⽤这个设备⽂件，就可以相互通信，所以它可\n以在不相关的进程间进⾏通信。\n(2) pipe函数",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1548,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000079",
    "content": "(1) 匿名管道和命名管道之间的区别\n\n匿名管道：没有名字的管道，⽤完就销毁， Linux 中的| 就是⼀个匿名管道，只适⽤于⽗⼦进程之间的通信。\n命名管道：提前创建了⼀个类型为管道的设备⽂件，在进程⾥只要使⽤这个设备⽂件，就可以相互通信，所以它可\n以在不相关的进程间进⾏通信。\n(2) pipe函数\n#include <sys/types.h>\n#include <sys/stat.h>\n- 命名管道的创建.\n- @param pathname 普通的路径名，也就是创建后 FIFO 的名字.\n- @param mode ⽂件的权限，\n- 与打开普通⽂件的 open() 函数中的 mode 参数相同。(0666).\n- @return 成功: 0 状态码;\n失败: 如果⽂件已经存在，则会出错且返回 -1.\nint mkfifo(const char *pathname, mode_t mode);\n（3）命名管道\n命名管道（FIFO）不同于匿名管道之处在于它提供了⼀个路径名与之关联，以 FIFO 的⽂件形式存在于⽂件系统\n中，这样，即使与 FIFO 的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过 FIFO 相互通\n信，因此，通过 FIFO 不相关的进程也能交换数据.\n与⽆名管道(pipe)不同之处：\n## FIFO 在⽂件系统中作为⼀个特殊的⽂件⽽存在，但 FIFO 中的内容却存放在内存中;\n## 当使⽤ FIFO 的进程退出后，FIFO ⽂件将继续保存在⽂件系统中以便以后使⽤;\n## FIFO  有名字，不相关的进程可以通过打开命名管道进⾏通信.\n通过命令创建有名管道\n通过函数创建有名管道\n信号量\n信号量⽤于控制多个进程对共享资源的访问，⽐如避免因为多个进程同时修改同⼀个共享内存造成冲突，信号量可\n以使共享的资源在任意时刻只能被⼀个进程访问。\n信号量其实是⼀个整型的计数器，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。\n信号量维护⼀个整数值，通常称为计数器。进程可以执⾏两种基本操作来操作信号量：\n- 创建⽆名管道.\n- @param pipefd 为int型数组的⾸地址，其存放了管道的⽂件描述符\n- pipefd[0]、pipefd[1].\n- @return 创建成功返回0，创建失败返回-1.\nint pipe(int pipefd[2]);\n- 当⼀个管道建⽴时，它会创建两个⽂件描述符 fd[0] 和 fd[1]。其中\n- fd[0] 固定⽤于读管道，⽽ fd[1] 固定⽤于写管道。\n- ⼀般⽂件 I/O的函数都可以⽤来操作管道(lseek() 除外。）\nmkfifo\nmyPipe\nP（Wait）操作：这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占⽤，进程需阻塞等待；\n相减后如果信号量     >=     0，则表明还有资源可使⽤，进程可正常继续执⾏。 V（Signal）操\n作：这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒\n运⾏；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；\n如果两个进程访问共享内存，我们可以初始化信号量为1\n进程 A 在访问共享内存前，先执⾏了 P 操作，由于信号量的初始值为 1，故在进程 A 执⾏ P 操作后信号量变\n为 0，表示共享资源可⽤，于是进程 A 就可以访问共享内存。\n若此时，进程 B 也想访问共享内存，执⾏了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占⽤，\n因此进程 B 被阻塞。\n直到进程 A 访问完共享内存，才会执⾏ V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得\n进程 B 可以访问共享内存，最后完成共享内存的访问后，执⾏ V 操作，使信号量恢复到初始值 1。\n可以发现，信号初始化为  1 ，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有⼀个进程在访问，这就\n很好的保护了共享内存。\n还可以使⽤信号量实现多进程同步，⽐如可以初始化信号量为0\nint socket(int domain, int type, int protocal)\n具体过程：\n如果进程 B ⽐进程 A 先执⾏了，那么执⾏到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进\n程 A 还没⽣产数据，于是进程 B 就阻塞等待；\n接着，当进程 A ⽣产完数据后，执⾏了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程\n最后，进程 B 被唤醒后，意味着进程 A 已经⽣产了数据，于是进程 B 就可以正常读取数据了。\n可以发现，信号初始化为  0 ，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执⾏。\n在 Linux 操作系统中， 为了响应各种各样的事件，提供了⼏⼗种信号，分别代表不同的意义。我们可以通过\n命令，查看所有的信号。\n信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。\n信号是进程间通信机制中唯⼀的异步通信机制，它可以在⼀个进程中通知另⼀个进程发⽣了某种事件从⽽实现进程\n通信。\nSocket通信\nSocket 通信是⼀种⽹络编程中常⻅的通信⽅式，但它也可以在同⼀台机器上的不同进程之间进⾏通信。\n创建 socket 的系统调⽤：\n三个参数分别代表：\ndomain 参数⽤来指定协议族，⽐如 AF_INET ⽤于 IPV4、AF_INET6 ⽤于 IPV6、AF_LOCAL/AF_UNIX ⽤于本\nkill\n- 初始化线程属性函数，注意：应先初始化线程属性，再pthread_create创建线程.\n- @param attr 线程属性结构体.\nint pthread attr init(pthread attr t *attr);\n- 销毁线程属性所占⽤的资源函数.\n- @param attr 线程属性结构体.\nint pthread attr destroy(pthread attr t *attr);\ntype 参数⽤来指定通信特性，⽐如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数\n据报，对应 UDP、SOCK_RAW 表示的是原始套接字；\nprotocal   参数原本是⽤来指定通信协议的，但现在基本废弃。因为协议已经通过前⾯两个参数指定完成，\nprotocol ⽬前⼀般写成 0 即可；\n根据创建 socket 类型的不同，通信的⽅式也就不同：\n实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；\n实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；\n实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket\n」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地\nsocket；\n线程通信\n线程间的通信⽬的主要是⽤于线程同步。所以线程没有像进程通信中的⽤于数据交换的通信机制。\n同⼀进程的不同线程共享同⼀份内存区域，所以线程之间可以⽅便、快速地共享信息。只需要将数据复制到共享\n（全局或堆）变量中即可。但是需要避免出现多个线程试图同时修改同⼀份信息。\n线程属性\n## 线程属性初始化和销毁\n## 线程分离状态\n（1） ⾮分离状态：\n线程的默认属性是⾮分离状态，这种情况下，原有的线程等待创建的线程结束。只有当pthread_join()函数返回\n时，创建的线程才算终⽌，才能释放⾃⼰占⽤的系统资源。\n（2） 分离状态：\n分离线程没有被其他的线程所等待，⾃⼰运⾏结束了，线程也就终⽌了，⻢上释放系统资源。应该根据⾃⼰的需\n要，选择适当的分离状态。\n- 设置线程分离状态.\n- @param attr 已初始化的线程属性.\n- @detachstate(分离状态)\n## PTHREAD_CREATE_DETACHED（分离线程）;\n## PTHREAD_CREATE_JOINABLE（⾮分离线程）.\n- @return 成功: 0; 失败: ⾮0.\n- 获取线程分离状态.\n- @param attr 已初始化的线程属性.\n- @detachstate(分离状态)\n## PTHREAD_CREATE_DETACHED（分离线程）;\n## PTHREAD_CREATE_JOINABLE（⾮分离线程）.\n- @return 成功: 0; 失败: ⾮0.\nint pthread attr getdetachstate(const pthread attr t *attr, int *detachstate);\n- 设置线程的栈地址.\n- @param stackaddr 内存⾸地址.\n- @param stacksize 返回线程的堆栈⼤⼩.\nint pthread_attr_setstack(pthread_attr_t *attr, void *stackaddr,\nsize_t stacksize);\n- 获取线程的栈地址.\n- @param stackaddr 返回获取的栈地址.\n- @param stacksize 返回获取的栈⼤⼩.\n注意：\n## 如果设置⼀个线程为分离线程，⽽这个线程运⾏⼜⾮常快，它很可能在pthread_create函数返回之前就终⽌\n了，它终⽌以后就可能将线程号和系统资源移交给其他的线程使⽤，这样调⽤pthread_create的线程就得到\n了错误的线程号。\n## 要避免这种情况可以采取⼀定的同步措施，最简单的⽅法之⼀是可以在被创建的线程⾥调⽤\npthread_cond_timedwait函数，让这个线程等待⼀会⼉，留出⾜够的时间让函数pthread_create返回。\n## 线程栈地址\n当进程栈地址空间不够⽤时，指定新建线程使⽤由malloc分配的空间作为⾃⼰的栈空间。\n通过pthread_attr_setstack和pthread_attr_getstack两个函数分别设置和获取线程的栈地址。\n- 设置线程的栈⼤⼩.\n- @param stacksize 线程的堆栈⼤⼩.\nint pthread attr setstacksize(pthread attr t *attr, size t stacksize);\n- 获取线程的栈⼤⼩.\n- @param stacksize 返回线程的堆栈⼤⼩.\nint pthread attr getstacksize(const pthread attr t *attr, size t *stacksize);\n## 线程栈⼤⼩\n## 线程使⽤注意事项\n（1） 主线程退出其他线程不退出，主线程应调⽤pthread_exit\n（2） 避免僵⼫线程\n## pthread_join\n## pthread_detach\n## pthread_create指定分离属性\n被join线程可能在join函数返回前就释放完⾃⼰的所有内存资源，所以不应当返回被回收线程栈中的值\n（3） malloc和mmap申请的内存可以被其他线程释放\n（4） 应避免在多线程模型中调⽤fork，除⾮⻢上exec，⼦进程中只有调⽤fork的线程存在，其他线程t在⼦进程中\n均pthread_exit\n（5） 信号的复杂语义很难和多线程共存，应避免在多线程引⼊信号机制\n（6） Cache伪共享：\n这种因为多个线程同时读写同⼀个 Cache Line 的不同变量时，⽽导致 CPU Cache 失效的现象。避免的⽅式⼀般有\nCache Line ⼤⼩字节对⻬，以及字节填充等⽅法。在 Linux 内核中存在cachelinealignedin_smp 宏定义，是⽤于\n解决伪共享的问题。\nint pthread_attr_getstack(const pthread_attr_t *attr, void **stackaddr,\nsize_t\n*stacksize);-\n多线程\n⽤户态的多线程模型，同⼀个进程内部有多个线程，所有的线程共享同⼀个进程的内存空间，进程中定义的全局变\n量会被所有的线程共享；\ni++在计算机中并不是原⼦操作，涉及内存取数，计算和写⼊内存⼏个环节，⽽线程的切换有可能发⽣在上述任何\n⼀个环节中间，所以不同的操作顺序很有可能带来意想不到的结果。\n多线程的好处：\n主要原因是许多应⽤中同时发⽣多个活动，某些活动随着时间推移⽽阻塞，将这些应⽤程序分解成并发运⾏的多个\n线程，简化设计模型。同时多线程有共享同⼀地址空间和可⽤数据的能⼒，这是多进程没有的。\n线程⽐进程开销⼩，更容易创建和释放。\n多个线程是IO密集型时，多线程可以使这些活动彼此重叠运⾏，可以加快程序执⾏的速度。\n对于线程需要考虑：\n线程之间有⽆先后访问顺序（线程依赖关系）\n多个线程共享访问同⼀变量（同步互斥问题）\n同⼀进程的多个线程共享进程的资源，除了标识线程的tid，每个线程还有⾃⼰独⽴的栈空间，线程彼此之间是⽆法\n访问其他线程栈上内容的。\n进程表：\n为了实现进程模型，操作系统维护着⼀张表格(⼀个结构数组)，即进程表。\n每个进程占有⼀个进程表项。(有些著作称这些为进程控制块)\n该表项包含了⼀个进程状态的重要信息\n包括程序计数器、堆栈指针、内存分配状况、所打开⽂件的状态、账号的调度信息，以及其他在进程由运⾏态转换\n到就绪态或阻塞态时必须保存的信息，从⽽保证该进程随后能再次启动，就像从未中断过⼀样\n## 进程切换为何⽐线程慢\n涉及到虚拟内存的问题，进程切换涉及虚拟地址空间的切换⽽线程不会。\n因为每个进程都有⾃⼰的虚拟地址空间，⽽线程是共享所在进程的虚拟地址空间的，所以同⼀个进程中的线程进⾏\n线程切换时不涉及虚拟地址空间的转换。\n把虚拟地址转换为物理地址需要查找⻚表，⻚表查找是⼀个很慢的过程（⾄少访问2次内存），因此通常使⽤\nCache来缓存常⽤的地址映射，这样可以加速⻚表查找，这个cache就是TLB（快表）。\n由于每个进程都有⾃⼰的虚拟地址空间，那么显然每个进程都有⾃⼰的⻚表，那么当进程切换后⻚表也要进⾏切\n换，⻚表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的\n就是程序运⾏会变慢，⽽线程切换则不会导致TLB失效，因为线程线程⽆需切换地址空间，这也就是进程切换要⽐\n同进程下线程切换慢的原因。\n## 守护进程\n守护进程是指在后台运⾏的，没有控制终端与它相连的进程。它独⽴于控制终端，周期性地执⾏某种任务。\nLinux的⼤多数服务器就是⽤守护进程的⽅式实现的，如web服务器进程http等。\n创建守护进程要点：\n（1） 让程序在后台执⾏。\n⽅法是调⽤fork()产⽣⼀个⼦进程，然后使⽗进程退出。\n（2） 调⽤setsid()创建⼀个新对话期。\n守护进程需要摆脱⽗进程的影响，⽅法是调⽤setsid()使进程成为⼀个会话组⻓。setsid()调⽤成功后，进程成为新\n的会话组⻓和进程组⻓，并与原来的登录会话、进程组和控制终端脱离。\n（3） 禁⽌进程重新打开控制终端。\n经过1和2，进程已经成为⼀个⽆终端的会话组⻓，但是它可以重新申请打开⼀个终端。为了避免这种情况发⽣，可\n以通过使进程不再是会话组⻓来实现。再⼀次通过fork（）创建新的⼦进程，使调⽤fork的进程退出。\n（4） 关闭不再需要的⽂件描述符。\n⼦进程从⽗进程继承打开的⽂件描述符。如不关闭，将会浪费系统资源，造成进程所在的⽂件系统⽆法卸下以及引\n起⽆法预料的错误。⾸先获得最⾼⽂件描述符值，然后⽤⼀个循环程序，关闭0到最⾼⽂件描述符值的所有⽂件描\n述符。\n（5） 将当前⽬录更改为根⽬录。\n（6） ⼦进程从⽗进程继承的⽂件创建屏蔽字可能会拒绝某些许可权。\n为防⽌这⼀点，使⽤unmask(0)将屏蔽字清零。\n（7） 处理SIGCHLD信号。\n对于服务器进程，在请求到来时往往⽣成⼦进程处理请求。如果⼦进程等待⽗进程捕获状态，则⼦进程将成为僵⼫\n进程（zombie），从⽽占⽤系统资源。如果⽗进程等待⼦进程结束，将增加⽗进程的负担，影响服务器进程的并\n发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样，⼦进程结束时不会产⽣僵⼫进程。\n## 僵⼫进程\n多进程程序，⽗进程⼀般需要跟踪⼦进程的退出状态，当⼦进程退出，⽗进程在运⾏，⼦进程必须等到⽗进程捕获\n到了⼦进程的退出状态才真正结束。在⼦进程结束后，⽗进程读取状态前，此时⼦进程为僵⼫进程。\n设置僵⼫进程的⽬的是维护⼦进程的信息，以便⽗进程在以后某个时候获取。这些信息⾄少包括进程ID，进程的终\n⽌状态，以及该进程使⽤的CPU时间。所以当终⽌⼦进程的⽗进程调⽤wait或waitpid时就可以得到这些信息。\n但是⼦进程停⽌在僵⼫态会占据内核资源，所以需要避免僵⼫进程的产⽣或⽴即结束⼦进程的僵⼫态。\n## ⽗进程调⽤wait/waitpid等函数等待⼦进程结束，如果尚⽆⼦进程退出wait会导致⽗进程阻塞。waitpid只会\n等待由pid参数指定的⼦进程，同时也是⾮阻塞，⽬标进程正常退出返回⼦进程PID，还没结束返回0。\nstatic void handle_child(int sig)\npid_t pid;\nint stat;\nwhile((pid = waitpid(-1, &stat, WNOHANG)) > 0)\n//结束⼦进程的处理;\n## 在事件已经发⽣情况下执⾏⾮阻塞调⽤可以提⾼程序效率。对waitpid，最好在⼦进程退出后调⽤。使⽤\nSIGCHLD信号通知⽗进程，⼦进程结束。\n⽗进程中捕获信号，然后在信号处理函数中调⽤waitpid以彻底结束⼦进程\n## 通过signal(SIGCHLD, SIG_IGN)通知内核对⼦进程的结束不关⼼，由内核回收。如果不想让⽗进程挂起，可以\n在⽗进程中加⼊⼀条语句：signal(SIGCHLD,SIG_IGN);表示⽗进程忽略SIGCHLD信号，该信号是⼦进程退出的\n时候向⽗进程发送的。\n## 忽略SIGCHLD信号，这常⽤于并发服务器的性能的⼀个技巧因为并发服务器常常fork很多⼦进程，⼦进程终\n结之后需要服务器进程去wait清理资源。如果将此信号的处理⽅式设为忽略，可让内核把僵⼫⼦进程转交给\ninit进程去处理，省去了⼤量僵⼫进程占⽤系统资源。\n## 多进程\n进程结构由以下⼏个部分组成：代码段、堆栈段、数据段。代码段是静态的⼆进制代码，多个程序可以共享。\n⽗进程创建⼦进程之后，⽗、⼦进程除了pid外，⼏乎所有的部分⼏乎⼀样。\n⽗、⼦进程共享全部数据，⼦进程在写数据时会使⽤写时复制技术将公共的数据重新拷⻉⼀份，之后在拷⻉出的数\n据上进⾏操作；不是对同⼀块数据进⾏操作；\n如果⼦进程想要运⾏⾃⼰的代码段，还可以通过调⽤execv()函数重新加载新的代码段，之后就和⽗进程独⽴开了。\n进程通信\n共享存储映射\n存储映射I/O (Memory-mapped I/O) 使⼀个磁盘⽂件与存储空间中的⼀个缓冲区相映射.\n于是当从缓冲区中取数据，就相当于读⽂件中的相应字节。于此类似，将数据存⼊缓冲区，则相应的字节就⾃动写\n⼊⽂件。\n这样，就可在不适⽤read和write函数的情况下，使⽤地址（指针）完成I/O操作，进程就可以直接通过读写内存来\n操作⽂件.\n共享内存可以说是最有⽤的进程间通信⽅式，也是最快的IPC形式, 因为进程可以直接读写内存，⽽不需要任何数据\n的拷⻉.\n## 存储映射函数：\n（1） mmap函数\n#include <sys/mman.h>\n- ⼀个⽂件或者其它对象映射进内存.\n- @param addr 指定映射的起始地址, 通常设为NULL, 由系统指定.\n- @param length 映射到内存的⽂件⻓度.\n- @param prot 映射区的保护⽅式, 最常⽤的:\n(1) 读：PROT_READ;\n(2) 写：PROT_WRITE;\n(3) 读写：PROT_READ | PROT_WRITE.\n- @param flags 映射区的特性, 可以是:\n(1) MAP_SHARED: 写⼊映射区的数据会复制回⽂件,\n且允许其他映射该⽂件的进程共享。\n(2) MAP_PRIVATE: 对映射区的写⼊操作\n会产⽣⼀个映射区的复制(copy - on - write),\n对此区域所做的修改不会写回原⽂件。\n- @param fd 由open返回的⽂件描述符, 代表要映射的⽂件.\n- @param offset 以⽂件开始处的偏移量,\n必须是4k的整数倍, 通常为0, 表示从⽂件头开始映射.\n- @return 成功：返回创建的映射区⾸地址; 失败：MAP_FAILED宏.\nvoid *mmap(void *addr, size_t length,\nint prot, int flags, int fd, off_t offset);\n内存是按照⻚来区别的，通常⼀⻚就是4K\n## 第⼀个参数写成NULL\n## 第⼆个参数要映射的⽂件⼤⼩ > 0\n## 第三个参数：PROT_READ 、PROT_WRITE\n## 第四个参数：MAP_SHARED 或者 MAP_PRIVATE\n## 第五个参数：打开的⽂件对应的⽂件描述符\n## 第六个参数：4k的整数倍，通常为0\n#include <sys/mman.h>\n- 释放内存映射区.\n- @param addr 使⽤mmap函数创建的映射区的⾸地址.\n- @param length 映射区的⼤⼩.\n- @return 成功返回0; 失败返回-1.\nint munmap(void *addr, size_t length);\nint *p = mmap(NULL, 4, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANONYMOUS, -1, 0);\n（2） munmap函数\n## 注意事项:\n## 创建映射区的过程中，隐含着⼀次对映射⽂件的读操作\n## 当MAP_SHARED时，要求：映射区的权限应 <=⽂件打开的权限(出于对映射区的保护)。⽽MAP_PRIVATE则⽆\n所谓，因为mmap中的权限是对内存的限制\n## 映射区的释放与⽂件关闭⽆关。只要映射建⽴成功，⽂件可以⽴即关闭\n## 特别注意，当映射⽂件⼤⼩为0时，不能创建映射区。所以，⽤于映射的⽂件必须要有实际⼤⼩。mmap使⽤\n时常常会出现总线错误，通常是由于共享⽂件存储空间⼤⼩引起的\n## munmap传⼊的地址⼀定是mmap的返回地址。坚决杜绝指针++操作\n## 如果⽂件偏移量必须为4K的整数倍\n## mmap创建映射区出错概率⾮常⾼，⼀定要检查返回值，确保映射区建⽴成功再进⾏后续操作\n## 匿名映射实现⽗⼦进⾏通信\n（1） 为什么使⽤匿名的⽅式实现通信？\n内存映射的需要依赖⽂件。⽽建⽴⽂件建⽴好了只会还要unlink   close掉，⽐较麻烦;\n（2） 有什么好的不能办法进⾏解决？\n直接使⽤匿名映射来代替;\n（3） Linux系统给我们提供了创建匿名映射区的⽅法，⽆需依赖⼀个⽂件即可创建映射区。同样需要借助标志位参\n数flags来指定;\n（4） 使⽤MAP_ANONYMOUS (或MAP_ANON):\n消息队列\n基本原理：A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时\n候再去读取数据就可以了。\n## 消息队列是保存在内核中的消息链表，每个消息体都是固定⼤⼩的存储块。如果进程从消息队列中读取了消息\n体，内核就会把这个消息体删除。\n## 如果没有释放消息队列或者没有关闭操作系统，消息队列会⼀直存在。\n## 通信不及时，附件也有⼤⼩限制。\n## 消息队列不适合⽐较⼤数据的传输，每个消息体都有⼀个最⼤⻓度的限制，同时所有队列所包含的全部消息体\n的总⻓度也是有上限\n## 消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销\n信号是linux进程通信的最古⽼的⽅式;\n信号是软件中断，它是在软件层次上对中断机制的⼀种模拟，是⼀种异步通信的⽅式  。信号可以导致⼀个正在运⾏的\n进程被另⼀个正在运⾏的异步进程中断，转⽽处理某⼀个突发事件;\n信号可以直接进⾏⽤户空间进程和内核空间进程的交互，内核进程可以利⽤它来通知⽤户空间进程发⽣了哪些系统\n事件.",
    "question": "(1) 匿名管道和命名管道之间的区别",
    "answer": "匿名管道：没有名字的管道，⽤完就销毁， Linux 中的| 就是⼀个匿名管道，只适⽤于⽗⼦进程之间的通信。\n命名管道：提前创建了⼀个类型为管道的设备⽂件，在进程⾥只要使⽤这个设备⽂件，就可以相互通信，所以它可\n以在不相关的进程间进⾏通信。\n(2) pipe函数\n#include <sys/types.h>\n#include <sys/stat.h>\n- 命名管道的创建.\n- @param pathname 普通的路径名，也就是创建后 FIFO 的名字.\n- @param mode ⽂件的权限，\n- 与打开普通⽂件的 open() 函数中的 mode 参数相同。(0666).\n- @return 成功: 0 状态码;\n失败: 如果⽂件已经存在，则会出错且返回 -1.\nint mkfifo(const char *pathname, mode_t mode);\n（3）命名管道\n命名管道（FIFO）不同于匿名管道之处在于它提供了⼀个路径名与之关联，以 FIFO 的⽂件形式存在于⽂件系统\n中，这样，即使与 FIFO 的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过 FIFO 相互通\n信，因此，通过 FIFO 不相关的进程也能交换数据.\n与⽆名管道(pipe)不同之处：\n## FIFO 在⽂件系统中作为⼀个特殊的⽂件⽽存在，但 FIFO 中的内容却存放在内存中;\n## 当使⽤ FIFO 的进程退出后，FIFO ⽂件将继续保存在⽂件系统中以便以后使⽤;\n## FIFO  有名字，不相关的进程可以通过打开命名管道进⾏通信.\n通过命令创建有名管道\n通过函数创建有名管道\n信号量\n信号量⽤于控制多个进程对共享资源的访问，⽐如避免因为多个进程同时修改同⼀个共享内存造成冲突，信号量可\n以使共享的资源在任意时刻只能被⼀个进程访问。\n信号量其实是⼀个整型的计数器，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。\n信号量维护⼀个整数值，通常称为计数器。进程可以执⾏两种基本操作来操作信号量：\n- 创建⽆名管道.\n- @param pipefd 为int型数组的⾸地址，其存放了管道的⽂件描述符\n- pipefd[0]、pipefd[1].\n- @return 创建成功返回0，创建失败返回-1.\nint pipe(int pipefd[2]);\n- 当⼀个管道建⽴时，它会创建两个⽂件描述符 fd[0] 和 fd[1]。其中\n- fd[0] 固定⽤于读管道，⽽ fd[1] 固定⽤于写管道。\n- ⼀般⽂件 I/O的函数都可以⽤来操作管道(lseek() 除外。）\nmkfifo\nmyPipe\nP（Wait）操作：这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占⽤，进程需阻塞等待；\n相减后如果信号量     >=     0，则表明还有资源可使⽤，进程可正常继续执⾏。 V（Signal）操\n作：这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒\n运⾏；相加后如果信号量 > 0，则表明当前没有阻塞中的进程；\n如果两个进程访问共享内存，我们可以初始化信号量为1\n进程 A 在访问共享内存前，先执⾏了 P 操作，由于信号量的初始值为 1，故在进程 A 执⾏ P 操作后信号量变\n为 0，表示共享资源可⽤，于是进程 A 就可以访问共享内存。\n若此时，进程 B 也想访问共享内存，执⾏了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占⽤，\n因此进程 B 被阻塞。\n直到进程 A 访问完共享内存，才会执⾏ V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得\n进程 B 可以访问共享内存，最后完成共享内存的访问后，执⾏ V 操作，使信号量恢复到初始值 1。\n可以发现，信号初始化为  1 ，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有⼀个进程在访问，这就\n很好的保护了共享内存。\n还可以使⽤信号量实现多进程同步，⽐如可以初始化信号量为0\nint socket(int domain, int type, int protocal)\n具体过程：\n如果进程 B ⽐进程 A 先执⾏了，那么执⾏到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进\n程 A 还没⽣产数据，于是进程 B 就阻塞等待；\n接着，当进程 A ⽣产完数据后，执⾏了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程\n最后，进程 B 被唤醒后，意味着进程 A 已经⽣产了数据，于是进程 B 就可以正常读取数据了。\n可以发现，信号初始化为  0 ，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执⾏。\n在 Linux 操作系统中， 为了响应各种各样的事件，提供了⼏⼗种信号，分别代表不同的意义。我们可以通过\n命令，查看所有的信号。\n信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。\n信号是进程间通信机制中唯⼀的异步通信机制，它可以在⼀个进程中通知另⼀个进程发⽣了某种事件从⽽实现进程\n通信。\nSocket通信\nSocket 通信是⼀种⽹络编程中常⻅的通信⽅式，但它也可以在同⼀台机器上的不同进程之间进⾏通信。\n创建 socket 的系统调⽤：\n三个参数分别代表：\ndomain 参数⽤来指定协议族，⽐如 AF_INET ⽤于 IPV4、AF_INET6 ⽤于 IPV6、AF_LOCAL/AF_UNIX ⽤于本\nkill\n- 初始化线程属性函数，注意：应先初始化线程属性，再pthread_create创建线程.\n- @param attr 线程属性结构体.\nint pthread attr init(pthread attr t *attr);\n- 销毁线程属性所占⽤的资源函数.\n- @param attr 线程属性结构体.\nint pthread attr destroy(pthread attr t *attr);\ntype 参数⽤来指定通信特性，⽐如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数\n据报，对应 UDP、SOCK_RAW 表示的是原始套接字；\nprotocal   参数原本是⽤来指定通信协议的，但现在基本废弃。因为协议已经通过前⾯两个参数指定完成，\nprotocol ⽬前⼀般写成 0 即可；\n根据创建 socket 类型的不同，通信的⽅式也就不同：\n实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；\n实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；\n实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket\n」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地\nsocket；\n线程通信\n线程间的通信⽬的主要是⽤于线程同步。所以线程没有像进程通信中的⽤于数据交换的通信机制。\n同⼀进程的不同线程共享同⼀份内存区域，所以线程之间可以⽅便、快速地共享信息。只需要将数据复制到共享\n（全局或堆）变量中即可。但是需要避免出现多个线程试图同时修改同⼀份信息。\n线程属性\n## 线程属性初始化和销毁\n## 线程分离状态\n（1） ⾮分离状态：\n线程的默认属性是⾮分离状态，这种情况下，原有的线程等待创建的线程结束。只有当pthread_join()函数返回\n时，创建的线程才算终⽌，才能释放⾃⼰占⽤的系统资源。\n（2） 分离状态：\n分离线程没有被其他的线程所等待，⾃⼰运⾏结束了，线程也就终⽌了，⻢上释放系统资源。应该根据⾃⼰的需\n要，选择适当的分离状态。\n- 设置线程分离状态.\n- @param attr 已初始化的线程属性.\n- @detachstate(分离状态)\n## PTHREAD_CREATE_DETACHED（分离线程）;\n## PTHREAD_CREATE_JOINABLE（⾮分离线程）.\n- @return 成功: 0; 失败: ⾮0.\n- 获取线程分离状态.\n- @param attr 已初始化的线程属性.\n- @detachstate(分离状态)\n## PTHREAD_CREATE_DETACHED（分离线程）;\n## PTHREAD_CREATE_JOINABLE（⾮分离线程）.\n- @return 成功: 0; 失败: ⾮0.\nint pthread attr getdetachstate(const pthread attr t *attr, int *detachstate);\n- 设置线程的栈地址.\n- @param stackaddr 内存⾸地址.\n- @param stacksize 返回线程的堆栈⼤⼩.\nint pthread_attr_setstack(pthread_attr_t *attr, void *stackaddr,\nsize_t stacksize);\n- 获取线程的栈地址.\n- @param stackaddr 返回获取的栈地址.\n- @param stacksize 返回获取的栈⼤⼩.\n注意：\n## 如果设置⼀个线程为分离线程，⽽这个线程运⾏⼜⾮常快，它很可能在pthread_create函数返回之前就终⽌\n了，它终⽌以后就可能将线程号和系统资源移交给其他的线程使⽤，这样调⽤pthread_create的线程就得到\n了错误的线程号。\n## 要避免这种情况可以采取⼀定的同步措施，最简单的⽅法之⼀是可以在被创建的线程⾥调⽤\npthread_cond_timedwait函数，让这个线程等待⼀会⼉，留出⾜够的时间让函数pthread_create返回。\n## 线程栈地址\n当进程栈地址空间不够⽤时，指定新建线程使⽤由malloc分配的空间作为⾃⼰的栈空间。\n通过pthread_attr_setstack和pthread_attr_getstack两个函数分别设置和获取线程的栈地址。\n- 设置线程的栈⼤⼩.\n- @param stacksize 线程的堆栈⼤⼩.\nint pthread attr setstacksize(pthread attr t *attr, size t stacksize);\n- 获取线程的栈⼤⼩.\n- @param stacksize 返回线程的堆栈⼤⼩.\nint pthread attr getstacksize(const pthread attr t *attr, size t *stacksize);\n## 线程栈⼤⼩\n## 线程使⽤注意事项\n（1） 主线程退出其他线程不退出，主线程应调⽤pthread_exit\n（2） 避免僵⼫线程\n## pthread_join\n## pthread_detach\n## pthread_create指定分离属性\n被join线程可能在join函数返回前就释放完⾃⼰的所有内存资源，所以不应当返回被回收线程栈中的值\n（3） malloc和mmap申请的内存可以被其他线程释放\n（4） 应避免在多线程模型中调⽤fork，除⾮⻢上exec，⼦进程中只有调⽤fork的线程存在，其他线程t在⼦进程中\n均pthread_exit\n（5） 信号的复杂语义很难和多线程共存，应避免在多线程引⼊信号机制\n（6） Cache伪共享：\n这种因为多个线程同时读写同⼀个 Cache Line 的不同变量时，⽽导致 CPU Cache 失效的现象。避免的⽅式⼀般有\nCache Line ⼤⼩字节对⻬，以及字节填充等⽅法。在 Linux 内核中存在cachelinealignedin_smp 宏定义，是⽤于\n解决伪共享的问题。\nint pthread_attr_getstack(const pthread_attr_t *attr, void **stackaddr,\nsize_t\n*stacksize);-\n多线程\n⽤户态的多线程模型，同⼀个进程内部有多个线程，所有的线程共享同⼀个进程的内存空间，进程中定义的全局变\n量会被所有的线程共享；\ni++在计算机中并不是原⼦操作，涉及内存取数，计算和写⼊内存⼏个环节，⽽线程的切换有可能发⽣在上述任何\n⼀个环节中间，所以不同的操作顺序很有可能带来意想不到的结果。\n多线程的好处：\n主要原因是许多应⽤中同时发⽣多个活动，某些活动随着时间推移⽽阻塞，将这些应⽤程序分解成并发运⾏的多个\n线程，简化设计模型。同时多线程有共享同⼀地址空间和可⽤数据的能⼒，这是多进程没有的。\n线程⽐进程开销⼩，更容易创建和释放。\n多个线程是IO密集型时，多线程可以使这些活动彼此重叠运⾏，可以加快程序执⾏的速度。\n对于线程需要考虑：\n线程之间有⽆先后访问顺序（线程依赖关系）\n多个线程共享访问同⼀变量（同步互斥问题）\n同⼀进程的多个线程共享进程的资源，除了标识线程的tid，每个线程还有⾃⼰独⽴的栈空间，线程彼此之间是⽆法\n访问其他线程栈上内容的。\n进程表：\n为了实现进程模型，操作系统维护着⼀张表格(⼀个结构数组)，即进程表。\n每个进程占有⼀个进程表项。(有些著作称这些为进程控制块)\n该表项包含了⼀个进程状态的重要信息\n包括程序计数器、堆栈指针、内存分配状况、所打开⽂件的状态、账号的调度信息，以及其他在进程由运⾏态转换\n到就绪态或阻塞态时必须保存的信息，从⽽保证该进程随后能再次启动，就像从未中断过⼀样\n## 进程切换为何⽐线程慢\n涉及到虚拟内存的问题，进程切换涉及虚拟地址空间的切换⽽线程不会。\n因为每个进程都有⾃⼰的虚拟地址空间，⽽线程是共享所在进程的虚拟地址空间的，所以同⼀个进程中的线程进⾏\n线程切换时不涉及虚拟地址空间的转换。\n把虚拟地址转换为物理地址需要查找⻚表，⻚表查找是⼀个很慢的过程（⾄少访问2次内存），因此通常使⽤\nCache来缓存常⽤的地址映射，这样可以加速⻚表查找，这个cache就是TLB（快表）。\n由于每个进程都有⾃⼰的虚拟地址空间，那么显然每个进程都有⾃⼰的⻚表，那么当进程切换后⻚表也要进⾏切\n换，⻚表切换后TLB就失效了，cache失效导致命中率降低，那么虚拟地址转换为物理地址就会变慢，表现出来的\n就是程序运⾏会变慢，⽽线程切换则不会导致TLB失效，因为线程线程⽆需切换地址空间，这也就是进程切换要⽐\n同进程下线程切换慢的原因。\n## 守护进程\n守护进程是指在后台运⾏的，没有控制终端与它相连的进程。它独⽴于控制终端，周期性地执⾏某种任务。\nLinux的⼤多数服务器就是⽤守护进程的⽅式实现的，如web服务器进程http等。\n创建守护进程要点：\n（1） 让程序在后台执⾏。\n⽅法是调⽤fork()产⽣⼀个⼦进程，然后使⽗进程退出。\n（2） 调⽤setsid()创建⼀个新对话期。\n守护进程需要摆脱⽗进程的影响，⽅法是调⽤setsid()使进程成为⼀个会话组⻓。setsid()调⽤成功后，进程成为新\n的会话组⻓和进程组⻓，并与原来的登录会话、进程组和控制终端脱离。\n（3） 禁⽌进程重新打开控制终端。\n经过1和2，进程已经成为⼀个⽆终端的会话组⻓，但是它可以重新申请打开⼀个终端。为了避免这种情况发⽣，可\n以通过使进程不再是会话组⻓来实现。再⼀次通过fork（）创建新的⼦进程，使调⽤fork的进程退出。\n（4） 关闭不再需要的⽂件描述符。\n⼦进程从⽗进程继承打开的⽂件描述符。如不关闭，将会浪费系统资源，造成进程所在的⽂件系统⽆法卸下以及引\n起⽆法预料的错误。⾸先获得最⾼⽂件描述符值，然后⽤⼀个循环程序，关闭0到最⾼⽂件描述符值的所有⽂件描\n述符。\n（5） 将当前⽬录更改为根⽬录。\n（6） ⼦进程从⽗进程继承的⽂件创建屏蔽字可能会拒绝某些许可权。\n为防⽌这⼀点，使⽤unmask(0)将屏蔽字清零。\n（7） 处理SIGCHLD信号。\n对于服务器进程，在请求到来时往往⽣成⼦进程处理请求。如果⼦进程等待⽗进程捕获状态，则⼦进程将成为僵⼫\n进程（zombie），从⽽占⽤系统资源。如果⽗进程等待⼦进程结束，将增加⽗进程的负担，影响服务器进程的并\n发性能。在Linux下可以简单地将SIGCHLD信号的操作设为SIG_IGN。这样，⼦进程结束时不会产⽣僵⼫进程。\n## 僵⼫进程\n多进程程序，⽗进程⼀般需要跟踪⼦进程的退出状态，当⼦进程退出，⽗进程在运⾏，⼦进程必须等到⽗进程捕获\n到了⼦进程的退出状态才真正结束。在⼦进程结束后，⽗进程读取状态前，此时⼦进程为僵⼫进程。\n设置僵⼫进程的⽬的是维护⼦进程的信息，以便⽗进程在以后某个时候获取。这些信息⾄少包括进程ID，进程的终\n⽌状态，以及该进程使⽤的CPU时间。所以当终⽌⼦进程的⽗进程调⽤wait或waitpid时就可以得到这些信息。\n但是⼦进程停⽌在僵⼫态会占据内核资源，所以需要避免僵⼫进程的产⽣或⽴即结束⼦进程的僵⼫态。\n## ⽗进程调⽤wait/waitpid等函数等待⼦进程结束，如果尚⽆⼦进程退出wait会导致⽗进程阻塞。waitpid只会\n等待由pid参数指定的⼦进程，同时也是⾮阻塞，⽬标进程正常退出返回⼦进程PID，还没结束返回0。\nstatic void handle_child(int sig)\npid_t pid;\nint stat;\nwhile((pid = waitpid(-1, &stat, WNOHANG)) > 0)\n//结束⼦进程的处理;\n## 在事件已经发⽣情况下执⾏⾮阻塞调⽤可以提⾼程序效率。对waitpid，最好在⼦进程退出后调⽤。使⽤\nSIGCHLD信号通知⽗进程，⼦进程结束。\n⽗进程中捕获信号，然后在信号处理函数中调⽤waitpid以彻底结束⼦进程\n## 通过signal(SIGCHLD, SIG_IGN)通知内核对⼦进程的结束不关⼼，由内核回收。如果不想让⽗进程挂起，可以\n在⽗进程中加⼊⼀条语句：signal(SIGCHLD,SIG_IGN);表示⽗进程忽略SIGCHLD信号，该信号是⼦进程退出的\n时候向⽗进程发送的。\n## 忽略SIGCHLD信号，这常⽤于并发服务器的性能的⼀个技巧因为并发服务器常常fork很多⼦进程，⼦进程终\n结之后需要服务器进程去wait清理资源。如果将此信号的处理⽅式设为忽略，可让内核把僵⼫⼦进程转交给\ninit进程去处理，省去了⼤量僵⼫进程占⽤系统资源。\n## 多进程\n进程结构由以下⼏个部分组成：代码段、堆栈段、数据段。代码段是静态的⼆进制代码，多个程序可以共享。\n⽗进程创建⼦进程之后，⽗、⼦进程除了pid外，⼏乎所有的部分⼏乎⼀样。\n⽗、⼦进程共享全部数据，⼦进程在写数据时会使⽤写时复制技术将公共的数据重新拷⻉⼀份，之后在拷⻉出的数\n据上进⾏操作；不是对同⼀块数据进⾏操作；\n如果⼦进程想要运⾏⾃⼰的代码段，还可以通过调⽤execv()函数重新加载新的代码段，之后就和⽗进程独⽴开了。\n进程通信\n共享存储映射\n存储映射I/O (Memory-mapped I/O) 使⼀个磁盘⽂件与存储空间中的⼀个缓冲区相映射.\n于是当从缓冲区中取数据，就相当于读⽂件中的相应字节。于此类似，将数据存⼊缓冲区，则相应的字节就⾃动写\n⼊⽂件。\n这样，就可在不适⽤read和write函数的情况下，使⽤地址（指针）完成I/O操作，进程就可以直接通过读写内存来\n操作⽂件.\n共享内存可以说是最有⽤的进程间通信⽅式，也是最快的IPC形式, 因为进程可以直接读写内存，⽽不需要任何数据\n的拷⻉.\n## 存储映射函数：\n（1） mmap函数\n#include <sys/mman.h>\n- ⼀个⽂件或者其它对象映射进内存.\n- @param addr 指定映射的起始地址, 通常设为NULL, 由系统指定.\n- @param length 映射到内存的⽂件⻓度.\n- @param prot 映射区的保护⽅式, 最常⽤的:\n(1) 读：PROT_READ;\n(2) 写：PROT_WRITE;\n(3) 读写：PROT_READ | PROT_WRITE.\n- @param flags 映射区的特性, 可以是:\n(1) MAP_SHARED: 写⼊映射区的数据会复制回⽂件,\n且允许其他映射该⽂件的进程共享。\n(2) MAP_PRIVATE: 对映射区的写⼊操作\n会产⽣⼀个映射区的复制(copy - on - write),\n对此区域所做的修改不会写回原⽂件。\n- @param fd 由open返回的⽂件描述符, 代表要映射的⽂件.\n- @param offset 以⽂件开始处的偏移量,\n必须是4k的整数倍, 通常为0, 表示从⽂件头开始映射.\n- @return 成功：返回创建的映射区⾸地址; 失败：MAP_FAILED宏.\nvoid *mmap(void *addr, size_t length,\nint prot, int flags, int fd, off_t offset);\n内存是按照⻚来区别的，通常⼀⻚就是4K\n## 第⼀个参数写成NULL\n## 第⼆个参数要映射的⽂件⼤⼩ > 0\n## 第三个参数：PROT_READ 、PROT_WRITE\n## 第四个参数：MAP_SHARED 或者 MAP_PRIVATE\n## 第五个参数：打开的⽂件对应的⽂件描述符\n## 第六个参数：4k的整数倍，通常为0\n#include <sys/mman.h>\n- 释放内存映射区.\n- @param addr 使⽤mmap函数创建的映射区的⾸地址.\n- @param length 映射区的⼤⼩.\n- @return 成功返回0; 失败返回-1.\nint munmap(void *addr, size_t length);\nint *p = mmap(NULL, 4, PROT_READ|PROT_WRITE, MAP_SHARED|MAP_ANONYMOUS, -1, 0);\n（2） munmap函数\n## 注意事项:\n## 创建映射区的过程中，隐含着⼀次对映射⽂件的读操作\n## 当MAP_SHARED时，要求：映射区的权限应 <=⽂件打开的权限(出于对映射区的保护)。⽽MAP_PRIVATE则⽆\n所谓，因为mmap中的权限是对内存的限制\n## 映射区的释放与⽂件关闭⽆关。只要映射建⽴成功，⽂件可以⽴即关闭\n## 特别注意，当映射⽂件⼤⼩为0时，不能创建映射区。所以，⽤于映射的⽂件必须要有实际⼤⼩。mmap使⽤\n时常常会出现总线错误，通常是由于共享⽂件存储空间⼤⼩引起的\n## munmap传⼊的地址⼀定是mmap的返回地址。坚决杜绝指针++操作\n## 如果⽂件偏移量必须为4K的整数倍\n## mmap创建映射区出错概率⾮常⾼，⼀定要检查返回值，确保映射区建⽴成功再进⾏后续操作\n## 匿名映射实现⽗⼦进⾏通信\n（1） 为什么使⽤匿名的⽅式实现通信？\n内存映射的需要依赖⽂件。⽽建⽴⽂件建⽴好了只会还要unlink   close掉，⽐较麻烦;\n（2） 有什么好的不能办法进⾏解决？\n直接使⽤匿名映射来代替;\n（3） Linux系统给我们提供了创建匿名映射区的⽅法，⽆需依赖⼀个⽂件即可创建映射区。同样需要借助标志位参\n数flags来指定;\n（4） 使⽤MAP_ANONYMOUS (或MAP_ANON):\n消息队列\n基本原理：A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时\n候再去读取数据就可以了。\n## 消息队列是保存在内核中的消息链表，每个消息体都是固定⼤⼩的存储块。如果进程从消息队列中读取了消息\n体，内核就会把这个消息体删除。\n## 如果没有释放消息队列或者没有关闭操作系统，消息队列会⼀直存在。\n## 通信不及时，附件也有⼤⼩限制。\n## 消息队列不适合⽐较⼤数据的传输，每个消息体都有⼀个最⼤⻓度的限制，同时所有队列所包含的全部消息体\n的总⻓度也是有上限\n## 消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销\n信号是linux进程通信的最古⽼的⽅式;\n信号是软件中断，它是在软件层次上对中断机制的⼀种模拟，是⼀种异步通信的⽅式  。信号可以导致⼀个正在运⾏的\n进程被另⼀个正在运⾏的异步进程中断，转⽽处理某⼀个突发事件;\n信号可以直接进⾏⽤户空间进程和内核空间进程的交互，内核进程可以利⽤它来通知⽤户空间进程发⽣了哪些系统\n事件.",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 10157,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000080",
    "content": "## 信号的特点\n\n## 简单\n## 不能携带⼤量信息\n## 满⾜某个特定条件才发送\n## ⼀个完整的信号周期\n## 信号的产⽣\n## 信号在进程种的注册，信号在进程种的注销\n## 执⾏信号处理函数\n## 信号编号\n（1） 不存在编号为0的信号\n## 其中1-31号信号称之为常规信号（也叫普通信号或标准信号）",
    "question": "## 信号的特点",
    "answer": "## 简单\n## 不能携带⼤量信息\n## 满⾜某个特定条件才发送\n## ⼀个完整的信号周期\n## 信号的产⽣\n## 信号在进程种的注册，信号在进程种的注销\n## 执⾏信号处理函数\n## 信号编号\n（1） 不存在编号为0的信号\n## 其中1-31号信号称之为常规信号（也叫普通信号或标准信号）",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 155,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000081",
    "content": "## 34-64称之为实时信号，驱动编程与硬件相关。名字上区别不⼤。⽽前32个名字各不相同\n\n（2） 不存在编号为0的号，也没有32-33号\n（3） ⽐较重要的⼀些，需要记住的⼏个信号\n## SIGINT  当⽤户按下了<Ctrl+C>组合键时，⽤户终端向正在运⾏中的由该终端启动的程序发出此信号，终⽌进\n## SIGQUIT  ⽤户按下<ctrl+>组合键时产⽣该信号，⽤户终端向正在运⾏中的由该终端启动的程序发出些信号,终\n⽌进程\n## SIGSEGV 指示进程进⾏了⽆效内存访问(段错误), 终⽌进程并产⽣core⽂件\n## SIGPIPE Broken pipe向⼀个没有读端的管道写数据,终⽌进程\n## SIGCHLD ⼦进程结束时，⽗进程会收到这个信号,忽略这个信号\n## 信号四要素\n（1） 编号: man 7 signal 查看⽂档帮助\n（2） 名称\n（3） 事件\n（4） 默认处理动作:\n#include <sys/types.h>\n- 给指定进程发送指定信号(不⼀定杀死).\n- @param pid 取值有四种情况：\npid > 0:\n将信号传送给进程 ID 为pid的进程.\npid = 0 : 将信号传送给当前进程所在进程组中的所有进程.\npid = -1 : 将信号传送给系统内所有的进程.\npid < -1 : 将信号传给指定进程组的所有进程，这个进程组号等于 pid 的绝对值.\n- @param sig 信号的编号，这⾥可以填数字编号，也可以填信号的宏定义.\n可以通过命令 kill - l(\"l\" 为字⺟)进⾏相应查看.\n不推荐直接使⽤数字，应使⽤宏名，因为不同操作系统信号编号可能不同，但名称⼀致.\n- 普通⽤户基本规则是：发送者实际或有效⽤户ID == 接收者实际或有效⽤户ID.\nint kill(pid t pid, int sig);\n## Term：终⽌进程\n## Ign： 忽略信号 (默认即时对该种信号忽略操作)\n## Core：终⽌进程，⽣成Core⽂件。(查验死亡原因，⽤于gdb调试)\n## Stop：停⽌（暂停）进程\n## Cont：继续运⾏进程\n特别强调: 9) SIGKILL 和19) SIGSTOP信号，不允许忽略和捕捉，只能执⾏默认动作。甚⾄不能将其设置为阻塞.\n## 信号的状态\n（1） 产⽣\n## 当⽤户按某些终端键时，将产⽣信号\n## 硬件异常将产⽣信号\n## 软件异常将产⽣信号\n## 调⽤系统函数(如：kill、raise、abort)将发送信号\n## 运⾏ kill /killall命令将发送信号\n（2） 未决状态：没有被处理\n（3） 递达状态：信号被处理了\n## 阻塞信号集和未决信号集\n（1） 阻塞信号集\n将某些信号加⼊集合，对他们设置屏蔽，当屏蔽x信号后，再收到该信号，该信号的处理将推后(处理发⽣在解除屏\n蔽后)\n（2） 未决信号集合\n信号产⽣，未决信号集中描述该信号的位⽴刻翻转为1，表示信号处于未决状态。当信号被处理对应位翻转回为0。\n这⼀时刻往往⾮常短暂.\n## 信号产⽣函数\n（1） kill函数：\n- 给当前进程发送指定信号(⾃⼰给⾃⼰发)，等价于 kill(getpid(), sig).\n- @param sig 信号编号.\n成功: 0; 失败: ⾮0值.\nint raise(int sig);\n#include <stdlib.h>\n- 给⾃⼰发送异常终⽌信号 6) SIGABRT，并产⽣core⽂件，等价于kill(getpid(), SIGABRT).\nvoid abort(void);\n- 设置定时器(闹钟)。在指定seconds后，内核会给当前进程发送14）SIGALRM信号。进程收到该信号，默认动作终\n⽌。每个进程都有且只有唯⼀的⼀个定时器;\n- 取消定时器alarm(0)，返回旧闹钟余下秒数.\n- @param seconds 指定的时间，以秒为单位.\n- @return 返回0或剩余的秒数.\nunsigned int alarm(unsigned int seconds);\n#include <sys/time.h>\nstruct itimerval {\nstruct timerval it_interval; // 闹钟触发周期\nstruct timerval it_value;\n// 闹钟触发时间\nstruct timeval {\nlong tv_sec;\n// 秒\nlong tv_usec;\n// 微秒\n- 设置定时器(闹钟)。 可代替alarm函数。精度微秒us，可以实现周期定时.\n- @param which 指定定时⽅式:\n(1) ⾃然定时：ITIMER_REAL → 14）SIGALRM计算⾃然时间;\n(2) 虚拟空间计时(⽤户空间)：ITIMER_VIRTUAL → 26）SIGVTALRM 只计算进程占⽤cpu\n的时间;\n（2） raise函数\n（3） abort函数\n（4） alarm函数(闹钟)\n（5） setitimer函数（定时器）\nint sigemptyset(sigset_t *set);\n// 将set集合置空\nint sigfillset(sigset_t *set);\n// 将所有信号加⼊set集合\nint sigaddset(sigset_t *set, int signo);  // 将signo信号加⼊到set集合\nint sigdelset(sigset_t *set, int signo);  // 从set集合中移除signo信号\nint sigismember(const sigset_t *set, int signo);\n// 判断信号是否存在\n## ⾃定义信号集函数\n除sigismember外，其余操作函数中的set均为传出参数。sigset_t类型的本质是位图;\n## 阻塞信号集\n（1） 信号阻塞集也称信号屏蔽集、信号掩码;\n（2） 信号阻塞集⽤来描述哪些信号递送到该进程的时候被阻塞;\n（3） sigprocmask函数\n- 检查或修改信号阻塞集，根据 how 指定的⽅法对进程的阻塞集合进⾏修改，\n- 新的信号阻塞集由 set 指定，⽽原先的信号阻塞集合由 oldset 保存.\n- @param how 信号阻塞集合的修改⽅法，有 3 种情况:\n(1) SIG_BLOCK：向信号阻塞集合中添加 set 信号集，\n新的信号掩码是set和旧信号掩码的并集。相当于 mask = mask|set;\n(2) SIG_UNBLOCK：从信号阻塞集合中删除 set 信号集，\n从当前信号掩码中去除 set 中的信号。相当于 mask = mask & ~ set;\n(3) SIG_SETMASK：将信号阻塞集合设为 set 信号集，\n相当于原来信号阻塞集的内容清空，然后按照 set 中的信号重新设置信号阻塞集。相当于\nmask = set.\n- @set 要操作的信号集地址,若 set 为 NULL，则不改变信号阻塞集合，函数只把当前信号阻塞集合保存到\noldset 中.\n- @oldset 保存原先信号阻塞集地址.\n- @return 成功: 0; 失败: -1，失败时错误代码只可能是 EINVAL，表示参数 how 不合法.\nint sigprocmask(int how, const sigset_t *set, sigset_t *oldset);\n的时间.\n(3) 虚拟空间计时(⽤户空间)：ITIMER_VIRTUAL → 26）SIGVTALRM\n只计算进程占⽤cpu\n- @param new_value 负责设定timeout时间.\n- @param old_value 存放旧的timeout值，⼀般指定为NULL.\nint setitimer(int which,\nconst struct itimerval *new_value, struct itimerval\n*old_value);\n// itimerval.it_value： 设定第⼀次执⾏function所延迟的秒数\n// itimerval.it_interval：\n设定以后每⼏秒执⾏function\n- 读取当前进程的未决信号集.\n- @param set 未决信号集.\nint sigpending(sigset_t *set);\n检查或修改指定信号的设置（或同时执⾏这两种操作）.\n@param signum 要操作的信号.\n@param act 要设置的对信号的新处理⽅式（传⼊参数）.\n@param oldact：原来对信号的处理⽅式（传出参数）.\n如果 act 指针⾮空，则要改变指定信号的处理⽅式（设置），\n如果 oldact 指针⾮空，则系统将此前指定信号的处理⽅式存⼊ oldact.\n@return 成功: 0; 失败: -1.\nint sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);\n（4） sigpending函数\n## 信号捕捉\n注意: SIGKILL 和 SIGSTOP 不能更改信号的处理⽅式，因为它们向⽤户提供了⼀种使进程终⽌的可靠⽅法;\n（1） sigaction函数\n（2） sa_handler、sa_sigaction：信号处理函数指针\n和 signal() ⾥的函数指针⽤法⼀样，应根据情况给sa_sigaction、sa_handler 两者之⼀赋值\n其取值如下：\n## SIG_IGN：忽略该信号\n## SIG_DFL：执⾏系统默认动作\n## 处理函数名：⾃定义信号处理函数\n（3） sa_mask：\n信号阻塞集，在信号处理函数执⾏过程中，临时屏蔽指定的信号;\n（4） sa_flags：\n⽤于指定信号处理的⾏为，通常设置为0，表使⽤默认属性。它可以是⼀下值的“按位或”组合：\n## A_RESTART：使被信号打断的系统调⽤⾃动重新发起（已经废弃）\n## SA_NOCLDSTOP：使⽗进程在它的⼦进程暂停或继续运⾏时不会收到 SIGCHLD 信号\n## SA_NOCLDWAIT：使⽗进程在它的⼦进程退出时不会收到 SIGCHLD 信号，这时⼦进程如果退出也不会成为\n僵⼫进程\nstruct sigaction {\nvoid(*sa_handler)(int); //旧的信号处理函数指针\nvoid(*sa_sigaction)(int, siginfo_t *, void *); //新的信号处理函数指针\nsigset_t\nsa_mask;\n//信号阻塞集\nint\nsa_flags;\n//信号处理的⽅式\nvoid(*sa_restorer)(void); //已弃⽤\n- @param signum 信号的编号.\n- @param info 记录信号发送进程信息的结构体.\n- @param context 可以赋给指向 ucontext_t 类型的⼀个对象的指针\n- 以引⽤在传递信号时被中断的接收进程或线程的上下⽂.\nvoid(*sa_sigaction)(int signum, siginfo_t *info, void *context);\n## SA_NODEFER：使对信号的屏蔽⽆效，即在信号处理函数执⾏期间仍能发出这个信号\n## SA_RESETHAND：信号处理之后重新设置为默认的处理⽅式\n## SA_SIGINFO：使⽤ sa_sigaction 成员⽽不是 sa_handler 作为信号处理函数\n## struct sigaction结构体\n## 信号处理函数\n## 不可重⼊、可重⼊函数\n如果有⼀个函数不幸被设计成为这样：那么不同任务调⽤这个函数时可能修改其他任务调⽤这个函数的数据，从⽽\n导致不可预料的后果。\n这样的函数是不安全的函数，也叫不可重⼊函数;\n（1） 不可重⼊函数:\n## 函数体内使⽤了静态的数据结构;\n## 函数体内调⽤了malloc() 或者 free() 函数(谨慎使⽤堆);\n## 函数体内调⽤了标准 I/O 函数;\n（2） 可重⼊函数:\n## 所谓可重⼊是指⼀个可以被多个任务调⽤的过程，任务在调⽤时不必担⼼数据是否会出错;\n## 在写函数时候尽量使⽤局部变量（例如寄存器、栈中的变量）;\n## 对于要使⽤的全局变量要加以保护（如采取关中断、信号量等互斥⽅法），这样构成的函数就⼀定是⼀个可重\n⼊的函数.\n## SIGCHLD信号\n## ⼦进程终⽌时;\n## ⼦进程接收到SIGSTOP信号停⽌时;\n## ⼦进程处在停⽌态，接受到SIGCONT后唤醒时。\n## 如何避免僵⼫进程\n- 获取进程所属的会话ID.\n- @param pid 进程号，pid为0表示查看当前进程session ID.\n- @return 成功: 返回调⽤进程的会话ID; 失败: -1.\npid_t getsid(pid_t pid);\n（1） 最简单的⽅法:\n⽗进程通过 wait()  和 waitpid() 等函数等待⼦进程结束，但是，这会导致⽗进程挂起;\n（2） 如果⽗进程要处理的事情很多，不能够挂起，通过 signal() 函数⼈为处理信号 SIGCHLD:\n只要有⼦进程退出⾃动调⽤指定好的回调函数，因为⼦进程结束后， ⽗进程会收到该信号 SIGCHLD ，可以在其回调\n函数⾥调⽤ wait() 或 waitpid() 回收;\n（3） 如果⽗进程不关⼼⼦进程什么时候结束，那么可以⽤signal（SIGCHLD,  SIG_IGN）通知内核:\n⾃⼰对⼦进程的结束不感兴趣，⽗进程忽略此信号，那么⼦进程结束后，内核会回收，并不再给⽗进程发送信号;\n守护进程\n## 进程组概述\n## 代表⼀个或多个进程的集合;\n## 每个进程都属于⼀个进程组;\n## 是为了简化对多个进程的管理。\n## 会话\n## ⼀个会话可以有⼀个控制终端。这通常是终端设备或伪终端设备;\n## 建⽴与控制终端连接的会话⾸进程被称为控制进程;\n## ⼀个会话中的⼏个进程组可被分为⼀个前台进程组以及⼀个或多个后台进程组;\n## 如果⼀个会话有⼀个控制终端，则它有⼀个前台进程组，其它进程组为后台进程组;\n## 如果终端接⼝检测到断开连接，则将挂断信号发送⾄控制进程（会话⾸进程。\n## 创建会话注意事项\n## 调⽤进程不能是进程组组⻓，该进程变成新会话⾸进程(session header);\n## 该调⽤进程是组⻓进程，则出错返回;\n## 该进程成为⼀个新进程组的组⻓进程;\n## 需有root权限(ubuntu不需要);\n## 新会话丢弃原有的控制终端，该会话没有控制终端;\n## 建⽴新会话时，先调⽤fork,   ⽗进程终⽌，⼦进程调⽤setsid。\n## API函数\n（1） getsid 函数\n（2） setsid函数\n## 守护进程\n守护进程（Daemon Process），也就是通常说的 Daemon 进程（精灵进程），是 Linux 中的后台服务进程\n## 它是⼀个⽣存期较⻓的进程，通常独⽴于控制终端并且周期性地执⾏某种任务或等待处理某些发⽣的事件\n## ⼀般采⽤以d结尾的名字\n## 所有的服务存在于 etc/init.d\n## 守护进程是个特殊的孤⼉进程\n## 之所以脱离于终端是为了避免进程被任何终端所产⽣的信息所打断，其在执⾏过程中的信息也不在任何终端上\n## Linux  的⼤多数服务器就是⽤守护进程实现的\n## 守护进程模型\n（1） 创建⼦进程，⽗进程退出(必须)\n所有⼯作在⼦进程中进⾏形式上脱离了控制终端\n（2） 在⼦进程中创建新会话(必须)\n## setsid()函数\n## 使⼦进程完全独⽴出来，脱离控制\n（3） 改变当前⽬录为根⽬录(不是必须)\n## chdir()函数\n## 防⽌占⽤可卸载的⽂件系统\n## 也可以换成其它路径\n（4） 重设⽂件权限掩码(不是必须)\n## umask()函数\n## 防⽌继承的⽂件创建屏蔽字拒绝某些权限\n## 增加守护进程灵活性\n（5） 关闭⽂件描述符(不是必须)\n继承的打开⽂件不会⽤到，浪费系统资源，⽆法卸载\n（6） 开始执⾏守护进程核⼼⼯作(必须)\n守护进程退出处理程序模型\n创建⼀个会话，并以⾃⼰的ID设置进程组ID，同时也是新会话的ID。\n调⽤了setsid函数的进程，既是新的会⻓，也是新的组⻓.\n@return 成功： 返回调⽤进程的会话ID; 失败: -1.\npid_t setsid(void);\n- 初始化⼀个互斥锁.\n- @param mutex 互斥锁地址。类型是 pthread_mutex_t.\n- @param attr 设置互斥量的属性，通常可采⽤默认属性，即可将 attr 设为 NULL.\n- @return 成功: 0 成功申请的锁默认是打开的; 失败: ⾮0(错误码).\nint pthread_mutex_init(pthread_mutex_t *restrict mutex,\nconst pthread_mutexattr_t *restrict attr);\n// 这种⽅法等价于使⽤ NULL 指定的 attr 参数调⽤ pthread_mutex_init() 来完成动态初始化，\n// 不同之处在于 PTHREAD_MUTEX_INITIALIZER 宏不进⾏错误检查。\n- 销毁指定的⼀个互斥锁。互斥锁在使⽤完毕后，必须要对互斥锁进⾏销毁，以释放资源.\n- @param mutex 互斥锁地址。类型是 pthread_mutex_t.\n- @return 成功: 0; 失败: ⾮0(错误码).\nint pthread_mutex_destroy(pthread_mutex_t *mutex);\n互斥与同步\n互斥锁Mutex\n互斥锁（mutex）：\n也叫互斥量，互斥锁是⼀种简单的加锁的⽅法来控制对共享资源的访问，互斥锁只有两种状态,即加锁(  lock ) 和解锁\n( unlock )\n## 在访问共享资源后临界区域前，对互斥锁进⾏加锁。\n## 在访问完成后释放互斥锁导上的锁。\n## 对互斥锁进⾏加锁后，任何其他试图再次对互斥锁加锁的线程将会被阻塞，直到锁被释放。\n互斥锁的数据类型是： pthread_mutex_t\n## 创建互斥锁\npthread_mutex_init()\n## 销毁互斥锁\npthread_mutex_destroy()\n## 互斥锁上锁\npthread_mutex_lock()\n- 对指定的互斥锁解锁.\n- @param mutex 互斥锁地址.\n- @return 成功: 0; 失败: ⾮0(错误码)\nint pthread_mutex_unlock(pthread_mutex_t *mutex);\n## 互斥锁解锁\npthread_mutex_unlock()\n死锁（DeadLock）\n如果⼀个进程集合中的每⼀个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么，该进程集合就\n是死锁\n## 资源\n## 可抢占资源\n可以从拥有它的进程中抢占⽽不会产⽣任何副作⽤，存储器就是⼀类可抢占资源\n## 不可抢占资源\n是指在不引起相关计算失败的情况下，⽆法把它从占有它的进程处抢占过来\n## 必要条件\n## 互斥\n每个资源要么已经分配给⼀个进程，要么就是可⽤的\n## 占有和等待\n已经得到了某个资源的进程可以再请求新的资源\n## 不可抢占\n- 对互斥锁上锁，若互斥锁已经上锁，则调⽤者阻塞，直到互斥锁解锁后再上锁.\n- @param mutex 互斥锁地址.\n- @return 成功: 0; 失败: ⾮0(错误码).\nint pthread mutex lock(pthread mutex t *mutex);\n- 调⽤该函数时，若互斥锁未加锁，则上锁，返回 0;\n- 若互斥锁已加锁，则函数直接返回失败，即 EBUSY.\nint pthread mutex trylock(pthread mutex t *mutex);\n已经分配给⼀个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放\n## 环路等待\n死锁发⽣时，系统中⼀定有由两个或两个以上的进程组成的⼀条环路，该环路中的每个进程都在等待着下⼀个进程\n所占有的资源。\n## 处理⽅法\n## 鸵⻦算法\n把头埋在沙⼦⾥，假装根本没发⽣问题。\n因为解决死锁问题的代价很⾼，因此鸵⻦算法这种不采取任务措施的⽅案会获得更⾼的性能。\n当发⽣死锁时不会对⽤户造成多⼤影响，或发⽣死锁的概率很低，可以采⽤鸵⻦算法。\n## 死锁检测与死锁恢复\n（1） 每种类型⼀个资源的死锁检测\n检测算法：\n通过检测有向图中是否存在环来实现，从⼀个节点出发进⾏深度优先搜索，对访问过的节点进⾏标记，如果访问了\n已经标记的节点，就表示有向图存在环，也就是检测到死锁发⽣\n（2） 每种类型多个资源的死锁检测\n锁检测算法如下：\n每个进程最开始时都不被标记，执⾏过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。\n## 寻找⼀个没有标记的进程Pi，它所请求的资源⼩于或等于A\n## 如果真找到这样⼀个进程，那么将C矩阵的第i⾏向量加到A中，标记该进程，并转回第1步\n## 如果没有这样的进程，那么算法终⽌\n## 从死锁中恢复\n（1） 利⽤抢占恢复\n将进程挂起，强⾏取⾛资源给另⼀个进程使⽤，⽤完再放回\n（2） 利⽤回滚恢复\n复位到更早的状态，那时它还没有取得所需的资源\n（3） 通过杀死进程恢复\n杀掉环中的⼀个进程或多个，牺牲掉⼀个环外进程\n## 死锁预防\n（1） 破坏互斥条件\n例如假脱机打印机技术允许若⼲个进程同时输出，唯⼀真正请求物理打印机的进程是打印机守护进程。\n（2） 破坏占有个等待条件\n## 规定所有进程在开始执⾏前请求所需要的全部资源。\n## 要求当⼀个进程请求资源时，先暂时释放其当前占⽤的所有资源，然后在尝试⼀次获得所需的全部资源。\n（3） 破坏不可抢占条件\n## 保证每⼀个进程在任何时刻只能占⽤⼀个资源，如果请求另⼀个资源必须先释放第⼀个资源\n## 将所有的资源统⼀编号，进程可以在任何时刻提出资源请求，但是所有请求必须按照资源编号的顺序(升序)提\n（4） 破坏环路等待\n## 死锁避免\n（1） 安全状态\n如果没有死锁发⽣，并且即使所有进程突然请求对资源的最⼤需求，也仍然存在某种调度次序能够使得每⼀个进程\n运⾏完毕，则称该状态是安全的。\n（2） 单个资源的银⾏家算法\n⼀个⼩城镇的银⾏家，他向⼀群客户分别承诺了⼀定的贷款额度，算法要做的是判断对请求的满⾜是否会进⼊不安\n全状态，如果是，就拒绝请求；否则予以分配。\n（3） 多个资源的银⾏家算法\n检查⼀个状态是否安全的算法\n## 查找右边的矩阵是否存在⼀⾏⼩于等于向量 A。如果不存在这样的⾏，那么系统将会发⽣死锁，状态是不安全\n## 假若找到这样⼀⾏，将该进程标记为终⽌，并将其已分配资源加到 A 中。\n## 重复以上两步，直到所有进程都标记为终⽌，则状态时安全的。\n如果⼀个状态不是安全的，需要拒绝进⼊这个状态。\n读写锁\n在对数据的读写操作中，更多的是读操作，写操作较少，例如对数据库数据的读写应⽤。\n为了满⾜当前能够允许多个读出，但只允许⼀个写⼊的需求，线程提供了读写锁来实现。",
    "question": "## 34-64称之为实时信号，驱动编程与硬件相关。名字上区别不⼤。⽽前32个名字各不相同",
    "answer": "（2） 不存在编号为0的号，也没有32-33号\n（3） ⽐较重要的⼀些，需要记住的⼏个信号\n## SIGINT  当⽤户按下了<Ctrl+C>组合键时，⽤户终端向正在运⾏中的由该终端启动的程序发出此信号，终⽌进\n## SIGQUIT  ⽤户按下<ctrl+>组合键时产⽣该信号，⽤户终端向正在运⾏中的由该终端启动的程序发出些信号,终\n⽌进程\n## SIGSEGV 指示进程进⾏了⽆效内存访问(段错误), 终⽌进程并产⽣core⽂件\n## SIGPIPE Broken pipe向⼀个没有读端的管道写数据,终⽌进程\n## SIGCHLD ⼦进程结束时，⽗进程会收到这个信号,忽略这个信号\n## 信号四要素\n（1） 编号: man 7 signal 查看⽂档帮助\n（2） 名称\n（3） 事件\n（4） 默认处理动作:\n#include <sys/types.h>\n- 给指定进程发送指定信号(不⼀定杀死).\n- @param pid 取值有四种情况：\npid > 0:\n将信号传送给进程 ID 为pid的进程.\npid = 0 : 将信号传送给当前进程所在进程组中的所有进程.\npid = -1 : 将信号传送给系统内所有的进程.\npid < -1 : 将信号传给指定进程组的所有进程，这个进程组号等于 pid 的绝对值.\n- @param sig 信号的编号，这⾥可以填数字编号，也可以填信号的宏定义.\n可以通过命令 kill - l(\"l\" 为字⺟)进⾏相应查看.\n不推荐直接使⽤数字，应使⽤宏名，因为不同操作系统信号编号可能不同，但名称⼀致.\n- 普通⽤户基本规则是：发送者实际或有效⽤户ID == 接收者实际或有效⽤户ID.\nint kill(pid t pid, int sig);\n## Term：终⽌进程\n## Ign： 忽略信号 (默认即时对该种信号忽略操作)\n## Core：终⽌进程，⽣成Core⽂件。(查验死亡原因，⽤于gdb调试)\n## Stop：停⽌（暂停）进程\n## Cont：继续运⾏进程\n特别强调: 9) SIGKILL 和19) SIGSTOP信号，不允许忽略和捕捉，只能执⾏默认动作。甚⾄不能将其设置为阻塞.\n## 信号的状态\n（1） 产⽣\n## 当⽤户按某些终端键时，将产⽣信号\n## 硬件异常将产⽣信号\n## 软件异常将产⽣信号\n## 调⽤系统函数(如：kill、raise、abort)将发送信号\n## 运⾏ kill /killall命令将发送信号\n（2） 未决状态：没有被处理\n（3） 递达状态：信号被处理了\n## 阻塞信号集和未决信号集\n（1） 阻塞信号集\n将某些信号加⼊集合，对他们设置屏蔽，当屏蔽x信号后，再收到该信号，该信号的处理将推后(处理发⽣在解除屏\n蔽后)\n（2） 未决信号集合\n信号产⽣，未决信号集中描述该信号的位⽴刻翻转为1，表示信号处于未决状态。当信号被处理对应位翻转回为0。\n这⼀时刻往往⾮常短暂.\n## 信号产⽣函数\n（1） kill函数：\n- 给当前进程发送指定信号(⾃⼰给⾃⼰发)，等价于 kill(getpid(), sig).\n- @param sig 信号编号.\n成功: 0; 失败: ⾮0值.\nint raise(int sig);\n#include <stdlib.h>\n- 给⾃⼰发送异常终⽌信号 6) SIGABRT，并产⽣core⽂件，等价于kill(getpid(), SIGABRT).\nvoid abort(void);\n- 设置定时器(闹钟)。在指定seconds后，内核会给当前进程发送14）SIGALRM信号。进程收到该信号，默认动作终\n⽌。每个进程都有且只有唯⼀的⼀个定时器;\n- 取消定时器alarm(0)，返回旧闹钟余下秒数.\n- @param seconds 指定的时间，以秒为单位.\n- @return 返回0或剩余的秒数.\nunsigned int alarm(unsigned int seconds);\n#include <sys/time.h>\nstruct itimerval {\nstruct timerval it_interval; // 闹钟触发周期\nstruct timerval it_value;\n// 闹钟触发时间\nstruct timeval {\nlong tv_sec;\n// 秒\nlong tv_usec;\n// 微秒\n- 设置定时器(闹钟)。 可代替alarm函数。精度微秒us，可以实现周期定时.\n- @param which 指定定时⽅式:\n(1) ⾃然定时：ITIMER_REAL → 14）SIGALRM计算⾃然时间;\n(2) 虚拟空间计时(⽤户空间)：ITIMER_VIRTUAL → 26）SIGVTALRM 只计算进程占⽤cpu\n的时间;\n（2） raise函数\n（3） abort函数\n（4） alarm函数(闹钟)\n（5） setitimer函数（定时器）\nint sigemptyset(sigset_t *set);\n// 将set集合置空\nint sigfillset(sigset_t *set);\n// 将所有信号加⼊set集合\nint sigaddset(sigset_t *set, int signo);  // 将signo信号加⼊到set集合\nint sigdelset(sigset_t *set, int signo);  // 从set集合中移除signo信号\nint sigismember(const sigset_t *set, int signo);\n// 判断信号是否存在\n## ⾃定义信号集函数\n除sigismember外，其余操作函数中的set均为传出参数。sigset_t类型的本质是位图;\n## 阻塞信号集\n（1） 信号阻塞集也称信号屏蔽集、信号掩码;\n（2） 信号阻塞集⽤来描述哪些信号递送到该进程的时候被阻塞;\n（3） sigprocmask函数\n- 检查或修改信号阻塞集，根据 how 指定的⽅法对进程的阻塞集合进⾏修改，\n- 新的信号阻塞集由 set 指定，⽽原先的信号阻塞集合由 oldset 保存.\n- @param how 信号阻塞集合的修改⽅法，有 3 种情况:\n(1) SIG_BLOCK：向信号阻塞集合中添加 set 信号集，\n新的信号掩码是set和旧信号掩码的并集。相当于 mask = mask|set;\n(2) SIG_UNBLOCK：从信号阻塞集合中删除 set 信号集，\n从当前信号掩码中去除 set 中的信号。相当于 mask = mask & ~ set;\n(3) SIG_SETMASK：将信号阻塞集合设为 set 信号集，\n相当于原来信号阻塞集的内容清空，然后按照 set 中的信号重新设置信号阻塞集。相当于\nmask = set.\n- @set 要操作的信号集地址,若 set 为 NULL，则不改变信号阻塞集合，函数只把当前信号阻塞集合保存到\noldset 中.\n- @oldset 保存原先信号阻塞集地址.\n- @return 成功: 0; 失败: -1，失败时错误代码只可能是 EINVAL，表示参数 how 不合法.\nint sigprocmask(int how, const sigset_t *set, sigset_t *oldset);\n的时间.\n(3) 虚拟空间计时(⽤户空间)：ITIMER_VIRTUAL → 26）SIGVTALRM\n只计算进程占⽤cpu\n- @param new_value 负责设定timeout时间.\n- @param old_value 存放旧的timeout值，⼀般指定为NULL.\nint setitimer(int which,\nconst struct itimerval *new_value, struct itimerval\n*old_value);\n// itimerval.it_value： 设定第⼀次执⾏function所延迟的秒数\n// itimerval.it_interval：\n设定以后每⼏秒执⾏function\n- 读取当前进程的未决信号集.\n- @param set 未决信号集.\nint sigpending(sigset_t *set);\n检查或修改指定信号的设置（或同时执⾏这两种操作）.\n@param signum 要操作的信号.\n@param act 要设置的对信号的新处理⽅式（传⼊参数）.\n@param oldact：原来对信号的处理⽅式（传出参数）.\n如果 act 指针⾮空，则要改变指定信号的处理⽅式（设置），\n如果 oldact 指针⾮空，则系统将此前指定信号的处理⽅式存⼊ oldact.\n@return 成功: 0; 失败: -1.\nint sigaction(int signum, const struct sigaction *act, struct sigaction *oldact);\n（4） sigpending函数\n## 信号捕捉\n注意: SIGKILL 和 SIGSTOP 不能更改信号的处理⽅式，因为它们向⽤户提供了⼀种使进程终⽌的可靠⽅法;\n（1） sigaction函数\n（2） sa_handler、sa_sigaction：信号处理函数指针\n和 signal() ⾥的函数指针⽤法⼀样，应根据情况给sa_sigaction、sa_handler 两者之⼀赋值\n其取值如下：\n## SIG_IGN：忽略该信号\n## SIG_DFL：执⾏系统默认动作\n## 处理函数名：⾃定义信号处理函数\n（3） sa_mask：\n信号阻塞集，在信号处理函数执⾏过程中，临时屏蔽指定的信号;\n（4） sa_flags：\n⽤于指定信号处理的⾏为，通常设置为0，表使⽤默认属性。它可以是⼀下值的“按位或”组合：\n## A_RESTART：使被信号打断的系统调⽤⾃动重新发起（已经废弃）\n## SA_NOCLDSTOP：使⽗进程在它的⼦进程暂停或继续运⾏时不会收到 SIGCHLD 信号\n## SA_NOCLDWAIT：使⽗进程在它的⼦进程退出时不会收到 SIGCHLD 信号，这时⼦进程如果退出也不会成为\n僵⼫进程\nstruct sigaction {\nvoid(*sa_handler)(int); //旧的信号处理函数指针\nvoid(*sa_sigaction)(int, siginfo_t *, void *); //新的信号处理函数指针\nsigset_t\nsa_mask;\n//信号阻塞集\nint\nsa_flags;\n//信号处理的⽅式\nvoid(*sa_restorer)(void); //已弃⽤\n- @param signum 信号的编号.\n- @param info 记录信号发送进程信息的结构体.\n- @param context 可以赋给指向 ucontext_t 类型的⼀个对象的指针\n- 以引⽤在传递信号时被中断的接收进程或线程的上下⽂.\nvoid(*sa_sigaction)(int signum, siginfo_t *info, void *context);\n## SA_NODEFER：使对信号的屏蔽⽆效，即在信号处理函数执⾏期间仍能发出这个信号\n## SA_RESETHAND：信号处理之后重新设置为默认的处理⽅式\n## SA_SIGINFO：使⽤ sa_sigaction 成员⽽不是 sa_handler 作为信号处理函数\n## struct sigaction结构体\n## 信号处理函数\n## 不可重⼊、可重⼊函数\n如果有⼀个函数不幸被设计成为这样：那么不同任务调⽤这个函数时可能修改其他任务调⽤这个函数的数据，从⽽\n导致不可预料的后果。\n这样的函数是不安全的函数，也叫不可重⼊函数;\n（1） 不可重⼊函数:\n## 函数体内使⽤了静态的数据结构;\n## 函数体内调⽤了malloc() 或者 free() 函数(谨慎使⽤堆);\n## 函数体内调⽤了标准 I/O 函数;\n（2） 可重⼊函数:\n## 所谓可重⼊是指⼀个可以被多个任务调⽤的过程，任务在调⽤时不必担⼼数据是否会出错;\n## 在写函数时候尽量使⽤局部变量（例如寄存器、栈中的变量）;\n## 对于要使⽤的全局变量要加以保护（如采取关中断、信号量等互斥⽅法），这样构成的函数就⼀定是⼀个可重\n⼊的函数.\n## SIGCHLD信号\n## ⼦进程终⽌时;\n## ⼦进程接收到SIGSTOP信号停⽌时;\n## ⼦进程处在停⽌态，接受到SIGCONT后唤醒时。\n## 如何避免僵⼫进程\n- 获取进程所属的会话ID.\n- @param pid 进程号，pid为0表示查看当前进程session ID.\n- @return 成功: 返回调⽤进程的会话ID; 失败: -1.\npid_t getsid(pid_t pid);\n（1） 最简单的⽅法:\n⽗进程通过 wait()  和 waitpid() 等函数等待⼦进程结束，但是，这会导致⽗进程挂起;\n（2） 如果⽗进程要处理的事情很多，不能够挂起，通过 signal() 函数⼈为处理信号 SIGCHLD:\n只要有⼦进程退出⾃动调⽤指定好的回调函数，因为⼦进程结束后， ⽗进程会收到该信号 SIGCHLD ，可以在其回调\n函数⾥调⽤ wait() 或 waitpid() 回收;\n（3） 如果⽗进程不关⼼⼦进程什么时候结束，那么可以⽤signal（SIGCHLD,  SIG_IGN）通知内核:\n⾃⼰对⼦进程的结束不感兴趣，⽗进程忽略此信号，那么⼦进程结束后，内核会回收，并不再给⽗进程发送信号;\n守护进程\n## 进程组概述\n## 代表⼀个或多个进程的集合;\n## 每个进程都属于⼀个进程组;\n## 是为了简化对多个进程的管理。\n## 会话\n## ⼀个会话可以有⼀个控制终端。这通常是终端设备或伪终端设备;\n## 建⽴与控制终端连接的会话⾸进程被称为控制进程;\n## ⼀个会话中的⼏个进程组可被分为⼀个前台进程组以及⼀个或多个后台进程组;\n## 如果⼀个会话有⼀个控制终端，则它有⼀个前台进程组，其它进程组为后台进程组;\n## 如果终端接⼝检测到断开连接，则将挂断信号发送⾄控制进程（会话⾸进程。\n## 创建会话注意事项\n## 调⽤进程不能是进程组组⻓，该进程变成新会话⾸进程(session header);\n## 该调⽤进程是组⻓进程，则出错返回;\n## 该进程成为⼀个新进程组的组⻓进程;\n## 需有root权限(ubuntu不需要);\n## 新会话丢弃原有的控制终端，该会话没有控制终端;\n## 建⽴新会话时，先调⽤fork,   ⽗进程终⽌，⼦进程调⽤setsid。\n## API函数\n（1） getsid 函数\n（2） setsid函数\n## 守护进程\n守护进程（Daemon Process），也就是通常说的 Daemon 进程（精灵进程），是 Linux 中的后台服务进程\n## 它是⼀个⽣存期较⻓的进程，通常独⽴于控制终端并且周期性地执⾏某种任务或等待处理某些发⽣的事件\n## ⼀般采⽤以d结尾的名字\n## 所有的服务存在于 etc/init.d\n## 守护进程是个特殊的孤⼉进程\n## 之所以脱离于终端是为了避免进程被任何终端所产⽣的信息所打断，其在执⾏过程中的信息也不在任何终端上\n## Linux  的⼤多数服务器就是⽤守护进程实现的\n## 守护进程模型\n（1） 创建⼦进程，⽗进程退出(必须)\n所有⼯作在⼦进程中进⾏形式上脱离了控制终端\n（2） 在⼦进程中创建新会话(必须)\n## setsid()函数\n## 使⼦进程完全独⽴出来，脱离控制\n（3） 改变当前⽬录为根⽬录(不是必须)\n## chdir()函数\n## 防⽌占⽤可卸载的⽂件系统\n## 也可以换成其它路径\n（4） 重设⽂件权限掩码(不是必须)\n## umask()函数\n## 防⽌继承的⽂件创建屏蔽字拒绝某些权限\n## 增加守护进程灵活性\n（5） 关闭⽂件描述符(不是必须)\n继承的打开⽂件不会⽤到，浪费系统资源，⽆法卸载\n（6） 开始执⾏守护进程核⼼⼯作(必须)\n守护进程退出处理程序模型\n创建⼀个会话，并以⾃⼰的ID设置进程组ID，同时也是新会话的ID。\n调⽤了setsid函数的进程，既是新的会⻓，也是新的组⻓.\n@return 成功： 返回调⽤进程的会话ID; 失败: -1.\npid_t setsid(void);\n- 初始化⼀个互斥锁.\n- @param mutex 互斥锁地址。类型是 pthread_mutex_t.\n- @param attr 设置互斥量的属性，通常可采⽤默认属性，即可将 attr 设为 NULL.\n- @return 成功: 0 成功申请的锁默认是打开的; 失败: ⾮0(错误码).\nint pthread_mutex_init(pthread_mutex_t *restrict mutex,\nconst pthread_mutexattr_t *restrict attr);\n// 这种⽅法等价于使⽤ NULL 指定的 attr 参数调⽤ pthread_mutex_init() 来完成动态初始化，\n// 不同之处在于 PTHREAD_MUTEX_INITIALIZER 宏不进⾏错误检查。\n- 销毁指定的⼀个互斥锁。互斥锁在使⽤完毕后，必须要对互斥锁进⾏销毁，以释放资源.\n- @param mutex 互斥锁地址。类型是 pthread_mutex_t.\n- @return 成功: 0; 失败: ⾮0(错误码).\nint pthread_mutex_destroy(pthread_mutex_t *mutex);\n互斥与同步\n互斥锁Mutex\n互斥锁（mutex）：\n也叫互斥量，互斥锁是⼀种简单的加锁的⽅法来控制对共享资源的访问，互斥锁只有两种状态,即加锁(  lock ) 和解锁\n( unlock )\n## 在访问共享资源后临界区域前，对互斥锁进⾏加锁。\n## 在访问完成后释放互斥锁导上的锁。\n## 对互斥锁进⾏加锁后，任何其他试图再次对互斥锁加锁的线程将会被阻塞，直到锁被释放。\n互斥锁的数据类型是： pthread_mutex_t\n## 创建互斥锁\npthread_mutex_init()\n## 销毁互斥锁\npthread_mutex_destroy()\n## 互斥锁上锁\npthread_mutex_lock()\n- 对指定的互斥锁解锁.\n- @param mutex 互斥锁地址.\n- @return 成功: 0; 失败: ⾮0(错误码)\nint pthread_mutex_unlock(pthread_mutex_t *mutex);\n## 互斥锁解锁\npthread_mutex_unlock()\n死锁（DeadLock）\n如果⼀个进程集合中的每⼀个进程都在等待只能由该进程集合中的其他进程才能引发的事件，那么，该进程集合就\n是死锁\n## 资源\n## 可抢占资源\n可以从拥有它的进程中抢占⽽不会产⽣任何副作⽤，存储器就是⼀类可抢占资源\n## 不可抢占资源\n是指在不引起相关计算失败的情况下，⽆法把它从占有它的进程处抢占过来\n## 必要条件\n## 互斥\n每个资源要么已经分配给⼀个进程，要么就是可⽤的\n## 占有和等待\n已经得到了某个资源的进程可以再请求新的资源\n## 不可抢占\n- 对互斥锁上锁，若互斥锁已经上锁，则调⽤者阻塞，直到互斥锁解锁后再上锁.\n- @param mutex 互斥锁地址.\n- @return 成功: 0; 失败: ⾮0(错误码).\nint pthread mutex lock(pthread mutex t *mutex);\n- 调⽤该函数时，若互斥锁未加锁，则上锁，返回 0;\n- 若互斥锁已加锁，则函数直接返回失败，即 EBUSY.\nint pthread mutex trylock(pthread mutex t *mutex);\n已经分配给⼀个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放\n## 环路等待\n死锁发⽣时，系统中⼀定有由两个或两个以上的进程组成的⼀条环路，该环路中的每个进程都在等待着下⼀个进程\n所占有的资源。\n## 处理⽅法\n## 鸵⻦算法\n把头埋在沙⼦⾥，假装根本没发⽣问题。\n因为解决死锁问题的代价很⾼，因此鸵⻦算法这种不采取任务措施的⽅案会获得更⾼的性能。\n当发⽣死锁时不会对⽤户造成多⼤影响，或发⽣死锁的概率很低，可以采⽤鸵⻦算法。\n## 死锁检测与死锁恢复\n（1） 每种类型⼀个资源的死锁检测\n检测算法：\n通过检测有向图中是否存在环来实现，从⼀个节点出发进⾏深度优先搜索，对访问过的节点进⾏标记，如果访问了\n已经标记的节点，就表示有向图存在环，也就是检测到死锁发⽣\n（2） 每种类型多个资源的死锁检测\n锁检测算法如下：\n每个进程最开始时都不被标记，执⾏过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。\n## 寻找⼀个没有标记的进程Pi，它所请求的资源⼩于或等于A\n## 如果真找到这样⼀个进程，那么将C矩阵的第i⾏向量加到A中，标记该进程，并转回第1步\n## 如果没有这样的进程，那么算法终⽌\n## 从死锁中恢复\n（1） 利⽤抢占恢复\n将进程挂起，强⾏取⾛资源给另⼀个进程使⽤，⽤完再放回\n（2） 利⽤回滚恢复\n复位到更早的状态，那时它还没有取得所需的资源\n（3） 通过杀死进程恢复\n杀掉环中的⼀个进程或多个，牺牲掉⼀个环外进程\n## 死锁预防\n（1） 破坏互斥条件\n例如假脱机打印机技术允许若⼲个进程同时输出，唯⼀真正请求物理打印机的进程是打印机守护进程。\n（2） 破坏占有个等待条件\n## 规定所有进程在开始执⾏前请求所需要的全部资源。\n## 要求当⼀个进程请求资源时，先暂时释放其当前占⽤的所有资源，然后在尝试⼀次获得所需的全部资源。\n（3） 破坏不可抢占条件\n## 保证每⼀个进程在任何时刻只能占⽤⼀个资源，如果请求另⼀个资源必须先释放第⼀个资源\n## 将所有的资源统⼀编号，进程可以在任何时刻提出资源请求，但是所有请求必须按照资源编号的顺序(升序)提\n（4） 破坏环路等待\n## 死锁避免\n（1） 安全状态\n如果没有死锁发⽣，并且即使所有进程突然请求对资源的最⼤需求，也仍然存在某种调度次序能够使得每⼀个进程\n运⾏完毕，则称该状态是安全的。\n（2） 单个资源的银⾏家算法\n⼀个⼩城镇的银⾏家，他向⼀群客户分别承诺了⼀定的贷款额度，算法要做的是判断对请求的满⾜是否会进⼊不安\n全状态，如果是，就拒绝请求；否则予以分配。\n（3） 多个资源的银⾏家算法\n检查⼀个状态是否安全的算法\n## 查找右边的矩阵是否存在⼀⾏⼩于等于向量 A。如果不存在这样的⾏，那么系统将会发⽣死锁，状态是不安全\n## 假若找到这样⼀⾏，将该进程标记为终⽌，并将其已分配资源加到 A 中。\n## 重复以上两步，直到所有进程都标记为终⽌，则状态时安全的。\n如果⼀个状态不是安全的，需要拒绝进⼊这个状态。\n读写锁\n在对数据的读写操作中，更多的是读操作，写操作较少，例如对数据库数据的读写应⽤。\n为了满⾜当前能够允许多个读出，但只允许⼀个写⼊的需求，线程提供了读写锁来实现。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": 34,
    "char_count": 9648,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000082",
    "content": "## 重复以上两步，直到所有进程都标记为终⽌，则状态时安全的。\n\n如果⼀个状态不是安全的，需要拒绝进⼊这个状态。\n读写锁\n在对数据的读写操作中，更多的是读操作，写操作较少，例如对数据库数据的读写应⽤。\n为了满⾜当前能够允许多个读出，但只允许⼀个写⼊的需求，线程提供了读写锁来实现。\n读写锁的特点",
    "question": "## 重复以上两步，直到所有进程都标记为终⽌，则状态时安全的。",
    "answer": "如果⼀个状态不是安全的，需要拒绝进⼊这个状态。\n读写锁\n在对数据的读写操作中，更多的是读操作，写操作较少，例如对数据库数据的读写应⽤。\n为了满⾜当前能够允许多个读出，但只允许⼀个写⼊的需求，线程提供了读写锁来实现。\n读写锁的特点",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 147,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000083",
    "content": "读写锁的特点\n\n## 如果有其它线程读数据，则允许其它线程执⾏读操作，但不允许写操作\n## 如果有其它线程写数据，则其它线程都不允许读、写操作\n读写锁分为读锁和写锁，规则如下\n## 如果某线程申请了读锁，其它线程可以再申请读锁，但不能申请写锁。\n## 如果某线程申请了写锁，其它线程不能申请读锁，也不能申请写锁。\nPOSIX 定义的读写锁的数据类型是： pthread_rwlock_t。\n## 初始化读写锁\npthread_rwlock_init()\n- ⽤于销毁⼀个读写锁，并释放所有相关联的资源（所谓的所有指的是由 pthread_rwlock_init() ⾃动申请的资\nint pthread_rwlock_destroy(pthread_rwlock_t *rwlock);\n- 以阻塞⽅式在读写锁上获取读锁（读锁定）.\n- 如果没有写者持有该锁，并且没有写者阻塞在该锁上，则调⽤线程会获取读锁.\n- 如果调⽤线程未获取读锁，则它将阻塞直到它获取了该锁。⼀个线程可以在⼀个读写锁上多次执⾏读锁定.\n- 线程可以成功调⽤ pthread_rwlock_rdlock() 函数 n 次，但是之后该线程必须调⽤\npthread_rwlock_unlock() 函数 n 次才能解除锁定.\nint pthread rwlock rdlock(pthread rwlock t *rwlock);\n- ⽤于尝试以⾮阻塞的⽅式来在读写锁上获取读锁.\n- 如果有任何的写者持有该锁或有写者阻塞在该读写锁上，则⽴即失败返回.\nint pthread rwlock tryrdlock(pthread rwlock t *rwlock);\n## 销毁读写锁\npthread_rwlock_destroy()\n## 读锁定\npthread_rwlock_rdlock()\n- ⽤来初始化 rwlock 所指向的读写锁.\n- @param rwlock 指向要初始化的读写锁指针.\n- @param attr：读写锁的属性指针。如果 attr 为 NULL 则会使⽤默认的属性初始化读写锁，否则使⽤指定的\nattr 初始化读写锁.\n- 可以使⽤宏 PTHREAD_RWLOCK_INITIALIZER 静态初始化读写锁，⽐如:\n- pthread_rwlock_t my_rwlock = PTHREAD_RWLOCK_INITIALIZER;\n- 这种⽅法等价于使⽤ NULL 指定的 attr 参数调⽤ pthread_rwlock_init() 来完成动态初始化，\n- 不同之处在于PTHREAD_RWLOCK_INITIALIZER 宏不进⾏错误检查.\n- @return 成功: 0，读写锁的状态将成为已初始化和已解锁; 失败: ⾮ 0 错误码.\nint pthread_rwlock_init(pthread_rwlock_t *restrict rwlock,\nconst pthread_rwlockattr_t *restrict attr);\n- 在读写锁上获取写锁（写锁定）.\n- 如果没有写者持有该锁，并且没有写者读者持有该锁，则调⽤线程会获取写锁.\n- 如果调⽤线程未获取写锁，则它将阻塞直到它获取了该锁.\nint pthread rwlock wrlock(pthread rwlock t *rwlock);\n- ⽤于尝试以⾮阻塞的⽅式来在读写锁上获取写锁.\n- 如果有任何的读者或写者持有该锁，则⽴即失败返回.\nint pthread rwlock trywrlock(pthread rwlock t *rwlock);\n- ⽆论是读锁或写锁，都可以通过此函数解锁.\nint pthread_rwlock_unlock(pthread_rwlock_t *rwlock);\n## 写锁定\npthread_rwlock_wrlock()\n## 解锁\npthread_rwlock_unlock()\n条件变量\n与互斥锁不同，条件变量是⽤来等待⽽不是⽤来上锁的，条件变量本身不是锁！\n条件变量⽤来⾃动阻塞⼀个线程，直到某特殊情况发⽣为⽌。通常条件变量和互斥锁同时使⽤。\n条件变量的两个动作：\n## 条件不满, 阻塞线程\n## 当条件满⾜, 通知阻塞的线程开始⼯作\n条件变量的类型: pthread_cond_t\n- 初始化⼀个条件变量.\n- @param attr 条件变量属性，通常为默认值，传NULL即可.\n也可以使⽤静态初始化的⽅法，初始化条件变量;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER.\n- return 成功: 0; 失败: ⾮0错误号.\nint pthread_cond_init(pthread_cond_t *restrict cond,\nconst pthread_condattr_t *restrict attr);\n- 销毁⼀个条件变量.\nint pthread_cond_destroy(pthread_cond_t *cond);\n- 唤醒⾄少⼀个阻塞在条件变量上的线程.\nint pthread cond signal(pthread cond t *cond);\n- 唤醒全部阻塞在条件变量上的线程.\nint pthread cond broadcast(pthread cond t *cond);\n## 创建条件变量\npthread_cond_init()\n## 删除条件变量\npthread_cond_destroy()\n## 唤醒线程\npthread_cond_signal()\n## 阻塞线程\npthread_cond_wait()\nstruct timespec {\ntime_t tv_sec;\n/* seconds */ // 秒\nlong\ntv_nsec; /* nanosecondes*/ // 纳秒\n// time_t cur = time(NULL);\n//获取当前时间。\n// struct timespec t;\n//定义timespec 结构体变量t\n// t.tv_sec = cur + 1;\n// 定时1秒\n// pthread_cond_timedwait(&cond, &t);\n- 阻塞等待⼀个条件变量\n## 阻塞等待条件变量cond（参1）满⾜\n## 释放已掌握的互斥锁（解锁互斥量）相当于pthread_mutex_unlock(&mutex);\n((1), (2)两步为⼀个原⼦操作)\n## 当被唤醒，pthread_cond_wait函数返回时，解除阻塞并重新申请获取互斥锁\npthread_mutex_lock(&mutex);\n- @param mutex 互斥锁.\n- @return 成功: 0; 失败: ⾮0错误号.\nint pthread_cond_wait(pthread_cond_t *restrict cond,\npthread_mutex_t *restrict mutex);\n- 限时等待⼀个条件变量.\n- @param mutex 互斥锁.\n- @param abstime 绝对时间.\n- @return 成功: 0; 失败: ⾮0错误号.\nint pthread_cond_timedwait(pthread_cond_t *restrict cond,\npthread_mutex_t *restrict mutex,\nconst struct *restrict abstime);\n## 条件变量流程分析",
    "question": "读写锁的特点",
    "answer": "## 如果有其它线程读数据，则允许其它线程执⾏读操作，但不允许写操作\n## 如果有其它线程写数据，则其它线程都不允许读、写操作\n读写锁分为读锁和写锁，规则如下\n## 如果某线程申请了读锁，其它线程可以再申请读锁，但不能申请写锁。\n## 如果某线程申请了写锁，其它线程不能申请读锁，也不能申请写锁。\nPOSIX 定义的读写锁的数据类型是： pthread_rwlock_t。\n## 初始化读写锁\npthread_rwlock_init()\n- ⽤于销毁⼀个读写锁，并释放所有相关联的资源（所谓的所有指的是由 pthread_rwlock_init() ⾃动申请的资\nint pthread_rwlock_destroy(pthread_rwlock_t *rwlock);\n- 以阻塞⽅式在读写锁上获取读锁（读锁定）.\n- 如果没有写者持有该锁，并且没有写者阻塞在该锁上，则调⽤线程会获取读锁.\n- 如果调⽤线程未获取读锁，则它将阻塞直到它获取了该锁。⼀个线程可以在⼀个读写锁上多次执⾏读锁定.\n- 线程可以成功调⽤ pthread_rwlock_rdlock() 函数 n 次，但是之后该线程必须调⽤\npthread_rwlock_unlock() 函数 n 次才能解除锁定.\nint pthread rwlock rdlock(pthread rwlock t *rwlock);\n- ⽤于尝试以⾮阻塞的⽅式来在读写锁上获取读锁.\n- 如果有任何的写者持有该锁或有写者阻塞在该读写锁上，则⽴即失败返回.\nint pthread rwlock tryrdlock(pthread rwlock t *rwlock);\n## 销毁读写锁\npthread_rwlock_destroy()\n## 读锁定\npthread_rwlock_rdlock()\n- ⽤来初始化 rwlock 所指向的读写锁.\n- @param rwlock 指向要初始化的读写锁指针.\n- @param attr：读写锁的属性指针。如果 attr 为 NULL 则会使⽤默认的属性初始化读写锁，否则使⽤指定的\nattr 初始化读写锁.\n- 可以使⽤宏 PTHREAD_RWLOCK_INITIALIZER 静态初始化读写锁，⽐如:\n- pthread_rwlock_t my_rwlock = PTHREAD_RWLOCK_INITIALIZER;\n- 这种⽅法等价于使⽤ NULL 指定的 attr 参数调⽤ pthread_rwlock_init() 来完成动态初始化，\n- 不同之处在于PTHREAD_RWLOCK_INITIALIZER 宏不进⾏错误检查.\n- @return 成功: 0，读写锁的状态将成为已初始化和已解锁; 失败: ⾮ 0 错误码.\nint pthread_rwlock_init(pthread_rwlock_t *restrict rwlock,\nconst pthread_rwlockattr_t *restrict attr);\n- 在读写锁上获取写锁（写锁定）.\n- 如果没有写者持有该锁，并且没有写者读者持有该锁，则调⽤线程会获取写锁.\n- 如果调⽤线程未获取写锁，则它将阻塞直到它获取了该锁.\nint pthread rwlock wrlock(pthread rwlock t *rwlock);\n- ⽤于尝试以⾮阻塞的⽅式来在读写锁上获取写锁.\n- 如果有任何的读者或写者持有该锁，则⽴即失败返回.\nint pthread rwlock trywrlock(pthread rwlock t *rwlock);\n- ⽆论是读锁或写锁，都可以通过此函数解锁.\nint pthread_rwlock_unlock(pthread_rwlock_t *rwlock);\n## 写锁定\npthread_rwlock_wrlock()\n## 解锁\npthread_rwlock_unlock()\n条件变量\n与互斥锁不同，条件变量是⽤来等待⽽不是⽤来上锁的，条件变量本身不是锁！\n条件变量⽤来⾃动阻塞⼀个线程，直到某特殊情况发⽣为⽌。通常条件变量和互斥锁同时使⽤。\n条件变量的两个动作：\n## 条件不满, 阻塞线程\n## 当条件满⾜, 通知阻塞的线程开始⼯作\n条件变量的类型: pthread_cond_t\n- 初始化⼀个条件变量.\n- @param attr 条件变量属性，通常为默认值，传NULL即可.\n也可以使⽤静态初始化的⽅法，初始化条件变量;\npthread_cond_t cond = PTHREAD_COND_INITIALIZER.\n- return 成功: 0; 失败: ⾮0错误号.\nint pthread_cond_init(pthread_cond_t *restrict cond,\nconst pthread_condattr_t *restrict attr);\n- 销毁⼀个条件变量.\nint pthread_cond_destroy(pthread_cond_t *cond);\n- 唤醒⾄少⼀个阻塞在条件变量上的线程.\nint pthread cond signal(pthread cond t *cond);\n- 唤醒全部阻塞在条件变量上的线程.\nint pthread cond broadcast(pthread cond t *cond);\n## 创建条件变量\npthread_cond_init()\n## 删除条件变量\npthread_cond_destroy()\n## 唤醒线程\npthread_cond_signal()\n## 阻塞线程\npthread_cond_wait()\nstruct timespec {\ntime_t tv_sec;\n/* seconds */ // 秒\nlong\ntv_nsec; /* nanosecondes*/ // 纳秒\n// time_t cur = time(NULL);\n//获取当前时间。\n// struct timespec t;\n//定义timespec 结构体变量t\n// t.tv_sec = cur + 1;\n// 定时1秒\n// pthread_cond_timedwait(&cond, &t);\n- 阻塞等待⼀个条件变量\n## 阻塞等待条件变量cond（参1）满⾜\n## 释放已掌握的互斥锁（解锁互斥量）相当于pthread_mutex_unlock(&mutex);\n((1), (2)两步为⼀个原⼦操作)\n## 当被唤醒，pthread_cond_wait函数返回时，解除阻塞并重新申请获取互斥锁\npthread_mutex_lock(&mutex);\n- @param mutex 互斥锁.\n- @return 成功: 0; 失败: ⾮0错误号.\nint pthread_cond_wait(pthread_cond_t *restrict cond,\npthread_mutex_t *restrict mutex);\n- 限时等待⼀个条件变量.\n- @param mutex 互斥锁.\n- @param abstime 绝对时间.\n- @return 成功: 0; 失败: ⾮0错误号.\nint pthread_cond_timedwait(pthread_cond_t *restrict cond,\npthread_mutex_t *restrict mutex,\nconst struct *restrict abstime);\n## 条件变量流程分析",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3151,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000084",
    "content": "## 条件变量的优缺点\n\n相较于mutex⽽⾔，条件变量可以减少竞争。\n如直接使⽤mutex，除了⽣产者、消费者之间要竞争互斥量以外，消费者之间也需要竞争互斥量;\n但如果汇聚（链表）中没有数据，消费者之间竞争互斥锁是⽆意义的。\n有了条件变量机制以后，只有⽣产者完成⽣产，才会引起消费者之间的竞争。提⾼了程序效率。\n## 条件变量流程分析\n场景: 你是个⽼板，招聘了三个员⼯，但是你不是有了活才去招聘员⼯，⽽是先把员⼯招来，没有活的时候员⼯需\n要在那⾥等着，⼀旦有了活，你要去通知他们，他们要去抢活⼲，⼲完了再等待，你再有活，再通知他们\n代码如下：\n#include <stdio.h>\n#include <stdlib.h>\n#define NUM_OF_TASKS 3\n#define MAX_TASK_QUEUE 11\nchar tasklist[MAX_TASK_QUEUE]=\"ABCDEFGHIJ\";\nint head = 0;\nint tail = 0;\nint quit = 0;\npthread_mutex_t g_task_lock;\npthread_cond_t g_task_cv;\nvoid *coder(void *notused)\npthread_t tid = pthread_self();\nwhile(!quit){\npthread_mutex_lock(&g_task_lock);\nwhile(tail == head){\nif(quit){\npthread_exit((void *)0);\nint)tid);\nprintf(\"No task now! Thread %u is waiting!\\n\", (unsigned int)tid);\npthread_cond_wait(&g_task_cv, &g_task_lock);\nprintf(\"Have task now! Thread %u is grabing the task !\\n\", (unsigned\nchar task = tasklist[head++];\nprintf(\"Thread %u has a task %c now!\\n\", (unsigned int)tid, task);\nsleep(5);\nprintf(\"Thread %u finish the task %c!\\n\", (unsigned int)tid, task);\npthread_exit((void *)0);\nint main(int argc, char *argv[])\npthread_t threads[NUM_OF_TASKS];\nint rc;\nint t;\npthread_mutex_init(&g_task_lock, NULL);\npthread_cond_init(&g_task_cv, NULL);\nfor(t=0;t<NUM_OF_TASKS;t++){\nNo task now! Thread 1461831424 is waiting!\nNo task now! Thread 1453438720 is waiting!\nNo task now! Thread 1445046016 is waiting!\nI am Boss, I assigned 1 tasks, I notify all coders!\nHave task now! Thread 1453438720 is grabing the task !\nHave task now! Thread 1445046016 is grabing the task !\nNo task now! Thread 1445046016 is waiting!\n下⾯是对于每个输出的分析：\n这是主线程新建的三个⼯作线程，这时候⼯作线程都是先获得锁，判断tail==head，阻塞，cond_wait释放了锁，\n三个⼯作线程都等待信号来唤醒\n主线程增加了⼀个任务，引起了head!=tail，这时候broadcast唤醒了所有⼯作线程，之后主线程释放锁，开始睡眠\n20s\n1⼯作线程在竞争中抢到了锁，退出了while(tail==head)循环，并开始完成A任务，这时候把头加1，释放锁\nrc = pthread_create(&threads[t], NULL, coder, NULL);\nif (rc){\nprintf(\"ERROR; return code from pthread_create() is %d\\n\", rc);\nexit(-1);\nsleep(5);\nfor (t=1;t<=4;t++)\n{ pthread_mutex_lock(&g_task_lock);\ntail+=t;\nprintf(\"I am Boss, I assigned %d tasks, I notify all coders!\\n\", t);\npthread_cond_broadcast(&g_task_cv);\nsleep(20);\npthread_mutex_lock(&g_task_lock);",
    "question": "## 条件变量的优缺点",
    "answer": "相较于mutex⽽⾔，条件变量可以减少竞争。\n如直接使⽤mutex，除了⽣产者、消费者之间要竞争互斥量以外，消费者之间也需要竞争互斥量;\n但如果汇聚（链表）中没有数据，消费者之间竞争互斥锁是⽆意义的。\n有了条件变量机制以后，只有⽣产者完成⽣产，才会引起消费者之间的竞争。提⾼了程序效率。\n## 条件变量流程分析\n场景: 你是个⽼板，招聘了三个员⼯，但是你不是有了活才去招聘员⼯，⽽是先把员⼯招来，没有活的时候员⼯需\n要在那⾥等着，⼀旦有了活，你要去通知他们，他们要去抢活⼲，⼲完了再等待，你再有活，再通知他们\n代码如下：\n#include <stdio.h>\n#include <stdlib.h>\n#define NUM_OF_TASKS 3\n#define MAX_TASK_QUEUE 11\nchar tasklist[MAX_TASK_QUEUE]=\"ABCDEFGHIJ\";\nint head = 0;\nint tail = 0;\nint quit = 0;\npthread_mutex_t g_task_lock;\npthread_cond_t g_task_cv;\nvoid *coder(void *notused)\npthread_t tid = pthread_self();\nwhile(!quit){\npthread_mutex_lock(&g_task_lock);\nwhile(tail == head){\nif(quit){\npthread_exit((void *)0);\nint)tid);\nprintf(\"No task now! Thread %u is waiting!\\n\", (unsigned int)tid);\npthread_cond_wait(&g_task_cv, &g_task_lock);\nprintf(\"Have task now! Thread %u is grabing the task !\\n\", (unsigned\nchar task = tasklist[head++];\nprintf(\"Thread %u has a task %c now!\\n\", (unsigned int)tid, task);\nsleep(5);\nprintf(\"Thread %u finish the task %c!\\n\", (unsigned int)tid, task);\npthread_exit((void *)0);\nint main(int argc, char *argv[])\npthread_t threads[NUM_OF_TASKS];\nint rc;\nint t;\npthread_mutex_init(&g_task_lock, NULL);\npthread_cond_init(&g_task_cv, NULL);\nfor(t=0;t<NUM_OF_TASKS;t++){\nNo task now! Thread 1461831424 is waiting!\nNo task now! Thread 1453438720 is waiting!\nNo task now! Thread 1445046016 is waiting!\nI am Boss, I assigned 1 tasks, I notify all coders!\nHave task now! Thread 1453438720 is grabing the task !\nHave task now! Thread 1445046016 is grabing the task !\nNo task now! Thread 1445046016 is waiting!\n下⾯是对于每个输出的分析：\n这是主线程新建的三个⼯作线程，这时候⼯作线程都是先获得锁，判断tail==head，阻塞，cond_wait释放了锁，\n三个⼯作线程都等待信号来唤醒\n主线程增加了⼀个任务，引起了head!=tail，这时候broadcast唤醒了所有⼯作线程，之后主线程释放锁，开始睡眠\n20s\n1⼯作线程在竞争中抢到了锁，退出了while(tail==head)循环，并开始完成A任务，这时候把头加1，释放锁\nrc = pthread_create(&threads[t], NULL, coder, NULL);\nif (rc){\nprintf(\"ERROR; return code from pthread_create() is %d\\n\", rc);\nexit(-1);\nsleep(5);\nfor (t=1;t<=4;t++)\n{ pthread_mutex_lock(&g_task_lock);\ntail+=t;\nprintf(\"I am Boss, I assigned %d tasks, I notify all coders!\\n\", t);\npthread_cond_broadcast(&g_task_cv);\nsleep(20);\npthread_mutex_lock(&g_task_lock);",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2149,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000085",
    "content": "#define MAX_TASK_QUEUE 11\n\nchar tasklist[MAX_TASK_QUEUE]=\"ABCDEFGHIJ\";\nint head = 0;\nint tail = 0;\nint quit = 0;\npthread_mutex_t g_task_lock;\npthread_cond_t g_task_cv;\nvoid *coder(void *notused)\npthread_t tid = pthread_self();\nwhile(!quit){\npthread_mutex_lock(&g_task_lock);\nwhile(tail == head){\nif(quit){\npthread_exit((void *)0);\nint)tid);\nprintf(\"No task now! Thread %u is waiting!\\n\", (unsigned int)tid);\npthread_cond_wait(&g_task_cv, &g_task_lock);\nprintf(\"Have task now! Thread %u is grabing the task !\\n\", (unsigned\nchar task = tasklist[head++];\nprintf(\"Thread %u has a task %c now!\\n\", (unsigned int)tid, task);\nsleep(5);\nprintf(\"Thread %u finish the task %c!\\n\", (unsigned int)tid, task);\npthread_exit((void *)0);\nint main(int argc, char *argv[])\npthread_t threads[NUM_OF_TASKS];\nint rc;\nint t;\npthread_mutex_init(&g_task_lock, NULL);\npthread_cond_init(&g_task_cv, NULL);\nfor(t=0;t<NUM_OF_TASKS;t++){\nNo task now! Thread 1461831424 is waiting!\nNo task now! Thread 1453438720 is waiting!\nNo task now! Thread 1445046016 is waiting!\nI am Boss, I assigned 1 tasks, I notify all coders!\nHave task now! Thread 1453438720 is grabing the task !\nHave task now! Thread 1445046016 is grabing the task !\nNo task now! Thread 1445046016 is waiting!\n下⾯是对于每个输出的分析：\n这是主线程新建的三个⼯作线程，这时候⼯作线程都是先获得锁，判断tail==head，阻塞，cond_wait释放了锁，\n三个⼯作线程都等待信号来唤醒\n主线程增加了⼀个任务，引起了head!=tail，这时候broadcast唤醒了所有⼯作线程，之后主线程释放锁，开始睡眠\n20s\n1⼯作线程在竞争中抢到了锁，退出了while(tail==head)循环，并开始完成A任务，这时候把头加1，释放锁\nrc = pthread_create(&threads[t], NULL, coder, NULL);\nif (rc){\nprintf(\"ERROR; return code from pthread_create() is %d\\n\", rc);\nexit(-1);\nsleep(5);\nfor (t=1;t<=4;t++)\n{ pthread_mutex_lock(&g_task_lock);\ntail+=t;\nprintf(\"I am Boss, I assigned %d tasks, I notify all coders!\\n\", t);\npthread_cond_broadcast(&g_task_cv);\nsleep(20);\npthread_mutex_lock(&g_task_lock);\nquit = 1;\npthread_cond_broadcast(&g_task_cv);\npthread_mutex_destroy(&g_task_lock);\npthread_cond_destroy(&g_task_cv);\npthread_exit(NULL);\nThread 1453438720 has a task A now!\nHave task now! Thread 1461831424 is grabing the task !\nNo task now! Thread 1461831424 is waiting!\nThread 1453438720 finish the task A!\nNo task now! Thread 1453438720 is waiting!\nI am Boss, I assigned 2 tasks, I notify all coders!\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task B now!\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task C now!\nHave task now! Thread 1453438720 is grabing the task !\nNo task now! Thread 1453438720 is waiting!\nThread 1445046016 finish the task C!\nNo task now! Thread 1445046016 is waiting!\nThread 1461831424 finish the task B!\nNo task now! Thread 1461831424 is waiting!\n1⼯作线程时间⽚到了，2，3⼯作线程对锁进⾏竞争，2得到了锁，但是这时候已经没有⼯作了。while(tail==head)\n循环没有退出，因此释放锁，等待唤醒\n调度程序调度到1线程执⾏，打印了这句话，开始睡眠5s\n3⼯作线程抢到了锁（虽然这时候只有它在抢锁），3得到了锁，但是这时候已经没有⼯作了。while(tail==head)循\n环没有退出，因此释放锁，等待唤醒\n20⼯作线程执⾏完任务，这时候还是没有⼯作。先上锁，后进⼊while(tail==head)循环没有退出，因此释放锁，等\n待唤醒\n主线程醒了，⼜找了两个⼯作B,C，唤醒了所有⼯作线程去做\n20号线程抢到了锁，没任务了，就释放锁，等待唤醒\nI am Boss, I assigned 3 tasks, I notify all coders!\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task D now!\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task E now!\nHave task now! Thread 1453438720 is grabing the task !\nThread 1453438720 has a task F now!\nThread 1461831424 finish the task D!\nNo task now! Thread 1461831424 is waiting!\nThread 1445046016 finish the task E!\nNo task now! Thread 1445046016 is waiting!\nThread 1453438720 finish the task F!\nNo task now! Thread 1453438720 is waiting!\nI am Boss, I assigned 4 tasks, I notify all coders!\nHave task now! Thread 1453438720 is grabing the task !\nThread 1453438720 has a task G now!\n主线程醒了，⼜找了三个个⼯作D,E,F，唤醒了所有⼯作线程去做\n20号线程抢到了锁，执⾏头加1，释放锁，然后睡眠了\n调度20号线程执⾏，20号线程完成任务，得到锁，发现没任务，释放锁，等待唤醒\n主线程醒了，⼜找了三个个⼯作G,H,I,J，唤醒了所有⼯作线程去做\n20号线程抢到了锁，执⾏头加1，释放锁，然后睡眠了\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task I now!\nThread 1453438720 finish the task G!\nThread 1453438720 has a task J now!\nThread 1461831424 finish the task H!\nNo task now! Thread 1461831424 is waiting!\nThread 1445046016 finish the task I!\nNo task now! Thread 1445046016 is waiting!\nThread 1453438720 finish the task J!\nNo task now! Thread 1453438720 is waiting!\nHave task now! Thread 1461831424 is grabing the task !\nHave task now! Thread 1445046016 is grabing the task !\nHave task now! Thread 1453438720 is grabing the task !\n20号线程执⾏完任务，下⼀轮while中，持有了锁，发现还有任务，就继续做J，执⾏头加1，释放了锁，开始睡眠\n20线程完成任务，下⼀轮while中持有锁，发现没任务了，释放锁，等待唤醒\n主线程抢锁，设置退出标志quit为1，并通知三个⼯作线程\n三个⼯作线程分别抢到了锁，发现quit为1，就释放锁，然后终⽌各⾃的线程\n主线程销毁了锁和条件变量\n终⽌了main线程\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task H now!\n- 创建⼀个信号量并初始化它的值。⼀个⽆名信号量在被使⽤前必须先初始化.\n- @param pshared 等于 0，信号量在线程间共享（常⽤）; 不等于0，信号量在进程间共享.\n- @param value 信号量的初始值.\nint sem_init(sem_t *sem, int pshared, unsigned int value);\n- 删除 sem 标识的信号量.\nint sem_destroy(sem_t *sem);\n- 将信号量的值减 1。操作前，先检查信号量（sem）的值是否为 0;\n- 若信号量为 0，此函数会阻塞，直到信号量⼤于 0 时才进⾏减 1 操作。\nint sem wait(sem t *sem);\n信号量\n信号量⼴泛⽤于进程或线程间的同步和互斥，信号量本质上是⼀个⾮负的整数计数器，它被⽤来控制对公共资源的\n访问。\n编程时可根据操作信号量值的结果判断是否对公共资源具有访问的权限，当信号量值⼤于 0 时，则可以访问，否则\n将阻塞。\nPV 原语是对信号量的操作，⼀次 P 操作使信号量减１，⼀次 V 操作使信号量加１。\n信号量数据类型为：sem_t",
    "question": "#define MAX_TASK_QUEUE 11",
    "answer": "char tasklist[MAX_TASK_QUEUE]=\"ABCDEFGHIJ\";\nint head = 0;\nint tail = 0;\nint quit = 0;\npthread_mutex_t g_task_lock;\npthread_cond_t g_task_cv;\nvoid *coder(void *notused)\npthread_t tid = pthread_self();\nwhile(!quit){\npthread_mutex_lock(&g_task_lock);\nwhile(tail == head){\nif(quit){\npthread_exit((void *)0);\nint)tid);\nprintf(\"No task now! Thread %u is waiting!\\n\", (unsigned int)tid);\npthread_cond_wait(&g_task_cv, &g_task_lock);\nprintf(\"Have task now! Thread %u is grabing the task !\\n\", (unsigned\nchar task = tasklist[head++];\nprintf(\"Thread %u has a task %c now!\\n\", (unsigned int)tid, task);\nsleep(5);\nprintf(\"Thread %u finish the task %c!\\n\", (unsigned int)tid, task);\npthread_exit((void *)0);\nint main(int argc, char *argv[])\npthread_t threads[NUM_OF_TASKS];\nint rc;\nint t;\npthread_mutex_init(&g_task_lock, NULL);\npthread_cond_init(&g_task_cv, NULL);\nfor(t=0;t<NUM_OF_TASKS;t++){\nNo task now! Thread 1461831424 is waiting!\nNo task now! Thread 1453438720 is waiting!\nNo task now! Thread 1445046016 is waiting!\nI am Boss, I assigned 1 tasks, I notify all coders!\nHave task now! Thread 1453438720 is grabing the task !\nHave task now! Thread 1445046016 is grabing the task !\nNo task now! Thread 1445046016 is waiting!\n下⾯是对于每个输出的分析：\n这是主线程新建的三个⼯作线程，这时候⼯作线程都是先获得锁，判断tail==head，阻塞，cond_wait释放了锁，\n三个⼯作线程都等待信号来唤醒\n主线程增加了⼀个任务，引起了head!=tail，这时候broadcast唤醒了所有⼯作线程，之后主线程释放锁，开始睡眠\n20s\n1⼯作线程在竞争中抢到了锁，退出了while(tail==head)循环，并开始完成A任务，这时候把头加1，释放锁\nrc = pthread_create(&threads[t], NULL, coder, NULL);\nif (rc){\nprintf(\"ERROR; return code from pthread_create() is %d\\n\", rc);\nexit(-1);\nsleep(5);\nfor (t=1;t<=4;t++)\n{ pthread_mutex_lock(&g_task_lock);\ntail+=t;\nprintf(\"I am Boss, I assigned %d tasks, I notify all coders!\\n\", t);\npthread_cond_broadcast(&g_task_cv);\nsleep(20);\npthread_mutex_lock(&g_task_lock);\nquit = 1;\npthread_cond_broadcast(&g_task_cv);\npthread_mutex_destroy(&g_task_lock);\npthread_cond_destroy(&g_task_cv);\npthread_exit(NULL);\nThread 1453438720 has a task A now!\nHave task now! Thread 1461831424 is grabing the task !\nNo task now! Thread 1461831424 is waiting!\nThread 1453438720 finish the task A!\nNo task now! Thread 1453438720 is waiting!\nI am Boss, I assigned 2 tasks, I notify all coders!\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task B now!\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task C now!\nHave task now! Thread 1453438720 is grabing the task !\nNo task now! Thread 1453438720 is waiting!\nThread 1445046016 finish the task C!\nNo task now! Thread 1445046016 is waiting!\nThread 1461831424 finish the task B!\nNo task now! Thread 1461831424 is waiting!\n1⼯作线程时间⽚到了，2，3⼯作线程对锁进⾏竞争，2得到了锁，但是这时候已经没有⼯作了。while(tail==head)\n循环没有退出，因此释放锁，等待唤醒\n调度程序调度到1线程执⾏，打印了这句话，开始睡眠5s\n3⼯作线程抢到了锁（虽然这时候只有它在抢锁），3得到了锁，但是这时候已经没有⼯作了。while(tail==head)循\n环没有退出，因此释放锁，等待唤醒\n20⼯作线程执⾏完任务，这时候还是没有⼯作。先上锁，后进⼊while(tail==head)循环没有退出，因此释放锁，等\n待唤醒\n主线程醒了，⼜找了两个⼯作B,C，唤醒了所有⼯作线程去做\n20号线程抢到了锁，没任务了，就释放锁，等待唤醒\nI am Boss, I assigned 3 tasks, I notify all coders!\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task D now!\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task E now!\nHave task now! Thread 1453438720 is grabing the task !\nThread 1453438720 has a task F now!\nThread 1461831424 finish the task D!\nNo task now! Thread 1461831424 is waiting!\nThread 1445046016 finish the task E!\nNo task now! Thread 1445046016 is waiting!\nThread 1453438720 finish the task F!\nNo task now! Thread 1453438720 is waiting!\nI am Boss, I assigned 4 tasks, I notify all coders!\nHave task now! Thread 1453438720 is grabing the task !\nThread 1453438720 has a task G now!\n主线程醒了，⼜找了三个个⼯作D,E,F，唤醒了所有⼯作线程去做\n20号线程抢到了锁，执⾏头加1，释放锁，然后睡眠了\n调度20号线程执⾏，20号线程完成任务，得到锁，发现没任务，释放锁，等待唤醒\n主线程醒了，⼜找了三个个⼯作G,H,I,J，唤醒了所有⼯作线程去做\n20号线程抢到了锁，执⾏头加1，释放锁，然后睡眠了\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task I now!\nThread 1453438720 finish the task G!\nThread 1453438720 has a task J now!\nThread 1461831424 finish the task H!\nNo task now! Thread 1461831424 is waiting!\nThread 1445046016 finish the task I!\nNo task now! Thread 1445046016 is waiting!\nThread 1453438720 finish the task J!\nNo task now! Thread 1453438720 is waiting!\nHave task now! Thread 1461831424 is grabing the task !\nHave task now! Thread 1445046016 is grabing the task !\nHave task now! Thread 1453438720 is grabing the task !\n20号线程执⾏完任务，下⼀轮while中，持有了锁，发现还有任务，就继续做J，执⾏头加1，释放了锁，开始睡眠\n20线程完成任务，下⼀轮while中持有锁，发现没任务了，释放锁，等待唤醒\n主线程抢锁，设置退出标志quit为1，并通知三个⼯作线程\n三个⼯作线程分别抢到了锁，发现quit为1，就释放锁，然后终⽌各⾃的线程\n主线程销毁了锁和条件变量\n终⽌了main线程\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task H now!\n- 创建⼀个信号量并初始化它的值。⼀个⽆名信号量在被使⽤前必须先初始化.\n- @param pshared 等于 0，信号量在线程间共享（常⽤）; 不等于0，信号量在进程间共享.\n- @param value 信号量的初始值.\nint sem_init(sem_t *sem, int pshared, unsigned int value);\n- 删除 sem 标识的信号量.\nint sem_destroy(sem_t *sem);\n- 将信号量的值减 1。操作前，先检查信号量（sem）的值是否为 0;\n- 若信号量为 0，此函数会阻塞，直到信号量⼤于 0 时才进⾏减 1 操作。\nint sem wait(sem t *sem);\n信号量\n信号量⼴泛⽤于进程或线程间的同步和互斥，信号量本质上是⼀个⾮负的整数计数器，它被⽤来控制对公共资源的\n访问。\n编程时可根据操作信号量值的结果判断是否对公共资源具有访问的权限，当信号量值⼤于 0 时，则可以访问，否则\n将阻塞。\nPV 原语是对信号量的操作，⼀次 P 操作使信号量减１，⼀次 V 操作使信号量加１。\n信号量数据类型为：sem_t",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 5163,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000086",
    "content": "quit = 1;\n\npthread_cond_broadcast(&g_task_cv);\npthread_mutex_destroy(&g_task_lock);\npthread_cond_destroy(&g_task_cv);\npthread_exit(NULL);\nThread 1453438720 has a task A now!\nHave task now! Thread 1461831424 is grabing the task !\nNo task now! Thread 1461831424 is waiting!\nThread 1453438720 finish the task A!\nNo task now! Thread 1453438720 is waiting!\nI am Boss, I assigned 2 tasks, I notify all coders!\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task B now!\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task C now!\nHave task now! Thread 1453438720 is grabing the task !\nNo task now! Thread 1453438720 is waiting!\nThread 1445046016 finish the task C!\nNo task now! Thread 1445046016 is waiting!\nThread 1461831424 finish the task B!\nNo task now! Thread 1461831424 is waiting!\n1⼯作线程时间⽚到了，2，3⼯作线程对锁进⾏竞争，2得到了锁，但是这时候已经没有⼯作了。while(tail==head)\n循环没有退出，因此释放锁，等待唤醒\n调度程序调度到1线程执⾏，打印了这句话，开始睡眠5s\n3⼯作线程抢到了锁（虽然这时候只有它在抢锁），3得到了锁，但是这时候已经没有⼯作了。while(tail==head)循\n环没有退出，因此释放锁，等待唤醒\n20⼯作线程执⾏完任务，这时候还是没有⼯作。先上锁，后进⼊while(tail==head)循环没有退出，因此释放锁，等\n待唤醒\n主线程醒了，⼜找了两个⼯作B,C，唤醒了所有⼯作线程去做\n20号线程抢到了锁，没任务了，就释放锁，等待唤醒\nI am Boss, I assigned 3 tasks, I notify all coders!\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task D now!\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task E now!\nHave task now! Thread 1453438720 is grabing the task !\nThread 1453438720 has a task F now!\nThread 1461831424 finish the task D!\nNo task now! Thread 1461831424 is waiting!\nThread 1445046016 finish the task E!\nNo task now! Thread 1445046016 is waiting!\nThread 1453438720 finish the task F!\nNo task now! Thread 1453438720 is waiting!\nI am Boss, I assigned 4 tasks, I notify all coders!\nHave task now! Thread 1453438720 is grabing the task !\nThread 1453438720 has a task G now!\n主线程醒了，⼜找了三个个⼯作D,E,F，唤醒了所有⼯作线程去做\n20号线程抢到了锁，执⾏头加1，释放锁，然后睡眠了\n调度20号线程执⾏，20号线程完成任务，得到锁，发现没任务，释放锁，等待唤醒\n主线程醒了，⼜找了三个个⼯作G,H,I,J，唤醒了所有⼯作线程去做\n20号线程抢到了锁，执⾏头加1，释放锁，然后睡眠了\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task I now!\nThread 1453438720 finish the task G!\nThread 1453438720 has a task J now!\nThread 1461831424 finish the task H!\nNo task now! Thread 1461831424 is waiting!\nThread 1445046016 finish the task I!\nNo task now! Thread 1445046016 is waiting!\nThread 1453438720 finish the task J!\nNo task now! Thread 1453438720 is waiting!\nHave task now! Thread 1461831424 is grabing the task !\nHave task now! Thread 1445046016 is grabing the task !\nHave task now! Thread 1453438720 is grabing the task !\n20号线程执⾏完任务，下⼀轮while中，持有了锁，发现还有任务，就继续做J，执⾏头加1，释放了锁，开始睡眠\n20线程完成任务，下⼀轮while中持有锁，发现没任务了，释放锁，等待唤醒\n主线程抢锁，设置退出标志quit为1，并通知三个⼯作线程\n三个⼯作线程分别抢到了锁，发现quit为1，就释放锁，然后终⽌各⾃的线程\n主线程销毁了锁和条件变量\n终⽌了main线程\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task H now!\n- 创建⼀个信号量并初始化它的值。⼀个⽆名信号量在被使⽤前必须先初始化.\n- @param pshared 等于 0，信号量在线程间共享（常⽤）; 不等于0，信号量在进程间共享.\n- @param value 信号量的初始值.\nint sem_init(sem_t *sem, int pshared, unsigned int value);\n- 删除 sem 标识的信号量.\nint sem_destroy(sem_t *sem);\n- 将信号量的值减 1。操作前，先检查信号量（sem）的值是否为 0;\n- 若信号量为 0，此函数会阻塞，直到信号量⼤于 0 时才进⾏减 1 操作。\nint sem wait(sem t *sem);\n信号量\n信号量⼴泛⽤于进程或线程间的同步和互斥，信号量本质上是⼀个⾮负的整数计数器，它被⽤来控制对公共资源的\n访问。\n编程时可根据操作信号量值的结果判断是否对公共资源具有访问的权限，当信号量值⼤于 0 时，则可以访问，否则\n将阻塞。\nPV 原语是对信号量的操作，⼀次 P 操作使信号量减１，⼀次 V 操作使信号量加１。\n信号量数据类型为：sem_t\n## 创建信号量\nsem_init()\n## 删除信号量\nsem_destroy()\n## P操作\nsem_wait()(P操作)\n- 将信号量的值加 1 并发出信号唤醒等待线程(sem_wait()).\nint sem_post(sem_t *sem);\n- 获取 sem 标识的信号量的值，保存在 sval 中.\n- @param sval 保存信号量值的地址.\nint sem_getvalue(sem_t *sem, int *sval);\\\n## V操作\nsem_post()(V操作)\n## 获取信号量的值\nsem_getvalue()\n使⽤信号量机制实现的⽣产者消费者问题需要客户端代码做很多控制，\n⽽管程把控制的代码独⽴出来，不仅不容易出错，也使得客户端代码调⽤更容易。\n下⾯是经典的IPC问题\n## 哲学家进餐问题\n下⾯是⼀种错误的解法，如果所有哲学家同时拿起左⼿边的筷⼦，那么所有哲学家都在等待其它哲学家吃完并释放\n⾃⼰⼿中的筷⼦，导致死锁。\n- 以⾮阻塞的⽅式来对信号量进⾏减 1 操作。\n- 若操作前，信号量的值等于 0，则对信号量的操作失败，函数⽴即返回。\nint sem trywait(sem t *sem);\n- 限时尝试将信号量的值减 1\n- abs_timeout：绝对时间\nint sem timedwait(sem t *sem, const struct timespec *abs timeout);\n#define N 5\n#define LEFT (i + N - 1) % N // 左邻居\n#define RIGHT (i + 1) % N\n// 右邻居\n#define THINKING 0\n#define HUNGRY  1\n#define EATING  2\ntypedef int semaphore;\nint state[N];\nsemaphore mutex = 1;\nsemaphore s[N];\n// 跟踪每个哲学家的状态\n// 临界区的互斥，临界区是 state 数组，对其修改需要互斥\n// 每个哲学家⼀个信号量\nvoid philosopher(int i) {\nwhile(TRUE) {\nthink(i);\ntake_two(i);\neat(i);\nput_two(i);\nvoid take_two(int i) {\nstate[i] = HUNGRY;\ncheck(i);\ndown(&s[i]); // 只有收到通知之后才可以开始吃，否则会⼀直等下去\nvoid put_two(i) {\nstate[i] = THINKING;\n为了防⽌死锁的发⽣，可以设置两个条件：\n## 必须同时拿起左右两根筷⼦\n## 只有在两个邻居都没有进餐的情况下才允许进餐\n#define N 5\nvoid philosopher(int i) {\nwhile(TRUE) {\nthink();\ntake(i); // 拿起左边的筷⼦\ntake((i+1)%N); // 拿起右边的筷⼦\neat();\nput(i);\nput((i+1)%N);\ntypedef int semaphore;\nsemaphore count_mutex = 1;\nsemaphore data_mutex = 1;\nint count = 0;\nvoid reader()\n{ while(TRUE) {\ndown(&count_mutex);\ncount++;\nif(count == 1) down(&data_mutex); // 第⼀个读者需要对数据进⾏加锁，防⽌写进程访问\nup(&count_mutex);\nread();\ndown(&count_mutex);\ncount--;\nif(count == 0) up(&data_mutex);\nup(&count_mutex);\nvoid writer()\n{ while(TRUE) {\ndown(&data_mutex);\nwrite();\nup(&data_mutex);\n## 读者-写者问题\n允许多个进程同时对数据进⾏读操作，但是不允许读和写以及写和写操作同时发⽣。\n⼀个整型变量 count 记录在对数据进⾏读操作的进程数量，⼀个互斥量 count_mutex ⽤于对 count 加锁，⼀个互\n斥量 data_mutex ⽤于对读写的数据加锁。\ncheck(LEFT); // 尝试通知左右邻居，⾃⼰吃完了，你们可以开始吃了\ncheck(RIGHT);\nvoid eat(int i) {\nstate[i] = EATING;\n// 检查两个邻居是否都没有⽤餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执⾏\nvoid check(i) {\nif(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING)\n{ state[i] = EATING;\nup(&s[i]);\n存储系统\n存储系统层级\n## 存储器的层次结构\n（1） 寄存器\n寄存器的访问速度⾮常快，⼀般要求在半个 CPU 时钟周期内完成读写，CPU 时钟周期跟 CPU 主频息息相关，⽐如\n2 GHz 主频的 CPU，那么它的时钟周期就是 1/2G，也就是 0.5ns（纳秒）。\n（2） CPU Cache（⽤的是⼀种叫 SRAM（Static Random-Access Memory，静态随机存储器）的芯⽚）\nSRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，⽽⼀旦断电，数据就会丢失了。\nCPU Cache 通常分为三层，如下图所示：\n查看各级Cache的⼤⼩：\n（3） 内存\n内存⽤的芯⽚和 CPU Cache 有所不同，它使⽤的是⼀种叫作 DRAM （Dynamic Random Access Memory，动态\n随机存取存储器） 的芯⽚。相⽐ SRAM，DRAM 的密度更⾼，功耗更低，有更⼤的容量，⽽且造价⽐ SRAM 芯⽚\n便宜很多。\nDRAM 存储⼀个 bit 数据，只需要⼀个晶体管和⼀个电容就能存储，但是因为数据会被存储在电容⾥，电容会不断\n漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原\n因，只有不断刷新，数据才能被存储起来。\nDRAM 的数据访问电路和刷新电路都⽐ SRAM 更复杂，所以访问的速度会更慢，内存速度⼤概在 200~300 个 时钟\n周期之间。\n（4） SSD/HDD硬盘:\nSSD（Solid-state disk） 就是我们常说的固体硬盘，结构和内存类似，但是它相⽐内存的优点是断电后数据还是存\n在的，⽽内存、寄存器、⾼速缓存断电后数据都会丢失。内存的读写速度⽐ SSD ⼤概快 10~1000 倍。\n机械硬盘（Hard Disk Drive, HDD），它是通过物理读写的⽅式来访问 数据的，因此它访问速度是⾮常慢的，它的\n速度⽐内存慢 10W 倍左右。\n## 存储器的层次关系\nCPU  并不会直接和每⼀种存储器设备直接打交道，⽽是每⼀种存储器设备只和它相邻的存储器设备打交道。\n所以，每个存储器只和相邻的⼀层存储器设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也\n是更⾼，也正因为成本太⾼，所以 CPU 内部的寄存器、L1\\L2\\L3 Cache 只好⽤较⼩的容量，相反内存、硬盘则可\n⽤更⼤的容量，这就我们今天所说的存储器层次结构。\n## 存储器之间的实际价格和性能差距\n不同层级的存储器之间的成本对⽐图：\n机械硬盘（HDD)到底有多慢：\n虚拟内存\n虚拟内存是计算机操作系统中的⼀种内存管理技术，它允许程序访问⽐物理内存（RAM）更⼤的地址空间，但⾸先\n我们要区分这两个概念：\n虚拟内存地址：程序所使⽤的内存地址\n物理内存地址：实际存在硬件⾥⾯的空间地址\n操作系统会提供⼀种机制，在物理内存和虚拟内存之间建⽴⼀个地址映射表，进程持有的虚拟地址会通过 CPU 芯\n⽚中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存\n操作系统主要通过内存分段和内存分⻚来管理虚拟内存和物理内存之间的关系。\n内存分段\n内存分段将物理内存划分成不同的逻辑段或区域，每个段⽤于存储特定类型的数据或执⾏特定类型的任务。每个段\n具有不同的⼤⼩和属性。常⻅的段包括代码段（存储程序执⾏代码）、数据段（存储程序数据）、堆栈段（存储函\n数调⽤和局部变量），以及其他⾃定义段，如共享库段等。\n分段机制下的虚拟地址由两部分组成，段选择因⼦和段内偏移量，⽽虚拟地址是通过段表与物理地址进⾏映射的。\n段选择因⼦中的段号与段表对应，作为段表的索引。段表⾥⾯保存的是这个段的基地址、段的界限和特权等级等。\n虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到\n物理内存地址。\n内存碎⽚\n内存碎⽚是指内存中的空闲空间被分割成多个不连续的⼩块，⽽不是⼀个连续的⼤块。这些⼩块空闲内存可能分布\n在整个内存地址空间中，导致内存资源的不充分利⽤。\n外部碎⽚：虽然整体内存容量⾜够，但⽆法为较⼤的内存请求分配连续的内存块，因为已分配的内存块分散在内存\n中，它们之间的未分配空间太⼩。\n内部碎⽚：有时分配的内存块⼤于进程实际需要的内存量，这意味着有⼀些内存浪费在内部碎⽚中。\n内存分段\n内存分⻚\n⻚⾯置换算法\n## 最佳⻚⾯置换算法(OPT)\n置换在「未来」最⻓时间不访问的⻚⾯,但是实际系统中⽆法实现，因为程序访问⻚⾯时是动态的\n我们是⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间，因此作为实际算法效率衡量标准。   2、\n先进先出置换算法(FIFO)\n顾名思义，将⻚⾯以队列形式保存，先进⼊队列的⻚⾯先被置换进⼊磁盘。\n## 最近最久未使⽤的置换算法（LRU）\n根据⻚⾯未被访问时⻓⽤升序列表将⻚⾯排列，每次将最久未被使⽤⻚⾯置换出去。\n## 时钟⻚⾯置换算法\n把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⻚⾯包含⼀个访问位。\n当发⽣缺⻚中断时，顺时针遍历⻚⾯，如果访问位为1，将其改为0，继续遍历，直到访问到访问位为0⻚⾯，进⾏\n置换。\n## 最不常⽤算法\n记录每个⻚⾯访问次数，当发⽣缺⻚中断时候，将访问次数最少的⻚⾯置换出去，此⽅法需要对每个⻚⾯访问次数\n统计，额外开销。\n虚拟内存采⽤的是分⻚技术，也就是将地址空间划分成固定⼤⼩的⻚，每⼀⻚再与内存进⾏映射。\n如果使⽤分⻚系统的⼀维地址空间，动态增⻓的特点会导致覆盖问题的出现。\n分段的做法是把每个表分成段，⼀个段构成⼀个独⽴的地址空间。\n每个段的⻓度可以不同，并且可以动态增⻓。\n## 纯分段\n分段和分⻚本质上是不同的，⻚⾯是定⻓的⽽段不是。\n(1) 共享：有助于⼏个进程之间共享过程和数据。  ⽐如共享库\n(2) 保护：每个段都可以独⽴地增⼤或减⼩⽽不会影响其他的段\n## 分段和分⻚结合\n程序的地址空间划分成多个拥有独⽴地址空间的段，每个段上的地址空间划分成⼤⼩相同的⻚。\n这样既拥有分段系统的共享和保护，⼜拥有分⻚系统的虚拟内存功能.\n## 分段与分⻚的⽐较\n对程序员的透明性：\n分⻚透明，但是分段需要程序员显式划分每个段。\n地址空间的维度：\n分⻚是⼀维地址空间，分段是⼆维的。\n⼤⼩是否可以改变：\n⻚的⼤⼩不可变，段的⼤⼩可以动态改变。\n出现的原因：\n分⻚主要⽤于实现虚拟内存，从⽽获得更⼤的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独⽴的\n地址空间并且有助于共享和保护。\n虚拟内存\n属于计算机系统内存管理的⼀种技术，虚拟地址空间构成虚拟内存，它使得应⽤程序认为⾃⼰拥有连续的可⽤内存\n空间，但实际上是被分隔的多个物理内存⻚、以及部分暂时存储在磁盘上的交换分区所构成的。虚拟内存的实现通\n过硬件异常、硬件地址翻译、主存、磁盘以及内核软件共同完成\n## 地址空间：\n地址空间是物理内存的抽象，是⼀个进程可⽤于寻址内存的⼀套地址集合。\n## 分⻚：\n地址空间被分割成多个块，每⼀块称作⼀⻚或⻚⾯(Page)。每⼀⻚有连续的地址范围，这些⻚被映射到连续的物理\n内存(⻚框)。\n## ⻚表：\n⻚表的⽬的是把虚拟⻚⾯(虚拟地址)映射为⻚框(物理地址)。⻚表给出了虚拟地址与物理地址的映射关系。从数学的\n⻆度说⻚表是⼀个函数，他的参数是虚拟⻚号，结果是物理⻚⻚框号\n## 加速分⻚：\n（1） TLB加速分⻚\n概念：将虚拟地址直接映射到物理地址，⽽不必再访问⻚表，这种设备被称为转换检测缓冲区（TLB）、相联存储\n器或快表\n⼯作过程：将⼀个虚拟地址放⼊MMU中进⾏转换时，硬件⾸先通过将该虚拟⻚号与TLB中所有表项同时进⾏匹配，\n判断虚拟⻚⾯是否在其中：\n## 虚拟⻚号在TLB中。如果MMU检测⼀个有效的匹配并且访问操作并不违反保护位，则将⻚框号直接从TLB中取\n出⽽不必访问⻚表。\n## 虚拟⻚号不在TLB中。如果MMU检测到没有有效的匹配项就会进⾏正常的⻚表查询。接着从TLB中淘汰⼀个表\n项，然后⽤新的⻚表项替换它。\n（2） 软件TLB管理\n## 针对⼤内存的⻚表\n（1） 多级⻚表\n（2） 倒排⻚表\n三个重要的能⼒：\n## ⾼速缓存\n按照存储器层次结构中的缓存划分来看，将位于k层的更⼩更快的存储设备作为存储在k+1层的更⼤更慢的存储设备\n的缓存。具体如下：\n在虚拟内存中的虚拟⻚共分为三种类型：\n## 未分配（没有被进程申请使⽤的，也就是空闲的虚拟内存，  不占⽤虚拟内存磁盘的任何空间）\n## 未缓存（仅仅加载到磁盘中的⻚）\n## 已缓存（已经加载到内存中的内存⻚（⻚框））\n## 内存管理\n## 内存保护\n现代操作系统中，⽤户进程不应该被允许修改它的只读代码段;\n⽽且也不应该允许它读取或修改任何内核中的代码和数据结构;\n并且也不允许其读取或者修改其他进程的私有内存，以及修改和其他进程共享的虚拟⻚⾯。\n如果不对进程的内存访问进⾏限制，攻击者就能够访问和修改其他进程的私有内存，进⽽导致整个系统崩溃。⼤体\n的虚拟寻址如下：\n通过MMU，每次都会读取⻚表中的⼀个⻚表条⽬(PTE)，通过在这些⻚表条⽬(PTE)中添加⼀些标志位，就能够实现\n对⼀个虚拟⻚的访问控制权限。譬如：",
    "question": "quit = 1;",
    "answer": "pthread_cond_broadcast(&g_task_cv);\npthread_mutex_destroy(&g_task_lock);\npthread_cond_destroy(&g_task_cv);\npthread_exit(NULL);\nThread 1453438720 has a task A now!\nHave task now! Thread 1461831424 is grabing the task !\nNo task now! Thread 1461831424 is waiting!\nThread 1453438720 finish the task A!\nNo task now! Thread 1453438720 is waiting!\nI am Boss, I assigned 2 tasks, I notify all coders!\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task B now!\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task C now!\nHave task now! Thread 1453438720 is grabing the task !\nNo task now! Thread 1453438720 is waiting!\nThread 1445046016 finish the task C!\nNo task now! Thread 1445046016 is waiting!\nThread 1461831424 finish the task B!\nNo task now! Thread 1461831424 is waiting!\n1⼯作线程时间⽚到了，2，3⼯作线程对锁进⾏竞争，2得到了锁，但是这时候已经没有⼯作了。while(tail==head)\n循环没有退出，因此释放锁，等待唤醒\n调度程序调度到1线程执⾏，打印了这句话，开始睡眠5s\n3⼯作线程抢到了锁（虽然这时候只有它在抢锁），3得到了锁，但是这时候已经没有⼯作了。while(tail==head)循\n环没有退出，因此释放锁，等待唤醒\n20⼯作线程执⾏完任务，这时候还是没有⼯作。先上锁，后进⼊while(tail==head)循环没有退出，因此释放锁，等\n待唤醒\n主线程醒了，⼜找了两个⼯作B,C，唤醒了所有⼯作线程去做\n20号线程抢到了锁，没任务了，就释放锁，等待唤醒\nI am Boss, I assigned 3 tasks, I notify all coders!\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task D now!\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task E now!\nHave task now! Thread 1453438720 is grabing the task !\nThread 1453438720 has a task F now!\nThread 1461831424 finish the task D!\nNo task now! Thread 1461831424 is waiting!\nThread 1445046016 finish the task E!\nNo task now! Thread 1445046016 is waiting!\nThread 1453438720 finish the task F!\nNo task now! Thread 1453438720 is waiting!\nI am Boss, I assigned 4 tasks, I notify all coders!\nHave task now! Thread 1453438720 is grabing the task !\nThread 1453438720 has a task G now!\n主线程醒了，⼜找了三个个⼯作D,E,F，唤醒了所有⼯作线程去做\n20号线程抢到了锁，执⾏头加1，释放锁，然后睡眠了\n调度20号线程执⾏，20号线程完成任务，得到锁，发现没任务，释放锁，等待唤醒\n主线程醒了，⼜找了三个个⼯作G,H,I,J，唤醒了所有⼯作线程去做\n20号线程抢到了锁，执⾏头加1，释放锁，然后睡眠了\nHave task now! Thread 1445046016 is grabing the task !\nThread 1445046016 has a task I now!\nThread 1453438720 finish the task G!\nThread 1453438720 has a task J now!\nThread 1461831424 finish the task H!\nNo task now! Thread 1461831424 is waiting!\nThread 1445046016 finish the task I!\nNo task now! Thread 1445046016 is waiting!\nThread 1453438720 finish the task J!\nNo task now! Thread 1453438720 is waiting!\nHave task now! Thread 1461831424 is grabing the task !\nHave task now! Thread 1445046016 is grabing the task !\nHave task now! Thread 1453438720 is grabing the task !\n20号线程执⾏完任务，下⼀轮while中，持有了锁，发现还有任务，就继续做J，执⾏头加1，释放了锁，开始睡眠\n20线程完成任务，下⼀轮while中持有锁，发现没任务了，释放锁，等待唤醒\n主线程抢锁，设置退出标志quit为1，并通知三个⼯作线程\n三个⼯作线程分别抢到了锁，发现quit为1，就释放锁，然后终⽌各⾃的线程\n主线程销毁了锁和条件变量\n终⽌了main线程\nHave task now! Thread 1461831424 is grabing the task !\nThread 1461831424 has a task H now!\n- 创建⼀个信号量并初始化它的值。⼀个⽆名信号量在被使⽤前必须先初始化.\n- @param pshared 等于 0，信号量在线程间共享（常⽤）; 不等于0，信号量在进程间共享.\n- @param value 信号量的初始值.\nint sem_init(sem_t *sem, int pshared, unsigned int value);\n- 删除 sem 标识的信号量.\nint sem_destroy(sem_t *sem);\n- 将信号量的值减 1。操作前，先检查信号量（sem）的值是否为 0;\n- 若信号量为 0，此函数会阻塞，直到信号量⼤于 0 时才进⾏减 1 操作。\nint sem wait(sem t *sem);\n信号量\n信号量⼴泛⽤于进程或线程间的同步和互斥，信号量本质上是⼀个⾮负的整数计数器，它被⽤来控制对公共资源的\n访问。\n编程时可根据操作信号量值的结果判断是否对公共资源具有访问的权限，当信号量值⼤于 0 时，则可以访问，否则\n将阻塞。\nPV 原语是对信号量的操作，⼀次 P 操作使信号量减１，⼀次 V 操作使信号量加１。\n信号量数据类型为：sem_t\n## 创建信号量\nsem_init()\n## 删除信号量\nsem_destroy()\n## P操作\nsem_wait()(P操作)\n- 将信号量的值加 1 并发出信号唤醒等待线程(sem_wait()).\nint sem_post(sem_t *sem);\n- 获取 sem 标识的信号量的值，保存在 sval 中.\n- @param sval 保存信号量值的地址.\nint sem_getvalue(sem_t *sem, int *sval);\\\n## V操作\nsem_post()(V操作)\n## 获取信号量的值\nsem_getvalue()\n使⽤信号量机制实现的⽣产者消费者问题需要客户端代码做很多控制，\n⽽管程把控制的代码独⽴出来，不仅不容易出错，也使得客户端代码调⽤更容易。\n下⾯是经典的IPC问题\n## 哲学家进餐问题\n下⾯是⼀种错误的解法，如果所有哲学家同时拿起左⼿边的筷⼦，那么所有哲学家都在等待其它哲学家吃完并释放\n⾃⼰⼿中的筷⼦，导致死锁。\n- 以⾮阻塞的⽅式来对信号量进⾏减 1 操作。\n- 若操作前，信号量的值等于 0，则对信号量的操作失败，函数⽴即返回。\nint sem trywait(sem t *sem);\n- 限时尝试将信号量的值减 1\n- abs_timeout：绝对时间\nint sem timedwait(sem t *sem, const struct timespec *abs timeout);\n#define N 5\n#define LEFT (i + N - 1) % N // 左邻居\n#define RIGHT (i + 1) % N\n// 右邻居\n#define THINKING 0\n#define HUNGRY  1\n#define EATING  2\ntypedef int semaphore;\nint state[N];\nsemaphore mutex = 1;\nsemaphore s[N];\n// 跟踪每个哲学家的状态\n// 临界区的互斥，临界区是 state 数组，对其修改需要互斥\n// 每个哲学家⼀个信号量\nvoid philosopher(int i) {\nwhile(TRUE) {\nthink(i);\ntake_two(i);\neat(i);\nput_two(i);\nvoid take_two(int i) {\nstate[i] = HUNGRY;\ncheck(i);\ndown(&s[i]); // 只有收到通知之后才可以开始吃，否则会⼀直等下去\nvoid put_two(i) {\nstate[i] = THINKING;\n为了防⽌死锁的发⽣，可以设置两个条件：\n## 必须同时拿起左右两根筷⼦\n## 只有在两个邻居都没有进餐的情况下才允许进餐\n#define N 5\nvoid philosopher(int i) {\nwhile(TRUE) {\nthink();\ntake(i); // 拿起左边的筷⼦\ntake((i+1)%N); // 拿起右边的筷⼦\neat();\nput(i);\nput((i+1)%N);\ntypedef int semaphore;\nsemaphore count_mutex = 1;\nsemaphore data_mutex = 1;\nint count = 0;\nvoid reader()\n{ while(TRUE) {\ndown(&count_mutex);\ncount++;\nif(count == 1) down(&data_mutex); // 第⼀个读者需要对数据进⾏加锁，防⽌写进程访问\nup(&count_mutex);\nread();\ndown(&count_mutex);\ncount--;\nif(count == 0) up(&data_mutex);\nup(&count_mutex);\nvoid writer()\n{ while(TRUE) {\ndown(&data_mutex);\nwrite();\nup(&data_mutex);\n## 读者-写者问题\n允许多个进程同时对数据进⾏读操作，但是不允许读和写以及写和写操作同时发⽣。\n⼀个整型变量 count 记录在对数据进⾏读操作的进程数量，⼀个互斥量 count_mutex ⽤于对 count 加锁，⼀个互\n斥量 data_mutex ⽤于对读写的数据加锁。\ncheck(LEFT); // 尝试通知左右邻居，⾃⼰吃完了，你们可以开始吃了\ncheck(RIGHT);\nvoid eat(int i) {\nstate[i] = EATING;\n// 检查两个邻居是否都没有⽤餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执⾏\nvoid check(i) {\nif(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING)\n{ state[i] = EATING;\nup(&s[i]);\n存储系统\n存储系统层级\n## 存储器的层次结构\n（1） 寄存器\n寄存器的访问速度⾮常快，⼀般要求在半个 CPU 时钟周期内完成读写，CPU 时钟周期跟 CPU 主频息息相关，⽐如\n2 GHz 主频的 CPU，那么它的时钟周期就是 1/2G，也就是 0.5ns（纳秒）。\n（2） CPU Cache（⽤的是⼀种叫 SRAM（Static Random-Access Memory，静态随机存储器）的芯⽚）\nSRAM 之所以叫「静态」存储器，是因为只要有电，数据就可以保持存在，⽽⼀旦断电，数据就会丢失了。\nCPU Cache 通常分为三层，如下图所示：\n查看各级Cache的⼤⼩：\n（3） 内存\n内存⽤的芯⽚和 CPU Cache 有所不同，它使⽤的是⼀种叫作 DRAM （Dynamic Random Access Memory，动态\n随机存取存储器） 的芯⽚。相⽐ SRAM，DRAM 的密度更⾼，功耗更低，有更⼤的容量，⽽且造价⽐ SRAM 芯⽚\n便宜很多。\nDRAM 存储⼀个 bit 数据，只需要⼀个晶体管和⼀个电容就能存储，但是因为数据会被存储在电容⾥，电容会不断\n漏电，所以需要「定时刷新」电容，才能保证数据不会被丢失，这就是 DRAM 之所以被称为「动态」存储器的原\n因，只有不断刷新，数据才能被存储起来。\nDRAM 的数据访问电路和刷新电路都⽐ SRAM 更复杂，所以访问的速度会更慢，内存速度⼤概在 200~300 个 时钟\n周期之间。\n（4） SSD/HDD硬盘:\nSSD（Solid-state disk） 就是我们常说的固体硬盘，结构和内存类似，但是它相⽐内存的优点是断电后数据还是存\n在的，⽽内存、寄存器、⾼速缓存断电后数据都会丢失。内存的读写速度⽐ SSD ⼤概快 10~1000 倍。\n机械硬盘（Hard Disk Drive, HDD），它是通过物理读写的⽅式来访问 数据的，因此它访问速度是⾮常慢的，它的\n速度⽐内存慢 10W 倍左右。\n## 存储器的层次关系\nCPU  并不会直接和每⼀种存储器设备直接打交道，⽽是每⼀种存储器设备只和它相邻的存储器设备打交道。\n所以，每个存储器只和相邻的⼀层存储器设备打交道，并且存储设备为了追求更快的速度，所需的材料成本必然也\n是更⾼，也正因为成本太⾼，所以 CPU 内部的寄存器、L1\\L2\\L3 Cache 只好⽤较⼩的容量，相反内存、硬盘则可\n⽤更⼤的容量，这就我们今天所说的存储器层次结构。\n## 存储器之间的实际价格和性能差距\n不同层级的存储器之间的成本对⽐图：\n机械硬盘（HDD)到底有多慢：\n虚拟内存\n虚拟内存是计算机操作系统中的⼀种内存管理技术，它允许程序访问⽐物理内存（RAM）更⼤的地址空间，但⾸先\n我们要区分这两个概念：\n虚拟内存地址：程序所使⽤的内存地址\n物理内存地址：实际存在硬件⾥⾯的空间地址\n操作系统会提供⼀种机制，在物理内存和虚拟内存之间建⽴⼀个地址映射表，进程持有的虚拟地址会通过 CPU 芯\n⽚中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存\n操作系统主要通过内存分段和内存分⻚来管理虚拟内存和物理内存之间的关系。\n内存分段\n内存分段将物理内存划分成不同的逻辑段或区域，每个段⽤于存储特定类型的数据或执⾏特定类型的任务。每个段\n具有不同的⼤⼩和属性。常⻅的段包括代码段（存储程序执⾏代码）、数据段（存储程序数据）、堆栈段（存储函\n数调⽤和局部变量），以及其他⾃定义段，如共享库段等。\n分段机制下的虚拟地址由两部分组成，段选择因⼦和段内偏移量，⽽虚拟地址是通过段表与物理地址进⾏映射的。\n段选择因⼦中的段号与段表对应，作为段表的索引。段表⾥⾯保存的是这个段的基地址、段的界限和特权等级等。\n虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到\n物理内存地址。\n内存碎⽚\n内存碎⽚是指内存中的空闲空间被分割成多个不连续的⼩块，⽽不是⼀个连续的⼤块。这些⼩块空闲内存可能分布\n在整个内存地址空间中，导致内存资源的不充分利⽤。\n外部碎⽚：虽然整体内存容量⾜够，但⽆法为较⼤的内存请求分配连续的内存块，因为已分配的内存块分散在内存\n中，它们之间的未分配空间太⼩。\n内部碎⽚：有时分配的内存块⼤于进程实际需要的内存量，这意味着有⼀些内存浪费在内部碎⽚中。\n内存分段\n内存分⻚\n⻚⾯置换算法\n## 最佳⻚⾯置换算法(OPT)\n置换在「未来」最⻓时间不访问的⻚⾯,但是实际系统中⽆法实现，因为程序访问⻚⾯时是动态的\n我们是⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间，因此作为实际算法效率衡量标准。   2、\n先进先出置换算法(FIFO)\n顾名思义，将⻚⾯以队列形式保存，先进⼊队列的⻚⾯先被置换进⼊磁盘。\n## 最近最久未使⽤的置换算法（LRU）\n根据⻚⾯未被访问时⻓⽤升序列表将⻚⾯排列，每次将最久未被使⽤⻚⾯置换出去。\n## 时钟⻚⾯置换算法\n把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⻚⾯包含⼀个访问位。\n当发⽣缺⻚中断时，顺时针遍历⻚⾯，如果访问位为1，将其改为0，继续遍历，直到访问到访问位为0⻚⾯，进⾏\n置换。\n## 最不常⽤算法\n记录每个⻚⾯访问次数，当发⽣缺⻚中断时候，将访问次数最少的⻚⾯置换出去，此⽅法需要对每个⻚⾯访问次数\n统计，额外开销。\n虚拟内存采⽤的是分⻚技术，也就是将地址空间划分成固定⼤⼩的⻚，每⼀⻚再与内存进⾏映射。\n如果使⽤分⻚系统的⼀维地址空间，动态增⻓的特点会导致覆盖问题的出现。\n分段的做法是把每个表分成段，⼀个段构成⼀个独⽴的地址空间。\n每个段的⻓度可以不同，并且可以动态增⻓。\n## 纯分段\n分段和分⻚本质上是不同的，⻚⾯是定⻓的⽽段不是。\n(1) 共享：有助于⼏个进程之间共享过程和数据。  ⽐如共享库\n(2) 保护：每个段都可以独⽴地增⼤或减⼩⽽不会影响其他的段\n## 分段和分⻚结合\n程序的地址空间划分成多个拥有独⽴地址空间的段，每个段上的地址空间划分成⼤⼩相同的⻚。\n这样既拥有分段系统的共享和保护，⼜拥有分⻚系统的虚拟内存功能.\n## 分段与分⻚的⽐较\n对程序员的透明性：\n分⻚透明，但是分段需要程序员显式划分每个段。\n地址空间的维度：\n分⻚是⼀维地址空间，分段是⼆维的。\n⼤⼩是否可以改变：\n⻚的⼤⼩不可变，段的⼤⼩可以动态改变。\n出现的原因：\n分⻚主要⽤于实现虚拟内存，从⽽获得更⼤的地址空间；分段主要是为了使程序和数据可以被划分为逻辑上独⽴的\n地址空间并且有助于共享和保护。\n虚拟内存\n属于计算机系统内存管理的⼀种技术，虚拟地址空间构成虚拟内存，它使得应⽤程序认为⾃⼰拥有连续的可⽤内存\n空间，但实际上是被分隔的多个物理内存⻚、以及部分暂时存储在磁盘上的交换分区所构成的。虚拟内存的实现通\n过硬件异常、硬件地址翻译、主存、磁盘以及内核软件共同完成\n## 地址空间：\n地址空间是物理内存的抽象，是⼀个进程可⽤于寻址内存的⼀套地址集合。\n## 分⻚：\n地址空间被分割成多个块，每⼀块称作⼀⻚或⻚⾯(Page)。每⼀⻚有连续的地址范围，这些⻚被映射到连续的物理\n内存(⻚框)。\n## ⻚表：\n⻚表的⽬的是把虚拟⻚⾯(虚拟地址)映射为⻚框(物理地址)。⻚表给出了虚拟地址与物理地址的映射关系。从数学的\n⻆度说⻚表是⼀个函数，他的参数是虚拟⻚号，结果是物理⻚⻚框号\n## 加速分⻚：\n（1） TLB加速分⻚\n概念：将虚拟地址直接映射到物理地址，⽽不必再访问⻚表，这种设备被称为转换检测缓冲区（TLB）、相联存储\n器或快表\n⼯作过程：将⼀个虚拟地址放⼊MMU中进⾏转换时，硬件⾸先通过将该虚拟⻚号与TLB中所有表项同时进⾏匹配，\n判断虚拟⻚⾯是否在其中：\n## 虚拟⻚号在TLB中。如果MMU检测⼀个有效的匹配并且访问操作并不违反保护位，则将⻚框号直接从TLB中取\n出⽽不必访问⻚表。\n## 虚拟⻚号不在TLB中。如果MMU检测到没有有效的匹配项就会进⾏正常的⻚表查询。接着从TLB中淘汰⼀个表\n项，然后⽤新的⻚表项替换它。\n（2） 软件TLB管理\n## 针对⼤内存的⻚表\n（1） 多级⻚表\n（2） 倒排⻚表\n三个重要的能⼒：\n## ⾼速缓存\n按照存储器层次结构中的缓存划分来看，将位于k层的更⼩更快的存储设备作为存储在k+1层的更⼤更慢的存储设备\n的缓存。具体如下：\n在虚拟内存中的虚拟⻚共分为三种类型：\n## 未分配（没有被进程申请使⽤的，也就是空闲的虚拟内存，  不占⽤虚拟内存磁盘的任何空间）\n## 未缓存（仅仅加载到磁盘中的⻚）\n## 已缓存（已经加载到内存中的内存⻚（⻚框））\n## 内存管理\n## 内存保护\n现代操作系统中，⽤户进程不应该被允许修改它的只读代码段;\n⽽且也不应该允许它读取或修改任何内核中的代码和数据结构;\n并且也不允许其读取或者修改其他进程的私有内存，以及修改和其他进程共享的虚拟⻚⾯。\n如果不对进程的内存访问进⾏限制，攻击者就能够访问和修改其他进程的私有内存，进⽽导致整个系统崩溃。⼤体\n的虚拟寻址如下：\n通过MMU，每次都会读取⻚表中的⼀个⻚表条⽬(PTE)，通过在这些⻚表条⽬(PTE)中添加⼀些标志位，就能够实现\n对⼀个虚拟⻚的访问控制权限。譬如：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 9273,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000087",
    "content": "## 内存保护\n\n现代操作系统中，⽤户进程不应该被允许修改它的只读代码段;\n⽽且也不应该允许它读取或修改任何内核中的代码和数据结构;\n并且也不允许其读取或者修改其他进程的私有内存，以及修改和其他进程共享的虚拟⻚⾯。\n如果不对进程的内存访问进⾏限制，攻击者就能够访问和修改其他进程的私有内存，进⽽导致整个系统崩溃。⼤体\n的虚拟寻址如下：\n通过MMU，每次都会读取⻚表中的⼀个⻚表条⽬(PTE)，通过在这些⻚表条⽬(PTE)中添加⼀些标志位，就能够实现\n对⼀个虚拟⻚的访问控制权限。譬如：\n相关的其他概念",
    "question": "## 内存保护",
    "answer": "现代操作系统中，⽤户进程不应该被允许修改它的只读代码段;\n⽽且也不应该允许它读取或修改任何内核中的代码和数据结构;\n并且也不允许其读取或者修改其他进程的私有内存，以及修改和其他进程共享的虚拟⻚⾯。\n如果不对进程的内存访问进⾏限制，攻击者就能够访问和修改其他进程的私有内存，进⽽导致整个系统崩溃。⼤体\n的虚拟寻址如下：\n通过MMU，每次都会读取⻚表中的⼀个⻚表条⽬(PTE)，通过在这些⻚表条⽬(PTE)中添加⼀些标志位，就能够实现\n对⼀个虚拟⻚的访问控制权限。譬如：\n相关的其他概念",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 250,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000088",
    "content": "相关的其他概念\n\n## ⽤户态和内核态\n为了使操作系统内核提供⼀个⽆懈可击的进程抽象，处理器必须提供⼀种机制，限制⼀个应⽤可以执⾏的指令以及\n他可以⽤来访问的地址空间范围。\n处理器通常是⽤某个控制寄存器中的⼀个模式位来提供这种观功能的，该寄存器描述了进程当前享有的特权。\n当设置了模式位时：\n进程就运⾏在内核态中。\n运⾏在内核态中的进程可以执⾏指令集中的任何指令，并且可以访问系统中的任何内存位置。\n没有设置模式位时：\n进程就运⾏在⽤户态。⽤户模式中的进程不允许执⾏特权指令。\n⽐如：停⽌处理器、改变模式位、或者发起⼀个I/O操作。同时也不允许⽤户态下的进程直接引⽤地址空间中内核\n空间的代码和数据。\n任何这样的尝试都会导致致命的保护故障。⽤户态下的程序必须通过系统调⽤接⼝间接的访问内核代码和数据。\n## 上下⽂切换\n上下⽂切换属于⼀种较⾼层形式的异常控制流，进⾏上下切换涉及到的内容如下：\n（1） 各种寄存器，TLB 也是其中之⼀。\n（2） 程序计数器\n（3） ⽤户栈\n（4） 内核栈\n（5） 内核中的各种数据结构\n## ⻚表\n## task_struct\n## mm_struct\n⼩总结\n虚拟内存的思想，整体来看就是：通过结合磁盘和内存各⾃的优势，利⽤中间层对资源进⾏更合理地调度，充分提\n⾼资源的利⽤率。并提供和谐以及统⼀的抽象。\n为什么需要虚拟内存：（摘⾃  为什么Linux需要虚拟内存⼀⽂)\n## 虚拟内存可以结合磁盘和物理内存的优势为进程提供看起来速度⾜够快并且容量⾜够⼤的存储\n## 虚拟内存可以为进程提供独⽴的内存空间并引⼊多层的⻚表结构将虚拟内存翻译成物理内存，进程之间可以共\n享物理内存减少开销，也能简化程序的链接、装载以及内存分配过程;\n## 虚拟内存可以控制进程对物理内存的访问，隔离不同进程的访问权限，提⾼系统的安全性。\n⽂件系统\n## ⽂件\n⽂件是⼀种抽象机制，它提供了⼀种在磁上保存信息⽽且⽅便以后读取的⽅法。这种⽅法可以使⽤户不必了解存储\n信息的⽅法、位置和实际磁盘⼯作⽅式等有关细节\n## ⽂件命名\nwin95、win98⽤的都是MS-DOS的⽂件系统，即FAT-16，  win98扩展了FAT-16成为FAT-32。\n较新版的操作系统NTFS,win8配备ReFS。微软优化FAT,叫作exFAT。prog.c，圆点后⾯的部分称为⽂件扩展名。\n## ⽂件结构\n## 字节结构\n把⽂件看成字节序列为操作系统提供了最⼤的灵活度\n## 记录序列\n⽂件结构上的第⼀步改进，这种模型中，⽂件是具有固定⻓度记录的序列\n## 树\n⽂件在这种结构中由⼀棵记录树构成，每个记录不必具有相同的⻓度，记录的固定位置上有⼀个键字段。这棵树按\n“键”字段进⾏排序，从⽽可以对特定“键”进⾏快速查找。\n## ⽂件类型\n## 普通⽂件\n## ⽬录\n## 字符特殊⽂件（UNIX）\n## 块特殊⽂件（UNIX）\n## ⽂件访问\n## 顺序访问\n按顺序读取⽂件的全部字节，早期操作系统只有这种访问⽅式\n## 随机访问⽂件\n当⽤磁盘存储⽂件时，可以以任何次序读取其中字节或记录的⽂件。许多应⽤程序需要这种类型⽂件\n## ⽂件属性\n除了⽂件名和数据外，所有操作系统还会保存其他的⽂件相关信息，如创建⽇期、时间和⼤⼩等，这些附加的信息\n称为⽂件属性\n举例：\n创建者：创建⽂件者ID\n所有者：当前所有者\n当前⼤⼩：⽂件字节数\n## ⽂件操作\n使⽤⽂件的⽬的是存储信息并⽅便以后检索。对于存储和检索，不同系统提供了不同的操作。\n常⻅的⽂件操作（系统调⽤）:\n## create\n创建不包含任何数据的⽂件\n## delete\n当不再需要某个⽂件时，必须删除该⽂件以释放磁盘空间\n## open\n在使⽤⽂件之前，必须先打开⽂件\n## close\n访问结束后，不再需要⽂件属性和磁盘地址，这时应该关闭⽂件以释放内部表空间\n## read\n在⽂件中读取数据\n## write\n向⽂件写数据，写操作⼀般也是从⽂件当前位置开始\n## append\n此调⽤是write的限制形式，他只能在⽂件末尾添加数据\n## seek\ncp /usr/ast/mailbox /usr/ast/mailbox/mailbox.bak\ncp mailbox mailbox.bak # 具有相同的含义\n对于随机访问⽂件，要指定从何处开始获取数据，通常的⽅法是⽤seek系统调⽤把当前位置指针指向⽂件中特定的\n位置。\n## get attributes\n进程运⾏常需要读取⽂件属性\n## set attributes\n某些属性是可由⽤户设置的，甚⾄在⽂件创建之后\n## rename\n⽤户尝尝要改变已有的名字，rename系统调⽤⽤于这⼀⽬的\n⽂件系统通常提供⽬录或⽂件夹⽤于记录⽂件的位置，在很多操作系统中⽬录本身也是⽂件\n## ⼀级⽬录系统\n在⼀个⽬录中包含所有⽂件，这有时称为根⽬录\n## 层级⽬录系统\n当⽤户有着数以千计的⽂件，为了寻找⽅便。需要层次结构（即⼀个⽬录树）\n## 路径名\n## 绝对路径名\n它由从根⽬录到⽂件的路径组成。\nWindows ：\nUNIX ： /usr/ast/mailbox\n路径名的第⼀个字符是分隔符，则这个路径是绝对路径\n## 相对路径名\n它常和⼯作⽬录(working  directory)(也和当前⽬录(acurrent  directory))⼀起使⽤\n例：UNIX\n和命令\n## 特殊⽬录项\n. dot ：指当前⽬录\n指其⽗⽬录\neg:\n\\usr\\ast\\maibox\n.. dotdot\ncreate\ndelete\nopendir\n## 创建⽬录\n## 删除⽬录\n## ⽬录内容可被读取\nclosedir\n## 读⽬录结束\nreaddir\nrename\nlink\nunlink\n## 返回打开⽬录下⼀个⽬录项\n## 改变⽬录名\n## 链接技术允许在多个⽬录中出现同⼀个⽂件\n## 删除⽬录项\n将usr/lib/下的dictionay复制到当前⽬录下\n## ⽬录操作\n管理⽬录的系统调⽤\n举例(Unix):\n⽂件系统的实现\n⽂件存储实现的关键问题是记录各个⽂件分别⽤到哪些磁盘块。不同的操作系统⽤到不同的⽅法\n## ⽂件系统布局\n⽂件系统存放在磁盘上。多数磁盘划分为⼀个或多个分区，每个分区中国有⼀个独⽴的⽂件系统。\n磁盘0号扇区称为主引导记录(MBR)，⽤来引导计算机。在MBR结尾是分区表。该表给出每个分区的起始结束地\n表中的⼀个分区被标记为活动区。在计算机被引导时，BIOS读⼊并执⾏MBR。MBR做的第⼀件事是确定活动分\n区，读⼊它的第⼀个块，称为引导块，并执⾏之。\n引导块中的程序将装载该分区中的操作系统。\n## ⽂件的实现\n## 连续分配\n最简单的分配是把每个⽂件作为⼀连串连续数据块存储在磁盘\n优势：\n（1） 实现简单\n记录每个⽂件⽤到磁盘块简化为只需记住两个数字即可：第⼀块的磁盘地址和⽂件的块数。给定了第⼀块编号，⼀\n个简单的加法就可以找到任何其他块的编号\n（2） 操作性能较好\n因为单个操作中就能从磁盘上读出整个⽂件。只需⼀次寻找。\n## 链表分配\n为每个⽂件构造磁盘块链表。每⼀块的第⼀个字作为指向下⼀块的指针，块的其他部分存放数据。\ncp ../lib/dictionay .\n优势：\n（1） 可以充分利⽤磁盘块，不会因为磁盘碎⽚浪费存储内存\n（2） 随机访问快。\n指针占⽤⼀些字节，每个磁盘块存储数据的字节数不再是2的整数次幂。怪异的⼤⼩降低了系统的运⾏效率，每个\n块前⼏个字节被指向下⼀个块的指针所占据，需要从两个磁盘中获取拼接信息，这就因复制⽽引发额外的开销。\n## 采⽤内存中的表进⾏链表分配\n取出每个磁盘块的指针字，把他放在内存的⼀个表中，解决链表分配的不⾜。内存中这样的表格称为⽂件分配表\n(File Allocation Table，FAT)\n## i节点\n最后⼀个记录各⽂件分别包含哪些磁盘块的⽅法是给每个⽂件赋予⼀个称为i节点的数据结构，其中列出了⽂件属性\n和⽂件的磁盘地址。\n## ⽬录的实现\n在读⽂件之前，必须先打开⽂件。打开⽂件时，操作系统利⽤⽤户给出的路径名找到相应的⽬录项。\n简单⽬录：包含固定⼤⼩的⽬录，在⽬录项中有磁盘地址和属性\n采⽤i节点的系统：把⽂件属性存放在i节点中⽽不是⽬录项中。这种情形下，⽬录项会更短。\n## 共享⽂件\n当⼏个⽤户同在⼀个项⽬⾥⼯作时，他们常常需要共享⽂件。\n共享⽂件与⽬录的联系称为⼀个链接（link）。这样⽂件系统本身就是⼀个有向⽆环图（DAG），⽽不是⼀棵树。\n## ⽇志结构⽂件系统\nCPU运⾏速度越来越快，磁盘容量越来越⼤，价格越来越便宜（但磁盘速度并没有增快多少），同时内存容量也以\n指数形式增⻓。\n⽽没有得到快速发展的参数是磁道的寻道时间。这些成为了⽂件系统性能的瓶颈，为了解决这⼀问题设计了全新的\n⽂件系统即⽇志结构⽂件系统（LFS）。\n虽然是⼀个很吸引⼈的想法，由于它们和⽂件系统不匹配，该⽂件系统并没有被⼴泛应⽤。\n## ⽇志⽂件系统\n基本的想法是保存⼀个⽤于记录系统下⼀步将要做什么的⽇志。\n这样当系统在完成他们即将完成的任务前崩溃时，重新启动后，可以通过查看⽇志，获取崩溃前计划完成的任务，\n并完成它们。\n这样的⽂件⽇志系统，并已经被实际应⽤。微软的NTFS、Linux的  ext3和ReiserFS⽂件系统都使⽤⽇志。\n## 虚拟⽂件系统\n将多个⽂件系统整合到⼀个统⼀的结构中。\n⼀个Linux系统可以⽤ext2作为根⽂件系统，ext3分区装载在/usr下，另⼀块采⽤ReiserFS⽂件系统的硬盘装载\n在/home下，以及⼀个ISO 9660的CD-ROM临时装载在/mnt下。从⽤户的观点来看，只有⼀个⽂件系统层级。\n它们事实上是多种⽂件系统，对于⽤户和进程是不可⻅的。绝⼤多数Unix操作系统都在使⽤虚拟⽂件系统（Virtual\nFile System, VFS）\n⽂件系统的管理和优化\n## 磁盘空间管理\n⼏乎所有⽂件系统都把⽂件分割成固定⼤⼩的块来存储，各块之间不⼀定相邻\n## 块⼤⼩\n从历史的观点上来说，⽂件系统将⼤⼩设在1~4KB之间，但现在随着磁盘超过了1TB，还是将块的⼤⼩提升到64KB\n并且接受浪费的磁盘孔空间，这样也许更好。磁盘空间⼏乎不再会短缺。\n## 记录空闲块\n（1） 磁盘块链表\n链表的每个块中包含尽可能多的空闲磁盘块号。\n通常情况下，采⽤空闲块存放空闲表，这样不会影响存储器\n（2） 位图\n在位图中，空闲块⽤1表示，已分配块⽤0表示。\n（3） 磁盘配额\n为防⽌⼈们贪⼼⽽占有太多的磁盘空间，⽤户操作系统常常提供⼀种强制性磁盘配额机制。\n其思想是系统管理员分给每个⽤户拥有⽂件和块的最⼤数量，操作系统确保每个⽤户不超过分给他们的配额。（配\n额表、打开⽂件表）\n## ⽂件系统备份\n做磁盘备份主要是处理好两个潜在问题中的⼀个\n## 从意外的灾难中恢复\n## 从错误的操作中恢复\n## ⽂件系统的⼀致性\n很多⽂件系统读取磁盘块，进⾏修改后，再写回磁盘。\n如果在修改过的磁盘块全部写回之前系统崩溃，则⽂件系统有可能处于不⼀致状态。\n如果⼀些未被写回的块是i节点块、⽬录块或者是包含有空闲表的块时，这个问题尤为严重\n## ⽂件系统性能\n## ⾼速缓存\n减少磁盘访问次数技术是块⾼速缓存（block  cache）或者缓冲区⾼速缓存（buffer  cache）。\n本书中，⾼速缓存指的是⼀系列的块，它们在逻辑上属于磁盘，但实际上基于性能的考虑被保存在内存中。\n## 块提取读\n在需要⽤到块之前，试图提前将其写⼊⾼速缓存，从⽽提⾼命中率。\n块提前读策略只适⽤于实际顺序读取的⽂件。对随机访问⽂件，提前读丝毫不起作⽤。\n## 减少磁盘臂运动\n把可能顺序访问的块放⼀起，当然最好是同⼀柱⾯上，从⽽减少磁盘臂的移动次数。\n## 磁盘碎⽚整理\n移动⽂件使它们相邻，并把所有的空闲空间放在⼀个或多个⼤的连续区域内。\n⽣磁盘的使⽤\n⽣磁盘：根据盘块号来使⽤磁盘；\n熟磁盘：根据⽂件来使⽤磁盘。\n磁盘如何使⽤？\n## 发送 out 指令；\n## ⽂件视图；\n## 发送 中断\n磁盘的结构\n盘⾯：类似于多个堆叠在⼀起的 DVD 光盘\n磁道：每个 DVD 光盘上的同⼼圆\n扇区：每个同⼼圆上的 ⼀段⼉ ⼩区域\n磁盘 IO 过程\n寻道：将磁头移动到 指定 磁道\n旋转：将磁头旋转到磁道中的指定 扇区\n传输：对指定扇区 进⾏ 磁盘数据 IO 读写\n⼀层抽象\n通过盘块号读写磁盘\n对于⽤户来说，如果直接利⽤ 盘/柱⾯ C、磁头 H、扇区 S 来进⾏ 磁盘 IO 不太友好，所以通过⼀层抽象，即 ⽤户\n只⽤利⽤ 盘块号 block 来进⾏ 磁盘IO，然后由系统根据 block 计算出 C、H、S 即可\n磁盘编址\n由于寻道时间 通常时间更⻓⼀些，所以，为了让 磁盘 IO 时间尽可能短⼀些，则需要使 寻道时间尽量段。即，把当\n⼀个 磁道编址⽤完后，向下⼀个 柱⾯ 继续编号，⽽不是向 下⼀个 磁道继续编号。\n计算公式：盘块号 block = C (Heads Sectors) + H * Sectors + S\n⼆层抽象\n多个进程通过队列使⽤磁盘\n虽然⼀层抽象（利⽤ 盘块号）可以达到使⽤磁盘的⽬的，但是如果有多个磁盘访问请求出现在请求队列怎么办?\n此时，操作系统会根据 磁盘调度算法 来挑选⼀个 磁盘请求服务\n常⻅磁盘调度算法\n## FCFS：找最先来的请求\n优点：公平\n缺点：并不提供 最快的服务\nFCFS 在寻道过程中，可能已经遇到⼀些以后可能需要访问的 磁道，但是会跳过，⽽造成 访问磁道 耗费时间较多。\n## SSTF：类似于 SJF，每次选择距离当前磁头最近的待处理请求\n优点：寻道时间最短\n缺点：可能造成部分请求 “饥饿”（当某个请求的磁盘距离磁头较远，⽽⼀直有⽐其更近的请求时，这个请求⼀直⽆\n法执⾏）\n## SCAN 算法：类似电梯，先处理向上的请求，然后再处理反⽅向的请求\n优点：不会造成部分请求的 “饥饿”\n三层抽象\n利⽤⽂件使⽤磁盘，就成了熟磁盘\n让普通⽤户使⽤ raw disk： 许多⼈连扇区都不知道是什么? 要求他们根据盘块号来访问磁盘不太便利\n需要在盘块上引⼊更⾼⼀层次的抽象概念! ⽂件\n⽤户眼⾥的 “⽂件”：⼀堆字符序列（字符流）\n磁盘上的 “⽂件”：多个盘块构成的集合\n所以，如果要利⽤⽂件来进⾏磁盘IO的话，就需要建⽴字符流到盘块集合的映射关系\n常⻅的⽂件映射关系（⽂件实现⽅式）有以下 3 种：\n## 顺序结构\n## 链式结构\n## 索引\n顺序结构-实现⽂件\nFCB：记录⽂件在磁盘中的起始块\n⽂件->盘块号\n如何根据 ⽂件 找到 盘块号？\n将⽂件按照 连续结构存放；（下 左图）；\n对每个⽂件建⽴⼀个 FCB，记录该⽂件在磁盘中的 起始块号；\n根据⽂件（字符流）中的第 n 个待查字符 + FCB 计算 （n / 每个盘块的⼤⼩ + FCB中的 起始块号】出其在磁盘上对\n应的 盘块号 【得到盘块号，然后采⽤ SCAN 算法]\n这种⽅法的缺点：\n## 利⽤顺序结构存储⽂件，不利⽤⽂件的修改（因为 顺序存储的 增/删 代价⾮常⼤）\n## 所以，当需要 动态修改 ⽂件时，最好使⽤ 链式存储⽂件\n链式结构-实现⽂件\n优点：利于 增/删\n缺点：不利于查询\n外设管理\n如何让外设动起来\n## CPU 向 外设的控制器发送指令，即 out 指令\n## 形成 ⽂件视图（为了统⼀ out 指令的形式）\n## 中断（外设处理完事后，需要通知 cpu 继续接⼿ 下⼀步处理）",
    "question": "相关的其他概念",
    "answer": "## ⽤户态和内核态\n为了使操作系统内核提供⼀个⽆懈可击的进程抽象，处理器必须提供⼀种机制，限制⼀个应⽤可以执⾏的指令以及\n他可以⽤来访问的地址空间范围。\n处理器通常是⽤某个控制寄存器中的⼀个模式位来提供这种观功能的，该寄存器描述了进程当前享有的特权。\n当设置了模式位时：\n进程就运⾏在内核态中。\n运⾏在内核态中的进程可以执⾏指令集中的任何指令，并且可以访问系统中的任何内存位置。\n没有设置模式位时：\n进程就运⾏在⽤户态。⽤户模式中的进程不允许执⾏特权指令。\n⽐如：停⽌处理器、改变模式位、或者发起⼀个I/O操作。同时也不允许⽤户态下的进程直接引⽤地址空间中内核\n空间的代码和数据。\n任何这样的尝试都会导致致命的保护故障。⽤户态下的程序必须通过系统调⽤接⼝间接的访问内核代码和数据。\n## 上下⽂切换\n上下⽂切换属于⼀种较⾼层形式的异常控制流，进⾏上下切换涉及到的内容如下：\n（1） 各种寄存器，TLB 也是其中之⼀。\n（2） 程序计数器\n（3） ⽤户栈\n（4） 内核栈\n（5） 内核中的各种数据结构\n## ⻚表\n## task_struct\n## mm_struct\n⼩总结\n虚拟内存的思想，整体来看就是：通过结合磁盘和内存各⾃的优势，利⽤中间层对资源进⾏更合理地调度，充分提\n⾼资源的利⽤率。并提供和谐以及统⼀的抽象。\n为什么需要虚拟内存：（摘⾃  为什么Linux需要虚拟内存⼀⽂)\n## 虚拟内存可以结合磁盘和物理内存的优势为进程提供看起来速度⾜够快并且容量⾜够⼤的存储\n## 虚拟内存可以为进程提供独⽴的内存空间并引⼊多层的⻚表结构将虚拟内存翻译成物理内存，进程之间可以共\n享物理内存减少开销，也能简化程序的链接、装载以及内存分配过程;\n## 虚拟内存可以控制进程对物理内存的访问，隔离不同进程的访问权限，提⾼系统的安全性。\n⽂件系统\n## ⽂件\n⽂件是⼀种抽象机制，它提供了⼀种在磁上保存信息⽽且⽅便以后读取的⽅法。这种⽅法可以使⽤户不必了解存储\n信息的⽅法、位置和实际磁盘⼯作⽅式等有关细节\n## ⽂件命名\nwin95、win98⽤的都是MS-DOS的⽂件系统，即FAT-16，  win98扩展了FAT-16成为FAT-32。\n较新版的操作系统NTFS,win8配备ReFS。微软优化FAT,叫作exFAT。prog.c，圆点后⾯的部分称为⽂件扩展名。\n## ⽂件结构\n## 字节结构\n把⽂件看成字节序列为操作系统提供了最⼤的灵活度\n## 记录序列\n⽂件结构上的第⼀步改进，这种模型中，⽂件是具有固定⻓度记录的序列\n## 树\n⽂件在这种结构中由⼀棵记录树构成，每个记录不必具有相同的⻓度，记录的固定位置上有⼀个键字段。这棵树按\n“键”字段进⾏排序，从⽽可以对特定“键”进⾏快速查找。\n## ⽂件类型\n## 普通⽂件\n## ⽬录\n## 字符特殊⽂件（UNIX）\n## 块特殊⽂件（UNIX）\n## ⽂件访问\n## 顺序访问\n按顺序读取⽂件的全部字节，早期操作系统只有这种访问⽅式\n## 随机访问⽂件\n当⽤磁盘存储⽂件时，可以以任何次序读取其中字节或记录的⽂件。许多应⽤程序需要这种类型⽂件\n## ⽂件属性\n除了⽂件名和数据外，所有操作系统还会保存其他的⽂件相关信息，如创建⽇期、时间和⼤⼩等，这些附加的信息\n称为⽂件属性\n举例：\n创建者：创建⽂件者ID\n所有者：当前所有者\n当前⼤⼩：⽂件字节数\n## ⽂件操作\n使⽤⽂件的⽬的是存储信息并⽅便以后检索。对于存储和检索，不同系统提供了不同的操作。\n常⻅的⽂件操作（系统调⽤）:\n## create\n创建不包含任何数据的⽂件\n## delete\n当不再需要某个⽂件时，必须删除该⽂件以释放磁盘空间\n## open\n在使⽤⽂件之前，必须先打开⽂件\n## close\n访问结束后，不再需要⽂件属性和磁盘地址，这时应该关闭⽂件以释放内部表空间\n## read\n在⽂件中读取数据\n## write\n向⽂件写数据，写操作⼀般也是从⽂件当前位置开始\n## append\n此调⽤是write的限制形式，他只能在⽂件末尾添加数据\n## seek\ncp /usr/ast/mailbox /usr/ast/mailbox/mailbox.bak\ncp mailbox mailbox.bak # 具有相同的含义\n对于随机访问⽂件，要指定从何处开始获取数据，通常的⽅法是⽤seek系统调⽤把当前位置指针指向⽂件中特定的\n位置。\n## get attributes\n进程运⾏常需要读取⽂件属性\n## set attributes\n某些属性是可由⽤户设置的，甚⾄在⽂件创建之后\n## rename\n⽤户尝尝要改变已有的名字，rename系统调⽤⽤于这⼀⽬的\n⽂件系统通常提供⽬录或⽂件夹⽤于记录⽂件的位置，在很多操作系统中⽬录本身也是⽂件\n## ⼀级⽬录系统\n在⼀个⽬录中包含所有⽂件，这有时称为根⽬录\n## 层级⽬录系统\n当⽤户有着数以千计的⽂件，为了寻找⽅便。需要层次结构（即⼀个⽬录树）\n## 路径名\n## 绝对路径名\n它由从根⽬录到⽂件的路径组成。\nWindows ：\nUNIX ： /usr/ast/mailbox\n路径名的第⼀个字符是分隔符，则这个路径是绝对路径\n## 相对路径名\n它常和⼯作⽬录(working  directory)(也和当前⽬录(acurrent  directory))⼀起使⽤\n例：UNIX\n和命令\n## 特殊⽬录项\n. dot ：指当前⽬录\n指其⽗⽬录\neg:\n\\usr\\ast\\maibox\n.. dotdot\ncreate\ndelete\nopendir\n## 创建⽬录\n## 删除⽬录\n## ⽬录内容可被读取\nclosedir\n## 读⽬录结束\nreaddir\nrename\nlink\nunlink\n## 返回打开⽬录下⼀个⽬录项\n## 改变⽬录名\n## 链接技术允许在多个⽬录中出现同⼀个⽂件\n## 删除⽬录项\n将usr/lib/下的dictionay复制到当前⽬录下\n## ⽬录操作\n管理⽬录的系统调⽤\n举例(Unix):\n⽂件系统的实现\n⽂件存储实现的关键问题是记录各个⽂件分别⽤到哪些磁盘块。不同的操作系统⽤到不同的⽅法\n## ⽂件系统布局\n⽂件系统存放在磁盘上。多数磁盘划分为⼀个或多个分区，每个分区中国有⼀个独⽴的⽂件系统。\n磁盘0号扇区称为主引导记录(MBR)，⽤来引导计算机。在MBR结尾是分区表。该表给出每个分区的起始结束地\n表中的⼀个分区被标记为活动区。在计算机被引导时，BIOS读⼊并执⾏MBR。MBR做的第⼀件事是确定活动分\n区，读⼊它的第⼀个块，称为引导块，并执⾏之。\n引导块中的程序将装载该分区中的操作系统。\n## ⽂件的实现\n## 连续分配\n最简单的分配是把每个⽂件作为⼀连串连续数据块存储在磁盘\n优势：\n（1） 实现简单\n记录每个⽂件⽤到磁盘块简化为只需记住两个数字即可：第⼀块的磁盘地址和⽂件的块数。给定了第⼀块编号，⼀\n个简单的加法就可以找到任何其他块的编号\n（2） 操作性能较好\n因为单个操作中就能从磁盘上读出整个⽂件。只需⼀次寻找。\n## 链表分配\n为每个⽂件构造磁盘块链表。每⼀块的第⼀个字作为指向下⼀块的指针，块的其他部分存放数据。\ncp ../lib/dictionay .\n优势：\n（1） 可以充分利⽤磁盘块，不会因为磁盘碎⽚浪费存储内存\n（2） 随机访问快。\n指针占⽤⼀些字节，每个磁盘块存储数据的字节数不再是2的整数次幂。怪异的⼤⼩降低了系统的运⾏效率，每个\n块前⼏个字节被指向下⼀个块的指针所占据，需要从两个磁盘中获取拼接信息，这就因复制⽽引发额外的开销。\n## 采⽤内存中的表进⾏链表分配\n取出每个磁盘块的指针字，把他放在内存的⼀个表中，解决链表分配的不⾜。内存中这样的表格称为⽂件分配表\n(File Allocation Table，FAT)\n## i节点\n最后⼀个记录各⽂件分别包含哪些磁盘块的⽅法是给每个⽂件赋予⼀个称为i节点的数据结构，其中列出了⽂件属性\n和⽂件的磁盘地址。\n## ⽬录的实现\n在读⽂件之前，必须先打开⽂件。打开⽂件时，操作系统利⽤⽤户给出的路径名找到相应的⽬录项。\n简单⽬录：包含固定⼤⼩的⽬录，在⽬录项中有磁盘地址和属性\n采⽤i节点的系统：把⽂件属性存放在i节点中⽽不是⽬录项中。这种情形下，⽬录项会更短。\n## 共享⽂件\n当⼏个⽤户同在⼀个项⽬⾥⼯作时，他们常常需要共享⽂件。\n共享⽂件与⽬录的联系称为⼀个链接（link）。这样⽂件系统本身就是⼀个有向⽆环图（DAG），⽽不是⼀棵树。\n## ⽇志结构⽂件系统\nCPU运⾏速度越来越快，磁盘容量越来越⼤，价格越来越便宜（但磁盘速度并没有增快多少），同时内存容量也以\n指数形式增⻓。\n⽽没有得到快速发展的参数是磁道的寻道时间。这些成为了⽂件系统性能的瓶颈，为了解决这⼀问题设计了全新的\n⽂件系统即⽇志结构⽂件系统（LFS）。\n虽然是⼀个很吸引⼈的想法，由于它们和⽂件系统不匹配，该⽂件系统并没有被⼴泛应⽤。\n## ⽇志⽂件系统\n基本的想法是保存⼀个⽤于记录系统下⼀步将要做什么的⽇志。\n这样当系统在完成他们即将完成的任务前崩溃时，重新启动后，可以通过查看⽇志，获取崩溃前计划完成的任务，\n并完成它们。\n这样的⽂件⽇志系统，并已经被实际应⽤。微软的NTFS、Linux的  ext3和ReiserFS⽂件系统都使⽤⽇志。\n## 虚拟⽂件系统\n将多个⽂件系统整合到⼀个统⼀的结构中。\n⼀个Linux系统可以⽤ext2作为根⽂件系统，ext3分区装载在/usr下，另⼀块采⽤ReiserFS⽂件系统的硬盘装载\n在/home下，以及⼀个ISO 9660的CD-ROM临时装载在/mnt下。从⽤户的观点来看，只有⼀个⽂件系统层级。\n它们事实上是多种⽂件系统，对于⽤户和进程是不可⻅的。绝⼤多数Unix操作系统都在使⽤虚拟⽂件系统（Virtual\nFile System, VFS）\n⽂件系统的管理和优化\n## 磁盘空间管理\n⼏乎所有⽂件系统都把⽂件分割成固定⼤⼩的块来存储，各块之间不⼀定相邻\n## 块⼤⼩\n从历史的观点上来说，⽂件系统将⼤⼩设在1~4KB之间，但现在随着磁盘超过了1TB，还是将块的⼤⼩提升到64KB\n并且接受浪费的磁盘孔空间，这样也许更好。磁盘空间⼏乎不再会短缺。\n## 记录空闲块\n（1） 磁盘块链表\n链表的每个块中包含尽可能多的空闲磁盘块号。\n通常情况下，采⽤空闲块存放空闲表，这样不会影响存储器\n（2） 位图\n在位图中，空闲块⽤1表示，已分配块⽤0表示。\n（3） 磁盘配额\n为防⽌⼈们贪⼼⽽占有太多的磁盘空间，⽤户操作系统常常提供⼀种强制性磁盘配额机制。\n其思想是系统管理员分给每个⽤户拥有⽂件和块的最⼤数量，操作系统确保每个⽤户不超过分给他们的配额。（配\n额表、打开⽂件表）\n## ⽂件系统备份\n做磁盘备份主要是处理好两个潜在问题中的⼀个\n## 从意外的灾难中恢复\n## 从错误的操作中恢复\n## ⽂件系统的⼀致性\n很多⽂件系统读取磁盘块，进⾏修改后，再写回磁盘。\n如果在修改过的磁盘块全部写回之前系统崩溃，则⽂件系统有可能处于不⼀致状态。\n如果⼀些未被写回的块是i节点块、⽬录块或者是包含有空闲表的块时，这个问题尤为严重\n## ⽂件系统性能\n## ⾼速缓存\n减少磁盘访问次数技术是块⾼速缓存（block  cache）或者缓冲区⾼速缓存（buffer  cache）。\n本书中，⾼速缓存指的是⼀系列的块，它们在逻辑上属于磁盘，但实际上基于性能的考虑被保存在内存中。\n## 块提取读\n在需要⽤到块之前，试图提前将其写⼊⾼速缓存，从⽽提⾼命中率。\n块提前读策略只适⽤于实际顺序读取的⽂件。对随机访问⽂件，提前读丝毫不起作⽤。\n## 减少磁盘臂运动\n把可能顺序访问的块放⼀起，当然最好是同⼀柱⾯上，从⽽减少磁盘臂的移动次数。\n## 磁盘碎⽚整理\n移动⽂件使它们相邻，并把所有的空闲空间放在⼀个或多个⼤的连续区域内。\n⽣磁盘的使⽤\n⽣磁盘：根据盘块号来使⽤磁盘；\n熟磁盘：根据⽂件来使⽤磁盘。\n磁盘如何使⽤？\n## 发送 out 指令；\n## ⽂件视图；\n## 发送 中断\n磁盘的结构\n盘⾯：类似于多个堆叠在⼀起的 DVD 光盘\n磁道：每个 DVD 光盘上的同⼼圆\n扇区：每个同⼼圆上的 ⼀段⼉ ⼩区域\n磁盘 IO 过程\n寻道：将磁头移动到 指定 磁道\n旋转：将磁头旋转到磁道中的指定 扇区\n传输：对指定扇区 进⾏ 磁盘数据 IO 读写\n⼀层抽象\n通过盘块号读写磁盘\n对于⽤户来说，如果直接利⽤ 盘/柱⾯ C、磁头 H、扇区 S 来进⾏ 磁盘 IO 不太友好，所以通过⼀层抽象，即 ⽤户\n只⽤利⽤ 盘块号 block 来进⾏ 磁盘IO，然后由系统根据 block 计算出 C、H、S 即可\n磁盘编址\n由于寻道时间 通常时间更⻓⼀些，所以，为了让 磁盘 IO 时间尽可能短⼀些，则需要使 寻道时间尽量段。即，把当\n⼀个 磁道编址⽤完后，向下⼀个 柱⾯ 继续编号，⽽不是向 下⼀个 磁道继续编号。\n计算公式：盘块号 block = C (Heads Sectors) + H * Sectors + S\n⼆层抽象\n多个进程通过队列使⽤磁盘\n虽然⼀层抽象（利⽤ 盘块号）可以达到使⽤磁盘的⽬的，但是如果有多个磁盘访问请求出现在请求队列怎么办?\n此时，操作系统会根据 磁盘调度算法 来挑选⼀个 磁盘请求服务\n常⻅磁盘调度算法\n## FCFS：找最先来的请求\n优点：公平\n缺点：并不提供 最快的服务\nFCFS 在寻道过程中，可能已经遇到⼀些以后可能需要访问的 磁道，但是会跳过，⽽造成 访问磁道 耗费时间较多。\n## SSTF：类似于 SJF，每次选择距离当前磁头最近的待处理请求\n优点：寻道时间最短\n缺点：可能造成部分请求 “饥饿”（当某个请求的磁盘距离磁头较远，⽽⼀直有⽐其更近的请求时，这个请求⼀直⽆\n法执⾏）\n## SCAN 算法：类似电梯，先处理向上的请求，然后再处理反⽅向的请求\n优点：不会造成部分请求的 “饥饿”\n三层抽象\n利⽤⽂件使⽤磁盘，就成了熟磁盘\n让普通⽤户使⽤ raw disk： 许多⼈连扇区都不知道是什么? 要求他们根据盘块号来访问磁盘不太便利\n需要在盘块上引⼊更⾼⼀层次的抽象概念! ⽂件\n⽤户眼⾥的 “⽂件”：⼀堆字符序列（字符流）\n磁盘上的 “⽂件”：多个盘块构成的集合\n所以，如果要利⽤⽂件来进⾏磁盘IO的话，就需要建⽴字符流到盘块集合的映射关系\n常⻅的⽂件映射关系（⽂件实现⽅式）有以下 3 种：\n## 顺序结构\n## 链式结构\n## 索引\n顺序结构-实现⽂件\nFCB：记录⽂件在磁盘中的起始块\n⽂件->盘块号\n如何根据 ⽂件 找到 盘块号？\n将⽂件按照 连续结构存放；（下 左图）；\n对每个⽂件建⽴⼀个 FCB，记录该⽂件在磁盘中的 起始块号；\n根据⽂件（字符流）中的第 n 个待查字符 + FCB 计算 （n / 每个盘块的⼤⼩ + FCB中的 起始块号】出其在磁盘上对\n应的 盘块号 【得到盘块号，然后采⽤ SCAN 算法]\n这种⽅法的缺点：\n## 利⽤顺序结构存储⽂件，不利⽤⽂件的修改（因为 顺序存储的 增/删 代价⾮常⼤）\n## 所以，当需要 动态修改 ⽂件时，最好使⽤ 链式存储⽂件\n链式结构-实现⽂件\n优点：利于 增/删\n缺点：不利于查询\n外设管理\n如何让外设动起来\n## CPU 向 外设的控制器发送指令，即 out 指令\n## 形成 ⽂件视图（为了统⼀ out 指令的形式）\n## 中断（外设处理完事后，需要通知 cpu 继续接⼿ 下⼀步处理）",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 6417,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000089",
    "content": "## 中断（外设处理完事后，需要通知 cpu 继续接⼿ 下⼀步处理）\n\n显示器如何⼯作？即，printf 函数的⼯作流程\n键盘如何⼯作？\n中断处理（根据扫描码 获取 对应的 ascii 码）；\n将对应的 ascii 码 加⼊ 缓冲队列 read_que 中，等待上层程序调⽤\nLinux\n什么是IO多路复⽤\nI/O多路复⽤是⼀种在单个线程或进程中处理多个输⼊和输出操作的机制。它允许单个进程同时监视多个⽂件描述\n符(通常是套接字)，当⼀个或多个⽂件描述符准备好读或写时，它就可以⽴即响应。\nI/O多路复⽤通常通过select、poll、epoll等系统调⽤来实现。\nselect：  select是⼀个最古⽼的I/O多路复⽤机制，它可以监视多个⽂件描述符的可读、可写和错误状态。然\n⽽，但是它的效率可能随着监视的⽂件描述符数量的增加⽽降低。\npoll： poll是select的⼀种改进，它使⽤轮询⽅式来检查多个⽂件描述符的状态，避免了select中⽂件描述符\n数量有限的问题。但对于⼤量的⽂件描述符，poll的性能也可能变得不⾜够⾼效。\nepoll： epoll是Linux特有的I/O多路复⽤机制，相较于select和poll，它在处理⼤量⽂件描述符时更加⾼效。\nepoll使⽤事件通知的⽅式，只有在⽂件描述符就绪时才会通知应⽤程序，⽽不需要应⽤程序轮询。\nI/O多路复⽤允许在⼀个线程中处理多个I/O操作，避免了创建多个线程或进程的开销，允许在⼀个线程中处理多个\nI/O操作，避免了创建多个线程或进程的开销。\nselect/poll/epoll的区别和联系\nselect ,   poll 和epoll 都是I/O多路复⽤技术，它们⽤于同时处理多个I/O操作，特别是在⾼并发⽹络编程中。\nselect\nselect 是最早的I/O多路复⽤技术，它可以同时监视多个⽂件描述符（file descriptor, FD）的I/O状态（如可读、\n可写、异常等）。 select 函数使⽤⼀个⽂件描述符集合（通常是⼀个位图）来表示要监视的⽂件描述符，当有I/O\n事件发⽣时， select 会返回对应的⽂件描述符集合。\nselect的主要限制如下：\n⽂件描述符数量限制：  select 使⽤⼀个位图来表示⽂件描述符集合，这限制了它能够处理的⽂件描述符数量\n（通常是1024个）。\n效率问题：当⽂件描述符数量较⼤时， select 需要遍历整个⽂件描述符集合来查找就绪的⽂件描述符，这会\n导致较低的效率。\n⾮实时性：每次调⽤select  时，需要重新设置⽂件描述符集合，这会增加函数调⽤的开销。\npoll\npoll 是为了克服select 的限制⽽引⼊的⼀种I/O多路复⽤技术。 poll 使⽤⼀个⽂件描述符数组（通常是⼀个结\n构体数组）来表示要监视的⽂件描述符。与select 类似， poll 可以监视多个⽂件描述符的I/O状态。\npoll的优点如下：\n⽂件描述符数量不受限制：由于poll 使⽤⼀个动态数组来表示⽂件描述符，因此它可以处理任意数量的⽂件\n描述符。\n效率相对较⾼：  poll 在查找就绪的⽂件描述符时，只需要遍历实际使⽤的⽂件描述符数组，⽽不是整个⽂件\n描述符集合。\n然⽽， poll 仍然存在⼀些问题：\n效率问题：尽管poll 相对于select 具有较⾼的效率，但当⽂件描述符数量很⼤时，它仍然需要遍历整个⽂\n件描述符数组。\n⾮实时性：与select 类似，每次调⽤poll 时，需要重新设置⽂件描述符数组。\nepoll\nepoll 是Linux特有的⼀种⾼效I/O多路复⽤技术，它克服了 select 和poll 的主要限制。 epoll 使⽤⼀个事件驱\n动（event-driven）的⽅式来处理I/O操作，它只会返回就绪的⽂件描述符，⽽不是遍历整个⽂件描述符集合。\nepoll的主要优点如下：\n⾼效： epoll 使⽤事件驱动的⽅式来处理I/O操作，因此它在处理⼤量⽂件描述符时具有很⾼的效率。当有\nI/O事件发⽣时， epoll 可以⽴即得到通知，⽽⽆需遍历整个⽂件描述符集合。这使得epoll 在⾼并发场景中\n具有更好的性能。\n可扩展性：与poll 类似， epoll 可以处理任意数量的⽂件描述符，因为它使⽤⼀个动态数据结构来表示⽂件\n描述符。\n实时性： epoll 使⽤⼀个内核事件表来记录要监视的⽂件描述符和事件，因此在每次调⽤epoll 时⽆需重新\n设置⽂件描述符集合。这可以减少函数调⽤的开销，并提⾼实时性。\nepoll  具有诸多优点，但它⽬前仅在Linux平台上可⽤。对于其他平台，可能需要使⽤类似的I/O多路复⽤技术，如\nBSD中的 kqueue 。\n总结： select 是最早的I/O多路复⽤技术，但受到⽂件描述符数量和效率⽅⾯的限制。 poll 克服了⽂件描述符数\n量的限制，但仍然存在⼀定的效率问题。 epoll 是⼀种⾼效的I/O多路复⽤技术，尤其适⽤于⾼并发场景，但它仅\n在Linux平台上可⽤。⼀般来说，epoll的效率是要⽐select和poll⾼的，但是对于活动连接较多的时候，由于回调函\n数触发的很频繁，其效率不⼀定⽐select和poll⾼。所以epoll在连接数量很多，但活动连接较⼩的情况性能体现的\n⽐较明显。\nLinux 内存管理",
    "question": "## 中断（外设处理完事后，需要通知 cpu 继续接⼿ 下⼀步处理）",
    "answer": "显示器如何⼯作？即，printf 函数的⼯作流程\n键盘如何⼯作？\n中断处理（根据扫描码 获取 对应的 ascii 码）；\n将对应的 ascii 码 加⼊ 缓冲队列 read_que 中，等待上层程序调⽤\nLinux\n什么是IO多路复⽤\nI/O多路复⽤是⼀种在单个线程或进程中处理多个输⼊和输出操作的机制。它允许单个进程同时监视多个⽂件描述\n符(通常是套接字)，当⼀个或多个⽂件描述符准备好读或写时，它就可以⽴即响应。\nI/O多路复⽤通常通过select、poll、epoll等系统调⽤来实现。\nselect：  select是⼀个最古⽼的I/O多路复⽤机制，它可以监视多个⽂件描述符的可读、可写和错误状态。然\n⽽，但是它的效率可能随着监视的⽂件描述符数量的增加⽽降低。\npoll： poll是select的⼀种改进，它使⽤轮询⽅式来检查多个⽂件描述符的状态，避免了select中⽂件描述符\n数量有限的问题。但对于⼤量的⽂件描述符，poll的性能也可能变得不⾜够⾼效。\nepoll： epoll是Linux特有的I/O多路复⽤机制，相较于select和poll，它在处理⼤量⽂件描述符时更加⾼效。\nepoll使⽤事件通知的⽅式，只有在⽂件描述符就绪时才会通知应⽤程序，⽽不需要应⽤程序轮询。\nI/O多路复⽤允许在⼀个线程中处理多个I/O操作，避免了创建多个线程或进程的开销，允许在⼀个线程中处理多个\nI/O操作，避免了创建多个线程或进程的开销。\nselect/poll/epoll的区别和联系\nselect ,   poll 和epoll 都是I/O多路复⽤技术，它们⽤于同时处理多个I/O操作，特别是在⾼并发⽹络编程中。\nselect\nselect 是最早的I/O多路复⽤技术，它可以同时监视多个⽂件描述符（file descriptor, FD）的I/O状态（如可读、\n可写、异常等）。 select 函数使⽤⼀个⽂件描述符集合（通常是⼀个位图）来表示要监视的⽂件描述符，当有I/O\n事件发⽣时， select 会返回对应的⽂件描述符集合。\nselect的主要限制如下：\n⽂件描述符数量限制：  select 使⽤⼀个位图来表示⽂件描述符集合，这限制了它能够处理的⽂件描述符数量\n（通常是1024个）。\n效率问题：当⽂件描述符数量较⼤时， select 需要遍历整个⽂件描述符集合来查找就绪的⽂件描述符，这会\n导致较低的效率。\n⾮实时性：每次调⽤select  时，需要重新设置⽂件描述符集合，这会增加函数调⽤的开销。\npoll\npoll 是为了克服select 的限制⽽引⼊的⼀种I/O多路复⽤技术。 poll 使⽤⼀个⽂件描述符数组（通常是⼀个结\n构体数组）来表示要监视的⽂件描述符。与select 类似， poll 可以监视多个⽂件描述符的I/O状态。\npoll的优点如下：\n⽂件描述符数量不受限制：由于poll 使⽤⼀个动态数组来表示⽂件描述符，因此它可以处理任意数量的⽂件\n描述符。\n效率相对较⾼：  poll 在查找就绪的⽂件描述符时，只需要遍历实际使⽤的⽂件描述符数组，⽽不是整个⽂件\n描述符集合。\n然⽽， poll 仍然存在⼀些问题：\n效率问题：尽管poll 相对于select 具有较⾼的效率，但当⽂件描述符数量很⼤时，它仍然需要遍历整个⽂\n件描述符数组。\n⾮实时性：与select 类似，每次调⽤poll 时，需要重新设置⽂件描述符数组。\nepoll\nepoll 是Linux特有的⼀种⾼效I/O多路复⽤技术，它克服了 select 和poll 的主要限制。 epoll 使⽤⼀个事件驱\n动（event-driven）的⽅式来处理I/O操作，它只会返回就绪的⽂件描述符，⽽不是遍历整个⽂件描述符集合。\nepoll的主要优点如下：\n⾼效： epoll 使⽤事件驱动的⽅式来处理I/O操作，因此它在处理⼤量⽂件描述符时具有很⾼的效率。当有\nI/O事件发⽣时， epoll 可以⽴即得到通知，⽽⽆需遍历整个⽂件描述符集合。这使得epoll 在⾼并发场景中\n具有更好的性能。\n可扩展性：与poll 类似， epoll 可以处理任意数量的⽂件描述符，因为它使⽤⼀个动态数据结构来表示⽂件\n描述符。\n实时性： epoll 使⽤⼀个内核事件表来记录要监视的⽂件描述符和事件，因此在每次调⽤epoll 时⽆需重新\n设置⽂件描述符集合。这可以减少函数调⽤的开销，并提⾼实时性。\nepoll  具有诸多优点，但它⽬前仅在Linux平台上可⽤。对于其他平台，可能需要使⽤类似的I/O多路复⽤技术，如\nBSD中的 kqueue 。\n总结： select 是最早的I/O多路复⽤技术，但受到⽂件描述符数量和效率⽅⾯的限制。 poll 克服了⽂件描述符数\n量的限制，但仍然存在⼀定的效率问题。 epoll 是⼀种⾼效的I/O多路复⽤技术，尤其适⽤于⾼并发场景，但它仅\n在Linux平台上可⽤。⼀般来说，epoll的效率是要⽐select和poll⾼的，但是对于活动连接较多的时候，由于回调函\n数触发的很频繁，其效率不⼀定⽐select和poll⾼。所以epoll在连接数量很多，但活动连接较⼩的情况性能体现的\n⽐较明显。\nLinux 内存管理",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2204,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000090",
    "content": "显示器如何⼯作？即，printf 函数的⼯作流程\n\n键盘如何⼯作？\n中断处理（根据扫描码 获取 对应的 ascii 码）；\n将对应的 ascii 码 加⼊ 缓冲队列 read_que 中，等待上层程序调⽤\nLinux\n什么是IO多路复⽤\nI/O多路复⽤是⼀种在单个线程或进程中处理多个输⼊和输出操作的机制。它允许单个进程同时监视多个⽂件描述\n符(通常是套接字)，当⼀个或多个⽂件描述符准备好读或写时，它就可以⽴即响应。\nI/O多路复⽤通常通过select、poll、epoll等系统调⽤来实现。\nselect：  select是⼀个最古⽼的I/O多路复⽤机制，它可以监视多个⽂件描述符的可读、可写和错误状态。然\n⽽，但是它的效率可能随着监视的⽂件描述符数量的增加⽽降低。\npoll： poll是select的⼀种改进，它使⽤轮询⽅式来检查多个⽂件描述符的状态，避免了select中⽂件描述符\n数量有限的问题。但对于⼤量的⽂件描述符，poll的性能也可能变得不⾜够⾼效。\nepoll： epoll是Linux特有的I/O多路复⽤机制，相较于select和poll，它在处理⼤量⽂件描述符时更加⾼效。\nepoll使⽤事件通知的⽅式，只有在⽂件描述符就绪时才会通知应⽤程序，⽽不需要应⽤程序轮询。\nI/O多路复⽤允许在⼀个线程中处理多个I/O操作，避免了创建多个线程或进程的开销，允许在⼀个线程中处理多个\nI/O操作，避免了创建多个线程或进程的开销。\nselect/poll/epoll的区别和联系\nselect ,   poll 和epoll 都是I/O多路复⽤技术，它们⽤于同时处理多个I/O操作，特别是在⾼并发⽹络编程中。\nselect\nselect 是最早的I/O多路复⽤技术，它可以同时监视多个⽂件描述符（file descriptor, FD）的I/O状态（如可读、\n可写、异常等）。 select 函数使⽤⼀个⽂件描述符集合（通常是⼀个位图）来表示要监视的⽂件描述符，当有I/O\n事件发⽣时， select 会返回对应的⽂件描述符集合。\nselect的主要限制如下：\n⽂件描述符数量限制：  select 使⽤⼀个位图来表示⽂件描述符集合，这限制了它能够处理的⽂件描述符数量\n（通常是1024个）。\n效率问题：当⽂件描述符数量较⼤时， select 需要遍历整个⽂件描述符集合来查找就绪的⽂件描述符，这会\n导致较低的效率。\n⾮实时性：每次调⽤select  时，需要重新设置⽂件描述符集合，这会增加函数调⽤的开销。\npoll\npoll 是为了克服select 的限制⽽引⼊的⼀种I/O多路复⽤技术。 poll 使⽤⼀个⽂件描述符数组（通常是⼀个结\n构体数组）来表示要监视的⽂件描述符。与select 类似， poll 可以监视多个⽂件描述符的I/O状态。\npoll的优点如下：\n⽂件描述符数量不受限制：由于poll 使⽤⼀个动态数组来表示⽂件描述符，因此它可以处理任意数量的⽂件\n描述符。\n效率相对较⾼：  poll 在查找就绪的⽂件描述符时，只需要遍历实际使⽤的⽂件描述符数组，⽽不是整个⽂件\n描述符集合。\n然⽽， poll 仍然存在⼀些问题：\n效率问题：尽管poll 相对于select 具有较⾼的效率，但当⽂件描述符数量很⼤时，它仍然需要遍历整个⽂\n件描述符数组。\n⾮实时性：与select 类似，每次调⽤poll 时，需要重新设置⽂件描述符数组。\nepoll\nepoll 是Linux特有的⼀种⾼效I/O多路复⽤技术，它克服了 select 和poll 的主要限制。 epoll 使⽤⼀个事件驱\n动（event-driven）的⽅式来处理I/O操作，它只会返回就绪的⽂件描述符，⽽不是遍历整个⽂件描述符集合。\nepoll的主要优点如下：\n⾼效： epoll 使⽤事件驱动的⽅式来处理I/O操作，因此它在处理⼤量⽂件描述符时具有很⾼的效率。当有\nI/O事件发⽣时， epoll 可以⽴即得到通知，⽽⽆需遍历整个⽂件描述符集合。这使得epoll 在⾼并发场景中\n具有更好的性能。\n可扩展性：与poll 类似， epoll 可以处理任意数量的⽂件描述符，因为它使⽤⼀个动态数据结构来表示⽂件\n描述符。\n实时性： epoll 使⽤⼀个内核事件表来记录要监视的⽂件描述符和事件，因此在每次调⽤epoll 时⽆需重新\n设置⽂件描述符集合。这可以减少函数调⽤的开销，并提⾼实时性。\nepoll  具有诸多优点，但它⽬前仅在Linux平台上可⽤。对于其他平台，可能需要使⽤类似的I/O多路复⽤技术，如\nBSD中的 kqueue 。\n总结： select 是最早的I/O多路复⽤技术，但受到⽂件描述符数量和效率⽅⾯的限制。 poll 克服了⽂件描述符数\n量的限制，但仍然存在⼀定的效率问题。 epoll 是⼀种⾼效的I/O多路复⽤技术，尤其适⽤于⾼并发场景，但它仅\n在Linux平台上可⽤。⼀般来说，epoll的效率是要⽐select和poll⾼的，但是对于活动连接较多的时候，由于回调函\n数触发的很频繁，其效率不⼀定⽐select和poll⾼。所以epoll在连接数量很多，但活动连接较⼩的情况性能体现的\n⽐较明显。\nLinux 内存管理\n## 程序⽂件段\n包括程序的⼆进制可执⾏代码，只读；TEXT\n## 已初始化数据段\n包括已初始化的全局变量和静态常量；DATA\n## 未初始化数据段\n包括未初始化的静态变量和全局变量；BSS\n## 堆段\n包括动态分配的内存，从低地址开始向上增⻓；\n## ⽂件映射段\n包括动态库、共享内存等，从低地址开始向上增⻓（跟硬件和内核版本有关）；\n## 栈段\n包括函数的参数值和局部变量、函数调⽤的上下⽂等。栈的⼤⼩是固定的，⼀般是 8 MB 。当然系统也提供了参\n数，以便我们⾃定义⼤⼩；栈区是从⾼地址位向低地址位增⻓的\nLinux虚拟内存\n对32位处理器，虚拟内存空间为4G，每个进程都认为⾃⼰拥有4G的空间，实际上，在虚拟内存对应的物理内存\n上，可能只对应的⼀点点的物理内存。\n进程得到的这4G虚拟内存是⼀个连续的地址空间（这也只是进程认为），⽽实际上，它通常是被分隔成多个物理内\n存碎⽚，还有⼀部分存储在外部磁盘存储器上，在需要时进⾏数据交换。\n由于存在两个内存地址，因此⼀个应⽤程序从编写到被执⾏，需要进⾏两次映射。第⼀次是映射到虚拟内存空间，\n第⼆次时映射到物理内存空间。在计算机系统中，第两次映射的⼯作是由硬件和软件共同来完成的。承担这个任务\n的硬件部分叫做存储管理单元 MMU，软件部分就是操作系统的内存管理模块了。\n## 如何处理虚拟地址和物理地址的关系\n（1） 内存分⻚\n分⻚就是把整个虚拟和物理内存切成⼀段段固定⼤⼩的空间，连续且尺⼨固定的内存空间叫⻚，Linux下每⼀⻚⼤\n⼩4KB。虚拟内存和物理内存之间通过⻚表来映射。\n当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个缺⻚异常，进⼊系统内核空间分配物理内存、更新进程\n⻚表，最后再返回⽤户空间，恢复进程的运⾏。\n## 采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存，解决了内存碎\n⽚的问题\n## 内存空间不⾜时，操作系统将正在运⾏的进程中，最近没使⽤的内存⻚⾯释放（暂时写⼊硬盘）需要的时候再\n加载进来，⼀次性只有少数的⻚，解决了交换效率低的问题\n## 分⻚使我们在加载程序时，不⽤⼀次性加载到物理内存，可以只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥\n⾯的指令和数据时，再加载到物理内存⾥⾯去\n## 分⻚虚拟地址和物理地址是如何映射的\n虚拟地址分为：⻚号和⻚内偏移。\n⻚号作为⻚表的索引，⻚表包含物理⻚每⻚所在物理内存的基地址，这个基地址与⻚内偏移的组合就形成了物理内\n存地址。\n## 简单的分⻚缺陷\n空间上的缺陷：\n32位，单进程⼀个⻚4KB，虚拟内存4GB，就有2^20个⻚，⼀个⻚表项4字节，结果是4GB空间映射需要4*2^20 =\n4MB存储⻚表。多进程100，需要400MB。\n以⻚表⼀定要覆盖全部虚拟地址空间，不分级的⻚表就需要有 100 多万个⻚表项来映射，⼆级分⻚则只需要 1024\n个⻚表项（此时⼀级⻚表覆盖到了全部虚拟地址空间，⼆级⻚表在需要时创建）。\n## 段⻚式内存管理\n地址结构就由段号、段内⻚号和⻚内位移三部分组成。\n## 第⼀次访问段表，得到⻚表起始地址\n## 第⼆次访问⻚表，得到物理⻚号\n## 第三次将物理⻚号与⻚内位移组合，得到物理地址\n可⽤软、硬件相结合的⽅法实现段⻚式地址变换，这样虽然增加了硬件成本和系统开销，但提⾼了内存的利⽤率。\nLinux 信号\n信号是⽤户、系统、进程发送给⽬标进程的信息，通知某个状态的改变或系统异常。\nlinux常⽤信号：\n## SIGHUP控制终端挂起\n## SIGPIPE向读端关闭的通道或socket连接中写数据\n## SIGURG：socket连接上收到紧急数据\nLinux设计\n## MutiTask 多任务\n多个任务同时执⾏，同时可以是并发或并⾏。\n## SMP 对称多处理\n每个CPU地位相等，使⽤权限相同，多个CPU共享⼀个内存，每个 CPU 都可以访问完整的内存和硬件资源。\n## ELF 可执⾏⽂件链接格式\nLinux中可执⾏⽂件的存储格式。\n## Monolithic Kerne宏内核的特征是系统内核的所有模块\n⽐如进程调度、内存管理、⽂件系统、设备驱动等，都运⾏在内核态。Linux 的内核是⼀个完整的可执⾏程序，且\n拥有最⾼的权限。\nIO复⽤\n## I/O(数据交换过程)\n## 背景\nI/O即Input/Output（输⼊和输出），由于程序和运⾏时数据是在内存中驻留，由CPU这个超快的计算核⼼来执\n⾏，涉及到数据交换的地⽅，通常是磁盘、⽹络等，就需要IO接⼝。\nIO编程中涉及到流，其是相对于内存⽽⾔的，所以，Input Stream就是数据从外⾯（磁盘、⽹络）流进内存，\nOutput Stream就是数据从内存流到外⾯去。",
    "question": "显示器如何⼯作？即，printf 函数的⼯作流程",
    "answer": "键盘如何⼯作？\n中断处理（根据扫描码 获取 对应的 ascii 码）；\n将对应的 ascii 码 加⼊ 缓冲队列 read_que 中，等待上层程序调⽤\nLinux\n什么是IO多路复⽤\nI/O多路复⽤是⼀种在单个线程或进程中处理多个输⼊和输出操作的机制。它允许单个进程同时监视多个⽂件描述\n符(通常是套接字)，当⼀个或多个⽂件描述符准备好读或写时，它就可以⽴即响应。\nI/O多路复⽤通常通过select、poll、epoll等系统调⽤来实现。\nselect：  select是⼀个最古⽼的I/O多路复⽤机制，它可以监视多个⽂件描述符的可读、可写和错误状态。然\n⽽，但是它的效率可能随着监视的⽂件描述符数量的增加⽽降低。\npoll： poll是select的⼀种改进，它使⽤轮询⽅式来检查多个⽂件描述符的状态，避免了select中⽂件描述符\n数量有限的问题。但对于⼤量的⽂件描述符，poll的性能也可能变得不⾜够⾼效。\nepoll： epoll是Linux特有的I/O多路复⽤机制，相较于select和poll，它在处理⼤量⽂件描述符时更加⾼效。\nepoll使⽤事件通知的⽅式，只有在⽂件描述符就绪时才会通知应⽤程序，⽽不需要应⽤程序轮询。\nI/O多路复⽤允许在⼀个线程中处理多个I/O操作，避免了创建多个线程或进程的开销，允许在⼀个线程中处理多个\nI/O操作，避免了创建多个线程或进程的开销。\nselect/poll/epoll的区别和联系\nselect ,   poll 和epoll 都是I/O多路复⽤技术，它们⽤于同时处理多个I/O操作，特别是在⾼并发⽹络编程中。\nselect\nselect 是最早的I/O多路复⽤技术，它可以同时监视多个⽂件描述符（file descriptor, FD）的I/O状态（如可读、\n可写、异常等）。 select 函数使⽤⼀个⽂件描述符集合（通常是⼀个位图）来表示要监视的⽂件描述符，当有I/O\n事件发⽣时， select 会返回对应的⽂件描述符集合。\nselect的主要限制如下：\n⽂件描述符数量限制：  select 使⽤⼀个位图来表示⽂件描述符集合，这限制了它能够处理的⽂件描述符数量\n（通常是1024个）。\n效率问题：当⽂件描述符数量较⼤时， select 需要遍历整个⽂件描述符集合来查找就绪的⽂件描述符，这会\n导致较低的效率。\n⾮实时性：每次调⽤select  时，需要重新设置⽂件描述符集合，这会增加函数调⽤的开销。\npoll\npoll 是为了克服select 的限制⽽引⼊的⼀种I/O多路复⽤技术。 poll 使⽤⼀个⽂件描述符数组（通常是⼀个结\n构体数组）来表示要监视的⽂件描述符。与select 类似， poll 可以监视多个⽂件描述符的I/O状态。\npoll的优点如下：\n⽂件描述符数量不受限制：由于poll 使⽤⼀个动态数组来表示⽂件描述符，因此它可以处理任意数量的⽂件\n描述符。\n效率相对较⾼：  poll 在查找就绪的⽂件描述符时，只需要遍历实际使⽤的⽂件描述符数组，⽽不是整个⽂件\n描述符集合。\n然⽽， poll 仍然存在⼀些问题：\n效率问题：尽管poll 相对于select 具有较⾼的效率，但当⽂件描述符数量很⼤时，它仍然需要遍历整个⽂\n件描述符数组。\n⾮实时性：与select 类似，每次调⽤poll 时，需要重新设置⽂件描述符数组。\nepoll\nepoll 是Linux特有的⼀种⾼效I/O多路复⽤技术，它克服了 select 和poll 的主要限制。 epoll 使⽤⼀个事件驱\n动（event-driven）的⽅式来处理I/O操作，它只会返回就绪的⽂件描述符，⽽不是遍历整个⽂件描述符集合。\nepoll的主要优点如下：\n⾼效： epoll 使⽤事件驱动的⽅式来处理I/O操作，因此它在处理⼤量⽂件描述符时具有很⾼的效率。当有\nI/O事件发⽣时， epoll 可以⽴即得到通知，⽽⽆需遍历整个⽂件描述符集合。这使得epoll 在⾼并发场景中\n具有更好的性能。\n可扩展性：与poll 类似， epoll 可以处理任意数量的⽂件描述符，因为它使⽤⼀个动态数据结构来表示⽂件\n描述符。\n实时性： epoll 使⽤⼀个内核事件表来记录要监视的⽂件描述符和事件，因此在每次调⽤epoll 时⽆需重新\n设置⽂件描述符集合。这可以减少函数调⽤的开销，并提⾼实时性。\nepoll  具有诸多优点，但它⽬前仅在Linux平台上可⽤。对于其他平台，可能需要使⽤类似的I/O多路复⽤技术，如\nBSD中的 kqueue 。\n总结： select 是最早的I/O多路复⽤技术，但受到⽂件描述符数量和效率⽅⾯的限制。 poll 克服了⽂件描述符数\n量的限制，但仍然存在⼀定的效率问题。 epoll 是⼀种⾼效的I/O多路复⽤技术，尤其适⽤于⾼并发场景，但它仅\n在Linux平台上可⽤。⼀般来说，epoll的效率是要⽐select和poll⾼的，但是对于活动连接较多的时候，由于回调函\n数触发的很频繁，其效率不⼀定⽐select和poll⾼。所以epoll在连接数量很多，但活动连接较⼩的情况性能体现的\n⽐较明显。\nLinux 内存管理\n## 程序⽂件段\n包括程序的⼆进制可执⾏代码，只读；TEXT\n## 已初始化数据段\n包括已初始化的全局变量和静态常量；DATA\n## 未初始化数据段\n包括未初始化的静态变量和全局变量；BSS\n## 堆段\n包括动态分配的内存，从低地址开始向上增⻓；\n## ⽂件映射段\n包括动态库、共享内存等，从低地址开始向上增⻓（跟硬件和内核版本有关）；\n## 栈段\n包括函数的参数值和局部变量、函数调⽤的上下⽂等。栈的⼤⼩是固定的，⼀般是 8 MB 。当然系统也提供了参\n数，以便我们⾃定义⼤⼩；栈区是从⾼地址位向低地址位增⻓的\nLinux虚拟内存\n对32位处理器，虚拟内存空间为4G，每个进程都认为⾃⼰拥有4G的空间，实际上，在虚拟内存对应的物理内存\n上，可能只对应的⼀点点的物理内存。\n进程得到的这4G虚拟内存是⼀个连续的地址空间（这也只是进程认为），⽽实际上，它通常是被分隔成多个物理内\n存碎⽚，还有⼀部分存储在外部磁盘存储器上，在需要时进⾏数据交换。\n由于存在两个内存地址，因此⼀个应⽤程序从编写到被执⾏，需要进⾏两次映射。第⼀次是映射到虚拟内存空间，\n第⼆次时映射到物理内存空间。在计算机系统中，第两次映射的⼯作是由硬件和软件共同来完成的。承担这个任务\n的硬件部分叫做存储管理单元 MMU，软件部分就是操作系统的内存管理模块了。\n## 如何处理虚拟地址和物理地址的关系\n（1） 内存分⻚\n分⻚就是把整个虚拟和物理内存切成⼀段段固定⼤⼩的空间，连续且尺⼨固定的内存空间叫⻚，Linux下每⼀⻚⼤\n⼩4KB。虚拟内存和物理内存之间通过⻚表来映射。\n当进程访问的虚拟地址在⻚表中查不到时，系统会产⽣⼀个缺⻚异常，进⼊系统内核空间分配物理内存、更新进程\n⻚表，最后再返回⽤户空间，恢复进程的运⾏。\n## 采⽤了分⻚，那么释放的内存都是以⻚为单位释放的，也就不会产⽣⽆法给进程使⽤的⼩内存，解决了内存碎\n⽚的问题\n## 内存空间不⾜时，操作系统将正在运⾏的进程中，最近没使⽤的内存⻚⾯释放（暂时写⼊硬盘）需要的时候再\n加载进来，⼀次性只有少数的⻚，解决了交换效率低的问题\n## 分⻚使我们在加载程序时，不⽤⼀次性加载到物理内存，可以只有在程序运⾏中，需要⽤到对应虚拟内存⻚⾥\n⾯的指令和数据时，再加载到物理内存⾥⾯去\n## 分⻚虚拟地址和物理地址是如何映射的\n虚拟地址分为：⻚号和⻚内偏移。\n⻚号作为⻚表的索引，⻚表包含物理⻚每⻚所在物理内存的基地址，这个基地址与⻚内偏移的组合就形成了物理内\n存地址。\n## 简单的分⻚缺陷\n空间上的缺陷：\n32位，单进程⼀个⻚4KB，虚拟内存4GB，就有2^20个⻚，⼀个⻚表项4字节，结果是4GB空间映射需要4*2^20 =\n4MB存储⻚表。多进程100，需要400MB。\n以⻚表⼀定要覆盖全部虚拟地址空间，不分级的⻚表就需要有 100 多万个⻚表项来映射，⼆级分⻚则只需要 1024\n个⻚表项（此时⼀级⻚表覆盖到了全部虚拟地址空间，⼆级⻚表在需要时创建）。\n## 段⻚式内存管理\n地址结构就由段号、段内⻚号和⻚内位移三部分组成。\n## 第⼀次访问段表，得到⻚表起始地址\n## 第⼆次访问⻚表，得到物理⻚号\n## 第三次将物理⻚号与⻚内位移组合，得到物理地址\n可⽤软、硬件相结合的⽅法实现段⻚式地址变换，这样虽然增加了硬件成本和系统开销，但提⾼了内存的利⽤率。\nLinux 信号\n信号是⽤户、系统、进程发送给⽬标进程的信息，通知某个状态的改变或系统异常。\nlinux常⽤信号：\n## SIGHUP控制终端挂起\n## SIGPIPE向读端关闭的通道或socket连接中写数据\n## SIGURG：socket连接上收到紧急数据\nLinux设计\n## MutiTask 多任务\n多个任务同时执⾏，同时可以是并发或并⾏。\n## SMP 对称多处理\n每个CPU地位相等，使⽤权限相同，多个CPU共享⼀个内存，每个 CPU 都可以访问完整的内存和硬件资源。\n## ELF 可执⾏⽂件链接格式\nLinux中可执⾏⽂件的存储格式。\n## Monolithic Kerne宏内核的特征是系统内核的所有模块\n⽐如进程调度、内存管理、⽂件系统、设备驱动等，都运⾏在内核态。Linux 的内核是⼀个完整的可执⾏程序，且\n拥有最⾼的权限。\nIO复⽤\n## I/O(数据交换过程)\n## 背景\nI/O即Input/Output（输⼊和输出），由于程序和运⾏时数据是在内存中驻留，由CPU这个超快的计算核⼼来执\n⾏，涉及到数据交换的地⽅，通常是磁盘、⽹络等，就需要IO接⼝。\nIO编程中涉及到流，其是相对于内存⽽⾔的，所以，Input Stream就是数据从外⾯（磁盘、⽹络）流进内存，\nOutput Stream就是数据从内存流到外⾯去。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 4137,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000091",
    "content": "## 概念\n\nI/O操作就是在运⾏代码的过程中，可能需要对⽂件的读写，即将⽂件输⼊（Input）到内存和将代码执⾏结果产⽣\n的⽂件输出（Output）到外设（⽹络、磁盘）的过程。\n## 分类\n## ⽹络I/O：通过⽹络进⾏数据的拉取和输出;\n## 磁盘I/O：主要是对磁盘进⾏读写⼯作。\n## 五种IO模型\n## 输⼊阶段⼀般操作\n## 等待数据准备好\n## 从内核向进程复制数据\n## 例如：\n## 等待数据从⽹络中到达：所等分组到达时，被复制到内核中的某个缓冲区\n## 把数据从内核缓冲区复制到应⽤进程缓冲区\n## 分类\n## 阻塞式I/O\n## ⾮阻塞式I/O\n## I/O复⽤（select和poll）\n## 信号驱动式I/O（SIGIO）\n## 异步I/O（POSIX的aio_系列函数）\n## 同步I/O\n（1） 阻塞式I/O\n进程或线程等待某个条件，如果条件不满⾜，则⼀直等下去。条件满⾜，则进⾏下⼀步操作。（默认情况下）\n应⽤进程通过系统调⽤ recvfrom 接收数据，但由于内核还未准备好数据报，应⽤进程就会阻塞住，直到内核准备\n好数据报，recvfrom 完成数据报复制⼯作，应⽤进程才能结束阻塞状态。\n设备⽂件不可操作时，可进⼊休眠状态，将CPU资源让出；当设备⽂件可以操作的时候就必须唤醒进程，⼀般在中\n断函数中完成唤醒⼯作;\n耗费时间，适合并发低，时效性要求低的情况。\n（2） ⾮阻塞式I/O\n应⽤进程与内核交互，⽬的未达到之前，不再⼀味的等着，⽽是直接返回;\n通过轮询的⽅式，不停的去问内核数据有没有准备好。如果某⼀次轮询发现数据已经准备好了，那就把数据拷⻉到\n⽤户空间中。\n前三次调⽤ recvfrom 时没有数据可返回，内核⽴即返回 EWOULDBLOCK 错误\n第四次调⽤ recvfrom 时，已有⼀个数据报准备好，将其从内核复制到应⽤进程缓冲区， recvfrom 成功返回;\n轮询（polling）：\n应⽤进程持续轮询内核，以查看某个操作是否就绪;\n缺点：往往耗费⼤量CPU时间。\n（3） IO复⽤\n通过调⽤  select  或  poll，阻塞在这两个系统调⽤中的某⼀个之上，⽽不是阻塞在真正的I/O系统调⽤上。\n阻塞于 select 调⽤，等待数据报套接字变为可读，当 select 返回套接字可读这⼀条件时，调⽤ recvfrom 把所读数\n据报复制到应⽤进程缓存区。\n多个进程I/O注册到同⼀个 select，当⽤户进程调⽤ select，select 监听所有注册好的IO：\n## 若所有被监听的I/O需要的数据未准备好，则阻塞\n## 任意⼀个所需数据准备好后，select  调⽤返回\n## ⽤户进程通过 recvfrom 进⾏数据拷⻉\n优点：可以等待多个描述符就绪。\n（4） 信号驱动I/O\n开启套接字信号驱动I/O功能，通过 sigaction 系统调⽤安装⼀个信号处理函数，该系统函数⽴即返回，不阻塞;\n数据报准备好后，内核为该进程产⽣⼀个 SIGIO 信号递交给进程;\n可以在信号处理函数中调⽤ recvfrom 读取数据报，通知主循环数据已准备好待处理;\n可以⽴即通知主循环，读取数据报。\n等待数据报到达期间进程不被阻塞。主循环可以继续执⾏，等待来⾃信号处理函数的通知：既可以是数据已经准备\n好被处理，也可以是数据报已经准备好被读取。\n（5） 异步IO\n⽤户进程告知内核启动某个操作，并由内核在整个操作中完成后通知⽤户进程。\n与信号驱动I/O的区别：\n## 信号驱动I/O是由内核通知我们何时可以启动⼀个I/O操作\n## 异步I/O是由内核通知我们I/O操作何时完成\n步骤：\n## ⽤户进程调⽤aio_read函数，给内核传递描述符、缓冲区指针、缓冲区⼤⼩和⽂件偏移，告诉内核整个操作完\n成时如何通知我们，然后就⽴刻去做其他事情;\n## 当内核收到aio_read后，会⽴刻返回，然后内核开始等待数据准备，数据准备好以后，直接把数据拷⻉到⽤户\n空间，然后再通知进程本次IO已经完成。\n## 各种IO模型的⽐较\n## 同步I/O\n导致请求进程阻塞，直到I/O操作完成;\n四种同步模型的区别在于第⼀阶段等待数据的处理⽅式不同，第⼆阶段均为将数据从内核空间复制到⽤户空间缓冲\n区期间，进程阻塞于recvfrom调⽤。\n## 异步I/O\n不导致请求进程阻塞。\n## I/O复⽤函数\n多路复⽤接⼝ select/poll/epoll ，内核提供给⽤户态的多路复⽤系统调⽤，进程可以通过⼀个系统调⽤函数从内核\n中获取多个事件：\n（1） select-->两次遍历+两次拷⻉",
    "question": "## 概念",
    "answer": "I/O操作就是在运⾏代码的过程中，可能需要对⽂件的读写，即将⽂件输⼊（Input）到内存和将代码执⾏结果产⽣\n的⽂件输出（Output）到外设（⽹络、磁盘）的过程。\n## 分类\n## ⽹络I/O：通过⽹络进⾏数据的拉取和输出;\n## 磁盘I/O：主要是对磁盘进⾏读写⼯作。\n## 五种IO模型\n## 输⼊阶段⼀般操作\n## 等待数据准备好\n## 从内核向进程复制数据\n## 例如：\n## 等待数据从⽹络中到达：所等分组到达时，被复制到内核中的某个缓冲区\n## 把数据从内核缓冲区复制到应⽤进程缓冲区\n## 分类\n## 阻塞式I/O\n## ⾮阻塞式I/O\n## I/O复⽤（select和poll）\n## 信号驱动式I/O（SIGIO）\n## 异步I/O（POSIX的aio_系列函数）\n## 同步I/O\n（1） 阻塞式I/O\n进程或线程等待某个条件，如果条件不满⾜，则⼀直等下去。条件满⾜，则进⾏下⼀步操作。（默认情况下）\n应⽤进程通过系统调⽤ recvfrom 接收数据，但由于内核还未准备好数据报，应⽤进程就会阻塞住，直到内核准备\n好数据报，recvfrom 完成数据报复制⼯作，应⽤进程才能结束阻塞状态。\n设备⽂件不可操作时，可进⼊休眠状态，将CPU资源让出；当设备⽂件可以操作的时候就必须唤醒进程，⼀般在中\n断函数中完成唤醒⼯作;\n耗费时间，适合并发低，时效性要求低的情况。\n（2） ⾮阻塞式I/O\n应⽤进程与内核交互，⽬的未达到之前，不再⼀味的等着，⽽是直接返回;\n通过轮询的⽅式，不停的去问内核数据有没有准备好。如果某⼀次轮询发现数据已经准备好了，那就把数据拷⻉到\n⽤户空间中。\n前三次调⽤ recvfrom 时没有数据可返回，内核⽴即返回 EWOULDBLOCK 错误\n第四次调⽤ recvfrom 时，已有⼀个数据报准备好，将其从内核复制到应⽤进程缓冲区， recvfrom 成功返回;\n轮询（polling）：\n应⽤进程持续轮询内核，以查看某个操作是否就绪;\n缺点：往往耗费⼤量CPU时间。\n（3） IO复⽤\n通过调⽤  select  或  poll，阻塞在这两个系统调⽤中的某⼀个之上，⽽不是阻塞在真正的I/O系统调⽤上。\n阻塞于 select 调⽤，等待数据报套接字变为可读，当 select 返回套接字可读这⼀条件时，调⽤ recvfrom 把所读数\n据报复制到应⽤进程缓存区。\n多个进程I/O注册到同⼀个 select，当⽤户进程调⽤ select，select 监听所有注册好的IO：\n## 若所有被监听的I/O需要的数据未准备好，则阻塞\n## 任意⼀个所需数据准备好后，select  调⽤返回\n## ⽤户进程通过 recvfrom 进⾏数据拷⻉\n优点：可以等待多个描述符就绪。\n（4） 信号驱动I/O\n开启套接字信号驱动I/O功能，通过 sigaction 系统调⽤安装⼀个信号处理函数，该系统函数⽴即返回，不阻塞;\n数据报准备好后，内核为该进程产⽣⼀个 SIGIO 信号递交给进程;\n可以在信号处理函数中调⽤ recvfrom 读取数据报，通知主循环数据已准备好待处理;\n可以⽴即通知主循环，读取数据报。\n等待数据报到达期间进程不被阻塞。主循环可以继续执⾏，等待来⾃信号处理函数的通知：既可以是数据已经准备\n好被处理，也可以是数据报已经准备好被读取。\n（5） 异步IO\n⽤户进程告知内核启动某个操作，并由内核在整个操作中完成后通知⽤户进程。\n与信号驱动I/O的区别：\n## 信号驱动I/O是由内核通知我们何时可以启动⼀个I/O操作\n## 异步I/O是由内核通知我们I/O操作何时完成\n步骤：\n## ⽤户进程调⽤aio_read函数，给内核传递描述符、缓冲区指针、缓冲区⼤⼩和⽂件偏移，告诉内核整个操作完\n成时如何通知我们，然后就⽴刻去做其他事情;\n## 当内核收到aio_read后，会⽴刻返回，然后内核开始等待数据准备，数据准备好以后，直接把数据拷⻉到⽤户\n空间，然后再通知进程本次IO已经完成。\n## 各种IO模型的⽐较\n## 同步I/O\n导致请求进程阻塞，直到I/O操作完成;\n四种同步模型的区别在于第⼀阶段等待数据的处理⽅式不同，第⼆阶段均为将数据从内核空间复制到⽤户空间缓冲\n区期间，进程阻塞于recvfrom调⽤。\n## 异步I/O\n不导致请求进程阻塞。\n## I/O复⽤函数\n多路复⽤接⼝ select/poll/epoll ，内核提供给⽤户态的多路复⽤系统调⽤，进程可以通过⼀个系统调⽤函数从内核\n中获取多个事件：\n（1） select-->两次遍历+两次拷⻉",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1913,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000092",
    "content": "## I/O复⽤函数\n\n多路复⽤接⼝ select/poll/epoll ，内核提供给⽤户态的多路复⽤系统调⽤，进程可以通过⼀个系统调⽤函数从内核\n中获取多个事件：\n（1） select-->两次遍历+两次拷⻉\n把已连接的socket放在⼀个⽂件描述符集合，调⽤ select 函数将⽂件描述符集合拷⻉到内核⾥，让内核来检查是否\n有⽹络事件产⽣；\n通过遍历，有事件产⽣就把此socket标记为可读/可写，然后再整个拷⻉回⽤户态；\n⽤户态还需要遍历找到刚刚标记的socket。\n（2） poll\n动态数组，以链表形式来组织，相⽐于select，没有⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。\n（3） epoll(event poll)-->红⿊树\n在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字。\n调⽤epoll_ctl() 函数，把需要监控的 socket 加⼊内核中的红⿊树⾥：（红⿊树的增删查时间复杂度是O(logn)，不\n需要每次操作都传⼊整个集合，只需要传⼊⼀个待检测的socket，减少了内核和⽤户空间的⼤量数据拷⻉和内存分\nepoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件（当某个 socket 有事件发⽣时，通过回调函\n数，内核会将其加⼊到这个就绪事件列表中）\n当⽤户调⽤ epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select/poll 那样轮询扫描整\n个 socket 集合，⼤⼤提⾼了检测的效率。\n（4） epoll触发模式\nepoll⽀持的事件触发模式：\n(1)边缘触发ET\n(2)⽔平触发LT\n边缘触发模式ET：\n当被监控的 Socket 描述符上有可读事件发⽣时，服务器只会从 epoll_wait中苏醒⼀次，即使进程没有调⽤ read 函\n数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完，只有第⼀次满⾜\n条件的时候才触发，之后就不会再传递同样的事件了。\n⽔平触发模式LT：\n当被监控的 Socket 上有可读事件发⽣时，服务器不断地从 epoll_wait中苏醒，直到内核缓冲区数据被 read 函数读\n完才结束，⽬的是告诉我们有数据，只要满⾜事件的条件，⽐如内核中有数据需要读，就⼀直不断地把这个事件传\n递给⽤户。\n（5） select和epoll的区别",
    "question": "## I/O复⽤函数",
    "answer": "多路复⽤接⼝ select/poll/epoll ，内核提供给⽤户态的多路复⽤系统调⽤，进程可以通过⼀个系统调⽤函数从内核\n中获取多个事件：\n（1） select-->两次遍历+两次拷⻉\n把已连接的socket放在⼀个⽂件描述符集合，调⽤ select 函数将⽂件描述符集合拷⻉到内核⾥，让内核来检查是否\n有⽹络事件产⽣；\n通过遍历，有事件产⽣就把此socket标记为可读/可写，然后再整个拷⻉回⽤户态；\n⽤户态还需要遍历找到刚刚标记的socket。\n（2） poll\n动态数组，以链表形式来组织，相⽐于select，没有⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。\n（3） epoll(event poll)-->红⿊树\n在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字。\n调⽤epoll_ctl() 函数，把需要监控的 socket 加⼊内核中的红⿊树⾥：（红⿊树的增删查时间复杂度是O(logn)，不\n需要每次操作都传⼊整个集合，只需要传⼊⼀个待检测的socket，减少了内核和⽤户空间的⼤量数据拷⻉和内存分\nepoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件（当某个 socket 有事件发⽣时，通过回调函\n数，内核会将其加⼊到这个就绪事件列表中）\n当⽤户调⽤ epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select/poll 那样轮询扫描整\n个 socket 集合，⼤⼤提⾼了检测的效率。\n（4） epoll触发模式\nepoll⽀持的事件触发模式：\n(1)边缘触发ET\n(2)⽔平触发LT\n边缘触发模式ET：\n当被监控的 Socket 描述符上有可读事件发⽣时，服务器只会从 epoll_wait中苏醒⼀次，即使进程没有调⽤ read 函\n数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完，只有第⼀次满⾜\n条件的时候才触发，之后就不会再传递同样的事件了。\n⽔平触发模式LT：\n当被监控的 Socket 上有可读事件发⽣时，服务器不断地从 epoll_wait中苏醒，直到内核缓冲区数据被 read 函数读\n完才结束，⽬的是告诉我们有数据，只要满⾜事件的条件，⽐如内核中有数据需要读，就⼀直不断地把这个事件传\n递给⽤户。\n（5） select和epoll的区别",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 997,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000093",
    "content": "把已连接的socket放在⼀个⽂件描述符集合，调⽤ select 函数将⽂件描述符集合拷⻉到内核⾥，让内核来检查是否\n\n有⽹络事件产⽣；\n通过遍历，有事件产⽣就把此socket标记为可读/可写，然后再整个拷⻉回⽤户态；\n⽤户态还需要遍历找到刚刚标记的socket。\n（2） poll\n动态数组，以链表形式来组织，相⽐于select，没有⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。\n（3） epoll(event poll)-->红⿊树\n在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字。\n调⽤epoll_ctl() 函数，把需要监控的 socket 加⼊内核中的红⿊树⾥：（红⿊树的增删查时间复杂度是O(logn)，不\n需要每次操作都传⼊整个集合，只需要传⼊⼀个待检测的socket，减少了内核和⽤户空间的⼤量数据拷⻉和内存分\nepoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件（当某个 socket 有事件发⽣时，通过回调函\n数，内核会将其加⼊到这个就绪事件列表中）\n当⽤户调⽤ epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select/poll 那样轮询扫描整\n个 socket 集合，⼤⼤提⾼了检测的效率。\n（4） epoll触发模式\nepoll⽀持的事件触发模式：\n(1)边缘触发ET\n(2)⽔平触发LT\n边缘触发模式ET：\n当被监控的 Socket 描述符上有可读事件发⽣时，服务器只会从 epoll_wait中苏醒⼀次，即使进程没有调⽤ read 函\n数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完，只有第⼀次满⾜\n条件的时候才触发，之后就不会再传递同样的事件了。\n⽔平触发模式LT：\n当被监控的 Socket 上有可读事件发⽣时，服务器不断地从 epoll_wait中苏醒，直到内核缓冲区数据被 read 函数读\n完才结束，⽬的是告诉我们有数据，只要满⾜事件的条件，⽐如内核中有数据需要读，就⼀直不断地把这个事件传\n递给⽤户。",
    "question": "把已连接的socket放在⼀个⽂件描述符集合，调⽤ select 函数将⽂件描述符集合拷⻉到内核⾥，让内核来检查是否",
    "answer": "有⽹络事件产⽣；\n通过遍历，有事件产⽣就把此socket标记为可读/可写，然后再整个拷⻉回⽤户态；\n⽤户态还需要遍历找到刚刚标记的socket。\n（2） poll\n动态数组，以链表形式来组织，相⽐于select，没有⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。\n（3） epoll(event poll)-->红⿊树\n在内核⾥使⽤红⿊树来跟踪进程所有待检测的⽂件描述字。\n调⽤epoll_ctl() 函数，把需要监控的 socket 加⼊内核中的红⿊树⾥：（红⿊树的增删查时间复杂度是O(logn)，不\n需要每次操作都传⼊整个集合，只需要传⼊⼀个待检测的socket，减少了内核和⽤户空间的⼤量数据拷⻉和内存分\nepoll 使⽤事件驱动的机制，内核⾥维护了⼀个链表来记录就绪事件（当某个 socket 有事件发⽣时，通过回调函\n数，内核会将其加⼊到这个就绪事件列表中）\n当⽤户调⽤ epoll_wait() 函数时，只会返回有事件发⽣的⽂件描述符的个数，不需要像 select/poll 那样轮询扫描整\n个 socket 集合，⼤⼤提⾼了检测的效率。\n（4） epoll触发模式\nepoll⽀持的事件触发模式：\n(1)边缘触发ET\n(2)⽔平触发LT\n边缘触发模式ET：\n当被监控的 Socket 描述符上有可读事件发⽣时，服务器只会从 epoll_wait中苏醒⼀次，即使进程没有调⽤ read 函\n数从内核读取数据，也依然只苏醒⼀次，因此我们程序要保证⼀次性将内核缓冲区的数据读取完，只有第⼀次满⾜\n条件的时候才触发，之后就不会再传递同样的事件了。\n⽔平触发模式LT：\n当被监控的 Socket 上有可读事件发⽣时，服务器不断地从 epoll_wait中苏醒，直到内核缓冲区数据被 read 函数读\n完才结束，⽬的是告诉我们有数据，只要满⾜事件的条件，⽐如内核中有数据需要读，就⼀直不断地把这个事件传\n递给⽤户。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 872,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000094",
    "content": "（5） select和epoll的区别\n\n## select 和 poll 采⽤轮询的⽅式检查就绪事件，每次都要扫描整个⽂件描述符，复杂度O(N);\n## epoll  采⽤回调⽅式检查就绪事件，只会返回有事件发⽣的⽂件描述符的个数，复杂度O(1);\n## select 只⼯作在低效的LT模式，epoll 可以在 ET ⾼效模式⼯作;\n## epoll 是 Linux 所特有，⽽ select 则应该是 POSIX 所规定，⼀般操作系统均有实现;\n## select 单个进程可监视的fd数量有限，即能监听端⼝的⼤⼩有限，64位是2048；epoll 没有最⼤并发连接的限\n制，能打开的 fd 的上限远⼤于2048（1G的内存上能监听约10万个端⼝）;\n## select 内核需要将消息传递到⽤户空间，都需要内核拷⻉动作；epoll通过内核和⽤户空间共享⼀块内存来实\n现的。\nLinux⽹络\n如何在基本⽹络通信模型基础上提升服务器⾃身服务响应？\n## 多进程服务器\n每次的请求⽗进程fork出⼦进程进⾏业务处理，⽗进程⽤于处理请求连接\n（1） ⽗⼦进程的⽣命周期绝⼤多数都不相同，如何、何时进⾏销毁，才能确保不会⼤量出僵⼫进程\n（2） ⼦⽗进程之间如何进⾏通讯？\n进程的创建、切换都需要都会带来⼤量的开销，同时每个进程都具有⾃⼰独⽴的虚拟内存空间，所以需要使⽤到\nIPC机制，完成进程间的数据交换\n## I/O复⽤服务器\n## 在不额外创建进程的基础上同时为多个请求端提供请求",
    "question": "（5） select和epoll的区别",
    "answer": "## select 和 poll 采⽤轮询的⽅式检查就绪事件，每次都要扫描整个⽂件描述符，复杂度O(N);\n## epoll  采⽤回调⽅式检查就绪事件，只会返回有事件发⽣的⽂件描述符的个数，复杂度O(1);\n## select 只⼯作在低效的LT模式，epoll 可以在 ET ⾼效模式⼯作;\n## epoll 是 Linux 所特有，⽽ select 则应该是 POSIX 所规定，⼀般操作系统均有实现;\n## select 单个进程可监视的fd数量有限，即能监听端⼝的⼤⼩有限，64位是2048；epoll 没有最⼤并发连接的限\n制，能打开的 fd 的上限远⼤于2048（1G的内存上能监听约10万个端⼝）;\n## select 内核需要将消息传递到⽤户空间，都需要内核拷⻉动作；epoll通过内核和⽤户空间共享⼀块内存来实\n现的。\nLinux⽹络\n如何在基本⽹络通信模型基础上提升服务器⾃身服务响应？\n## 多进程服务器\n每次的请求⽗进程fork出⼦进程进⾏业务处理，⽗进程⽤于处理请求连接\n（1） ⽗⼦进程的⽣命周期绝⼤多数都不相同，如何、何时进⾏销毁，才能确保不会⼤量出僵⼫进程\n（2） ⼦⽗进程之间如何进⾏通讯？\n进程的创建、切换都需要都会带来⼤量的开销，同时每个进程都具有⾃⼰独⽴的虚拟内存空间，所以需要使⽤到\nIPC机制，完成进程间的数据交换\n## I/O复⽤服务器\n## 在不额外创建进程的基础上同时为多个请求端提供请求",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 641,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000095",
    "content": "## select、poll、epoll实现优缺点\n\n## 多线程服务器\n同⼀进程下的多个线程共享进程的系统资源，所以相⽐于多进程，同进程下的多线程通信更加⽅便，并且切\n换的开销⼩很多。\n## 如何创建、销毁线程\n## 如何保证线程的安全\n## 线程间的通信\nLinux中的软链接和硬链接有什么区别？\n物理实现：\n软链接：   软链接是⼀个独⽴的⽂件，它包含了指向⽬标⽂件或⽬录的路径。软链接实际上是⼀个特殊的\n⽂件，其中包含有关⽬标⽂件的引⽤。\n硬链接： 硬链接是⽬标⽂件的⼀个额外的⽬录项。⽬录项指向相同的物理数据块，实际上只是⽂件系统中\n的两个或多个⽬录项指向相同的inode。\n链接的⽬标：\n软链接：  软链接可以链接到⽂件或⽬录，甚⾄可以链接到不存在的⽂件。\n硬链接：  硬链接只能链接到⽂件，⽽且必须是同⼀⽂件系统中的。\n对链接的影响：\n软链接： 如果原始⽂件被删除或移动，软链接仍然存在，但链接将失效。软链接可以跨⽂件系统，但如\n果⽬标⽂件被删除，软链接将成为坏链接（dangling link）。\n硬链接： 删除或移动原始⽂件并不会影响硬链接，因为硬链接只是inode的另⼀个引⽤。只有当所有硬\n链接都被删除后，inode的数据块才会被释放。\n创建⽅式：\n软链接： 使⽤ln -s 命令创建软链接。例如， ln -s target_file link_name 。\n硬链接： 使⽤ln 命令创建硬链接。例如， ln target_file link_name 。\n链接数量：\n软链接：  软链接只会增加⽬标⽂件的链接计数，⽽不会增加inode的链接计数。\n硬链接： 硬链接会增加⽬标⽂件的链接计数，也会增加inode的链接计数。当链接计数为零时，⽂件系\n统才会释放相关的数据块。\n什么是中断和异常\n中断和异常都会导致处理器暂停当前正在执⾏的任务，并转向执⾏⼀个特定的处理程序（中断处理程序或异常处理\n程序）。然后在处理完这些特殊情况后，处理器会返回到被打断的任务继续执⾏。\n## 中断是由计算机系统外部事件触发的，通常与硬件设备相关。中断的⽬的是为了及时响应重要事件⽽暂时中断\n正常的程序执⾏。典型的中断包括时钟中断、I/O设备中断（如键盘输⼊、⿏标事件）和硬件错误中断等。操\n作系统通常会为每种类型的中断分配⼀个中断处理程序，⽤于处理相应的事件。\n## 异常是由计算机系统内部事件触发的，通常与正在执⾏的程序或指令有关，⽐如程序的⾮法操作码、地址越\n界、运算溢出等错误引起的事件，异常不能被屏蔽，当出现异常时，计算机系统会暂停正常的执⾏流程，并转\n到异常处理程序来处理该异常。\n⽤户态和核⼼态",
    "question": "## select、poll、epoll实现优缺点",
    "answer": "## 多线程服务器\n同⼀进程下的多个线程共享进程的系统资源，所以相⽐于多进程，同进程下的多线程通信更加⽅便，并且切\n换的开销⼩很多。\n## 如何创建、销毁线程\n## 如何保证线程的安全\n## 线程间的通信\nLinux中的软链接和硬链接有什么区别？\n物理实现：\n软链接：   软链接是⼀个独⽴的⽂件，它包含了指向⽬标⽂件或⽬录的路径。软链接实际上是⼀个特殊的\n⽂件，其中包含有关⽬标⽂件的引⽤。\n硬链接： 硬链接是⽬标⽂件的⼀个额外的⽬录项。⽬录项指向相同的物理数据块，实际上只是⽂件系统中\n的两个或多个⽬录项指向相同的inode。\n链接的⽬标：\n软链接：  软链接可以链接到⽂件或⽬录，甚⾄可以链接到不存在的⽂件。\n硬链接：  硬链接只能链接到⽂件，⽽且必须是同⼀⽂件系统中的。\n对链接的影响：\n软链接： 如果原始⽂件被删除或移动，软链接仍然存在，但链接将失效。软链接可以跨⽂件系统，但如\n果⽬标⽂件被删除，软链接将成为坏链接（dangling link）。\n硬链接： 删除或移动原始⽂件并不会影响硬链接，因为硬链接只是inode的另⼀个引⽤。只有当所有硬\n链接都被删除后，inode的数据块才会被释放。\n创建⽅式：\n软链接： 使⽤ln -s 命令创建软链接。例如， ln -s target_file link_name 。\n硬链接： 使⽤ln 命令创建硬链接。例如， ln target_file link_name 。\n链接数量：\n软链接：  软链接只会增加⽬标⽂件的链接计数，⽽不会增加inode的链接计数。\n硬链接： 硬链接会增加⽬标⽂件的链接计数，也会增加inode的链接计数。当链接计数为零时，⽂件系\n统才会释放相关的数据块。\n什么是中断和异常\n中断和异常都会导致处理器暂停当前正在执⾏的任务，并转向执⾏⼀个特定的处理程序（中断处理程序或异常处理\n程序）。然后在处理完这些特殊情况后，处理器会返回到被打断的任务继续执⾏。\n## 中断是由计算机系统外部事件触发的，通常与硬件设备相关。中断的⽬的是为了及时响应重要事件⽽暂时中断\n正常的程序执⾏。典型的中断包括时钟中断、I/O设备中断（如键盘输⼊、⿏标事件）和硬件错误中断等。操\n作系统通常会为每种类型的中断分配⼀个中断处理程序，⽤于处理相应的事件。\n## 异常是由计算机系统内部事件触发的，通常与正在执⾏的程序或指令有关，⽐如程序的⾮法操作码、地址越\n界、运算溢出等错误引起的事件，异常不能被屏蔽，当出现异常时，计算机系统会暂停正常的执⾏流程，并转\n到异常处理程序来处理该异常。\n⽤户态和核⼼态",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1105,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000096",
    "content": "## ⽤户态和内核态的区别\n\n⽤户态（User Mode） 和内核态（Kernel Mode） 是操作系统为了保护系统资源和实现权限控制⽽设计的两种不\n同的CPU运⾏级别，可以控制进程或程序对计算机硬件资源的访问权限和操作范围。\n⽤户态：在⽤户态下，进程或程序只能访问受限的资源和执⾏受限的指令集，不能直接访问操作系统的核⼼部\n分，也不能直接访问硬件资源。\n核⼼态：核⼼态是操作系统的特权级别，允许进程或程序执⾏特权指令和访问操作系统的核⼼部分。在核⼼态\n下，进程可以直接访问硬件资源，执⾏系统调⽤，管理内存、⽂件系统等操作。\n## 在什么场景下，会发⽣内核态和⽤户态的切换\n系统调⽤：当⽤户程序需要请求操作系统提供的服务时，会通过系统调⽤进⼊内核态。\n异常：当程序执⾏过程中出现错误或异常情况时，CPU会⾃动切换到内核态，以便操作系统能够处理这些异\n中断：外部设备（如键盘、⿏标、磁盘等）产⽣的中断信号会使CPU从⽤户态切换到内核态。操作系统会处理\n这些中断，执⾏相应的中断处理程序，然后再将CPU切换回⽤户态。",
    "question": "## ⽤户态和内核态的区别",
    "answer": "⽤户态（User Mode） 和内核态（Kernel Mode） 是操作系统为了保护系统资源和实现权限控制⽽设计的两种不\n同的CPU运⾏级别，可以控制进程或程序对计算机硬件资源的访问权限和操作范围。\n⽤户态：在⽤户态下，进程或程序只能访问受限的资源和执⾏受限的指令集，不能直接访问操作系统的核⼼部\n分，也不能直接访问硬件资源。\n核⼼态：核⼼态是操作系统的特权级别，允许进程或程序执⾏特权指令和访问操作系统的核⼼部分。在核⼼态\n下，进程可以直接访问硬件资源，执⾏系统调⽤，管理内存、⽂件系统等操作。\n## 在什么场景下，会发⽣内核态和⽤户态的切换\n系统调⽤：当⽤户程序需要请求操作系统提供的服务时，会通过系统调⽤进⼊内核态。\n异常：当程序执⾏过程中出现错误或异常情况时，CPU会⾃动切换到内核态，以便操作系统能够处理这些异\n中断：外部设备（如键盘、⿏标、磁盘等）产⽣的中断信号会使CPU从⽤户态切换到内核态。操作系统会处理\n这些中断，执⾏相应的中断处理程序，然后再将CPU切换回⽤户态。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 457,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000097",
    "content": "## 在什么场景下，会发⽣内核态和⽤户态的切换\n\n系统调⽤：当⽤户程序需要请求操作系统提供的服务时，会通过系统调⽤进⼊内核态。\n异常：当程序执⾏过程中出现错误或异常情况时，CPU会⾃动切换到内核态，以便操作系统能够处理这些异\n中断：外部设备（如键盘、⿏标、磁盘等）产⽣的中断信号会使CPU从⽤户态切换到内核态。操作系统会处理\n这些中断，执⾏相应的中断处理程序，然后再将CPU切换回⽤户态。\n并⾏和并发是什么\n并⾏是在同⼀时刻执⾏多个任务。\n并发是在相同的时间段内执⾏多个任务，任务可能交替执⾏，通过调度实现。\n并⾏是指在同⼀时刻执⾏多个任务，这些任务可以同时进⾏，每个任务都在不同的处理单元（如多个CPU核⼼）上\n执⾏。在并⾏系统中，多个处理单元可以同时处理独⽴的⼦任务，从⽽加速整体任务的完成。\n并发是指在相同的时间段内执⾏多个任务，这些任务可能不是同时发⽣的，⽽是交替执⾏，通过时间⽚轮转或者事\n件驱动的⽅式。并发通常与任务之间的交替执⾏和任务调度有关。\n什么是内部碎⽚和外部碎⽚\n说⼀说僵⼫进程和孤⼉进程",
    "question": "## 在什么场景下，会发⽣内核态和⽤户态的切换",
    "answer": "系统调⽤：当⽤户程序需要请求操作系统提供的服务时，会通过系统调⽤进⼊内核态。\n异常：当程序执⾏过程中出现错误或异常情况时，CPU会⾃动切换到内核态，以便操作系统能够处理这些异\n中断：外部设备（如键盘、⿏标、磁盘等）产⽣的中断信号会使CPU从⽤户态切换到内核态。操作系统会处理\n这些中断，执⾏相应的中断处理程序，然后再将CPU切换回⽤户态。\n并⾏和并发是什么\n并⾏是在同⼀时刻执⾏多个任务。\n并发是在相同的时间段内执⾏多个任务，任务可能交替执⾏，通过调度实现。\n并⾏是指在同⼀时刻执⾏多个任务，这些任务可以同时进⾏，每个任务都在不同的处理单元（如多个CPU核⼼）上\n执⾏。在并⾏系统中，多个处理单元可以同时处理独⽴的⼦任务，从⽽加速整体任务的完成。\n并发是指在相同的时间段内执⾏多个任务，这些任务可能不是同时发⽣的，⽽是交替执⾏，通过时间⽚轮转或者事\n件驱动的⽅式。并发通常与任务之间的交替执⾏和任务调度有关。\n什么是内部碎⽚和外部碎⽚\n说⼀说僵⼫进程和孤⼉进程",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 455,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000098",
    "content": "并⾏和并发是什么\n\n并⾏是在同⼀时刻执⾏多个任务。\n并发是在相同的时间段内执⾏多个任务，任务可能交替执⾏，通过调度实现。\n并⾏是指在同⼀时刻执⾏多个任务，这些任务可以同时进⾏，每个任务都在不同的处理单元（如多个CPU核⼼）上\n执⾏。在并⾏系统中，多个处理单元可以同时处理独⽴的⼦任务，从⽽加速整体任务的完成。\n并发是指在相同的时间段内执⾏多个任务，这些任务可能不是同时发⽣的，⽽是交替执⾏，通过时间⽚轮转或者事\n件驱动的⽅式。并发通常与任务之间的交替执⾏和任务调度有关。\n什么是内部碎⽚和外部碎⽚\n说⼀说僵⼫进程和孤⼉进程\n## 孤⼉进程：⼀个⽗进程退出，⽽它的⼀个或多个⼦进程还在运⾏，那么那些⼦进程将成为孤⼉进程。孤⼉进程\n将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集⼯作。\n## 僵⼫进程：⼀个进程使⽤fork创建⼦进程，如果⼦进程退出，⽽⽗进程并没有调⽤wait或waitpid获取⼦进程\n的状态信息，那么⼦进程的进程描述符仍然保存在系统中。这种进程称之为僵⼫进程。",
    "question": "并⾏和并发是什么",
    "answer": "并⾏是在同⼀时刻执⾏多个任务。\n并发是在相同的时间段内执⾏多个任务，任务可能交替执⾏，通过调度实现。\n并⾏是指在同⼀时刻执⾏多个任务，这些任务可以同时进⾏，每个任务都在不同的处理单元（如多个CPU核⼼）上\n执⾏。在并⾏系统中，多个处理单元可以同时处理独⽴的⼦任务，从⽽加速整体任务的完成。\n并发是指在相同的时间段内执⾏多个任务，这些任务可能不是同时发⽣的，⽽是交替执⾏，通过时间⽚轮转或者事\n件驱动的⽅式。并发通常与任务之间的交替执⾏和任务调度有关。\n什么是内部碎⽚和外部碎⽚\n说⼀说僵⼫进程和孤⼉进程\n## 孤⼉进程：⼀个⽗进程退出，⽽它的⼀个或多个⼦进程还在运⾏，那么那些⼦进程将成为孤⼉进程。孤⼉进程\n将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集⼯作。\n## 僵⼫进程：⼀个进程使⽤fork创建⼦进程，如果⼦进程退出，⽽⽗进程并没有调⽤wait或waitpid获取⼦进程\n的状态信息，那么⼦进程的进程描述符仍然保存在系统中。这种进程称之为僵⼫进程。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 451,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000099",
    "content": "## 僵⼫进程：⼀个进程使⽤fork创建⼦进程，如果⼦进程退出，⽽⽗进程并没有调⽤wait或waitpid获取⼦进程\n\n的状态信息，那么⼦进程的进程描述符仍然保存在系统中。这种进程称之为僵⼫进程。\n信号和信号量有什么区别\n信号：⼀种处理异步事件的⽅式。信号是⽐较复杂的通信⽅式，⽤于通知接收进程有某种事件发⽣，除了⽤于进程\n外，还可以发送信号给进程本身。\n信号量：进程间通信处理同步互斥的机制。是在多线程环境下使⽤的⼀种设施，它负责协调各个线程，以保证它们\n能够正确，合理的使⽤公共资源。\n常⽤的Linux命令\nls：列出当前⽬录下的⽂件和⼦⽬录。\ncd：切换⽬录。          pwd：\n显示当前⼯作⽬录的路径。 touch：创\n建新⽂件。     mkdir：创建新⽬\n录。       rm：删除⽂件或⽬录。\ncp：复制⽂件或⽬录。       mv：\n移动⽂件或⽬录，也⽤于重命名。 cat：\n显示⽂件的内容。\nvi: 编辑⽂件\nhead 和 tail：查看⽂件的开头和结尾部分。\ngrep：查找⽂件或其他内容⾥符合条件的字符串\nfind：查找⽂件和⽬录。         chmod：\n更改⽂件或⽬录的权限。    chown：更改⽂\n件或⽬录的所有者。     ps：列出运⾏中的\n进程。\nkill：终⽌进程。                df：\n显示磁盘空间使⽤情况。         tar：创\n建和提取归档⽂件（通常是.tar⽂件）。\nifconfig：查看ip地址\npgrep myprocess\npidof myprocess\nLinux中如何查看⼀个进程\nps 命令⽤于列出当前⽤户的进程信息如果要查找特定进程。\n可以使⽤\n命令来过滤结果。例如，要查找名为  \"myprocess\"  的进程，可以执⾏以下命令：\n和pidof 命令⽤于通过进程名称查找进程的PID（进程ID）\n如何杀死⼀个进程\n使⽤kill 命令可以向⼀个进程发送信号，终⽌进程，\nkillall 命令⽤于根据进程名杀死所有匹配的进程。\n杀死⽗进程并不会同时杀死⼦进程：每个进程都有⼀个⽗进程。可以使⽤ pstree 或 ps ⼯具来观察这⼀点。\n杀死⽗进程后，⼦进程将会成为孤⼉进程，⽽ init 进程将重新成为它的⽗进程。\n局部性原理\n在⼀段时间内，程序倾向于多次访问相同的数据或接近的数据，⽽不是随机地访问内存中的各个位置。局部性原理\n通常分为两种类型：时间局部性和空间局部性。",
    "question": "## 僵⼫进程：⼀个进程使⽤fork创建⼦进程，如果⼦进程退出，⽽⽗进程并没有调⽤wait或waitpid获取⼦进程",
    "answer": "的状态信息，那么⼦进程的进程描述符仍然保存在系统中。这种进程称之为僵⼫进程。\n信号和信号量有什么区别\n信号：⼀种处理异步事件的⽅式。信号是⽐较复杂的通信⽅式，⽤于通知接收进程有某种事件发⽣，除了⽤于进程\n外，还可以发送信号给进程本身。\n信号量：进程间通信处理同步互斥的机制。是在多线程环境下使⽤的⼀种设施，它负责协调各个线程，以保证它们\n能够正确，合理的使⽤公共资源。\n常⽤的Linux命令\nls：列出当前⽬录下的⽂件和⼦⽬录。\ncd：切换⽬录。          pwd：\n显示当前⼯作⽬录的路径。 touch：创\n建新⽂件。     mkdir：创建新⽬\n录。       rm：删除⽂件或⽬录。\ncp：复制⽂件或⽬录。       mv：\n移动⽂件或⽬录，也⽤于重命名。 cat：\n显示⽂件的内容。\nvi: 编辑⽂件\nhead 和 tail：查看⽂件的开头和结尾部分。\ngrep：查找⽂件或其他内容⾥符合条件的字符串\nfind：查找⽂件和⽬录。         chmod：\n更改⽂件或⽬录的权限。    chown：更改⽂\n件或⽬录的所有者。     ps：列出运⾏中的\n进程。\nkill：终⽌进程。                df：\n显示磁盘空间使⽤情况。         tar：创\n建和提取归档⽂件（通常是.tar⽂件）。\nifconfig：查看ip地址\npgrep myprocess\npidof myprocess\nLinux中如何查看⼀个进程\nps 命令⽤于列出当前⽤户的进程信息如果要查找特定进程。\n可以使⽤\n命令来过滤结果。例如，要查找名为  \"myprocess\"  的进程，可以执⾏以下命令：\n和pidof 命令⽤于通过进程名称查找进程的PID（进程ID）\n如何杀死⼀个进程\n使⽤kill 命令可以向⼀个进程发送信号，终⽌进程，\nkillall 命令⽤于根据进程名杀死所有匹配的进程。\n杀死⽗进程并不会同时杀死⼦进程：每个进程都有⼀个⽗进程。可以使⽤ pstree 或 ps ⼯具来观察这⼀点。\n杀死⽗进程后，⼦进程将会成为孤⼉进程，⽽ init 进程将重新成为它的⽗进程。\n局部性原理\n在⼀段时间内，程序倾向于多次访问相同的数据或接近的数据，⽽不是随机地访问内存中的各个位置。局部性原理\n通常分为两种类型：时间局部性和空间局部性。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1042,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000100",
    "content": "信号和信号量有什么区别\n\n信号：⼀种处理异步事件的⽅式。信号是⽐较复杂的通信⽅式，⽤于通知接收进程有某种事件发⽣，除了⽤于进程\n外，还可以发送信号给进程本身。\n信号量：进程间通信处理同步互斥的机制。是在多线程环境下使⽤的⼀种设施，它负责协调各个线程，以保证它们\n能够正确，合理的使⽤公共资源。\n常⽤的Linux命令\nls：列出当前⽬录下的⽂件和⼦⽬录。\ncd：切换⽬录。          pwd：\n显示当前⼯作⽬录的路径。 touch：创\n建新⽂件。     mkdir：创建新⽬\n录。       rm：删除⽂件或⽬录。\ncp：复制⽂件或⽬录。       mv：\n移动⽂件或⽬录，也⽤于重命名。 cat：\n显示⽂件的内容。\nvi: 编辑⽂件\nhead 和 tail：查看⽂件的开头和结尾部分。\ngrep：查找⽂件或其他内容⾥符合条件的字符串\nfind：查找⽂件和⽬录。         chmod：\n更改⽂件或⽬录的权限。    chown：更改⽂\n件或⽬录的所有者。     ps：列出运⾏中的\n进程。\nkill：终⽌进程。                df：\n显示磁盘空间使⽤情况。         tar：创\n建和提取归档⽂件（通常是.tar⽂件）。\nifconfig：查看ip地址\npgrep myprocess\npidof myprocess\nLinux中如何查看⼀个进程\nps 命令⽤于列出当前⽤户的进程信息如果要查找特定进程。\n可以使⽤\n命令来过滤结果。例如，要查找名为  \"myprocess\"  的进程，可以执⾏以下命令：\n和pidof 命令⽤于通过进程名称查找进程的PID（进程ID）\n如何杀死⼀个进程\n使⽤kill 命令可以向⼀个进程发送信号，终⽌进程，\nkillall 命令⽤于根据进程名杀死所有匹配的进程。\n杀死⽗进程并不会同时杀死⼦进程：每个进程都有⼀个⽗进程。可以使⽤ pstree 或 ps ⼯具来观察这⼀点。\n杀死⽗进程后，⼦进程将会成为孤⼉进程，⽽ init 进程将重新成为它的⽗进程。",
    "question": "信号和信号量有什么区别",
    "answer": "信号：⼀种处理异步事件的⽅式。信号是⽐较复杂的通信⽅式，⽤于通知接收进程有某种事件发⽣，除了⽤于进程\n外，还可以发送信号给进程本身。\n信号量：进程间通信处理同步互斥的机制。是在多线程环境下使⽤的⼀种设施，它负责协调各个线程，以保证它们\n能够正确，合理的使⽤公共资源。\n常⽤的Linux命令\nls：列出当前⽬录下的⽂件和⼦⽬录。\ncd：切换⽬录。          pwd：\n显示当前⼯作⽬录的路径。 touch：创\n建新⽂件。     mkdir：创建新⽬\n录。       rm：删除⽂件或⽬录。\ncp：复制⽂件或⽬录。       mv：\n移动⽂件或⽬录，也⽤于重命名。 cat：\n显示⽂件的内容。\nvi: 编辑⽂件\nhead 和 tail：查看⽂件的开头和结尾部分。\ngrep：查找⽂件或其他内容⾥符合条件的字符串\nfind：查找⽂件和⽬录。         chmod：\n更改⽂件或⽬录的权限。    chown：更改⽂\n件或⽬录的所有者。     ps：列出运⾏中的\n进程。\nkill：终⽌进程。                df：\n显示磁盘空间使⽤情况。         tar：创\n建和提取归档⽂件（通常是.tar⽂件）。\nifconfig：查看ip地址\npgrep myprocess\npidof myprocess\nLinux中如何查看⼀个进程\nps 命令⽤于列出当前⽤户的进程信息如果要查找特定进程。\n可以使⽤\n命令来过滤结果。例如，要查找名为  \"myprocess\"  的进程，可以执⾏以下命令：\n和pidof 命令⽤于通过进程名称查找进程的PID（进程ID）\n如何杀死⼀个进程\n使⽤kill 命令可以向⼀个进程发送信号，终⽌进程，\nkillall 命令⽤于根据进程名杀死所有匹配的进程。\n杀死⽗进程并不会同时杀死⼦进程：每个进程都有⼀个⽗进程。可以使⽤ pstree 或 ps ⼯具来观察这⼀点。\n杀死⽗进程后，⼦进程将会成为孤⼉进程，⽽ init 进程将重新成为它的⽗进程。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 865,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000101",
    "content": "在⼀段时间内，程序倾向于多次访问相同的数据或接近的数据，⽽不是随机地访问内存中的各个位置。局部性原理\n\n通常分为两种类型：时间局部性和空间局部性。\n## 时间局部性\n如果⼀个数据被访问，那么在不久的将来它很可能会再次被访问。这意味着程序在短时间内倾向于反复使⽤相同的\n数据项，例如在循环中反复访问数组的元素。\n通过利⽤时间局部性，程序可以将频繁使⽤的数据存储在缓存中，从⽽减少访问主内存的次数，提⾼程序的执⾏速\n## 空间局部性\n如果⼀个数据被访问，那么它附近的数据也很可能会被访问。这意味着程序在访问⼀个数据时，通常会在接近该数\n据的附近访问其他数据，例如遍历数组时，往往会访问相邻的元素。\n⽂件系统在磁盘上存储数据时，通常会将相关的数据块放在相邻的磁盘扇区上，以便在访问⼀个数据块时能够快速\n地访问相邻的数据块。\nping：测试⽹络连接。\nssh：通过SSH协议远程登录到其他计算机。\napt（Debian/Ubuntu）或 yum（Red Hat/CentOS）：包管理器，⽤于安装、更新和删除软件包。\nps aux | grep myprocess\ngrep\npgrep\nkill [options] PID\n进程、线程的区别？\n进程是系统进⾏资源分配和调度的基本单位。\n线程是操作系统能够进⾏运算调度的最⼩单位，线程是进程的⼦任务，是进程内的执⾏单元。  ⼀个进程⾄少有⼀个线\n程，⼀个进程可以运⾏多个线程，这些线程共享同⼀块内存。\n资源开销：\n进程：由于每个进程都有独⽴的内存空间，创建和销毁进程的开销较⼤。进程间切换需要保存和恢复整个进程\n的状态，因此上下⽂切换的开销较⾼。\n线程：线程共享相同的内存空间，创建和销毁线程的开销较⼩。线程间切换只需要保存和恢复少量的线程上下\n⽂，因此上下⽂切换的开销较⼩。\n通信与同步：\n进程：由于进程间相互隔离，进程之间的通信需要使⽤⼀些特殊机制，如管道、消息队列、共享内存等。\n线程：由于线程共享相同的内存空间，它们之间可以直接访问共享数据，线程间通信更加⽅便。\n安全性：\n进程：由于进程间相互隔离，⼀个进程的崩溃不会直接影响其他进程的稳定性。\n线程：由于线程共享相同的内存空间，⼀个线程的错误可能会影响整个进程的稳定性。",
    "question": "在⼀段时间内，程序倾向于多次访问相同的数据或接近的数据，⽽不是随机地访问内存中的各个位置。局部性原理",
    "answer": "通常分为两种类型：时间局部性和空间局部性。\n## 时间局部性\n如果⼀个数据被访问，那么在不久的将来它很可能会再次被访问。这意味着程序在短时间内倾向于反复使⽤相同的\n数据项，例如在循环中反复访问数组的元素。\n通过利⽤时间局部性，程序可以将频繁使⽤的数据存储在缓存中，从⽽减少访问主内存的次数，提⾼程序的执⾏速\n## 空间局部性\n如果⼀个数据被访问，那么它附近的数据也很可能会被访问。这意味着程序在访问⼀个数据时，通常会在接近该数\n据的附近访问其他数据，例如遍历数组时，往往会访问相邻的元素。\n⽂件系统在磁盘上存储数据时，通常会将相关的数据块放在相邻的磁盘扇区上，以便在访问⼀个数据块时能够快速\n地访问相邻的数据块。\nping：测试⽹络连接。\nssh：通过SSH协议远程登录到其他计算机。\napt（Debian/Ubuntu）或 yum（Red Hat/CentOS）：包管理器，⽤于安装、更新和删除软件包。\nps aux | grep myprocess\ngrep\npgrep\nkill [options] PID\n进程、线程的区别？\n进程是系统进⾏资源分配和调度的基本单位。\n线程是操作系统能够进⾏运算调度的最⼩单位，线程是进程的⼦任务，是进程内的执⾏单元。  ⼀个进程⾄少有⼀个线\n程，⼀个进程可以运⾏多个线程，这些线程共享同⼀块内存。\n资源开销：\n进程：由于每个进程都有独⽴的内存空间，创建和销毁进程的开销较⼤。进程间切换需要保存和恢复整个进程\n的状态，因此上下⽂切换的开销较⾼。\n线程：线程共享相同的内存空间，创建和销毁线程的开销较⼩。线程间切换只需要保存和恢复少量的线程上下\n⽂，因此上下⽂切换的开销较⼩。\n通信与同步：\n进程：由于进程间相互隔离，进程之间的通信需要使⽤⼀些特殊机制，如管道、消息队列、共享内存等。\n线程：由于线程共享相同的内存空间，它们之间可以直接访问共享数据，线程间通信更加⽅便。\n安全性：\n进程：由于进程间相互隔离，⼀个进程的崩溃不会直接影响其他进程的稳定性。\n线程：由于线程共享相同的内存空间，⼀个线程的错误可能会影响整个进程的稳定性。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 936,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000102",
    "content": "## 空间局部性\n\n如果⼀个数据被访问，那么它附近的数据也很可能会被访问。这意味着程序在访问⼀个数据时，通常会在接近该数\n据的附近访问其他数据，例如遍历数组时，往往会访问相邻的元素。\n⽂件系统在磁盘上存储数据时，通常会将相关的数据块放在相邻的磁盘扇区上，以便在访问⼀个数据块时能够快速\n地访问相邻的数据块。\nping：测试⽹络连接。\nssh：通过SSH协议远程登录到其他计算机。\napt（Debian/Ubuntu）或 yum（Red Hat/CentOS）：包管理器，⽤于安装、更新和删除软件包。\nps aux | grep myprocess\ngrep\npgrep\nkill [options] PID\n进程、线程的区别？\n进程是系统进⾏资源分配和调度的基本单位。\n线程是操作系统能够进⾏运算调度的最⼩单位，线程是进程的⼦任务，是进程内的执⾏单元。  ⼀个进程⾄少有⼀个线\n程，⼀个进程可以运⾏多个线程，这些线程共享同⼀块内存。\n资源开销：\n进程：由于每个进程都有独⽴的内存空间，创建和销毁进程的开销较⼤。进程间切换需要保存和恢复整个进程\n的状态，因此上下⽂切换的开销较⾼。\n线程：线程共享相同的内存空间，创建和销毁线程的开销较⼩。线程间切换只需要保存和恢复少量的线程上下\n⽂，因此上下⽂切换的开销较⼩。\n通信与同步：\n进程：由于进程间相互隔离，进程之间的通信需要使⽤⼀些特殊机制，如管道、消息队列、共享内存等。\n线程：由于线程共享相同的内存空间，它们之间可以直接访问共享数据，线程间通信更加⽅便。\n安全性：\n进程：由于进程间相互隔离，⼀个进程的崩溃不会直接影响其他进程的稳定性。\n线程：由于线程共享相同的内存空间，⼀个线程的错误可能会影响整个进程的稳定性。\n进程的状态有哪些\n进程的3种基本状态：运⾏、就绪和阻塞。\n（1） 就绪：当⼀个进程获得了除处理机以外的⼀切所需资源，⼀旦得到处理机即可运⾏，则称此进程处于就绪状\n态。就绪进程可以按多个优先级来划分队列。例如，当⼀个进程由于时间⽚⽤完⽽进⼊就绪状态时，排⼊低优先级\n队列；当进程由I／O操作完成⽽进⼊就绪状态时，排⼊⾼优先级队列。\n（2） 运⾏：当⼀个进程在处理机上运⾏时，则称该进程处于运⾏状态。处于此状态的进程的数⽬⼩于等于处理器\n的数⽬，对于单处理机系统，处于运⾏状态的进程只有⼀个。在没有其他进程可以执⾏时（如所有进程都在阻塞状\n态），通常会⾃动执⾏系统的空闲进程。\n（3） 阻塞：也称为等待或睡眠状态，⼀个进程正在等待某⼀事件发⽣（例如请求I/O⽽等待I/O完成等）⽽暂时停\n⽌运⾏，这时即使把处理机分配给进程也⽆法运⾏，故称该进程处于阻塞状态。\n进程的五种状态\n创建状态：进程在创建时需要申请⼀个空⽩PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建⼯\n作⽆法完成，⽐如资源⽆法满⾜，就⽆法被调度运⾏，把此时进程所处状态称为创建状态\n就绪状态：进程已经准备好，已分配到所需资源，只要分配到CPU就能够⽴即运⾏\n执⾏状态：进程处于就绪状态被调度后，进程进⼊执⾏状态\n阻塞状态：正在执⾏的进程由于某些事件（I/O请求，申请缓存区失败）⽽暂时⽆法运⾏，进程受到阻塞。在满⾜\n请求时进⼊就绪状态等待系统调⽤\n终⽌状态：进程结束，或出现错误，或被系统终⽌，进⼊终⽌状态。⽆法再执⾏\n进程之间的通信⽅式",
    "question": "## 空间局部性",
    "answer": "如果⼀个数据被访问，那么它附近的数据也很可能会被访问。这意味着程序在访问⼀个数据时，通常会在接近该数\n据的附近访问其他数据，例如遍历数组时，往往会访问相邻的元素。\n⽂件系统在磁盘上存储数据时，通常会将相关的数据块放在相邻的磁盘扇区上，以便在访问⼀个数据块时能够快速\n地访问相邻的数据块。\nping：测试⽹络连接。\nssh：通过SSH协议远程登录到其他计算机。\napt（Debian/Ubuntu）或 yum（Red Hat/CentOS）：包管理器，⽤于安装、更新和删除软件包。\nps aux | grep myprocess\ngrep\npgrep\nkill [options] PID\n进程、线程的区别？\n进程是系统进⾏资源分配和调度的基本单位。\n线程是操作系统能够进⾏运算调度的最⼩单位，线程是进程的⼦任务，是进程内的执⾏单元。  ⼀个进程⾄少有⼀个线\n程，⼀个进程可以运⾏多个线程，这些线程共享同⼀块内存。\n资源开销：\n进程：由于每个进程都有独⽴的内存空间，创建和销毁进程的开销较⼤。进程间切换需要保存和恢复整个进程\n的状态，因此上下⽂切换的开销较⾼。\n线程：线程共享相同的内存空间，创建和销毁线程的开销较⼩。线程间切换只需要保存和恢复少量的线程上下\n⽂，因此上下⽂切换的开销较⼩。\n通信与同步：\n进程：由于进程间相互隔离，进程之间的通信需要使⽤⼀些特殊机制，如管道、消息队列、共享内存等。\n线程：由于线程共享相同的内存空间，它们之间可以直接访问共享数据，线程间通信更加⽅便。\n安全性：\n进程：由于进程间相互隔离，⼀个进程的崩溃不会直接影响其他进程的稳定性。\n线程：由于线程共享相同的内存空间，⼀个线程的错误可能会影响整个进程的稳定性。\n进程的状态有哪些\n进程的3种基本状态：运⾏、就绪和阻塞。\n（1） 就绪：当⼀个进程获得了除处理机以外的⼀切所需资源，⼀旦得到处理机即可运⾏，则称此进程处于就绪状\n态。就绪进程可以按多个优先级来划分队列。例如，当⼀个进程由于时间⽚⽤完⽽进⼊就绪状态时，排⼊低优先级\n队列；当进程由I／O操作完成⽽进⼊就绪状态时，排⼊⾼优先级队列。\n（2） 运⾏：当⼀个进程在处理机上运⾏时，则称该进程处于运⾏状态。处于此状态的进程的数⽬⼩于等于处理器\n的数⽬，对于单处理机系统，处于运⾏状态的进程只有⼀个。在没有其他进程可以执⾏时（如所有进程都在阻塞状\n态），通常会⾃动执⾏系统的空闲进程。\n（3） 阻塞：也称为等待或睡眠状态，⼀个进程正在等待某⼀事件发⽣（例如请求I/O⽽等待I/O完成等）⽽暂时停\n⽌运⾏，这时即使把处理机分配给进程也⽆法运⾏，故称该进程处于阻塞状态。\n进程的五种状态\n创建状态：进程在创建时需要申请⼀个空⽩PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建⼯\n作⽆法完成，⽐如资源⽆法满⾜，就⽆法被调度运⾏，把此时进程所处状态称为创建状态\n就绪状态：进程已经准备好，已分配到所需资源，只要分配到CPU就能够⽴即运⾏\n执⾏状态：进程处于就绪状态被调度后，进程进⼊执⾏状态\n阻塞状态：正在执⾏的进程由于某些事件（I/O请求，申请缓存区失败）⽽暂时⽆法运⾏，进程受到阻塞。在满⾜\n请求时进⼊就绪状态等待系统调⽤\n终⽌状态：进程结束，或出现错误，或被系统终⽌，进⼊终⽌状态。⽆法再执⾏\n进程之间的通信⽅式",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1388,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000103",
    "content": "进程的状态有哪些\n\n进程的3种基本状态：运⾏、就绪和阻塞。\n（1） 就绪：当⼀个进程获得了除处理机以外的⼀切所需资源，⼀旦得到处理机即可运⾏，则称此进程处于就绪状\n态。就绪进程可以按多个优先级来划分队列。例如，当⼀个进程由于时间⽚⽤完⽽进⼊就绪状态时，排⼊低优先级\n队列；当进程由I／O操作完成⽽进⼊就绪状态时，排⼊⾼优先级队列。\n（2） 运⾏：当⼀个进程在处理机上运⾏时，则称该进程处于运⾏状态。处于此状态的进程的数⽬⼩于等于处理器\n的数⽬，对于单处理机系统，处于运⾏状态的进程只有⼀个。在没有其他进程可以执⾏时（如所有进程都在阻塞状\n态），通常会⾃动执⾏系统的空闲进程。\n（3） 阻塞：也称为等待或睡眠状态，⼀个进程正在等待某⼀事件发⽣（例如请求I/O⽽等待I/O完成等）⽽暂时停\n⽌运⾏，这时即使把处理机分配给进程也⽆法运⾏，故称该进程处于阻塞状态。\n进程的五种状态\n创建状态：进程在创建时需要申请⼀个空⽩PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建⼯\n作⽆法完成，⽐如资源⽆法满⾜，就⽆法被调度运⾏，把此时进程所处状态称为创建状态\n就绪状态：进程已经准备好，已分配到所需资源，只要分配到CPU就能够⽴即运⾏\n执⾏状态：进程处于就绪状态被调度后，进程进⼊执⾏状态\n阻塞状态：正在执⾏的进程由于某些事件（I/O请求，申请缓存区失败）⽽暂时⽆法运⾏，进程受到阻塞。在满⾜\n请求时进⼊就绪状态等待系统调⽤\n终⽌状态：进程结束，或出现错误，或被系统终⽌，进⼊终⽌状态。⽆法再执⾏\n进程之间的通信⽅式\n## 管道：是⼀种半双⼯的通信⽅式，数据只能单向流动⽽且只能在具有⽗⼦进程关系的进程间使⽤。\n## 命名管道：  也是半双⼯的通信⽅式，但是它允许⽆亲缘关系进程间的通信。\n## 信号量：是⼀个计数器，可以⽤来控制多个进程对共享资源的访问，常作为⼀种锁机制，防⽌某进程正在访问\n共享资源时，其他进程也访问该资源。因此主要作为进程间以及同⼀进程内不同线程之间的同步⼿段。\n## 消息队列：消息队列是消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息\n少、管道只能承载⽆格式字节流以及缓冲区⼤⼩受限等缺点。\n## 信号：⽤于通知接收进程某个事件已经发⽣，从⽽迫使进程执⾏信号处理程序。\n## 共享内存：就是映射⼀段能被其他进程所访问的内存，这段共享内存由⼀个进程创建，但多个进程都可以访",
    "question": "进程的状态有哪些",
    "answer": "进程的3种基本状态：运⾏、就绪和阻塞。\n（1） 就绪：当⼀个进程获得了除处理机以外的⼀切所需资源，⼀旦得到处理机即可运⾏，则称此进程处于就绪状\n态。就绪进程可以按多个优先级来划分队列。例如，当⼀个进程由于时间⽚⽤完⽽进⼊就绪状态时，排⼊低优先级\n队列；当进程由I／O操作完成⽽进⼊就绪状态时，排⼊⾼优先级队列。\n（2） 运⾏：当⼀个进程在处理机上运⾏时，则称该进程处于运⾏状态。处于此状态的进程的数⽬⼩于等于处理器\n的数⽬，对于单处理机系统，处于运⾏状态的进程只有⼀个。在没有其他进程可以执⾏时（如所有进程都在阻塞状\n态），通常会⾃动执⾏系统的空闲进程。\n（3） 阻塞：也称为等待或睡眠状态，⼀个进程正在等待某⼀事件发⽣（例如请求I/O⽽等待I/O完成等）⽽暂时停\n⽌运⾏，这时即使把处理机分配给进程也⽆法运⾏，故称该进程处于阻塞状态。\n进程的五种状态\n创建状态：进程在创建时需要申请⼀个空⽩PCB，向其中填写控制和管理进程的信息，完成资源分配。如果创建⼯\n作⽆法完成，⽐如资源⽆法满⾜，就⽆法被调度运⾏，把此时进程所处状态称为创建状态\n就绪状态：进程已经准备好，已分配到所需资源，只要分配到CPU就能够⽴即运⾏\n执⾏状态：进程处于就绪状态被调度后，进程进⼊执⾏状态\n阻塞状态：正在执⾏的进程由于某些事件（I/O请求，申请缓存区失败）⽽暂时⽆法运⾏，进程受到阻塞。在满⾜\n请求时进⼊就绪状态等待系统调⽤\n终⽌状态：进程结束，或出现错误，或被系统终⽌，进⼊终⽌状态。⽆法再执⾏\n进程之间的通信⽅式\n## 管道：是⼀种半双⼯的通信⽅式，数据只能单向流动⽽且只能在具有⽗⼦进程关系的进程间使⽤。\n## 命名管道：  也是半双⼯的通信⽅式，但是它允许⽆亲缘关系进程间的通信。\n## 信号量：是⼀个计数器，可以⽤来控制多个进程对共享资源的访问，常作为⼀种锁机制，防⽌某进程正在访问\n共享资源时，其他进程也访问该资源。因此主要作为进程间以及同⼀进程内不同线程之间的同步⼿段。\n## 消息队列：消息队列是消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息\n少、管道只能承载⽆格式字节流以及缓冲区⼤⼩受限等缺点。\n## 信号：⽤于通知接收进程某个事件已经发⽣，从⽽迫使进程执⾏信号处理程序。\n## 共享内存：就是映射⼀段能被其他进程所访问的内存，这段共享内存由⼀个进程创建，但多个进程都可以访",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1010,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000104",
    "content": "## 共享内存：就是映射⼀段能被其他进程所访问的内存，这段共享内存由⼀个进程创建，但多个进程都可以访\n\n问。共享内存是最快的进程通信⽅式，它是针对其他进程间通信⽅式运⾏效率低⽽专⻔设计的。它往往与其他\n通信机制，⽐如信号量配合使⽤，来实现进程间的同步和通信。",
    "question": "## 共享内存：就是映射⼀段能被其他进程所访问的内存，这段共享内存由⼀个进程创建，但多个进程都可以访",
    "answer": "问。共享内存是最快的进程通信⽅式，它是针对其他进程间通信⽅式运⾏效率低⽽专⻔设计的。它往往与其他\n通信机制，⽐如信号量配合使⽤，来实现进程间的同步和通信。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 129,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000105",
    "content": "问。共享内存是最快的进程通信⽅式，它是针对其他进程间通信⽅式运⾏效率低⽽专⻔设计的。它往往与其他\n\n通信机制，⽐如信号量配合使⽤，来实现进程间的同步和通信。\n## Socket 套接字：是⽀持TCP/IP 的⽹络通信的基本操作单元，主要⽤于在客户端和服务器之间通过⽹络进⾏\n通信。\n线程之间的同步⽅式\n线程同步机制是指在多线程编程中，为了保证线程之间的互不⼲扰，⽽采⽤的⼀种机制。常⻅的线程同步机制有以\n下⼏种：\n## 互斥锁：互斥锁是最常⻅的线程同步机制。它允许只有⼀个线程同时访问被保护的临界区（共享资源）\n## 条件变量：条件变量⽤于线程间通信，允许⼀个线程等待某个条件满⾜，⽽其他线程可以发出信号通知等待线\n程。通常与互斥锁⼀起使⽤。\n## 读写锁：  读写锁允许多个线程同时读取共享资源，但只允许⼀个线程写⼊资源。\n## 信号量：⽤于控制多个线程对共享资源进⾏访问的⼯具。\n介绍⼀下你知道的锁\n两个基础的锁：\n互斥锁：互斥锁是⼀种最常⻅的锁类型，⽤于实现互斥访问共享资源。在任何时刻，只有⼀个线程可以持有互\n斥锁，其他线程必须等待直到锁被释放。这确保了同⼀时间只有⼀个线程能够访问被保护的资源。\n⾃旋锁：⾃旋锁是⼀种基于忙等待的锁，即线程在尝试获取锁时会不断轮询，直到锁被释放。\n其他的锁都是基于这两个锁的\n读写锁：允许多个线程同时读共享资源，只允许⼀个线程进⾏写操作。分为读（共享）和写（排他）两种状\n悲观锁：认为多线程同时修改共享资源的概率⽐较⾼，所以访问共享资源时候要上锁\n乐观锁：先不管，修改了共享资源再说，如果出现同时修改的情况，再放弃本次操作\n什么情况下会产⽣死锁\n死锁是指两个或多个进程在争夺系统资源时，由于互相等待对⽅释放资源⽽⽆法继续执⾏的状态。\n死锁只有同时满⾜以下四个条件才会发⽣：\n互斥条件：⼀个进程占⽤了某个资源时，其他进程⽆法同时占⽤该资源。\n请求保持条件：⼀个线程因为请求资源⽽阻塞的时候，不会释放⾃⼰的资源。\n不可剥夺条件：资源不能被强制性地从⼀个进程中剥夺，只能由持有者⾃愿释放。\n环路等待条件：多个进程之间形成⼀个循环等待资源的链，每个进程都在等待下⼀个进程所占有的资源。\n如何解除死锁\n只需要破坏上⾯⼀个条件就可以破坏死锁。\n破坏请求与保持条件：⼀次性申请所有的资源。\n破坏不可剥夺条件：占⽤部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资\n破坏循环等待条件：靠按序申请资源来预防。让所有进程按照相同的顺序请求资源，释放资源则反序释放。\n进程的调度算法有哪些？\n## 批处理系统中的调度\n（1） 先来先服务：\n⾮抢占式的调度算法，按照请求的顺序进⾏调度。\n有利于⻓作业，但不利于短作业，因为短作业必须⼀直等待前⾯的⻓作业执⾏完毕才能执⾏，⽽⻓作业⼜需要执⾏\n很⻓时间，造成了短作业等待时间过⻓。\n（2） 最短作业优先：\n⾮抢占式的调度算法，按估计运⾏时间最短的顺序进⾏调度。\n⻓作业有可能会饿死，处于⼀直等待短作业执⾏完毕的状态。因为如果⼀直有短作业到来，那么⻓作业永远得不到\n调度。\n（3） 最短剩余时间优先：\n最短作业优先的抢占式版本，按剩余运⾏时间的顺序进⾏调度。\n当⼀个新的作业到达时，其整个运⾏时间与当前进程的剩余时间作⽐较。如果新的进程需要的时间更少，则挂起当\n前进程，运⾏新的进程。否则新的进程等待。\n## 交互式系统中的调度\n（1） 时间⽚轮转调度\n将所有就绪进程按 FCFS 的原则排成⼀个队列，每次调度时，把 CPU 时间分配给队⾸进程，该进程可以执⾏⼀个时\n间⽚。当时间⽚⽤完时，由计时器发出时钟中断，调度程序便停⽌该进程的执⾏，并将它送往就绪队列的末尾，同\n时继续把 CPU 时间分配给队⾸的进程。\n（2） 优先级调度\n为每个进程分配⼀个优先级，按优先级进⾏调度。为了防⽌低优先级的进程永远等不到调度，可以随着时间的推移\n增加等待进程的优先级。\n（3） 多级队列\n⼀个进程需要执⾏ 100 个时间⽚，如果采⽤时间⽚轮转调度算法，那么需要交换 100 次。\n多级队列是为这种需要连续执⾏多个时间⽚的进程考虑，它设置了多个队列，每个队列时间⽚⼤⼩都不同，例如\n1,2,4,8,..。进程在第⼀个队列没执⾏完，就会被移到下⼀个队列。这种⽅式下，之前的进程只需要交换  7  次。\n每个队列优先权也不同，最上⾯的优先权最⾼。因此只有上⼀个队列没有进程在排队，才能调度当前队列上的进\n可以将这种调度算法看成是时间⽚轮转调度算法和优先级调度算法的结合。\n（4） 最短进程优先\n如果我们将每⼀条命令的执⾏看作是⼀个独⽴的“作业”，则我们可以通过⾸先运⾏最短的作业来使响应事件最短",
    "question": "问。共享内存是最快的进程通信⽅式，它是针对其他进程间通信⽅式运⾏效率低⽽专⻔设计的。它往往与其他",
    "answer": "通信机制，⽐如信号量配合使⽤，来实现进程间的同步和通信。\n## Socket 套接字：是⽀持TCP/IP 的⽹络通信的基本操作单元，主要⽤于在客户端和服务器之间通过⽹络进⾏\n通信。\n线程之间的同步⽅式\n线程同步机制是指在多线程编程中，为了保证线程之间的互不⼲扰，⽽采⽤的⼀种机制。常⻅的线程同步机制有以\n下⼏种：\n## 互斥锁：互斥锁是最常⻅的线程同步机制。它允许只有⼀个线程同时访问被保护的临界区（共享资源）\n## 条件变量：条件变量⽤于线程间通信，允许⼀个线程等待某个条件满⾜，⽽其他线程可以发出信号通知等待线\n程。通常与互斥锁⼀起使⽤。\n## 读写锁：  读写锁允许多个线程同时读取共享资源，但只允许⼀个线程写⼊资源。\n## 信号量：⽤于控制多个线程对共享资源进⾏访问的⼯具。\n介绍⼀下你知道的锁\n两个基础的锁：\n互斥锁：互斥锁是⼀种最常⻅的锁类型，⽤于实现互斥访问共享资源。在任何时刻，只有⼀个线程可以持有互\n斥锁，其他线程必须等待直到锁被释放。这确保了同⼀时间只有⼀个线程能够访问被保护的资源。\n⾃旋锁：⾃旋锁是⼀种基于忙等待的锁，即线程在尝试获取锁时会不断轮询，直到锁被释放。\n其他的锁都是基于这两个锁的\n读写锁：允许多个线程同时读共享资源，只允许⼀个线程进⾏写操作。分为读（共享）和写（排他）两种状\n悲观锁：认为多线程同时修改共享资源的概率⽐较⾼，所以访问共享资源时候要上锁\n乐观锁：先不管，修改了共享资源再说，如果出现同时修改的情况，再放弃本次操作\n什么情况下会产⽣死锁\n死锁是指两个或多个进程在争夺系统资源时，由于互相等待对⽅释放资源⽽⽆法继续执⾏的状态。\n死锁只有同时满⾜以下四个条件才会发⽣：\n互斥条件：⼀个进程占⽤了某个资源时，其他进程⽆法同时占⽤该资源。\n请求保持条件：⼀个线程因为请求资源⽽阻塞的时候，不会释放⾃⼰的资源。\n不可剥夺条件：资源不能被强制性地从⼀个进程中剥夺，只能由持有者⾃愿释放。\n环路等待条件：多个进程之间形成⼀个循环等待资源的链，每个进程都在等待下⼀个进程所占有的资源。\n如何解除死锁\n只需要破坏上⾯⼀个条件就可以破坏死锁。\n破坏请求与保持条件：⼀次性申请所有的资源。\n破坏不可剥夺条件：占⽤部分资源的线程进⼀步申请其他资源时，如果申请不到，可以主动释放它占有的资\n破坏循环等待条件：靠按序申请资源来预防。让所有进程按照相同的顺序请求资源，释放资源则反序释放。\n进程的调度算法有哪些？\n## 批处理系统中的调度\n（1） 先来先服务：\n⾮抢占式的调度算法，按照请求的顺序进⾏调度。\n有利于⻓作业，但不利于短作业，因为短作业必须⼀直等待前⾯的⻓作业执⾏完毕才能执⾏，⽽⻓作业⼜需要执⾏\n很⻓时间，造成了短作业等待时间过⻓。\n（2） 最短作业优先：\n⾮抢占式的调度算法，按估计运⾏时间最短的顺序进⾏调度。\n⻓作业有可能会饿死，处于⼀直等待短作业执⾏完毕的状态。因为如果⼀直有短作业到来，那么⻓作业永远得不到\n调度。\n（3） 最短剩余时间优先：\n最短作业优先的抢占式版本，按剩余运⾏时间的顺序进⾏调度。\n当⼀个新的作业到达时，其整个运⾏时间与当前进程的剩余时间作⽐较。如果新的进程需要的时间更少，则挂起当\n前进程，运⾏新的进程。否则新的进程等待。\n## 交互式系统中的调度\n（1） 时间⽚轮转调度\n将所有就绪进程按 FCFS 的原则排成⼀个队列，每次调度时，把 CPU 时间分配给队⾸进程，该进程可以执⾏⼀个时\n间⽚。当时间⽚⽤完时，由计时器发出时钟中断，调度程序便停⽌该进程的执⾏，并将它送往就绪队列的末尾，同\n时继续把 CPU 时间分配给队⾸的进程。\n（2） 优先级调度\n为每个进程分配⼀个优先级，按优先级进⾏调度。为了防⽌低优先级的进程永远等不到调度，可以随着时间的推移\n增加等待进程的优先级。\n（3） 多级队列\n⼀个进程需要执⾏ 100 个时间⽚，如果采⽤时间⽚轮转调度算法，那么需要交换 100 次。\n多级队列是为这种需要连续执⾏多个时间⽚的进程考虑，它设置了多个队列，每个队列时间⽚⼤⼩都不同，例如\n1,2,4,8,..。进程在第⼀个队列没执⾏完，就会被移到下⼀个队列。这种⽅式下，之前的进程只需要交换  7  次。\n每个队列优先权也不同，最上⾯的优先权最⾼。因此只有上⼀个队列没有进程在排队，才能调度当前队列上的进\n可以将这种调度算法看成是时间⽚轮转调度算法和优先级调度算法的结合。\n（4） 最短进程优先\n如果我们将每⼀条命令的执⾏看作是⼀个独⽴的“作业”，则我们可以通过⾸先运⾏最短的作业来使响应事件最短",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1930,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000106",
    "content": "## 交互式系统中的调度\n\n（1） 时间⽚轮转调度\n将所有就绪进程按 FCFS 的原则排成⼀个队列，每次调度时，把 CPU 时间分配给队⾸进程，该进程可以执⾏⼀个时\n间⽚。当时间⽚⽤完时，由计时器发出时钟中断，调度程序便停⽌该进程的执⾏，并将它送往就绪队列的末尾，同\n时继续把 CPU 时间分配给队⾸的进程。\n（2） 优先级调度\n为每个进程分配⼀个优先级，按优先级进⾏调度。为了防⽌低优先级的进程永远等不到调度，可以随着时间的推移\n增加等待进程的优先级。\n（3） 多级队列\n⼀个进程需要执⾏ 100 个时间⽚，如果采⽤时间⽚轮转调度算法，那么需要交换 100 次。\n多级队列是为这种需要连续执⾏多个时间⽚的进程考虑，它设置了多个队列，每个队列时间⽚⼤⼩都不同，例如\n1,2,4,8,..。进程在第⼀个队列没执⾏完，就会被移到下⼀个队列。这种⽅式下，之前的进程只需要交换  7  次。\n每个队列优先权也不同，最上⾯的优先权最⾼。因此只有上⼀个队列没有进程在排队，才能调度当前队列上的进\n可以将这种调度算法看成是时间⽚轮转调度算法和优先级调度算法的结合。\n（4） 最短进程优先\n如果我们将每⼀条命令的执⾏看作是⼀个独⽴的“作业”，则我们可以通过⾸先运⾏最短的作业来使响应事件最短\n分段和分⻚的区别\n基本单位：  地址空间被划分为不同的逻辑段，每个段具有独⽴的含义，如代码段、数据段等。\n段的⻓度：  每个段的⻓度可以动态变化，不同段的⻓度可以不同。\n内部碎⽚：  由于每个段的⻓度可以动态变化，可能会导致内部碎⽚，即段内部的未使⽤空间。\n外部碎⽚：  可能会导致外部碎⽚，即段之间的未使⽤空间。\n逻辑地址：  逻辑地址由两部分组成，⼀个是段号，另⼀个是段内偏移。\n分⻚（Paging）：\n基本单位：  地址空间被划分为固定⼤⼩的⻚⾯，物理内存也被划分为相同⼤⼩的⻚⾯框。\n⻚⾯的⻓度：  ⻚⾯的⻓度是固定的，由操作系统定义。\n内部碎⽚：  由于⻚⾯⻓度固定，可能会导致内部碎⽚，即⻚⾯内部的未使⽤空间。\n外部碎⽚：  由于⻚⾯⻓度固定，不同⻚⾯之间的未使⽤空间⽆法利⽤，可能导致外部碎⽚。\n逻辑地址：  逻辑地址由两部分组成，⼀个是⻚号，另⼀个是⻚内偏移。\n⻚⾯置换算法\nLRU（最近最少使⽤）算法：每次选择最⻓时间没有被使⽤的⻆⾊进⾏切换。这种策略基于你对⻆⾊的喜好，\n认为最近被使⽤过的⻆⾊很可能还会被使⽤，⽽最久未被使⽤的⻆⾊很可能不会再被使⽤。LRU算法可以有效\n地减少切换次数，但是实现起来⽐较复杂，需要记录每个⻆⾊的使⽤时间或者维护⼀个使⽤顺序的列表。\nFIFO（先进先出）算法：每次选择最早进⼊内存的⻆⾊进⾏切换。这种策略很简单，只需要维护⼀个⻆⾊队\n列，每次淘汰队⾸的⻆⾊，然后把新的⻆⾊加⼊队尾。但是FIFO算法可能会淘汰⼀些经常被使⽤的⻆⾊，导\n致切换次数增加。⽽且FIFO算法有可能出现⻉拉迪异常（Belady anomaly），即当分配给内存的空间增加\n时，切换次数反⽽增加。\n最佳⻚⾯置换算法(OPT)\n置换在「未来」最⻓时间不访问的⻚⾯,但是实际系统中⽆法实现，因为程序访问⻚⾯时是动态的\n我们是⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间，因此作为实际算法效率衡量标准。\n时钟⻚⾯置换算法：把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⻚⾯包含⼀个访问位。\n当发⽣缺⻚中断时，顺时针遍历⻚⾯，如果访问位为1，将其改为0，继续遍历，直到访问到访问位为0⻚⾯，\n进⾏置换。\n最不常⽤算法  ：记录每个⻚⾯访问次数，当发⽣缺⻚中断时候，将访问次数最少的⻚⾯置换出去，此⽅法需\n要对每个⻚⾯访问次数统计，额外开销。\nIO多路复⽤\nI/O多路复⽤通常通过select、poll、epoll等系统调⽤来实现。\nselect：  select是⼀个最古⽼的I/O多路复⽤机制，它可以监视多个⽂件描述符的可读、可写和错误状态。然\n⽽，但是它的效率可能随着监视的⽂件描述符数量的增加⽽降低。\npoll： poll是select的⼀种改进，它使⽤轮询⽅式来检查多个⽂件描述符的状态，避免了select中⽂件描述符\n数量有限的问题。但对于⼤量的⽂件描述符，poll的性能也可能变得不⾜够⾼效。\nepoll： epoll是Linux特有的I/O多路复⽤机制，相较于select和poll，它在处理⼤量⽂件描述符时更加⾼效。\nepoll使⽤事件通知的⽅式，只有在⽂件描述符就绪时才会通知应⽤程序，⽽不需要应⽤程序轮询。\nI/O多路复⽤允许在⼀个线程中处理多个I/O操作，避免了创建多个线程或进程的开销，允许在⼀个线程中处理多个\nI/O操作，避免了创建多个线程或进程的开销。\n数据库-MySQL\n内容参考总结⾃⽹络资料，如⼩林coding、MySQL45讲\nMySQL基础\n主键、索引、外键",
    "question": "## 交互式系统中的调度",
    "answer": "（1） 时间⽚轮转调度\n将所有就绪进程按 FCFS 的原则排成⼀个队列，每次调度时，把 CPU 时间分配给队⾸进程，该进程可以执⾏⼀个时\n间⽚。当时间⽚⽤完时，由计时器发出时钟中断，调度程序便停⽌该进程的执⾏，并将它送往就绪队列的末尾，同\n时继续把 CPU 时间分配给队⾸的进程。\n（2） 优先级调度\n为每个进程分配⼀个优先级，按优先级进⾏调度。为了防⽌低优先级的进程永远等不到调度，可以随着时间的推移\n增加等待进程的优先级。\n（3） 多级队列\n⼀个进程需要执⾏ 100 个时间⽚，如果采⽤时间⽚轮转调度算法，那么需要交换 100 次。\n多级队列是为这种需要连续执⾏多个时间⽚的进程考虑，它设置了多个队列，每个队列时间⽚⼤⼩都不同，例如\n1,2,4,8,..。进程在第⼀个队列没执⾏完，就会被移到下⼀个队列。这种⽅式下，之前的进程只需要交换  7  次。\n每个队列优先权也不同，最上⾯的优先权最⾼。因此只有上⼀个队列没有进程在排队，才能调度当前队列上的进\n可以将这种调度算法看成是时间⽚轮转调度算法和优先级调度算法的结合。\n（4） 最短进程优先\n如果我们将每⼀条命令的执⾏看作是⼀个独⽴的“作业”，则我们可以通过⾸先运⾏最短的作业来使响应事件最短\n分段和分⻚的区别\n基本单位：  地址空间被划分为不同的逻辑段，每个段具有独⽴的含义，如代码段、数据段等。\n段的⻓度：  每个段的⻓度可以动态变化，不同段的⻓度可以不同。\n内部碎⽚：  由于每个段的⻓度可以动态变化，可能会导致内部碎⽚，即段内部的未使⽤空间。\n外部碎⽚：  可能会导致外部碎⽚，即段之间的未使⽤空间。\n逻辑地址：  逻辑地址由两部分组成，⼀个是段号，另⼀个是段内偏移。\n分⻚（Paging）：\n基本单位：  地址空间被划分为固定⼤⼩的⻚⾯，物理内存也被划分为相同⼤⼩的⻚⾯框。\n⻚⾯的⻓度：  ⻚⾯的⻓度是固定的，由操作系统定义。\n内部碎⽚：  由于⻚⾯⻓度固定，可能会导致内部碎⽚，即⻚⾯内部的未使⽤空间。\n外部碎⽚：  由于⻚⾯⻓度固定，不同⻚⾯之间的未使⽤空间⽆法利⽤，可能导致外部碎⽚。\n逻辑地址：  逻辑地址由两部分组成，⼀个是⻚号，另⼀个是⻚内偏移。\n⻚⾯置换算法\nLRU（最近最少使⽤）算法：每次选择最⻓时间没有被使⽤的⻆⾊进⾏切换。这种策略基于你对⻆⾊的喜好，\n认为最近被使⽤过的⻆⾊很可能还会被使⽤，⽽最久未被使⽤的⻆⾊很可能不会再被使⽤。LRU算法可以有效\n地减少切换次数，但是实现起来⽐较复杂，需要记录每个⻆⾊的使⽤时间或者维护⼀个使⽤顺序的列表。\nFIFO（先进先出）算法：每次选择最早进⼊内存的⻆⾊进⾏切换。这种策略很简单，只需要维护⼀个⻆⾊队\n列，每次淘汰队⾸的⻆⾊，然后把新的⻆⾊加⼊队尾。但是FIFO算法可能会淘汰⼀些经常被使⽤的⻆⾊，导\n致切换次数增加。⽽且FIFO算法有可能出现⻉拉迪异常（Belady anomaly），即当分配给内存的空间增加\n时，切换次数反⽽增加。\n最佳⻚⾯置换算法(OPT)\n置换在「未来」最⻓时间不访问的⻚⾯,但是实际系统中⽆法实现，因为程序访问⻚⾯时是动态的\n我们是⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间，因此作为实际算法效率衡量标准。\n时钟⻚⾯置换算法：把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⻚⾯包含⼀个访问位。\n当发⽣缺⻚中断时，顺时针遍历⻚⾯，如果访问位为1，将其改为0，继续遍历，直到访问到访问位为0⻚⾯，\n进⾏置换。\n最不常⽤算法  ：记录每个⻚⾯访问次数，当发⽣缺⻚中断时候，将访问次数最少的⻚⾯置换出去，此⽅法需\n要对每个⻚⾯访问次数统计，额外开销。\nIO多路复⽤\nI/O多路复⽤通常通过select、poll、epoll等系统调⽤来实现。\nselect：  select是⼀个最古⽼的I/O多路复⽤机制，它可以监视多个⽂件描述符的可读、可写和错误状态。然\n⽽，但是它的效率可能随着监视的⽂件描述符数量的增加⽽降低。\npoll： poll是select的⼀种改进，它使⽤轮询⽅式来检查多个⽂件描述符的状态，避免了select中⽂件描述符\n数量有限的问题。但对于⼤量的⽂件描述符，poll的性能也可能变得不⾜够⾼效。\nepoll： epoll是Linux特有的I/O多路复⽤机制，相较于select和poll，它在处理⼤量⽂件描述符时更加⾼效。\nepoll使⽤事件通知的⽅式，只有在⽂件描述符就绪时才会通知应⽤程序，⽽不需要应⽤程序轮询。\nI/O多路复⽤允许在⼀个线程中处理多个I/O操作，避免了创建多个线程或进程的开销，允许在⼀个线程中处理多个\nI/O操作，避免了创建多个线程或进程的开销。\n数据库-MySQL\n内容参考总结⾃⽹络资料，如⼩林coding、MySQL45讲\nMySQL基础\n主键、索引、外键",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1996,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000107",
    "content": "分段和分⻚的区别\n\n基本单位：  地址空间被划分为不同的逻辑段，每个段具有独⽴的含义，如代码段、数据段等。\n段的⻓度：  每个段的⻓度可以动态变化，不同段的⻓度可以不同。\n内部碎⽚：  由于每个段的⻓度可以动态变化，可能会导致内部碎⽚，即段内部的未使⽤空间。\n外部碎⽚：  可能会导致外部碎⽚，即段之间的未使⽤空间。\n逻辑地址：  逻辑地址由两部分组成，⼀个是段号，另⼀个是段内偏移。\n分⻚（Paging）：\n基本单位：  地址空间被划分为固定⼤⼩的⻚⾯，物理内存也被划分为相同⼤⼩的⻚⾯框。\n⻚⾯的⻓度：  ⻚⾯的⻓度是固定的，由操作系统定义。\n内部碎⽚：  由于⻚⾯⻓度固定，可能会导致内部碎⽚，即⻚⾯内部的未使⽤空间。\n外部碎⽚：  由于⻚⾯⻓度固定，不同⻚⾯之间的未使⽤空间⽆法利⽤，可能导致外部碎⽚。\n逻辑地址：  逻辑地址由两部分组成，⼀个是⻚号，另⼀个是⻚内偏移。\n⻚⾯置换算法\nLRU（最近最少使⽤）算法：每次选择最⻓时间没有被使⽤的⻆⾊进⾏切换。这种策略基于你对⻆⾊的喜好，\n认为最近被使⽤过的⻆⾊很可能还会被使⽤，⽽最久未被使⽤的⻆⾊很可能不会再被使⽤。LRU算法可以有效\n地减少切换次数，但是实现起来⽐较复杂，需要记录每个⻆⾊的使⽤时间或者维护⼀个使⽤顺序的列表。\nFIFO（先进先出）算法：每次选择最早进⼊内存的⻆⾊进⾏切换。这种策略很简单，只需要维护⼀个⻆⾊队\n列，每次淘汰队⾸的⻆⾊，然后把新的⻆⾊加⼊队尾。但是FIFO算法可能会淘汰⼀些经常被使⽤的⻆⾊，导\n致切换次数增加。⽽且FIFO算法有可能出现⻉拉迪异常（Belady anomaly），即当分配给内存的空间增加\n时，切换次数反⽽增加。\n最佳⻚⾯置换算法(OPT)\n置换在「未来」最⻓时间不访问的⻚⾯,但是实际系统中⽆法实现，因为程序访问⻚⾯时是动态的\n我们是⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间，因此作为实际算法效率衡量标准。\n时钟⻚⾯置换算法：把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⻚⾯包含⼀个访问位。\n当发⽣缺⻚中断时，顺时针遍历⻚⾯，如果访问位为1，将其改为0，继续遍历，直到访问到访问位为0⻚⾯，\n进⾏置换。\n最不常⽤算法  ：记录每个⻚⾯访问次数，当发⽣缺⻚中断时候，将访问次数最少的⻚⾯置换出去，此⽅法需\n要对每个⻚⾯访问次数统计，额外开销。\nIO多路复⽤\nI/O多路复⽤通常通过select、poll、epoll等系统调⽤来实现。\nselect：  select是⼀个最古⽼的I/O多路复⽤机制，它可以监视多个⽂件描述符的可读、可写和错误状态。然\n⽽，但是它的效率可能随着监视的⽂件描述符数量的增加⽽降低。\npoll： poll是select的⼀种改进，它使⽤轮询⽅式来检查多个⽂件描述符的状态，避免了select中⽂件描述符\n数量有限的问题。但对于⼤量的⽂件描述符，poll的性能也可能变得不⾜够⾼效。\nepoll： epoll是Linux特有的I/O多路复⽤机制，相较于select和poll，它在处理⼤量⽂件描述符时更加⾼效。\nepoll使⽤事件通知的⽅式，只有在⽂件描述符就绪时才会通知应⽤程序，⽽不需要应⽤程序轮询。\nI/O多路复⽤允许在⼀个线程中处理多个I/O操作，避免了创建多个线程或进程的开销，允许在⼀个线程中处理多个\nI/O操作，避免了创建多个线程或进程的开销。\n数据库-MySQL\n内容参考总结⾃⽹络资料，如⼩林coding、MySQL45讲\nMySQL基础\n主键、索引、外键\n## 什么是主键\n主键是⼀列，其值可以唯⼀标识表中的每⼀⾏数据，每个表只能有⼀个主键，⽽且主键的值不能重复，也不能包含\nNULL值，通常⽤来保证数据的唯⼀性和⽤于在表中查找特定的⾏。",
    "question": "分段和分⻚的区别",
    "answer": "基本单位：  地址空间被划分为不同的逻辑段，每个段具有独⽴的含义，如代码段、数据段等。\n段的⻓度：  每个段的⻓度可以动态变化，不同段的⻓度可以不同。\n内部碎⽚：  由于每个段的⻓度可以动态变化，可能会导致内部碎⽚，即段内部的未使⽤空间。\n外部碎⽚：  可能会导致外部碎⽚，即段之间的未使⽤空间。\n逻辑地址：  逻辑地址由两部分组成，⼀个是段号，另⼀个是段内偏移。\n分⻚（Paging）：\n基本单位：  地址空间被划分为固定⼤⼩的⻚⾯，物理内存也被划分为相同⼤⼩的⻚⾯框。\n⻚⾯的⻓度：  ⻚⾯的⻓度是固定的，由操作系统定义。\n内部碎⽚：  由于⻚⾯⻓度固定，可能会导致内部碎⽚，即⻚⾯内部的未使⽤空间。\n外部碎⽚：  由于⻚⾯⻓度固定，不同⻚⾯之间的未使⽤空间⽆法利⽤，可能导致外部碎⽚。\n逻辑地址：  逻辑地址由两部分组成，⼀个是⻚号，另⼀个是⻚内偏移。\n⻚⾯置换算法\nLRU（最近最少使⽤）算法：每次选择最⻓时间没有被使⽤的⻆⾊进⾏切换。这种策略基于你对⻆⾊的喜好，\n认为最近被使⽤过的⻆⾊很可能还会被使⽤，⽽最久未被使⽤的⻆⾊很可能不会再被使⽤。LRU算法可以有效\n地减少切换次数，但是实现起来⽐较复杂，需要记录每个⻆⾊的使⽤时间或者维护⼀个使⽤顺序的列表。\nFIFO（先进先出）算法：每次选择最早进⼊内存的⻆⾊进⾏切换。这种策略很简单，只需要维护⼀个⻆⾊队\n列，每次淘汰队⾸的⻆⾊，然后把新的⻆⾊加⼊队尾。但是FIFO算法可能会淘汰⼀些经常被使⽤的⻆⾊，导\n致切换次数增加。⽽且FIFO算法有可能出现⻉拉迪异常（Belady anomaly），即当分配给内存的空间增加\n时，切换次数反⽽增加。\n最佳⻚⾯置换算法(OPT)\n置换在「未来」最⻓时间不访问的⻚⾯,但是实际系统中⽆法实现，因为程序访问⻚⾯时是动态的\n我们是⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间，因此作为实际算法效率衡量标准。\n时钟⻚⾯置换算法：把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⻚⾯包含⼀个访问位。\n当发⽣缺⻚中断时，顺时针遍历⻚⾯，如果访问位为1，将其改为0，继续遍历，直到访问到访问位为0⻚⾯，\n进⾏置换。\n最不常⽤算法  ：记录每个⻚⾯访问次数，当发⽣缺⻚中断时候，将访问次数最少的⻚⾯置换出去，此⽅法需\n要对每个⻚⾯访问次数统计，额外开销。\nIO多路复⽤\nI/O多路复⽤通常通过select、poll、epoll等系统调⽤来实现。\nselect：  select是⼀个最古⽼的I/O多路复⽤机制，它可以监视多个⽂件描述符的可读、可写和错误状态。然\n⽽，但是它的效率可能随着监视的⽂件描述符数量的增加⽽降低。\npoll： poll是select的⼀种改进，它使⽤轮询⽅式来检查多个⽂件描述符的状态，避免了select中⽂件描述符\n数量有限的问题。但对于⼤量的⽂件描述符，poll的性能也可能变得不⾜够⾼效。\nepoll： epoll是Linux特有的I/O多路复⽤机制，相较于select和poll，它在处理⼤量⽂件描述符时更加⾼效。\nepoll使⽤事件通知的⽅式，只有在⽂件描述符就绪时才会通知应⽤程序，⽽不需要应⽤程序轮询。\nI/O多路复⽤允许在⼀个线程中处理多个I/O操作，避免了创建多个线程或进程的开销，允许在⼀个线程中处理多个\nI/O操作，避免了创建多个线程或进程的开销。\n数据库-MySQL\n内容参考总结⾃⽹络资料，如⼩林coding、MySQL45讲\nMySQL基础\n主键、索引、外键\n## 什么是主键\n主键是⼀列，其值可以唯⼀标识表中的每⼀⾏数据，每个表只能有⼀个主键，⽽且主键的值不能重复，也不能包含\nNULL值，通常⽤来保证数据的唯⼀性和⽤于在表中查找特定的⾏。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1551,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000108",
    "content": "## 主键、外键、索引的区别\n\n定义：\n主键：唯⼀标识⼀条记录，不允许重复，不允许为空\n外键：外键是⼀个表中的字段，其值是另⼀个表的主键，⽤于建⽴两个表之间的关系。\n索引：没有重复值，但可以有⼀个空值  ，⽤于快速查询到数据。\n作⽤：\n主键：⽤于唯⼀标识表中每⼀⾏的字段\n外键：主要⽤于和其它表建⽴联系\n索引：为了提⾼查询排序的速度\n外键是⼀个表中的字段，它与另⼀个表的主键形成关联，⽤于建⽴表之间的关系。\n主键和外键通常都与索引有关，但索引不⼀定是主键或外键。\nselect * from 驱动表, 被驱动表;\nselect * from 驱动表 join 被驱动表;\nselect * from 驱动表 inner join 被驱动表;\nselect * from 驱动表 cross join 被驱动表;\nselect * from 驱动表 left join 被驱动表 on 连接条件;\nselect * from 被驱动表 right join 驱动表 on 连接条件;\nMySQL表连接\n连接和笛卡尔积\n连接：\n将各个表中的记录都取出来进⾏依次匹配，将匹配后的结果发给客户端\n笛卡尔积：\n连接查询的结果中包含⼀个表的每⼀条记录与另⼀个表中每⼀条记录的组合，这样的查询结果就是笛卡尔积\n⽐如表a有5条记录；表b有6条记录；a和b的笛卡尔积就是30\n连接过程\n## 确定第⼀个需要查询的表，此表为驱动表\n## 从驱动表中取每⼀条符合搜索条件的记录，到接下来的表中查找匹配的记录；驱动表之后的那个表就叫被驱动\n只需要访问驱动表⼀次，可能会多次访问被驱动表\n每获得⼀条满⾜条件的驱动表记录，⻢上到被驱动表中寻找匹配的记录\n内/外连接\n内连接\n驱动表中的记录在被驱动表中找不到匹配的记录，那么驱动表的这条记录不会加⼊到最后的结果中\n外连接：\n驱动表中的记录在被驱动表中找不到匹配的记录，也仍需要加⼊到最后结果中\n左外连接：语句左侧的表为驱动表\n右外连接：语句右侧的表为驱动表\n对于内连接，驱动表和被驱动表的顺序可以更换；对于外连接，这个顺序不能随意更换\n过滤条件\nwhere：\n不论内外连接，只要是不符合  where  ⼦句的记录都不会加⼊到最后的结果中\non：\n在内连接中与 where 等价；\n在外连接中，如果驱动表中的记录在被驱动表中没有记录可以匹配，该驱动表记录仍会加⼊到结果中，对应的被驱\n动表字段以 null 填充\n嵌套循环连接\n如果有3个表进⾏连接，那么表1和表2完成连接后的结果作为驱动表，将表3作为被驱动表进⾏连接查询",
    "question": "## 主键、外键、索引的区别",
    "answer": "定义：\n主键：唯⼀标识⼀条记录，不允许重复，不允许为空\n外键：外键是⼀个表中的字段，其值是另⼀个表的主键，⽤于建⽴两个表之间的关系。\n索引：没有重复值，但可以有⼀个空值  ，⽤于快速查询到数据。\n作⽤：\n主键：⽤于唯⼀标识表中每⼀⾏的字段\n外键：主要⽤于和其它表建⽴联系\n索引：为了提⾼查询排序的速度\n外键是⼀个表中的字段，它与另⼀个表的主键形成关联，⽤于建⽴表之间的关系。\n主键和外键通常都与索引有关，但索引不⼀定是主键或外键。\nselect * from 驱动表, 被驱动表;\nselect * from 驱动表 join 被驱动表;\nselect * from 驱动表 inner join 被驱动表;\nselect * from 驱动表 cross join 被驱动表;\nselect * from 驱动表 left join 被驱动表 on 连接条件;\nselect * from 被驱动表 right join 驱动表 on 连接条件;\nMySQL表连接\n连接和笛卡尔积\n连接：\n将各个表中的记录都取出来进⾏依次匹配，将匹配后的结果发给客户端\n笛卡尔积：\n连接查询的结果中包含⼀个表的每⼀条记录与另⼀个表中每⼀条记录的组合，这样的查询结果就是笛卡尔积\n⽐如表a有5条记录；表b有6条记录；a和b的笛卡尔积就是30\n连接过程\n## 确定第⼀个需要查询的表，此表为驱动表\n## 从驱动表中取每⼀条符合搜索条件的记录，到接下来的表中查找匹配的记录；驱动表之后的那个表就叫被驱动\n只需要访问驱动表⼀次，可能会多次访问被驱动表\n每获得⼀条满⾜条件的驱动表记录，⻢上到被驱动表中寻找匹配的记录\n内/外连接\n内连接\n驱动表中的记录在被驱动表中找不到匹配的记录，那么驱动表的这条记录不会加⼊到最后的结果中\n外连接：\n驱动表中的记录在被驱动表中找不到匹配的记录，也仍需要加⼊到最后结果中\n左外连接：语句左侧的表为驱动表\n右外连接：语句右侧的表为驱动表\n对于内连接，驱动表和被驱动表的顺序可以更换；对于外连接，这个顺序不能随意更换\n过滤条件\nwhere：\n不论内外连接，只要是不符合  where  ⼦句的记录都不会加⼊到最后的结果中\non：\n在内连接中与 where 等价；\n在外连接中，如果驱动表中的记录在被驱动表中没有记录可以匹配，该驱动表记录仍会加⼊到结果中，对应的被驱\n动表字段以 null 填充\n嵌套循环连接\n如果有3个表进⾏连接，那么表1和表2完成连接后的结果作为驱动表，将表3作为被驱动表进⾏连接查询",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1070,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000109",
    "content": "## 从驱动表中取每⼀条符合搜索条件的记录，到接下来的表中查找匹配的记录；驱动表之后的那个表就叫被驱动\n\n只需要访问驱动表⼀次，可能会多次访问被驱动表\n每获得⼀条满⾜条件的驱动表记录，⻢上到被驱动表中寻找匹配的记录\n内/外连接\n内连接\n驱动表中的记录在被驱动表中找不到匹配的记录，那么驱动表的这条记录不会加⼊到最后的结果中\n外连接：\n驱动表中的记录在被驱动表中找不到匹配的记录，也仍需要加⼊到最后结果中\n左外连接：语句左侧的表为驱动表\n右外连接：语句右侧的表为驱动表\n对于内连接，驱动表和被驱动表的顺序可以更换；对于外连接，这个顺序不能随意更换\n过滤条件\nwhere：\n不论内外连接，只要是不符合  where  ⼦句的记录都不会加⼊到最后的结果中\non：\n在内连接中与 where 等价；\n在外连接中，如果驱动表中的记录在被驱动表中没有记录可以匹配，该驱动表记录仍会加⼊到结果中，对应的被驱\n动表字段以 null 填充\n嵌套循环连接\n如果有3个表进⾏连接，那么表1和表2完成连接后的结果作为驱动表，将表3作为被驱动表进⾏连接查询\n执⾏⼀次 select 语句，发⽣了什么\nwait_timeout\nMySQL 的架构共分为两层：Server 层和存储引擎层\nServer 层负责建⽴连接、分析和执⾏ SQL\n存储引擎层负责数据的存储和提取, ⽀持 InnoDB、MyISAM、Memory 等多个存储引擎, 现在最常⽤的存储引\n擎是 InnoDB，其⽀持索引类型是 B+ 树索引。",
    "question": "## 从驱动表中取每⼀条符合搜索条件的记录，到接下来的表中查找匹配的记录；驱动表之后的那个表就叫被驱动",
    "answer": "只需要访问驱动表⼀次，可能会多次访问被驱动表\n每获得⼀条满⾜条件的驱动表记录，⻢上到被驱动表中寻找匹配的记录\n内/外连接\n内连接\n驱动表中的记录在被驱动表中找不到匹配的记录，那么驱动表的这条记录不会加⼊到最后的结果中\n外连接：\n驱动表中的记录在被驱动表中找不到匹配的记录，也仍需要加⼊到最后结果中\n左外连接：语句左侧的表为驱动表\n右外连接：语句右侧的表为驱动表\n对于内连接，驱动表和被驱动表的顺序可以更换；对于外连接，这个顺序不能随意更换\n过滤条件\nwhere：\n不论内外连接，只要是不符合  where  ⼦句的记录都不会加⼊到最后的结果中\non：\n在内连接中与 where 等价；\n在外连接中，如果驱动表中的记录在被驱动表中没有记录可以匹配，该驱动表记录仍会加⼊到结果中，对应的被驱\n动表字段以 null 填充\n嵌套循环连接\n如果有3个表进⾏连接，那么表1和表2完成连接后的结果作为驱动表，将表3作为被驱动表进⾏连接查询\n执⾏⼀次 select 语句，发⽣了什么\nwait_timeout\nMySQL 的架构共分为两层：Server 层和存储引擎层\nServer 层负责建⽴连接、分析和执⾏ SQL\n存储引擎层负责数据的存储和提取, ⽀持 InnoDB、MyISAM、Memory 等多个存储引擎, 现在最常⽤的存储引\n擎是 InnoDB，其⽀持索引类型是 B+ 树索引。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 641,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000110",
    "content": "执⾏⼀次 select 语句，发⽣了什么\n\nwait_timeout\nMySQL 的架构共分为两层：Server 层和存储引擎层\nServer 层负责建⽴连接、分析和执⾏ SQL\n存储引擎层负责数据的存储和提取, ⽀持 InnoDB、MyISAM、Memory 等多个存储引擎, 现在最常⽤的存储引\n擎是 InnoDB，其⽀持索引类型是 B+ 树索引。\n## 连接器：管理连接和权限验证\n连接器跟客户端建⽴连接、获取权限、然后后⾯的权限逻辑判断都基于此时读取到的权限。\nMysql  会定期⾃动清理\"空闲\"连接，由参数\n控制的，默认值是 8 ⼩时。\n由于建⽴连接⽐较复杂，所以尽量使⽤⻓连接，⽽不是  短连接（少量查询后，就断开连接)\n但是，当 ⻓连接 过多时，可能导致内存占⽤太⼤，被系统强⾏杀掉（OOM），会导致 MySQL 异常重启\n解决⽅案为:\n定期断开⻓连接\nMySQL 5.7以后版本，可以通过执⾏  mysql_reset_connection 来重新初始化连接资源\n## 查询缓存\n执⾏查询语句前，先看下查询缓存中是否有结果\n如果有，则不必执⾏查询语句，直接取出缓存结果\n如果没命中缓存，则执⾏查询语句，并将执⾏查询语句后的结果，放⼊查询缓存中\n不建议使⽤查询缓存（当 数据表频繁更新时，最新查询结果可能和查询缓存中存放的结果不⼀致)\nMySQL 8.0 开始，执⾏⼀条 SQL 查询语句，不会再⾛到查询缓存这个阶段了。\n## 解析SQL\n你输⼊的是由多个字符串和空格组成的⼀条SQL语句，MySQL需要识别出⾥⾯的字符串分别是什么，代表什么。\n词法分析：根据你输⼊的字符串识别出关键字出来\n语法分析：根据词法分析的结果判断是否符合SQL语法，并构建SQL语法课\n## 执⾏SQL\n分为三个阶段：预处理阶段、优化阶段、执⾏阶段\n预处理阶段：判断表和字段是否存在\n优化阶段：将 SQL 查询语句的执⾏⽅案确定下来，⽐如在表⾥⾯有多个索引的时候，优化器会基于查询成本的考\n虑，来决定选择使⽤哪个索引, 或者在⼀个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执⾏阶段：MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进⼊了执⾏器阶段，开始执\n⾏语句（执⾏语句时，⾸先会判断当前⽤户是否有执⾏权限）。",
    "question": "执⾏⼀次 select 语句，发⽣了什么",
    "answer": "wait_timeout\nMySQL 的架构共分为两层：Server 层和存储引擎层\nServer 层负责建⽴连接、分析和执⾏ SQL\n存储引擎层负责数据的存储和提取, ⽀持 InnoDB、MyISAM、Memory 等多个存储引擎, 现在最常⽤的存储引\n擎是 InnoDB，其⽀持索引类型是 B+ 树索引。\n## 连接器：管理连接和权限验证\n连接器跟客户端建⽴连接、获取权限、然后后⾯的权限逻辑判断都基于此时读取到的权限。\nMysql  会定期⾃动清理\"空闲\"连接，由参数\n控制的，默认值是 8 ⼩时。\n由于建⽴连接⽐较复杂，所以尽量使⽤⻓连接，⽽不是  短连接（少量查询后，就断开连接)\n但是，当 ⻓连接 过多时，可能导致内存占⽤太⼤，被系统强⾏杀掉（OOM），会导致 MySQL 异常重启\n解决⽅案为:\n定期断开⻓连接\nMySQL 5.7以后版本，可以通过执⾏  mysql_reset_connection 来重新初始化连接资源\n## 查询缓存\n执⾏查询语句前，先看下查询缓存中是否有结果\n如果有，则不必执⾏查询语句，直接取出缓存结果\n如果没命中缓存，则执⾏查询语句，并将执⾏查询语句后的结果，放⼊查询缓存中\n不建议使⽤查询缓存（当 数据表频繁更新时，最新查询结果可能和查询缓存中存放的结果不⼀致)\nMySQL 8.0 开始，执⾏⼀条 SQL 查询语句，不会再⾛到查询缓存这个阶段了。\n## 解析SQL\n你输⼊的是由多个字符串和空格组成的⼀条SQL语句，MySQL需要识别出⾥⾯的字符串分别是什么，代表什么。\n词法分析：根据你输⼊的字符串识别出关键字出来\n语法分析：根据词法分析的结果判断是否符合SQL语法，并构建SQL语法课\n## 执⾏SQL\n分为三个阶段：预处理阶段、优化阶段、执⾏阶段\n预处理阶段：判断表和字段是否存在\n优化阶段：将 SQL 查询语句的执⾏⽅案确定下来，⽐如在表⾥⾯有多个索引的时候，优化器会基于查询成本的考\n虑，来决定选择使⽤哪个索引, 或者在⼀个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执⾏阶段：MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进⼊了执⾏器阶段，开始执\n⾏语句（执⾏语句时，⾸先会判断当前⽤户是否有执⾏权限）。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 972,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000111",
    "content": "## 执⾏SQL\n\n分为三个阶段：预处理阶段、优化阶段、执⾏阶段\n预处理阶段：判断表和字段是否存在\n优化阶段：将 SQL 查询语句的执⾏⽅案确定下来，⽐如在表⾥⾯有多个索引的时候，优化器会基于查询成本的考\n虑，来决定选择使⽤哪个索引, 或者在⼀个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执⾏阶段：MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进⼊了执⾏器阶段，开始执\n⾏语句（执⾏语句时，⾸先会判断当前⽤户是否有执⾏权限）。\n执⾏⼀次update语句，发⽣了什么\n查询语句的流程，更新语句同样需要⾛⼀遍",
    "question": "## 执⾏SQL",
    "answer": "分为三个阶段：预处理阶段、优化阶段、执⾏阶段\n预处理阶段：判断表和字段是否存在\n优化阶段：将 SQL 查询语句的执⾏⽅案确定下来，⽐如在表⾥⾯有多个索引的时候，优化器会基于查询成本的考\n虑，来决定选择使⽤哪个索引, 或者在⼀个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执⾏阶段：MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进⼊了执⾏器阶段，开始执\n⾏语句（执⾏语句时，⾸先会判断当前⽤户是否有执⾏权限）。\n执⾏⼀次update语句，发⽣了什么\n查询语句的流程，更新语句同样需要⾛⼀遍",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 272,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000112",
    "content": "执⾏⼀次update语句，发⽣了什么\n\n查询语句的流程，更新语句同样需要⾛⼀遍\n## 执⾏语句前先连接数据库\n## 数据库表有更新，跟表有关的查询缓存会失效，所以会清空之前的缓存结果\n## 分析器进⾏词法和语法解析，优化器进⾏优化，执⾏器负责执⾏，然后更新。\n但是更新流程涉及到了两个重要的⽇志模块： redo log（重做⽇志） 和binlog(归档⽇志) , 具体会在⽇志章节中\n讲解。\nredo log 和binlog 有什么不同？\n是 InnoDB 引擎特有的； binlog 是 MySQL 的 Server 层实现的，所有引擎都\n可以使⽤。\n是物理⽇志，记录的是“在某个数据⻚上做了什么修改”； binlog 是逻辑⽇\n志，记录的是这个语句的原始逻辑，⽐如“给 ID=2 这⼀⾏的 c 字段加 1\n是循环写的，空间固定会⽤完； binlog 是可以追加写⼊的。“追加写”是指\nbinlog  ⽂件写到⼀定⼤⼩后会切换到下⼀个，并不会覆盖以前的⽇志。\nMySQL语句\n⽬的：为了保证MySql服务器的安全，每个MySql的⽤户应该对他们需要的数据具有适当的访问权;\n例如:\n## 多数⽤户只能够⽤到读写权限，只有少数⽤户能够创建表格和删除表格\n## ⼀些⽤户只能访问某个数据库⽽不能访问其他的数据库\n## ⼀些⽤户可以管理其他⽤户的账号，但⼤多数⼈不需要管理别⼈的账号\nuse mysql\nselect user from user\nCREATE USER [user_name] IDENTIFIED BY [user_pwd]\nCREATE USER zhangsan IDENTIFIED BY '123456'\nRENAME USER [user_name] TO [new_user_name]\n每个⽤户需要⽤到什么权限，就只给他们什么权限\n如果每个⽤户的权限都很⾼，那数据库会变得⼗分危险，随时都需要⾯临很多误操作，所以要进⾏访问权限控制\n⽤户账号存储\n在 MySql 下，所有的⽤户的账号，密码，对数据库的操作权限，都存储在 mysql 下（数据库的名字就叫 mysql）\n的 user 表格中。\nuser 表格有⼀个 user 属性，user 属性就是当前所有的⽤户名，通过以下操作可以查看当前 mysql 的⽤户⼀共有\n多少。\n⽤户账号管理\n既然 mysql 中的 user 表格中存放着当前 mysql 的⽤户，那么新增⽤户只需要在 user 表中使⽤ insert 语句新增⼀\n条记录即可。\n不过为了安全起⻅不建议这样做，mysql 数据库存放着很重要的数据，这样直接对 mysql 数据库直接操作可能会\n伤害到 mysql 服务器。\n## 新增⽤户\n新增⼀个⽤户的语法：\n例如：新增⽤户 zhangsan，pwd=123456\n## 修改⽤户名\n修改⽤户名的语法：\nRENAME USER zhangsan TO lisi\nSET PASSWORD FOR [user_name] = Password('[new_pwd]')\nSET PASSWORD = Password('[new_pwd]')\nSET PASSWORD FOR lisi = Password('135790')\nDROP USER [user_name]\nDROP USER lisi\nSHOW GRANTS FOR [user_name]\n例如：例如将账号名从 zhangsan 改为 lisi\n## 修改⽤户密码\n修改⽤户密码语法：\n这⾥使⽤ password 函数对新密码进⾏加密。\n如果不指定⽤户名：\n默认为修改当前登陆的⽤户的密码。\n例如：修改 lisi 账号的密码：\n⽤户账号删除\n删除⽤户账号语法：\n例如：删除 lisi 的账号\n如果mysql版本低于mysql5，需要先revoke⽤户所有的权限，才能删除账号。更⾼版本则可以⼀次性删除权限和账\n⽤户权限控制\n## 查看⽤户权限\n刚创建的的⽤户是没有任何权限的，使⽤以下语法查看某⽤户所拥有的权限：\nGRANT [权限名] ON [数据库名].[表名] TO [⽤户名]\nREVOKE [权限名] ON [数据库名].[表名] FROM [⽤户名]\n⽽GRANT USAGE ON *.* TO 'lS'@'%' 则代表了⽤户ls没有任何权限。\n## ⽤户授权\n给⽤户授权的语法：\n例如：⽤户 'ls' 查找权限 select\n从表格中可以看到 'ls' 新增的权限。\n## 撤销授权\n撤销⽤户权限的语法：\n收回⽤户 ls 查找权限 select\ntype=ALL\ncreate index 索引名 on 表名(列名);\n## 也可以有多个列名构成索引（即，组合索引）\ndrop index 索引名 on 表名;\n从表格中可以看初 ls 新增的权限消失了\n什么是索引\n索引：索引的出现其实就是为了提⾼数据查询的效率，就像书的⽬录⼀样\nMySQL 在查询⽅⾯主要就是两种⽅式：\n## 全表扫描（⼀个⼀个挨个找）\n## 根据索引检索\n索引操作\n## 创建索引\n## 删除索引\n怎么查看⼀个SQL语句是否使⽤了索引进⾏检索\n在 SQL 语句前，添加 explian 关键字\n时，表示使⽤ 全表查询（未使⽤索引）\n当 type=RES 时，表示使⽤索引\n索引有哪些类别\n按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。\n按「物理存储」分类：聚簇索引（主键索引）、⼆级索引（辅助索引）。\n按「字段特性」分类：主键索引、唯⼀索引、普通索引、前缀索引。\n按「字段个数」分类：单列索引、联合索引。\n## 按照数据结构分类\n哈希表：使⽤ key-value 对，存储数据 ，可能存在 hash 冲突（多个 value 对应同⼀个 key）\n优点：key ⽆序，插⼊数据时⽆需维护顺序（直接在最后⼀个元素后追加，即可），效率较⾼；\n缺点：因为不是有序的，所以哈希索引做区间查询的速度是很慢\n适⽤场景：适⽤于只有等值查询的场景，⽽不适⽤频繁 区间查找\n有序数组：\n优点：等值查询 和 区间查询 性能都挺6 （有序数组 适合 查询）\n缺点：有序数组不适合 频繁 增/删 记录的场景 （但是，有序数组不适合 增/删）\n等值查询使⽤⼆分（前提是，有序 + 顺序存储），查询时间复杂度 O(log N)\n区间查询先⽤ ⼆分查找 “左边界”（不存在的时，则找第⼀个⽐ 它⼤的记录） ，然后，再向右扫描，直\n⾄ ⼤于右边界\n适⽤场景：有序数组只适⽤于静态存储引擎，在 等值查询 和 范围（区间）查询 场景中的性能⾮常优秀\n⼆叉搜索树\nBST 是为了 保留了 “有序数组” 查询（⼆分，O(logN)）性能好的优点，同时解决“有序数组” 不适合 增/删\n的缺点\nBST 查询的时间复杂度：O(log N) ，但是，为了维持 O(log(N)) 的查询复杂度，就需要保持这棵树是平\n衡⼆叉树。（维护 BST 是 AVL 的时间复杂度也是 O(log(N))）\n⼆叉树是搜索效率最⾼的，但是实际上⼤多数的数据库存储却并不使⽤⼆叉树。其原因是，索引不⽌存\n在内存中，还要写到磁盘上\nN叉树\ncreate table T\nid int primary key, # 主键 ⾃动创建索引\nk int not null,\nname varchar(16),\nindex (k)\n) # 给字段 k 条件 索引\nengine=InnoDB;\n为了让⼀个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块\n那么，我们就不应该使⽤⼆叉树，⽽是要使⽤ “N 叉”树（N 取决于数据块的⼤⼩）\n即，通过使⽤ N 叉树 来降低 树的⾼度，即 减少读取磁盘的次数（IO是很慢的），提⾼查询效率\nN 叉树特点：\n折中 考虑了 “查询性能” 和 “读取磁盘的次数”，⼴泛应⽤于 数据库引擎中\nMySQL 中，索引是在存储引擎层实现的，⽽且不同存储引擎的索引的⼯作⽅式并不⼀样。⽽即使多个存储引擎⽀\n持同⼀种类型的索引，其底层的实现也可能不同。\n下⾯以InnoDB  为例，和你分析⼀下其中的索引模型\nInnoDB 的索引模型:\nInnoDB 使⽤了 B+ 树索引模型，每⼀个索引在 InnoDB ⾥⾯对应⼀棵 B+ 树\n假设建表语句如下，则对应的 2 棵 索引树（主键 ⾃动创建⼀颗；字段 k 创建 ⼀颗索引树），如下所示\n## 按照存储分类\n根据叶⼦节点的内容，索引类型分为主键索引（聚簇索引）和⼆级索引（辅助索引）：\n主键索引的 B+Tree 的叶⼦节点存放的是实际数据，所有完整的⽤户记录都存放在主键索引的 B+Tree 的叶⼦\n节点⾥；\n⼆级索引的 B+Tree 的叶⼦节点存放的是主键值，⽽不是实际数据。\n主键查询和⼆级索引查询\n主键查询：直接在 主键索引 所在的 B+ 树中查询，然后直接返回查询到的叶⼦节点（此时，叶⼦节点⾥⾯就是整⾏记\n⼆级索引查询：⾸先，在普通索引所在的 B+ 树中，查询到待查询记录的 主键； 然后，再根据这些查到的 主键，执\n⾏ “主键查询” （即，回表）\n基于⾮主键索引的查询需要多扫描⼀棵索引树。因此，我们在应⽤中应该尽量使⽤主键查询。\n不过当查询的数据是能在⼆级索引的 B+Tree 的叶⼦节点⾥查询到，这时就不⽤再查主键索引查，这种在⼆级索引\n的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使⽤覆盖索引是⼀个常⽤的性能优化⼿段。\n## 按照字段特性分类\n主键索引：建⽴在主键字段上的索引，⼀张表最多只能有⼀个主键索引，不允许有空值。\n唯⼀索引：建⽴在UNIQUE 字段上的索引，⼀张表可以有多个唯⼀索引，索引列的值必须唯⼀，但是允许有空\n普通索引：建⽴在普通字段上的索引\n前缀索引：对字符类型字段的前⼏个字符建⽴的索引，⽽不是在整个字段上建⽴的索引，可以减⼩索引的⼤\n⼩，适⽤于较⻓列值的情况。\nWHERE column2 = 'value2'\n## 按照字段个数分类\n单列索引：建⽴在单列上的索引称为单列索引，⽐如主键索引；\n联合索引：由多个列组合⽽成的索引。适⽤于多列的查询条件\n什么是最左匹配原则\n通过将多个字段组合成⼀个索引，该索引就被称为联合索引。\n使⽤联合索引时，存在最左匹配原则，也就是按照最左优先的⽅式进⾏索引的匹配。\n最左匹配原则要求查询条件中的列应该从索引的最左边的列开始，并且不能跳过中间的列。如果查询条件不按照索\n引的顺序进⾏匹配，那么索引可能会失效。\n举个例⼦：\n如果查询条件为 WHERE column1 = 'value1' ，那么索引可以被有效使⽤。\n如果查询条件为 WHERE column1 = 'value1' AND column2 = 'value2' ，同样索引可以被有效使⽤。\n但如果查询条件为\n'value3' ，则最左匹配原则不成⽴。\n最左匹配时在遇到范围查询（如 >、<）的时候，就会停⽌匹配，范围查询的字段可以⽤到联合索引，但是范围查\n询字段的后⾯的字段⽆法⽤到联合索引。\n索引下推\n那些不符合最左前缀的部分，会怎么样呢？\n⽐如，执⾏如下语句时候，则存在不符合最左前缀的部分：\nWHERE column2 = 'value2' AND column3 =\n根据前缀索引规则，这个语句在搜索索引树的时候，只能⽤ “张”，找到第⼀个满⾜条件的记录 ID3\n然后在 MySQL 5.6 之前，只能从 ID3 开始⼀个个回表，到主键索引上找出数据⾏，再对⽐字段值。\n⽽ MySQL 5.6 引⼊了索引下推优化（index condition pushdown)\n可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满⾜条件的记录，减少回表次数。\n由图3可知，本例中 ⽆索引优化时，需要 回表 4 次；\n图4中，采⽤ 索引下推 优化，直接在索引遍历的过程中，过滤了不符合条件的记录（ID3、ID6），只⽤回表 2 次\nselect * from tuser\nwhere name like '张 %'\nand age=10\nand ismale=1;\n索引区分度\n索引区分度表示某个字段不同值的个数占整个表的⽐例，建⽴联合索引时，要把区分度⼤的字段排在前⾯。\n建⽴索引的注意事项\n索引不是越多越好，虽然索引会提⾼ select 效率，但是也降低了insert以及update的效率\n数据量⼩的表不需要建⽴索引，会增加额外的索引开销\n不经常使⽤的列不要建⽴索引\n频繁更新的列不要建⽴索引，会影响更新的效率",
    "question": "执⾏⼀次update语句，发⽣了什么",
    "answer": "查询语句的流程，更新语句同样需要⾛⼀遍\n## 执⾏语句前先连接数据库\n## 数据库表有更新，跟表有关的查询缓存会失效，所以会清空之前的缓存结果\n## 分析器进⾏词法和语法解析，优化器进⾏优化，执⾏器负责执⾏，然后更新。\n但是更新流程涉及到了两个重要的⽇志模块： redo log（重做⽇志） 和binlog(归档⽇志) , 具体会在⽇志章节中\n讲解。\nredo log 和binlog 有什么不同？\n是 InnoDB 引擎特有的； binlog 是 MySQL 的 Server 层实现的，所有引擎都\n可以使⽤。\n是物理⽇志，记录的是“在某个数据⻚上做了什么修改”； binlog 是逻辑⽇\n志，记录的是这个语句的原始逻辑，⽐如“给 ID=2 这⼀⾏的 c 字段加 1\n是循环写的，空间固定会⽤完； binlog 是可以追加写⼊的。“追加写”是指\nbinlog  ⽂件写到⼀定⼤⼩后会切换到下⼀个，并不会覆盖以前的⽇志。\nMySQL语句\n⽬的：为了保证MySql服务器的安全，每个MySql的⽤户应该对他们需要的数据具有适当的访问权;\n例如:\n## 多数⽤户只能够⽤到读写权限，只有少数⽤户能够创建表格和删除表格\n## ⼀些⽤户只能访问某个数据库⽽不能访问其他的数据库\n## ⼀些⽤户可以管理其他⽤户的账号，但⼤多数⼈不需要管理别⼈的账号\nuse mysql\nselect user from user\nCREATE USER [user_name] IDENTIFIED BY [user_pwd]\nCREATE USER zhangsan IDENTIFIED BY '123456'\nRENAME USER [user_name] TO [new_user_name]\n每个⽤户需要⽤到什么权限，就只给他们什么权限\n如果每个⽤户的权限都很⾼，那数据库会变得⼗分危险，随时都需要⾯临很多误操作，所以要进⾏访问权限控制\n⽤户账号存储\n在 MySql 下，所有的⽤户的账号，密码，对数据库的操作权限，都存储在 mysql 下（数据库的名字就叫 mysql）\n的 user 表格中。\nuser 表格有⼀个 user 属性，user 属性就是当前所有的⽤户名，通过以下操作可以查看当前 mysql 的⽤户⼀共有\n多少。\n⽤户账号管理\n既然 mysql 中的 user 表格中存放着当前 mysql 的⽤户，那么新增⽤户只需要在 user 表中使⽤ insert 语句新增⼀\n条记录即可。\n不过为了安全起⻅不建议这样做，mysql 数据库存放着很重要的数据，这样直接对 mysql 数据库直接操作可能会\n伤害到 mysql 服务器。\n## 新增⽤户\n新增⼀个⽤户的语法：\n例如：新增⽤户 zhangsan，pwd=123456\n## 修改⽤户名\n修改⽤户名的语法：\nRENAME USER zhangsan TO lisi\nSET PASSWORD FOR [user_name] = Password('[new_pwd]')\nSET PASSWORD = Password('[new_pwd]')\nSET PASSWORD FOR lisi = Password('135790')\nDROP USER [user_name]\nDROP USER lisi\nSHOW GRANTS FOR [user_name]\n例如：例如将账号名从 zhangsan 改为 lisi\n## 修改⽤户密码\n修改⽤户密码语法：\n这⾥使⽤ password 函数对新密码进⾏加密。\n如果不指定⽤户名：\n默认为修改当前登陆的⽤户的密码。\n例如：修改 lisi 账号的密码：\n⽤户账号删除\n删除⽤户账号语法：\n例如：删除 lisi 的账号\n如果mysql版本低于mysql5，需要先revoke⽤户所有的权限，才能删除账号。更⾼版本则可以⼀次性删除权限和账\n⽤户权限控制\n## 查看⽤户权限\n刚创建的的⽤户是没有任何权限的，使⽤以下语法查看某⽤户所拥有的权限：\nGRANT [权限名] ON [数据库名].[表名] TO [⽤户名]\nREVOKE [权限名] ON [数据库名].[表名] FROM [⽤户名]\n⽽GRANT USAGE ON *.* TO 'lS'@'%' 则代表了⽤户ls没有任何权限。\n## ⽤户授权\n给⽤户授权的语法：\n例如：⽤户 'ls' 查找权限 select\n从表格中可以看到 'ls' 新增的权限。\n## 撤销授权\n撤销⽤户权限的语法：\n收回⽤户 ls 查找权限 select\ntype=ALL\ncreate index 索引名 on 表名(列名);\n## 也可以有多个列名构成索引（即，组合索引）\ndrop index 索引名 on 表名;\n从表格中可以看初 ls 新增的权限消失了\n什么是索引\n索引：索引的出现其实就是为了提⾼数据查询的效率，就像书的⽬录⼀样\nMySQL 在查询⽅⾯主要就是两种⽅式：\n## 全表扫描（⼀个⼀个挨个找）\n## 根据索引检索\n索引操作\n## 创建索引\n## 删除索引\n怎么查看⼀个SQL语句是否使⽤了索引进⾏检索\n在 SQL 语句前，添加 explian 关键字\n时，表示使⽤ 全表查询（未使⽤索引）\n当 type=RES 时，表示使⽤索引\n索引有哪些类别\n按「数据结构」分类：B+tree索引、Hash索引、Full-text索引。\n按「物理存储」分类：聚簇索引（主键索引）、⼆级索引（辅助索引）。\n按「字段特性」分类：主键索引、唯⼀索引、普通索引、前缀索引。\n按「字段个数」分类：单列索引、联合索引。\n## 按照数据结构分类\n哈希表：使⽤ key-value 对，存储数据 ，可能存在 hash 冲突（多个 value 对应同⼀个 key）\n优点：key ⽆序，插⼊数据时⽆需维护顺序（直接在最后⼀个元素后追加，即可），效率较⾼；\n缺点：因为不是有序的，所以哈希索引做区间查询的速度是很慢\n适⽤场景：适⽤于只有等值查询的场景，⽽不适⽤频繁 区间查找\n有序数组：\n优点：等值查询 和 区间查询 性能都挺6 （有序数组 适合 查询）\n缺点：有序数组不适合 频繁 增/删 记录的场景 （但是，有序数组不适合 增/删）\n等值查询使⽤⼆分（前提是，有序 + 顺序存储），查询时间复杂度 O(log N)\n区间查询先⽤ ⼆分查找 “左边界”（不存在的时，则找第⼀个⽐ 它⼤的记录） ，然后，再向右扫描，直\n⾄ ⼤于右边界\n适⽤场景：有序数组只适⽤于静态存储引擎，在 等值查询 和 范围（区间）查询 场景中的性能⾮常优秀\n⼆叉搜索树\nBST 是为了 保留了 “有序数组” 查询（⼆分，O(logN)）性能好的优点，同时解决“有序数组” 不适合 增/删\n的缺点\nBST 查询的时间复杂度：O(log N) ，但是，为了维持 O(log(N)) 的查询复杂度，就需要保持这棵树是平\n衡⼆叉树。（维护 BST 是 AVL 的时间复杂度也是 O(log(N))）\n⼆叉树是搜索效率最⾼的，但是实际上⼤多数的数据库存储却并不使⽤⼆叉树。其原因是，索引不⽌存\n在内存中，还要写到磁盘上\nN叉树\ncreate table T\nid int primary key, # 主键 ⾃动创建索引\nk int not null,\nname varchar(16),\nindex (k)\n) # 给字段 k 条件 索引\nengine=InnoDB;\n为了让⼀个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块\n那么，我们就不应该使⽤⼆叉树，⽽是要使⽤ “N 叉”树（N 取决于数据块的⼤⼩）\n即，通过使⽤ N 叉树 来降低 树的⾼度，即 减少读取磁盘的次数（IO是很慢的），提⾼查询效率\nN 叉树特点：\n折中 考虑了 “查询性能” 和 “读取磁盘的次数”，⼴泛应⽤于 数据库引擎中\nMySQL 中，索引是在存储引擎层实现的，⽽且不同存储引擎的索引的⼯作⽅式并不⼀样。⽽即使多个存储引擎⽀\n持同⼀种类型的索引，其底层的实现也可能不同。\n下⾯以InnoDB  为例，和你分析⼀下其中的索引模型\nInnoDB 的索引模型:\nInnoDB 使⽤了 B+ 树索引模型，每⼀个索引在 InnoDB ⾥⾯对应⼀棵 B+ 树\n假设建表语句如下，则对应的 2 棵 索引树（主键 ⾃动创建⼀颗；字段 k 创建 ⼀颗索引树），如下所示\n## 按照存储分类\n根据叶⼦节点的内容，索引类型分为主键索引（聚簇索引）和⼆级索引（辅助索引）：\n主键索引的 B+Tree 的叶⼦节点存放的是实际数据，所有完整的⽤户记录都存放在主键索引的 B+Tree 的叶⼦\n节点⾥；\n⼆级索引的 B+Tree 的叶⼦节点存放的是主键值，⽽不是实际数据。\n主键查询和⼆级索引查询\n主键查询：直接在 主键索引 所在的 B+ 树中查询，然后直接返回查询到的叶⼦节点（此时，叶⼦节点⾥⾯就是整⾏记\n⼆级索引查询：⾸先，在普通索引所在的 B+ 树中，查询到待查询记录的 主键； 然后，再根据这些查到的 主键，执\n⾏ “主键查询” （即，回表）\n基于⾮主键索引的查询需要多扫描⼀棵索引树。因此，我们在应⽤中应该尽量使⽤主键查询。\n不过当查询的数据是能在⼆级索引的 B+Tree 的叶⼦节点⾥查询到，这时就不⽤再查主键索引查，这种在⼆级索引\n的 B+Tree 就能查询到结果的过程就叫作「覆盖索引」\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使⽤覆盖索引是⼀个常⽤的性能优化⼿段。\n## 按照字段特性分类\n主键索引：建⽴在主键字段上的索引，⼀张表最多只能有⼀个主键索引，不允许有空值。\n唯⼀索引：建⽴在UNIQUE 字段上的索引，⼀张表可以有多个唯⼀索引，索引列的值必须唯⼀，但是允许有空\n普通索引：建⽴在普通字段上的索引\n前缀索引：对字符类型字段的前⼏个字符建⽴的索引，⽽不是在整个字段上建⽴的索引，可以减⼩索引的⼤\n⼩，适⽤于较⻓列值的情况。\nWHERE column2 = 'value2'\n## 按照字段个数分类\n单列索引：建⽴在单列上的索引称为单列索引，⽐如主键索引；\n联合索引：由多个列组合⽽成的索引。适⽤于多列的查询条件\n什么是最左匹配原则\n通过将多个字段组合成⼀个索引，该索引就被称为联合索引。\n使⽤联合索引时，存在最左匹配原则，也就是按照最左优先的⽅式进⾏索引的匹配。\n最左匹配原则要求查询条件中的列应该从索引的最左边的列开始，并且不能跳过中间的列。如果查询条件不按照索\n引的顺序进⾏匹配，那么索引可能会失效。\n举个例⼦：\n如果查询条件为 WHERE column1 = 'value1' ，那么索引可以被有效使⽤。\n如果查询条件为 WHERE column1 = 'value1' AND column2 = 'value2' ，同样索引可以被有效使⽤。\n但如果查询条件为\n'value3' ，则最左匹配原则不成⽴。\n最左匹配时在遇到范围查询（如 >、<）的时候，就会停⽌匹配，范围查询的字段可以⽤到联合索引，但是范围查\n询字段的后⾯的字段⽆法⽤到联合索引。\n索引下推\n那些不符合最左前缀的部分，会怎么样呢？\n⽐如，执⾏如下语句时候，则存在不符合最左前缀的部分：\nWHERE column2 = 'value2' AND column3 =\n根据前缀索引规则，这个语句在搜索索引树的时候，只能⽤ “张”，找到第⼀个满⾜条件的记录 ID3\n然后在 MySQL 5.6 之前，只能从 ID3 开始⼀个个回表，到主键索引上找出数据⾏，再对⽐字段值。\n⽽ MySQL 5.6 引⼊了索引下推优化（index condition pushdown)\n可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满⾜条件的记录，减少回表次数。\n由图3可知，本例中 ⽆索引优化时，需要 回表 4 次；\n图4中，采⽤ 索引下推 优化，直接在索引遍历的过程中，过滤了不符合条件的记录（ID3、ID6），只⽤回表 2 次\nselect * from tuser\nwhere name like '张 %'\nand age=10\nand ismale=1;\n索引区分度\n索引区分度表示某个字段不同值的个数占整个表的⽐例，建⽴联合索引时，要把区分度⼤的字段排在前⾯。\n建⽴索引的注意事项\n索引不是越多越好，虽然索引会提⾼ select 效率，但是也降低了insert以及update的效率\n数据量⼩的表不需要建⽴索引，会增加额外的索引开销\n不经常使⽤的列不要建⽴索引\n频繁更新的列不要建⽴索引，会影响更新的效率",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 5211,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000113",
    "content": "## 按照字段个数分类\n\n单列索引：建⽴在单列上的索引称为单列索引，⽐如主键索引；\n联合索引：由多个列组合⽽成的索引。适⽤于多列的查询条件\n什么是最左匹配原则\n通过将多个字段组合成⼀个索引，该索引就被称为联合索引。\n使⽤联合索引时，存在最左匹配原则，也就是按照最左优先的⽅式进⾏索引的匹配。\n最左匹配原则要求查询条件中的列应该从索引的最左边的列开始，并且不能跳过中间的列。如果查询条件不按照索\n引的顺序进⾏匹配，那么索引可能会失效。\n举个例⼦：\n如果查询条件为 WHERE column1 = 'value1' ，那么索引可以被有效使⽤。\n如果查询条件为 WHERE column1 = 'value1' AND column2 = 'value2' ，同样索引可以被有效使⽤。\n但如果查询条件为\n'value3' ，则最左匹配原则不成⽴。\n最左匹配时在遇到范围查询（如 >、<）的时候，就会停⽌匹配，范围查询的字段可以⽤到联合索引，但是范围查\n询字段的后⾯的字段⽆法⽤到联合索引。\n索引下推\n那些不符合最左前缀的部分，会怎么样呢？\n⽐如，执⾏如下语句时候，则存在不符合最左前缀的部分：\nWHERE column2 = 'value2' AND column3 =\n根据前缀索引规则，这个语句在搜索索引树的时候，只能⽤ “张”，找到第⼀个满⾜条件的记录 ID3\n然后在 MySQL 5.6 之前，只能从 ID3 开始⼀个个回表，到主键索引上找出数据⾏，再对⽐字段值。\n⽽ MySQL 5.6 引⼊了索引下推优化（index condition pushdown)\n可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满⾜条件的记录，减少回表次数。\n由图3可知，本例中 ⽆索引优化时，需要 回表 4 次；\n图4中，采⽤ 索引下推 优化，直接在索引遍历的过程中，过滤了不符合条件的记录（ID3、ID6），只⽤回表 2 次\nselect * from tuser\nwhere name like '张 %'\nand age=10\nand ismale=1;\n索引区分度\n索引区分度表示某个字段不同值的个数占整个表的⽐例，建⽴联合索引时，要把区分度⼤的字段排在前⾯。\n建⽴索引的注意事项\n索引不是越多越好，虽然索引会提⾼ select 效率，但是也降低了insert以及update的效率\n数据量⼩的表不需要建⽴索引，会增加额外的索引开销\n不经常使⽤的列不要建⽴索引\n频繁更新的列不要建⽴索引，会影响更新的效率\n索引的优缺点\n使⽤索引可以⼤⼤加快数据的检索速度（⼤⼤减少检索的数据量），这也是创建索引的最主要的原因。\n但是注意使⽤索引不⼀定能够提⾼查询性能，因为如果数据库的数据量不⼤，那么使⽤索引也不⼀定能够带来\n很⼤提升。其余⼤多数情况下，索引查询⽐全表扫描要快。\n通过创建唯⼀性索引，可以保证数据库表中每⼀⾏数据的唯⼀性。\n空间消耗，⼀个索引对应的就是⼀棵 B+树，每⼀个节点都是⼀个 16KB ⼤⼩的⻚。占⽤的空间较⼤。\n创建索引和维护索引需要耗费许多时间，当对表中的数据进⾏增删改的时候，如果数据有索引，那么索引也需\n要动态的修改，会降低 SQL 执⾏效率。\n什么时候需要创建索引\n频繁⽤于查询的列需要创建索引\n⼤表：对于很⼤的表，建⽴索引可以提⾼查询速度\n唯⼀性要求：主键列和唯⼀性约束的列会⾃动创建唯⼀索引，但如果查询中经常包含唯⼀性条件，可以额外创\n建唯⼀性索引。\n连接表的外键列：为外键列创建索引可以提⾼连接的效率。\n频繁使⽤排序和分组的列：如果某列经常⽤于 ORDER BY 或 GROUP BY ⼦句可以创建索引\n什么时候不需要创建索引\n⼩表：在⼩表上，索引不会带来显著的性能提升，还会增加维护开销。\n经常进⾏更新的字段不需要创建索引\n很少⽤于查询的字段\n字段中存在⼤量重复数据，不需要创建索引，⽐如性别字段\n索引优化的⽅法\n前缀索引优化：使⽤某个字段中字符串的前⼏个字符建⽴索引，从⽽减⼩索引字段⼤⼩\n覆盖索引优化：从⼆级索引中可以查询得到记录，避免回表\n主键索引最好是⾃增的；这样每次插⼊⼀条新记录，都是追加操作，不需要重新移动数据，⽽使⽤⾮⾃增主键\n会导致插⼊主键的索引值是随机的，这可能会插⼊到现有数据⻚的某个位置，导致其他数据的移动，造成⻚分\n避免过多的索引\nSELECT * FROM table WHERE UPPER(column) = 'VALUE';\n索引什么时候会失效\n使⽤左或者左右模糊匹配：⽐如LIKE '%abc' 这样的查询会导致索引失效。\n在索引列上使⽤函数或表达式：  索引列上参与计算，索引失效\n在 WHERE ⼦句中，如果在 OR 前的条件列是索引列，⽽在 OR 后的条件列不是索引列，那么索引会失效。\n违背最左匹配原则，索引失效\n数据分布不均匀：   如果数据分布不均匀，例如某个索引列的⼤多数值都相同，选择性降低，导致索引失效。\n隐式类型转换：   如果查询中的条件涉及到隐式类型转换，例如将字符串与数字⽐较，索引可能⽆法被使⽤。\n为什么使⽤B+树索引\nB+树的⾮叶⼦节点不存放实际的记录数据，仅存放索引，所以数据量相同的情况下，相⽐存储即存索引⼜存\n记录的 B 树，B+树的⾮叶⼦节点可以存放更多的索引，因此 B+ 树可以⽐ B 树更「矮胖」，查询底层节点的\n磁盘 I/O次数会更少。\nB+ 树有⼤量的冗余节点（所有⾮叶⼦节点都是冗余索引），这些冗余索引让 B+ 树在插⼊、删除的效率都更\n⾼，⽐如删除根节点的时候，不会像 B 树那样会发⽣复杂的树的变化；\nB+ 树叶⼦节点之间⽤链表连接了起来，有利于范围查询，⽽ B 树要实现范围查询，因此只能通过树的遍历来\n完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。\n思维导图：\nMySQL原⽣引擎MyISAM不⽀持事务，所以被InnoDB取代。\n事务的四⼤特性ACID\nACID（Atomicity、Consistency、Isolation、Durability，即原⼦性、⼀致性、隔离性、持久性）",
    "question": "## 按照字段个数分类",
    "answer": "单列索引：建⽴在单列上的索引称为单列索引，⽐如主键索引；\n联合索引：由多个列组合⽽成的索引。适⽤于多列的查询条件\n什么是最左匹配原则\n通过将多个字段组合成⼀个索引，该索引就被称为联合索引。\n使⽤联合索引时，存在最左匹配原则，也就是按照最左优先的⽅式进⾏索引的匹配。\n最左匹配原则要求查询条件中的列应该从索引的最左边的列开始，并且不能跳过中间的列。如果查询条件不按照索\n引的顺序进⾏匹配，那么索引可能会失效。\n举个例⼦：\n如果查询条件为 WHERE column1 = 'value1' ，那么索引可以被有效使⽤。\n如果查询条件为 WHERE column1 = 'value1' AND column2 = 'value2' ，同样索引可以被有效使⽤。\n但如果查询条件为\n'value3' ，则最左匹配原则不成⽴。\n最左匹配时在遇到范围查询（如 >、<）的时候，就会停⽌匹配，范围查询的字段可以⽤到联合索引，但是范围查\n询字段的后⾯的字段⽆法⽤到联合索引。\n索引下推\n那些不符合最左前缀的部分，会怎么样呢？\n⽐如，执⾏如下语句时候，则存在不符合最左前缀的部分：\nWHERE column2 = 'value2' AND column3 =\n根据前缀索引规则，这个语句在搜索索引树的时候，只能⽤ “张”，找到第⼀个满⾜条件的记录 ID3\n然后在 MySQL 5.6 之前，只能从 ID3 开始⼀个个回表，到主键索引上找出数据⾏，再对⽐字段值。\n⽽ MySQL 5.6 引⼊了索引下推优化（index condition pushdown)\n可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满⾜条件的记录，减少回表次数。\n由图3可知，本例中 ⽆索引优化时，需要 回表 4 次；\n图4中，采⽤ 索引下推 优化，直接在索引遍历的过程中，过滤了不符合条件的记录（ID3、ID6），只⽤回表 2 次\nselect * from tuser\nwhere name like '张 %'\nand age=10\nand ismale=1;\n索引区分度\n索引区分度表示某个字段不同值的个数占整个表的⽐例，建⽴联合索引时，要把区分度⼤的字段排在前⾯。\n建⽴索引的注意事项\n索引不是越多越好，虽然索引会提⾼ select 效率，但是也降低了insert以及update的效率\n数据量⼩的表不需要建⽴索引，会增加额外的索引开销\n不经常使⽤的列不要建⽴索引\n频繁更新的列不要建⽴索引，会影响更新的效率\n索引的优缺点\n使⽤索引可以⼤⼤加快数据的检索速度（⼤⼤减少检索的数据量），这也是创建索引的最主要的原因。\n但是注意使⽤索引不⼀定能够提⾼查询性能，因为如果数据库的数据量不⼤，那么使⽤索引也不⼀定能够带来\n很⼤提升。其余⼤多数情况下，索引查询⽐全表扫描要快。\n通过创建唯⼀性索引，可以保证数据库表中每⼀⾏数据的唯⼀性。\n空间消耗，⼀个索引对应的就是⼀棵 B+树，每⼀个节点都是⼀个 16KB ⼤⼩的⻚。占⽤的空间较⼤。\n创建索引和维护索引需要耗费许多时间，当对表中的数据进⾏增删改的时候，如果数据有索引，那么索引也需\n要动态的修改，会降低 SQL 执⾏效率。\n什么时候需要创建索引\n频繁⽤于查询的列需要创建索引\n⼤表：对于很⼤的表，建⽴索引可以提⾼查询速度\n唯⼀性要求：主键列和唯⼀性约束的列会⾃动创建唯⼀索引，但如果查询中经常包含唯⼀性条件，可以额外创\n建唯⼀性索引。\n连接表的外键列：为外键列创建索引可以提⾼连接的效率。\n频繁使⽤排序和分组的列：如果某列经常⽤于 ORDER BY 或 GROUP BY ⼦句可以创建索引\n什么时候不需要创建索引\n⼩表：在⼩表上，索引不会带来显著的性能提升，还会增加维护开销。\n经常进⾏更新的字段不需要创建索引\n很少⽤于查询的字段\n字段中存在⼤量重复数据，不需要创建索引，⽐如性别字段\n索引优化的⽅法\n前缀索引优化：使⽤某个字段中字符串的前⼏个字符建⽴索引，从⽽减⼩索引字段⼤⼩\n覆盖索引优化：从⼆级索引中可以查询得到记录，避免回表\n主键索引最好是⾃增的；这样每次插⼊⼀条新记录，都是追加操作，不需要重新移动数据，⽽使⽤⾮⾃增主键\n会导致插⼊主键的索引值是随机的，这可能会插⼊到现有数据⻚的某个位置，导致其他数据的移动，造成⻚分\n避免过多的索引\nSELECT * FROM table WHERE UPPER(column) = 'VALUE';\n索引什么时候会失效\n使⽤左或者左右模糊匹配：⽐如LIKE '%abc' 这样的查询会导致索引失效。\n在索引列上使⽤函数或表达式：  索引列上参与计算，索引失效\n在 WHERE ⼦句中，如果在 OR 前的条件列是索引列，⽽在 OR 后的条件列不是索引列，那么索引会失效。\n违背最左匹配原则，索引失效\n数据分布不均匀：   如果数据分布不均匀，例如某个索引列的⼤多数值都相同，选择性降低，导致索引失效。\n隐式类型转换：   如果查询中的条件涉及到隐式类型转换，例如将字符串与数字⽐较，索引可能⽆法被使⽤。\n为什么使⽤B+树索引\nB+树的⾮叶⼦节点不存放实际的记录数据，仅存放索引，所以数据量相同的情况下，相⽐存储即存索引⼜存\n记录的 B 树，B+树的⾮叶⼦节点可以存放更多的索引，因此 B+ 树可以⽐ B 树更「矮胖」，查询底层节点的\n磁盘 I/O次数会更少。\nB+ 树有⼤量的冗余节点（所有⾮叶⼦节点都是冗余索引），这些冗余索引让 B+ 树在插⼊、删除的效率都更\n⾼，⽐如删除根节点的时候，不会像 B 树那样会发⽣复杂的树的变化；\nB+ 树叶⼦节点之间⽤链表连接了起来，有利于范围查询，⽽ B 树要实现范围查询，因此只能通过树的遍历来\n完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。\n思维导图：\nMySQL原⽣引擎MyISAM不⽀持事务，所以被InnoDB取代。\n事务的四⼤特性ACID\nACID（Atomicity、Consistency、Isolation、Durability，即原⼦性、⼀致性、隔离性、持久性）",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2527,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000114",
    "content": "索引的优缺点\n\n使⽤索引可以⼤⼤加快数据的检索速度（⼤⼤减少检索的数据量），这也是创建索引的最主要的原因。\n但是注意使⽤索引不⼀定能够提⾼查询性能，因为如果数据库的数据量不⼤，那么使⽤索引也不⼀定能够带来\n很⼤提升。其余⼤多数情况下，索引查询⽐全表扫描要快。\n通过创建唯⼀性索引，可以保证数据库表中每⼀⾏数据的唯⼀性。\n空间消耗，⼀个索引对应的就是⼀棵 B+树，每⼀个节点都是⼀个 16KB ⼤⼩的⻚。占⽤的空间较⼤。\n创建索引和维护索引需要耗费许多时间，当对表中的数据进⾏增删改的时候，如果数据有索引，那么索引也需\n要动态的修改，会降低 SQL 执⾏效率。\n什么时候需要创建索引\n频繁⽤于查询的列需要创建索引\n⼤表：对于很⼤的表，建⽴索引可以提⾼查询速度\n唯⼀性要求：主键列和唯⼀性约束的列会⾃动创建唯⼀索引，但如果查询中经常包含唯⼀性条件，可以额外创\n建唯⼀性索引。\n连接表的外键列：为外键列创建索引可以提⾼连接的效率。\n频繁使⽤排序和分组的列：如果某列经常⽤于 ORDER BY 或 GROUP BY ⼦句可以创建索引\n什么时候不需要创建索引\n⼩表：在⼩表上，索引不会带来显著的性能提升，还会增加维护开销。\n经常进⾏更新的字段不需要创建索引\n很少⽤于查询的字段\n字段中存在⼤量重复数据，不需要创建索引，⽐如性别字段\n索引优化的⽅法\n前缀索引优化：使⽤某个字段中字符串的前⼏个字符建⽴索引，从⽽减⼩索引字段⼤⼩\n覆盖索引优化：从⼆级索引中可以查询得到记录，避免回表\n主键索引最好是⾃增的；这样每次插⼊⼀条新记录，都是追加操作，不需要重新移动数据，⽽使⽤⾮⾃增主键\n会导致插⼊主键的索引值是随机的，这可能会插⼊到现有数据⻚的某个位置，导致其他数据的移动，造成⻚分\n避免过多的索引\nSELECT * FROM table WHERE UPPER(column) = 'VALUE';\n索引什么时候会失效\n使⽤左或者左右模糊匹配：⽐如LIKE '%abc' 这样的查询会导致索引失效。\n在索引列上使⽤函数或表达式：  索引列上参与计算，索引失效\n在 WHERE ⼦句中，如果在 OR 前的条件列是索引列，⽽在 OR 后的条件列不是索引列，那么索引会失效。\n违背最左匹配原则，索引失效\n数据分布不均匀：   如果数据分布不均匀，例如某个索引列的⼤多数值都相同，选择性降低，导致索引失效。\n隐式类型转换：   如果查询中的条件涉及到隐式类型转换，例如将字符串与数字⽐较，索引可能⽆法被使⽤。\n为什么使⽤B+树索引\nB+树的⾮叶⼦节点不存放实际的记录数据，仅存放索引，所以数据量相同的情况下，相⽐存储即存索引⼜存\n记录的 B 树，B+树的⾮叶⼦节点可以存放更多的索引，因此 B+ 树可以⽐ B 树更「矮胖」，查询底层节点的\n磁盘 I/O次数会更少。\nB+ 树有⼤量的冗余节点（所有⾮叶⼦节点都是冗余索引），这些冗余索引让 B+ 树在插⼊、删除的效率都更\n⾼，⽐如删除根节点的时候，不会像 B 树那样会发⽣复杂的树的变化；\nB+ 树叶⼦节点之间⽤链表连接了起来，有利于范围查询，⽽ B 树要实现范围查询，因此只能通过树的遍历来\n完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。\n思维导图：\nMySQL原⽣引擎MyISAM不⽀持事务，所以被InnoDB取代。\n事务的四⼤特性ACID\nACID（Atomicity、Consistency、Isolation、Durability，即原⼦性、⼀致性、隔离性、持久性）\n## 原⼦性\n事务是⼀个不可分割的⼯作单元，要么完全执⾏，要么完全不执⾏。如果在事务执⾏的过程中发⽣了错误，系统会\n撤销事务中已经执⾏的操作，将数据库恢复到事务开始前的状态。原⼦性是通过 undo log（回滚⽇志） 来保证  的。\n## ⼀致性\n确保事务将数据库从⼀个⼀致的状态转变为另⼀个⼀致的状态。事务执⾏的结果必须满⾜数据库的完整性约束和规\n则，保持数据库的⼀致性。⼀致性则是通过持久性+原⼦性+隔离性来保证的。\n## 隔离性\n多个事务并发执⾏时，每个事务都不能看到其他事务的中间状态。每个事务都应该感觉就像它是唯⼀在数据库上运\n⾏的事务⼀样。防⽌了多个事务之间的相互⼲扰。隔离性是通过  MVCC（多版本并发控制）  或锁机制来保证的。\n## 持久性\n⼀旦事务被提交，其结果将永久保存在数据库中，即使系统发⽣故障。即使系统发⽣崩溃，事务的结果也不应该丢\n失，持久性是通过 redo log （重做⽇志）来保证的。\n并⾏事务会出现什么问题\n并⾏事务是指多个事务同时执⾏，这可以提⾼数据库系统的性能和吞吐量。但是并⾏事务也可能引发⼀些问题\n## 脏读：读到其他事务未提交的数据\n⼀个事务读取了另⼀个事务未提交的数据，如果另⼀个事务后来回滚，读取的数据就是⽆效的。读到了并⼀定最终\n存在的数据，这就是脏读。\n## 不可重复读：前后读取的数据不⼀致\n在⼀个事务内，同⼀查询可能返回不同的结果，因为在事务执⾏期间其他事务可能修改了数据。\n## 幻读：前后读取的记录数量不⼀致\n在⼀个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不⼀样的情况，就\n意味着发⽣了「幻读」现象。\n这三个现象严重性排序如下：\n隔离级别\n隔离级别是指多个并发事务之间相互隔离的程度，SQL标准定义了4个隔离级别\n## 读未提交：\n最低的隔离级别。在这个级别下，⼀个事务可以读取到另⼀个事务未提交的数据。这可能导致脏读（Dirty\nReads）和不可重复读、幻读等问题。\n## 读提交：\n在这个级别下，⼀个事务只能读取到已经提交的其他事务的数据。这解决了脏读的问题，但仍可能遇到不可重复读\n的问题。\n## 可重复读\n在这个级别下，⼀个事务在其⽣命周期内多次执⾏相同的查询，将始终看到相同的数据，但是，仍可能发⽣幻读。\n也是MySQL InnoDB 引擎的默认隔离级别；\n## 可串⾏化\n提供了最⾼的隔离级别。会对记录加上读写锁，在多个事务对这条记录进⾏读写操作时，如果发⽣了读写冲突的时\n候，后访问的事务必须等前⼀个事务执⾏完成，才能继续执⾏，在这个级别下，事务的执⾏效果就好像它们是按顺\n序执⾏的，事务之间没有并发。这可以防⽌脏读、不可重复读和幻读，但也可能导致性能下降，因为并发性降低。\n选择隔离级别需要根据应⽤程序的要求和性能需求进⾏权衡。较低的隔离级别提供更⾼的并发性能，但可能牺牲⼀\n致性。较⾼的隔离级别提供更强的⼀致性，但可能降低并发性能。\n在「读未提交」隔离级别下，可能发⽣脏读、不可重复读和幻读现象；\n在「读提交」隔离级别下，可能发⽣不可重复读和幻读现象，但是不可能发⽣脏读现象；\n在「可重复读」隔离级别下，可能发⽣幻读现象，但是不可能脏读和不可重复读现象；\n在「串⾏化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发⽣。\n幻读是如何解决的\nMySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很⼤程度上可以避免幻读现象。解决的⽅案有\n两种：\n针对快照读（普通 select 语句），是通过 MVCC ⽅式解决了幻读\n针对当前读：（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）⽅式解决了幻读，\n因为当执⾏ select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范\n围内插⼊。\nRead View\nmin_trx_id\n事务隔离的实现\n隔离级别具体是如何实现的呢？\n对于读未提交，可以读到未提交事务修改的数据，所以直接读取最新的数据就可以。\n对于串⾏化：加读写锁的⽅式来避免并⾏访问\n对于读提交和可重复读，通过\n来实现的\n「读提交」隔离级别是在每个 select 都会⽣成⼀个新的 Read View，也意味着，事务期间的多次读取同\n⼀条数据，前后两次读的数据可能会出现不⼀致，因为可能这期间另外⼀个事务修改了该记录，并提交\n了事务。\n「可重复读」隔离级别是启动事务时⽣成⼀个 Read View，然后整个事务期间都在⽤这个 Read View，\n这样就保证了在事务期间读到的数据都是事务启动前的记录。\nRead  View在MVCC中是如何⼯作的\n## 事务启动：当⼀个事务启动时，系统会为该事务创建⼀个 Read View。\n## Read View 包含的信息\nm_ids : 当前数据库中「活跃事务」的事务 id 列表, 表示启动了但还没有提交的事务\nmin_trx_id : 「活跃事务」中事务id 最⼩的事务\nmax_trx_id : 当前数据库中应该给下⼀个事务的 id 值\ncreator_trx_id : 创建该Read View的事务的id\n除此之外，聚簇索引记录中都包含下⾯两个隐藏列：\ntrx_id ，当⼀个事务对某条聚簇索引记录进⾏改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列⾥；\nroll_pointer ，每次对某条聚簇索引记录进⾏改动时，都会把旧版本的记录写⼊到 undo ⽇志中，然后这\n个隐藏列是个指针，指向每⼀个旧版本记录，于是就可以通过它找到修改前的记录。\n## 事务读取数据：当⼀个事务要执⾏读操作时，系统会使⽤ Read View 来确定该事务能够看到哪些数据版本。具\n体步骤如下：\n如果记录的trx_id ⼩于Read View 中的\n值，表示这个版本的记录是在创建 Read View 前\n已经提交的事务⽣成的，所以该版本的记录对当前事务可⻅。\nmax_trx_id\nbegin/start transaction、commit、rollback\nset autocommit=0;\n如果记录的 trx_id 值⼤于等于 Read View 中的\n值，表示这个版本的记录是在创建 Read\nView  后才启动的事务⽣成的，所以该版本的记录对当前事务不可⻅。\n如果记录的 trx_id 值在 Read View 的\nm_ids 列表中：\n之间，需要判断 trx_id 是否在\n如果记录的 trx_id 在\n列表中，表示⽣成该版本记录的活跃事务依然活跃着（还没提交事\n务），所以该版本的记录对当前事务不可⻅。\n如果记录的 trx_id 不在 m_ids 列表中，表示⽣成该版本记录的活跃事务已经被提交，所以该版本\n的记录对当前事务可⻅。\n## 事务提交：当⼀个事务提交时，它的事务ID会加⼊到已提交的事务ID集合中。这样，其他事务的 Read View\n就能够看到该事务提交的数据版本。\n读已提交是怎么实现的\n使⽤MVCC(多版本并法控制) 实现的\n读操作：在MVCC中，每个事务在读取数据时都可以看到数据的⼀个版本。已提交的事务产⽣⼀个版本，⽽未\n提交的事务则不会对其他事务可⻅。因此，读已提交只能看到已提交事务的版本。\n写操作：  写操作创建⼀个新的数据版本，⽽不是直接修改原始数据。这确保了正在进⾏的事务不会看到未提交\n事务的更改。\n事务的启动⽅式\n显式启动事务语句\n关闭线程的⾃提交\n事务会持续存在直到你主动执⾏commit或者rollback，或者断开连接，所以，如果采取了第⼆种⽅法，就导致了接\n下来的查询都在事务中，如果是⻓连接，就导致了⻓事务。\n所以，建议使⽤\n⻓事务的查询：\n在informationschema库下的innodbtrx表中查询。\n举个栗⼦\n如何避免⻓事务对业务的影响？\n从应⽤开发端来看:\n## 确定是否使⽤了set autocommit=0，如是，则改成1\n## 确定是否有不必要的只读事务\n## 业务连接数据库的时候，控制每个语句执⾏的最⻓时间 set maxexecutiontime\n从数据库端来看:\nmin_trx_id\nmax_trx_id\nm_ids\nset autocommit=1\n## 监控相关表，设置⻓事务阈值，超过就报警/kill\n## 可使⽤percona的pt-kill⼯具\n## 在功能测试阶段输出所有的log，分析⽇志提前发现问题\n## 把innodbundotablespaces设置成2或者更⼤的值\n多个事物在【并发情况下】会出现⼀些经典的问题，如脏读、不可重复读、幻读、丢失更新。为了不同程度的解决\n这些问题，出现了不同的隔离级别，锁就是实现各种隔离级别的⼀种⽅式。\n锁的种类\nflush tables with read lock (FTWRL)。\n## 全局锁\n顾名思义，全局锁就是对整个数据库实例加锁。\n典型使⽤场景：全库逻辑备份，即把整个库的表都select出来存成⽂本\nMySQL 提供了⼀个加全局读锁的⽅法，命令是\n当你需要让整个库处于只读状态的时候，可以使⽤这个命令，之后其他线程的以下语句会被阻塞：\n数据更新语句（数据的增删改）\n数据定义语句（包括建表、修改表结构等）\n更新类事务的提交语句\n## 表级锁\nMySQL ⾥⾯表级别的锁有下⾯⼏种：\n（1） 表锁\n每次操作锁住整张表\n开销⼩，加锁快\n并发度最低\n表锁的语法是 lock tables … read/write 。\n与 FTWRL 类似，可以⽤\n主动释放锁，也可以在客户端断开的时候⾃动释放。\n需要注意： lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n（2） 元数据锁（meta data lock，MDL）\nMDL  不需要显式使⽤，在访问⼀个表的时候会被⾃动加上。\nMDL 的作⽤：保证读写的正确性。\n你可以想象⼀下，如果⼀个查询正在遍历⼀个表中的数据，⽽执⾏期间另⼀个线程对这个表结构做变更，删了⼀\n列，那么查询线程拿到的结果跟表结构对不上，肯定是不⾏的。\n在 MySQL 5.5 版本中引⼊了 MDL\n当对⼀个表做增删改查操作的时候，加 MDL 读锁；\n当要对表做结构变更操作的时候，加 MDL 写锁。\n读锁之间不互斥，因此你可以有多个线程同时对⼀张表增删改查。读写锁之间、写锁之间是互斥的，⽤来保证变更\n表结构操作的安全性。因此，如果有两个线程要同时给⼀个表加字段，其中⼀个要等另⼀个执⾏完才能开始执⾏。\n事务中的  MDL  锁，在语句执⾏开始时申请，但是语句结束后并不会⻢上释放，⽽会等到整个事务提交后再释放。\n（这可能会产⽣死锁的问题）\n（3） 意向锁\n意向锁⽤于指示⼀个事务在未来可能会请求对某些资源（如数据⾏）的锁定\nunlock tables\nAUTO_INCREMENT\n意向共享锁表示事务打算在资源上获得共享锁。其他事务可以继续获得共享锁，但不能获得排他锁。\n意向排他（独占）锁： 表示事务打算在资源上获得排他锁。\n对某些记录加上「共享锁」之前，需要先在表级别加上⼀个「意向共享锁」，对某些纪录加上「独占锁」之前，需\n要先在表级别加上⼀个「意向独占锁」。\n意向共享锁和意向独占锁是表级锁，不会和⾏级的共享锁和独占锁发⽣冲突，意向锁之间也不会发⽣冲突，只会和\n共享表锁和独占表锁发⽣冲突。意向锁的⽬的是为了快速判断表⾥是否有记录被加锁。\n（4） AUTO-INC 锁\n作⽤：表⾥的主键通常都会设置成⾃增的，之后可以在插⼊数据时，可以不指定主键的值，数据库会⾃动给主键赋\n值递增的值通过 AUTO-INC 锁实现的。在插⼊数据时，会加⼀个表级别的 AUTO-INC 锁，然后为被\n修饰的字段赋值递增的值，等插⼊语句执⾏完成后，才会把 AUTO-INC 锁释放掉。其他事务的\n如果要向该表插⼊语句都会被阻塞，从⽽保证插⼊数据时字段的值是连续递增的。\n缺陷：对⼤量数据进⾏插⼊的时候，会影响插⼊性能，因为其他事务中的插⼊会被阻塞。\n改进：InnoDB  存储引擎提供了⼀种轻量级的锁来实现⾃增。在插⼊数据的时候，会为被\n的字段加上轻量级锁，然后给该字段赋值⼀个⾃增的值，就把这个轻量级锁释放了，⽽不需要等待整个插⼊语句执\n⾏完后才释放锁。\n## ⾏级锁\n顾名思义，⾏锁就是针对数据表中⾏记录的锁（也有⼈称为记录锁）。\n这很好理解，⽐如事务 A 更新了⼀⾏，⽽这时候事务 B 也要更新同⼀⾏，则必须等事务 A 的操作完成后才能进⾏\n更新。\n类型：\nRecord  Lock，记录锁，仅仅把⼀条记录锁上，记录锁分为排他锁和共享锁。\nGap Lock，间隙锁，锁定⼀个范围，但是不包含记录本身，只存在于可重复读隔离级别，⽬的是为了解决可\n重复读隔离级别下幻读的现象。间隙锁之间是兼容的，两个事务可以同时持有包含共同间隙范围的间隙锁，并\n不存在互斥关系。\nNext-Key Lock：Record Lock + Gap Lock 的组合，锁定⼀个范围，并且锁定记录本身。next-key lock 即能\n保护该记录，⼜能阻⽌其他事务将新纪录插⼊到被保护记录前⾯的间隙中。\n每次操作锁住⼀⾏数据\n开销⼤，加锁慢\n发⽣锁冲突的概率是最低的，并发度是最⾼的\n在 InnoDB 事务中，⾏锁是在需要的时候才加上的，但并不是不需要了就⽴刻释放，⽽是要等到事务结束时才释\n放。这个就是两阶段锁协议。\n知道了这个设定，对我们使⽤事务有什么帮助呢？那就是，如果你的事务中需要锁多个⾏，要把最可能造成锁冲\n突、最可能影响并发度的锁尽量往后放。\n加锁规则\n加锁规则⾥⾯，包含了两个“原则”、两个“优化”和⼀个“bug”\n两个原则：\nAUTO_INCREMENT\nSELECT user_id FROM product_comment WHERE user_id = 10 LOCK IN SHARE MODE;\nSELECT user_id FROM product_comment WHERE user_id = 10 FOR UPDATE;\nLOCK TABLE product_comment READ;\nUNLOCK TABLE;\n## 加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n## 查找过程中访问到的对象才会加锁。\n两个优化：\n## 索引上的等值查询，给唯⼀索引加锁的时候，next-key  lock  退化为⾏锁。\n## 索引上的等值查询，向右遍历时且最后⼀个值不满⾜等值条件的时候，next-key  lock  退化为间隙锁。\n⼀个\"bug\"：\n## 唯⼀索引上的范围查询会访问到不满⾜条件的第⼀个值为⽌。（MySQL8.0之后的版本已经修复）\n以上规则是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有\n加锁的资源，都是在事务提交或者回滚的时候才释放的。如果切换到读提交隔离级别 (read-committed) 的话，就\n好理解了，过程中去掉间隙锁的部分，也就是只剩下⾏锁的部分。\n锁的划分\n## 、数据库⻆度\n## 共享锁（共享锁也叫读锁或 S 锁 ）\n共享锁锁定的资源可以被其他⽤户读取，但不能修改。\n在进⾏SELECT的时候，会将对象进⾏共享锁锁定，当数据读取完毕之后，就会释放共享锁，这样就可以保证数据\n在读取时不被修改。\n如果我们想要给某⼀⾏加上共享锁呢，⽐如想对   user_id=10的数据⾏加上共享锁，可以像下⾯这样：\n## 排他锁（排它锁也叫独占锁、写锁或 X 锁）\n排它锁锁定的数据只允许进⾏锁定操作的事务使⽤，其他事务⽆法对已锁定的数据进⾏查询或修改。\n如果我们想要在某个数据⾏上添加排它锁，⽐如针对 user_id=10的数据⾏，则写成如下这样：\n另外当我们对数据进⾏更新的时候，也就是INSERT、DELETE或者UPDATE的时候，数据库也会⾃动使⽤排它锁，\n防⽌其他事务对该数据⾏进⾏操作。\n## 共享锁与排他锁\n共享锁和排他锁不仅可以锁住⼀⾏，也可以锁住⼀张表，如下所示：\n⽐如我们想给  product_comment  在表上加共享锁，可以使⽤下⾯这⾏命令\n如果我们想要对表上的共享锁进⾏解锁，可以使⽤下⾯这⾏命令：\nLOCK TABLE product_comment WRITE;\nUNLOCK TABLE;\n如果我们想给  product_comment  数据表添加排它锁，可以使⽤下⾯这⾏命令\n这时只有获得排它锁的事务可以对 product_comment 进⾏查询或修改，其他事务如果想要在 product_comment\n表上查询数据，则需要等待。\n你可以⾃⼰开两个  MySQL 客户端来模拟下。这时我们释放掉排它锁，使⽤这⾏命令即可\n## 意向锁（Intent Lock）\n简单来说就是给更⼤⼀级别的空间示意⾥⾯是否已经上过锁。\n举例：\n你可以给整个房⼦设置⼀个标识，告诉它⾥⾯有⼈，即使你只是获取了房⼦中某⼀个房间的锁。这样其他⼈如果想\n要获取整个房⼦的控制权，只需要看这个房⼦的标识即可，不需要再对房⼦中的每个房间进⾏查找。这样是不是很\n⽅便？\n返回数据表的场景，如果我们给某⼀⾏数据加上了排它锁，数据库会⾃动给更⼤⼀级的空间，⽐如数据⻚或数据表\n加上意向锁，告诉其他⼈这个数据⻚或数据表已经有⼈上过排它锁了，这样当其他⼈想要获取数据表排它锁的时\n候，只需要了解是否有⼈已经获取了这个数据表的意向排他锁即可。\n如果事务想要获得数据表中某些记录的共享锁，就需要在数据表上添加意向共享锁。同理，事务想要获得数据表中\n某些记录的排他锁，就需要在数据表上添加意向排他锁。这时，意向锁会告诉其他事务已经有⼈锁定了表中的某些\n记录，不能对整个表进⾏全表扫描。\n## 、程序员⻆度\n## 乐观锁（Optimistic Locking）\n认为对同⼀数据的并发操作不会总发⽣，属于⼩概率事件，不⽤每次都对数据上锁，也就是不采⽤数据库⾃身的锁\n机制，⽽是通过程序来实现。在程序上，我们可以采⽤版本号机制或者时间戳机制实现。\n## 悲观锁（Pessimistic Locking）\n也是⼀种思想，对数据被其他事务的修改持保守态度，会通过数据库⾃身的锁机制来实现，从⽽保证数据操作的排\n它性。\n## 乐观锁和悲观锁的适⽤场景\n（1） 乐观锁\n适合读操作多的场景，相对来说写的操作⽐较少。它的优点在于程序实现，不存在死锁问题，不过适⽤场景也会相\n对乐观，因为它阻⽌不了除了程序以外的数据库操作。\n（2） 悲观锁\n适合写操作多的场景，因为写的操作具有排它性。采⽤悲观锁的⽅式，可以在数据库层⾯阻⽌其他事务对该数据的\n操作权限，防⽌读 - 写和写 - 写的冲突。但是加锁的时间会⽐较⻓，可能会⻓时间限制其他⽤户的访问，也就是说\n他的并发访问性不好。\nInnodb使⽤表锁还是⾏锁\n对于Innodb，绝⼤部分情况应该使⽤⾏锁\n使⽤表锁的情况\n（1） 表⽐较⼤，事务需要更新全部或者⼤部分数据\n（2） 事务涉及到多个表，⽐较复杂，可能引起死锁，造成⼤量的事务回滚\n在前⾯中，我们提到了【更新语句】会设计到⽇志，具体包含下⾯⼏种\nundo log（回滚⽇志）：是 Innodb 存储引擎层⽣成的⽇志，实现了事务中的原⼦性，主要⽤于事务回滚和\nMVCC。\nredo log（重做⽇志）：是 Innodb 存储引擎层⽣成的⽇志，实现了事务中的持久性，主要⽤于掉电等故障恢\nbinlog （归档⽇志）：是 Server 层⽣成的⽇志，主要⽤于数据备份和主从复制；\n什么是undo logo\n当事务对数据库进⾏更新（插⼊、修改、删除）时，系统会记录相应的undo log ，以便在事务回滚或系统崩溃时\n进⾏数据恢复, 主要⽤于事务回滚和MVCC。 undo log 记录的信息包括操作类型（插⼊、删除还是更新），修改前\n的数据值，被修改的数据的位置，事务标识id等，⽐如在更新⼀条记录时，要把被更新的列的旧值记下来，这样之\n后回滚时再把这些列更新为旧值就好了。\n每⼀次更新操作产⽣的undo log 格式都有⼀个\n本链)和⼀个trx_id 事务id(记录是被哪个事务修改的)\n指针(将undo log 串成⼀个链表, 链表也被成为版\n事务回滚：如果事务在执⾏过程中出现错误或被⽤户显式地回滚，系统可以使⽤undo log 来还原事务所做的\n所有修改。通过undo log ，数据库系统可以逆向执⾏事务的操作，将数据库还原到事务开始前的状态。\n实现 MVCC（多版本并发控制）关键因素之⼀。MVCC 是通过 ReadView + undo log 实现的。undo log 为每\n条记录保存多份历史数据，MySQL 在执⾏快照读（普通 select 语句）的时候，会根据事务的 Read View ⾥\n的信息，顺着 undo log 的版本链找到满⾜其可⻅性的记录。\n什么是redo log\nredo log 是物理⽇志，记录了某个数据⻚做了什么修改，⽐如对 XXX 表空间中的 YYY 数据⻚ ZZZ 偏移量的地⽅做\n了AAA 更新，每当执⾏⼀个事务就会产⽣这样的⼀条或者多条物理⽇志。在事务提交时，只要先将 redo log 持久\n化到磁盘即可",
    "question": "索引的优缺点",
    "answer": "使⽤索引可以⼤⼤加快数据的检索速度（⼤⼤减少检索的数据量），这也是创建索引的最主要的原因。\n但是注意使⽤索引不⼀定能够提⾼查询性能，因为如果数据库的数据量不⼤，那么使⽤索引也不⼀定能够带来\n很⼤提升。其余⼤多数情况下，索引查询⽐全表扫描要快。\n通过创建唯⼀性索引，可以保证数据库表中每⼀⾏数据的唯⼀性。\n空间消耗，⼀个索引对应的就是⼀棵 B+树，每⼀个节点都是⼀个 16KB ⼤⼩的⻚。占⽤的空间较⼤。\n创建索引和维护索引需要耗费许多时间，当对表中的数据进⾏增删改的时候，如果数据有索引，那么索引也需\n要动态的修改，会降低 SQL 执⾏效率。\n什么时候需要创建索引\n频繁⽤于查询的列需要创建索引\n⼤表：对于很⼤的表，建⽴索引可以提⾼查询速度\n唯⼀性要求：主键列和唯⼀性约束的列会⾃动创建唯⼀索引，但如果查询中经常包含唯⼀性条件，可以额外创\n建唯⼀性索引。\n连接表的外键列：为外键列创建索引可以提⾼连接的效率。\n频繁使⽤排序和分组的列：如果某列经常⽤于 ORDER BY 或 GROUP BY ⼦句可以创建索引\n什么时候不需要创建索引\n⼩表：在⼩表上，索引不会带来显著的性能提升，还会增加维护开销。\n经常进⾏更新的字段不需要创建索引\n很少⽤于查询的字段\n字段中存在⼤量重复数据，不需要创建索引，⽐如性别字段\n索引优化的⽅法\n前缀索引优化：使⽤某个字段中字符串的前⼏个字符建⽴索引，从⽽减⼩索引字段⼤⼩\n覆盖索引优化：从⼆级索引中可以查询得到记录，避免回表\n主键索引最好是⾃增的；这样每次插⼊⼀条新记录，都是追加操作，不需要重新移动数据，⽽使⽤⾮⾃增主键\n会导致插⼊主键的索引值是随机的，这可能会插⼊到现有数据⻚的某个位置，导致其他数据的移动，造成⻚分\n避免过多的索引\nSELECT * FROM table WHERE UPPER(column) = 'VALUE';\n索引什么时候会失效\n使⽤左或者左右模糊匹配：⽐如LIKE '%abc' 这样的查询会导致索引失效。\n在索引列上使⽤函数或表达式：  索引列上参与计算，索引失效\n在 WHERE ⼦句中，如果在 OR 前的条件列是索引列，⽽在 OR 后的条件列不是索引列，那么索引会失效。\n违背最左匹配原则，索引失效\n数据分布不均匀：   如果数据分布不均匀，例如某个索引列的⼤多数值都相同，选择性降低，导致索引失效。\n隐式类型转换：   如果查询中的条件涉及到隐式类型转换，例如将字符串与数字⽐较，索引可能⽆法被使⽤。\n为什么使⽤B+树索引\nB+树的⾮叶⼦节点不存放实际的记录数据，仅存放索引，所以数据量相同的情况下，相⽐存储即存索引⼜存\n记录的 B 树，B+树的⾮叶⼦节点可以存放更多的索引，因此 B+ 树可以⽐ B 树更「矮胖」，查询底层节点的\n磁盘 I/O次数会更少。\nB+ 树有⼤量的冗余节点（所有⾮叶⼦节点都是冗余索引），这些冗余索引让 B+ 树在插⼊、删除的效率都更\n⾼，⽐如删除根节点的时候，不会像 B 树那样会发⽣复杂的树的变化；\nB+ 树叶⼦节点之间⽤链表连接了起来，有利于范围查询，⽽ B 树要实现范围查询，因此只能通过树的遍历来\n完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。\n思维导图：\nMySQL原⽣引擎MyISAM不⽀持事务，所以被InnoDB取代。\n事务的四⼤特性ACID\nACID（Atomicity、Consistency、Isolation、Durability，即原⼦性、⼀致性、隔离性、持久性）\n## 原⼦性\n事务是⼀个不可分割的⼯作单元，要么完全执⾏，要么完全不执⾏。如果在事务执⾏的过程中发⽣了错误，系统会\n撤销事务中已经执⾏的操作，将数据库恢复到事务开始前的状态。原⼦性是通过 undo log（回滚⽇志） 来保证  的。\n## ⼀致性\n确保事务将数据库从⼀个⼀致的状态转变为另⼀个⼀致的状态。事务执⾏的结果必须满⾜数据库的完整性约束和规\n则，保持数据库的⼀致性。⼀致性则是通过持久性+原⼦性+隔离性来保证的。\n## 隔离性\n多个事务并发执⾏时，每个事务都不能看到其他事务的中间状态。每个事务都应该感觉就像它是唯⼀在数据库上运\n⾏的事务⼀样。防⽌了多个事务之间的相互⼲扰。隔离性是通过  MVCC（多版本并发控制）  或锁机制来保证的。\n## 持久性\n⼀旦事务被提交，其结果将永久保存在数据库中，即使系统发⽣故障。即使系统发⽣崩溃，事务的结果也不应该丢\n失，持久性是通过 redo log （重做⽇志）来保证的。\n并⾏事务会出现什么问题\n并⾏事务是指多个事务同时执⾏，这可以提⾼数据库系统的性能和吞吐量。但是并⾏事务也可能引发⼀些问题\n## 脏读：读到其他事务未提交的数据\n⼀个事务读取了另⼀个事务未提交的数据，如果另⼀个事务后来回滚，读取的数据就是⽆效的。读到了并⼀定最终\n存在的数据，这就是脏读。\n## 不可重复读：前后读取的数据不⼀致\n在⼀个事务内，同⼀查询可能返回不同的结果，因为在事务执⾏期间其他事务可能修改了数据。\n## 幻读：前后读取的记录数量不⼀致\n在⼀个事务内多次查询某个符合查询条件的「记录数量」，如果出现前后两次查询到的记录数量不⼀样的情况，就\n意味着发⽣了「幻读」现象。\n这三个现象严重性排序如下：\n隔离级别\n隔离级别是指多个并发事务之间相互隔离的程度，SQL标准定义了4个隔离级别\n## 读未提交：\n最低的隔离级别。在这个级别下，⼀个事务可以读取到另⼀个事务未提交的数据。这可能导致脏读（Dirty\nReads）和不可重复读、幻读等问题。\n## 读提交：\n在这个级别下，⼀个事务只能读取到已经提交的其他事务的数据。这解决了脏读的问题，但仍可能遇到不可重复读\n的问题。\n## 可重复读\n在这个级别下，⼀个事务在其⽣命周期内多次执⾏相同的查询，将始终看到相同的数据，但是，仍可能发⽣幻读。\n也是MySQL InnoDB 引擎的默认隔离级别；\n## 可串⾏化\n提供了最⾼的隔离级别。会对记录加上读写锁，在多个事务对这条记录进⾏读写操作时，如果发⽣了读写冲突的时\n候，后访问的事务必须等前⼀个事务执⾏完成，才能继续执⾏，在这个级别下，事务的执⾏效果就好像它们是按顺\n序执⾏的，事务之间没有并发。这可以防⽌脏读、不可重复读和幻读，但也可能导致性能下降，因为并发性降低。\n选择隔离级别需要根据应⽤程序的要求和性能需求进⾏权衡。较低的隔离级别提供更⾼的并发性能，但可能牺牲⼀\n致性。较⾼的隔离级别提供更强的⼀致性，但可能降低并发性能。\n在「读未提交」隔离级别下，可能发⽣脏读、不可重复读和幻读现象；\n在「读提交」隔离级别下，可能发⽣不可重复读和幻读现象，但是不可能发⽣脏读现象；\n在「可重复读」隔离级别下，可能发⽣幻读现象，但是不可能脏读和不可重复读现象；\n在「串⾏化」隔离级别下，脏读、不可重复读和幻读现象都不可能会发⽣。\n幻读是如何解决的\nMySQL InnoDB 引擎的默认隔离级别虽然是「可重复读」，但是它很⼤程度上可以避免幻读现象。解决的⽅案有\n两种：\n针对快照读（普通 select 语句），是通过 MVCC ⽅式解决了幻读\n针对当前读：（select ... for update 等语句），是通过 next-key lock（记录锁+间隙锁）⽅式解决了幻读，\n因为当执⾏ select ... for update 语句的时候，会加上 next-key lock，如果有其他事务在 next-key lock 锁范\n围内插⼊。\nRead View\nmin_trx_id\n事务隔离的实现\n隔离级别具体是如何实现的呢？\n对于读未提交，可以读到未提交事务修改的数据，所以直接读取最新的数据就可以。\n对于串⾏化：加读写锁的⽅式来避免并⾏访问\n对于读提交和可重复读，通过\n来实现的\n「读提交」隔离级别是在每个 select 都会⽣成⼀个新的 Read View，也意味着，事务期间的多次读取同\n⼀条数据，前后两次读的数据可能会出现不⼀致，因为可能这期间另外⼀个事务修改了该记录，并提交\n了事务。\n「可重复读」隔离级别是启动事务时⽣成⼀个 Read View，然后整个事务期间都在⽤这个 Read View，\n这样就保证了在事务期间读到的数据都是事务启动前的记录。\nRead  View在MVCC中是如何⼯作的\n## 事务启动：当⼀个事务启动时，系统会为该事务创建⼀个 Read View。\n## Read View 包含的信息\nm_ids : 当前数据库中「活跃事务」的事务 id 列表, 表示启动了但还没有提交的事务\nmin_trx_id : 「活跃事务」中事务id 最⼩的事务\nmax_trx_id : 当前数据库中应该给下⼀个事务的 id 值\ncreator_trx_id : 创建该Read View的事务的id\n除此之外，聚簇索引记录中都包含下⾯两个隐藏列：\ntrx_id ，当⼀个事务对某条聚簇索引记录进⾏改动时，就会把该事务的事务 id 记录在 trx_id 隐藏列⾥；\nroll_pointer ，每次对某条聚簇索引记录进⾏改动时，都会把旧版本的记录写⼊到 undo ⽇志中，然后这\n个隐藏列是个指针，指向每⼀个旧版本记录，于是就可以通过它找到修改前的记录。\n## 事务读取数据：当⼀个事务要执⾏读操作时，系统会使⽤ Read View 来确定该事务能够看到哪些数据版本。具\n体步骤如下：\n如果记录的trx_id ⼩于Read View 中的\n值，表示这个版本的记录是在创建 Read View 前\n已经提交的事务⽣成的，所以该版本的记录对当前事务可⻅。\nmax_trx_id\nbegin/start transaction、commit、rollback\nset autocommit=0;\n如果记录的 trx_id 值⼤于等于 Read View 中的\n值，表示这个版本的记录是在创建 Read\nView  后才启动的事务⽣成的，所以该版本的记录对当前事务不可⻅。\n如果记录的 trx_id 值在 Read View 的\nm_ids 列表中：\n之间，需要判断 trx_id 是否在\n如果记录的 trx_id 在\n列表中，表示⽣成该版本记录的活跃事务依然活跃着（还没提交事\n务），所以该版本的记录对当前事务不可⻅。\n如果记录的 trx_id 不在 m_ids 列表中，表示⽣成该版本记录的活跃事务已经被提交，所以该版本\n的记录对当前事务可⻅。\n## 事务提交：当⼀个事务提交时，它的事务ID会加⼊到已提交的事务ID集合中。这样，其他事务的 Read View\n就能够看到该事务提交的数据版本。\n读已提交是怎么实现的\n使⽤MVCC(多版本并法控制) 实现的\n读操作：在MVCC中，每个事务在读取数据时都可以看到数据的⼀个版本。已提交的事务产⽣⼀个版本，⽽未\n提交的事务则不会对其他事务可⻅。因此，读已提交只能看到已提交事务的版本。\n写操作：  写操作创建⼀个新的数据版本，⽽不是直接修改原始数据。这确保了正在进⾏的事务不会看到未提交\n事务的更改。\n事务的启动⽅式\n显式启动事务语句\n关闭线程的⾃提交\n事务会持续存在直到你主动执⾏commit或者rollback，或者断开连接，所以，如果采取了第⼆种⽅法，就导致了接\n下来的查询都在事务中，如果是⻓连接，就导致了⻓事务。\n所以，建议使⽤\n⻓事务的查询：\n在informationschema库下的innodbtrx表中查询。\n举个栗⼦\n如何避免⻓事务对业务的影响？\n从应⽤开发端来看:\n## 确定是否使⽤了set autocommit=0，如是，则改成1\n## 确定是否有不必要的只读事务\n## 业务连接数据库的时候，控制每个语句执⾏的最⻓时间 set maxexecutiontime\n从数据库端来看:\nmin_trx_id\nmax_trx_id\nm_ids\nset autocommit=1\n## 监控相关表，设置⻓事务阈值，超过就报警/kill\n## 可使⽤percona的pt-kill⼯具\n## 在功能测试阶段输出所有的log，分析⽇志提前发现问题\n## 把innodbundotablespaces设置成2或者更⼤的值\n多个事物在【并发情况下】会出现⼀些经典的问题，如脏读、不可重复读、幻读、丢失更新。为了不同程度的解决\n这些问题，出现了不同的隔离级别，锁就是实现各种隔离级别的⼀种⽅式。\n锁的种类\nflush tables with read lock (FTWRL)。\n## 全局锁\n顾名思义，全局锁就是对整个数据库实例加锁。\n典型使⽤场景：全库逻辑备份，即把整个库的表都select出来存成⽂本\nMySQL 提供了⼀个加全局读锁的⽅法，命令是\n当你需要让整个库处于只读状态的时候，可以使⽤这个命令，之后其他线程的以下语句会被阻塞：\n数据更新语句（数据的增删改）\n数据定义语句（包括建表、修改表结构等）\n更新类事务的提交语句\n## 表级锁\nMySQL ⾥⾯表级别的锁有下⾯⼏种：\n（1） 表锁\n每次操作锁住整张表\n开销⼩，加锁快\n并发度最低\n表锁的语法是 lock tables … read/write 。\n与 FTWRL 类似，可以⽤\n主动释放锁，也可以在客户端断开的时候⾃动释放。\n需要注意： lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n（2） 元数据锁（meta data lock，MDL）\nMDL  不需要显式使⽤，在访问⼀个表的时候会被⾃动加上。\nMDL 的作⽤：保证读写的正确性。\n你可以想象⼀下，如果⼀个查询正在遍历⼀个表中的数据，⽽执⾏期间另⼀个线程对这个表结构做变更，删了⼀\n列，那么查询线程拿到的结果跟表结构对不上，肯定是不⾏的。\n在 MySQL 5.5 版本中引⼊了 MDL\n当对⼀个表做增删改查操作的时候，加 MDL 读锁；\n当要对表做结构变更操作的时候，加 MDL 写锁。\n读锁之间不互斥，因此你可以有多个线程同时对⼀张表增删改查。读写锁之间、写锁之间是互斥的，⽤来保证变更\n表结构操作的安全性。因此，如果有两个线程要同时给⼀个表加字段，其中⼀个要等另⼀个执⾏完才能开始执⾏。\n事务中的  MDL  锁，在语句执⾏开始时申请，但是语句结束后并不会⻢上释放，⽽会等到整个事务提交后再释放。\n（这可能会产⽣死锁的问题）\n（3） 意向锁\n意向锁⽤于指示⼀个事务在未来可能会请求对某些资源（如数据⾏）的锁定\nunlock tables\nAUTO_INCREMENT\n意向共享锁表示事务打算在资源上获得共享锁。其他事务可以继续获得共享锁，但不能获得排他锁。\n意向排他（独占）锁： 表示事务打算在资源上获得排他锁。\n对某些记录加上「共享锁」之前，需要先在表级别加上⼀个「意向共享锁」，对某些纪录加上「独占锁」之前，需\n要先在表级别加上⼀个「意向独占锁」。\n意向共享锁和意向独占锁是表级锁，不会和⾏级的共享锁和独占锁发⽣冲突，意向锁之间也不会发⽣冲突，只会和\n共享表锁和独占表锁发⽣冲突。意向锁的⽬的是为了快速判断表⾥是否有记录被加锁。\n（4） AUTO-INC 锁\n作⽤：表⾥的主键通常都会设置成⾃增的，之后可以在插⼊数据时，可以不指定主键的值，数据库会⾃动给主键赋\n值递增的值通过 AUTO-INC 锁实现的。在插⼊数据时，会加⼀个表级别的 AUTO-INC 锁，然后为被\n修饰的字段赋值递增的值，等插⼊语句执⾏完成后，才会把 AUTO-INC 锁释放掉。其他事务的\n如果要向该表插⼊语句都会被阻塞，从⽽保证插⼊数据时字段的值是连续递增的。\n缺陷：对⼤量数据进⾏插⼊的时候，会影响插⼊性能，因为其他事务中的插⼊会被阻塞。\n改进：InnoDB  存储引擎提供了⼀种轻量级的锁来实现⾃增。在插⼊数据的时候，会为被\n的字段加上轻量级锁，然后给该字段赋值⼀个⾃增的值，就把这个轻量级锁释放了，⽽不需要等待整个插⼊语句执\n⾏完后才释放锁。\n## ⾏级锁\n顾名思义，⾏锁就是针对数据表中⾏记录的锁（也有⼈称为记录锁）。\n这很好理解，⽐如事务 A 更新了⼀⾏，⽽这时候事务 B 也要更新同⼀⾏，则必须等事务 A 的操作完成后才能进⾏\n更新。\n类型：\nRecord  Lock，记录锁，仅仅把⼀条记录锁上，记录锁分为排他锁和共享锁。\nGap Lock，间隙锁，锁定⼀个范围，但是不包含记录本身，只存在于可重复读隔离级别，⽬的是为了解决可\n重复读隔离级别下幻读的现象。间隙锁之间是兼容的，两个事务可以同时持有包含共同间隙范围的间隙锁，并\n不存在互斥关系。\nNext-Key Lock：Record Lock + Gap Lock 的组合，锁定⼀个范围，并且锁定记录本身。next-key lock 即能\n保护该记录，⼜能阻⽌其他事务将新纪录插⼊到被保护记录前⾯的间隙中。\n每次操作锁住⼀⾏数据\n开销⼤，加锁慢\n发⽣锁冲突的概率是最低的，并发度是最⾼的\n在 InnoDB 事务中，⾏锁是在需要的时候才加上的，但并不是不需要了就⽴刻释放，⽽是要等到事务结束时才释\n放。这个就是两阶段锁协议。\n知道了这个设定，对我们使⽤事务有什么帮助呢？那就是，如果你的事务中需要锁多个⾏，要把最可能造成锁冲\n突、最可能影响并发度的锁尽量往后放。\n加锁规则\n加锁规则⾥⾯，包含了两个“原则”、两个“优化”和⼀个“bug”\n两个原则：\nAUTO_INCREMENT\nSELECT user_id FROM product_comment WHERE user_id = 10 LOCK IN SHARE MODE;\nSELECT user_id FROM product_comment WHERE user_id = 10 FOR UPDATE;\nLOCK TABLE product_comment READ;\nUNLOCK TABLE;\n## 加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n## 查找过程中访问到的对象才会加锁。\n两个优化：\n## 索引上的等值查询，给唯⼀索引加锁的时候，next-key  lock  退化为⾏锁。\n## 索引上的等值查询，向右遍历时且最后⼀个值不满⾜等值条件的时候，next-key  lock  退化为间隙锁。\n⼀个\"bug\"：\n## 唯⼀索引上的范围查询会访问到不满⾜条件的第⼀个值为⽌。（MySQL8.0之后的版本已经修复）\n以上规则是在可重复读隔离级别 (repeatable-read) 下验证的。同时，可重复读隔离级别遵守两阶段锁协议，所有\n加锁的资源，都是在事务提交或者回滚的时候才释放的。如果切换到读提交隔离级别 (read-committed) 的话，就\n好理解了，过程中去掉间隙锁的部分，也就是只剩下⾏锁的部分。\n锁的划分\n## 、数据库⻆度\n## 共享锁（共享锁也叫读锁或 S 锁 ）\n共享锁锁定的资源可以被其他⽤户读取，但不能修改。\n在进⾏SELECT的时候，会将对象进⾏共享锁锁定，当数据读取完毕之后，就会释放共享锁，这样就可以保证数据\n在读取时不被修改。\n如果我们想要给某⼀⾏加上共享锁呢，⽐如想对   user_id=10的数据⾏加上共享锁，可以像下⾯这样：\n## 排他锁（排它锁也叫独占锁、写锁或 X 锁）\n排它锁锁定的数据只允许进⾏锁定操作的事务使⽤，其他事务⽆法对已锁定的数据进⾏查询或修改。\n如果我们想要在某个数据⾏上添加排它锁，⽐如针对 user_id=10的数据⾏，则写成如下这样：\n另外当我们对数据进⾏更新的时候，也就是INSERT、DELETE或者UPDATE的时候，数据库也会⾃动使⽤排它锁，\n防⽌其他事务对该数据⾏进⾏操作。\n## 共享锁与排他锁\n共享锁和排他锁不仅可以锁住⼀⾏，也可以锁住⼀张表，如下所示：\n⽐如我们想给  product_comment  在表上加共享锁，可以使⽤下⾯这⾏命令\n如果我们想要对表上的共享锁进⾏解锁，可以使⽤下⾯这⾏命令：\nLOCK TABLE product_comment WRITE;\nUNLOCK TABLE;\n如果我们想给  product_comment  数据表添加排它锁，可以使⽤下⾯这⾏命令\n这时只有获得排它锁的事务可以对 product_comment 进⾏查询或修改，其他事务如果想要在 product_comment\n表上查询数据，则需要等待。\n你可以⾃⼰开两个  MySQL 客户端来模拟下。这时我们释放掉排它锁，使⽤这⾏命令即可\n## 意向锁（Intent Lock）\n简单来说就是给更⼤⼀级别的空间示意⾥⾯是否已经上过锁。\n举例：\n你可以给整个房⼦设置⼀个标识，告诉它⾥⾯有⼈，即使你只是获取了房⼦中某⼀个房间的锁。这样其他⼈如果想\n要获取整个房⼦的控制权，只需要看这个房⼦的标识即可，不需要再对房⼦中的每个房间进⾏查找。这样是不是很\n⽅便？\n返回数据表的场景，如果我们给某⼀⾏数据加上了排它锁，数据库会⾃动给更⼤⼀级的空间，⽐如数据⻚或数据表\n加上意向锁，告诉其他⼈这个数据⻚或数据表已经有⼈上过排它锁了，这样当其他⼈想要获取数据表排它锁的时\n候，只需要了解是否有⼈已经获取了这个数据表的意向排他锁即可。\n如果事务想要获得数据表中某些记录的共享锁，就需要在数据表上添加意向共享锁。同理，事务想要获得数据表中\n某些记录的排他锁，就需要在数据表上添加意向排他锁。这时，意向锁会告诉其他事务已经有⼈锁定了表中的某些\n记录，不能对整个表进⾏全表扫描。\n## 、程序员⻆度\n## 乐观锁（Optimistic Locking）\n认为对同⼀数据的并发操作不会总发⽣，属于⼩概率事件，不⽤每次都对数据上锁，也就是不采⽤数据库⾃身的锁\n机制，⽽是通过程序来实现。在程序上，我们可以采⽤版本号机制或者时间戳机制实现。\n## 悲观锁（Pessimistic Locking）\n也是⼀种思想，对数据被其他事务的修改持保守态度，会通过数据库⾃身的锁机制来实现，从⽽保证数据操作的排\n它性。\n## 乐观锁和悲观锁的适⽤场景\n（1） 乐观锁\n适合读操作多的场景，相对来说写的操作⽐较少。它的优点在于程序实现，不存在死锁问题，不过适⽤场景也会相\n对乐观，因为它阻⽌不了除了程序以外的数据库操作。\n（2） 悲观锁\n适合写操作多的场景，因为写的操作具有排它性。采⽤悲观锁的⽅式，可以在数据库层⾯阻⽌其他事务对该数据的\n操作权限，防⽌读 - 写和写 - 写的冲突。但是加锁的时间会⽐较⻓，可能会⻓时间限制其他⽤户的访问，也就是说\n他的并发访问性不好。\nInnodb使⽤表锁还是⾏锁\n对于Innodb，绝⼤部分情况应该使⽤⾏锁\n使⽤表锁的情况\n（1） 表⽐较⼤，事务需要更新全部或者⼤部分数据\n（2） 事务涉及到多个表，⽐较复杂，可能引起死锁，造成⼤量的事务回滚\n在前⾯中，我们提到了【更新语句】会设计到⽇志，具体包含下⾯⼏种\nundo log（回滚⽇志）：是 Innodb 存储引擎层⽣成的⽇志，实现了事务中的原⼦性，主要⽤于事务回滚和\nMVCC。\nredo log（重做⽇志）：是 Innodb 存储引擎层⽣成的⽇志，实现了事务中的持久性，主要⽤于掉电等故障恢\nbinlog （归档⽇志）：是 Server 层⽣成的⽇志，主要⽤于数据备份和主从复制；\n什么是undo logo\n当事务对数据库进⾏更新（插⼊、修改、删除）时，系统会记录相应的undo log ，以便在事务回滚或系统崩溃时\n进⾏数据恢复, 主要⽤于事务回滚和MVCC。 undo log 记录的信息包括操作类型（插⼊、删除还是更新），修改前\n的数据值，被修改的数据的位置，事务标识id等，⽐如在更新⼀条记录时，要把被更新的列的旧值记下来，这样之\n后回滚时再把这些列更新为旧值就好了。\n每⼀次更新操作产⽣的undo log 格式都有⼀个\n本链)和⼀个trx_id 事务id(记录是被哪个事务修改的)\n指针(将undo log 串成⼀个链表, 链表也被成为版\n事务回滚：如果事务在执⾏过程中出现错误或被⽤户显式地回滚，系统可以使⽤undo log 来还原事务所做的\n所有修改。通过undo log ，数据库系统可以逆向执⾏事务的操作，将数据库还原到事务开始前的状态。\n实现 MVCC（多版本并发控制）关键因素之⼀。MVCC 是通过 ReadView + undo log 实现的。undo log 为每\n条记录保存多份历史数据，MySQL 在执⾏快照读（普通 select 语句）的时候，会根据事务的 Read View ⾥\n的信息，顺着 undo log 的版本链找到满⾜其可⻅性的记录。\n什么是redo log\nredo log 是物理⽇志，记录了某个数据⻚做了什么修改，⽐如对 XXX 表空间中的 YYY 数据⻚ ZZZ 偏移量的地⽅做\n了AAA 更新，每当执⾏⼀个事务就会产⽣这样的⼀条或者多条物理⽇志。在事务提交时，只要先将 redo log 持久\n化到磁盘即可",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 10292,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000115",
    "content": "## 乐观锁和悲观锁的适⽤场景\n\n（1） 乐观锁\n适合读操作多的场景，相对来说写的操作⽐较少。它的优点在于程序实现，不存在死锁问题，不过适⽤场景也会相\n对乐观，因为它阻⽌不了除了程序以外的数据库操作。\n（2） 悲观锁\n适合写操作多的场景，因为写的操作具有排它性。采⽤悲观锁的⽅式，可以在数据库层⾯阻⽌其他事务对该数据的\n操作权限，防⽌读 - 写和写 - 写的冲突。但是加锁的时间会⽐较⻓，可能会⻓时间限制其他⽤户的访问，也就是说\n他的并发访问性不好。\nInnodb使⽤表锁还是⾏锁\n对于Innodb，绝⼤部分情况应该使⽤⾏锁\n使⽤表锁的情况\n（1） 表⽐较⼤，事务需要更新全部或者⼤部分数据\n（2） 事务涉及到多个表，⽐较复杂，可能引起死锁，造成⼤量的事务回滚\n在前⾯中，我们提到了【更新语句】会设计到⽇志，具体包含下⾯⼏种\nundo log（回滚⽇志）：是 Innodb 存储引擎层⽣成的⽇志，实现了事务中的原⼦性，主要⽤于事务回滚和\nMVCC。\nredo log（重做⽇志）：是 Innodb 存储引擎层⽣成的⽇志，实现了事务中的持久性，主要⽤于掉电等故障恢\nbinlog （归档⽇志）：是 Server 层⽣成的⽇志，主要⽤于数据备份和主从复制；\n什么是undo logo\n当事务对数据库进⾏更新（插⼊、修改、删除）时，系统会记录相应的undo log ，以便在事务回滚或系统崩溃时\n进⾏数据恢复, 主要⽤于事务回滚和MVCC。 undo log 记录的信息包括操作类型（插⼊、删除还是更新），修改前\n的数据值，被修改的数据的位置，事务标识id等，⽐如在更新⼀条记录时，要把被更新的列的旧值记下来，这样之\n后回滚时再把这些列更新为旧值就好了。\n每⼀次更新操作产⽣的undo log 格式都有⼀个\n本链)和⼀个trx_id 事务id(记录是被哪个事务修改的)\n指针(将undo log 串成⼀个链表, 链表也被成为版\n事务回滚：如果事务在执⾏过程中出现错误或被⽤户显式地回滚，系统可以使⽤undo log 来还原事务所做的\n所有修改。通过undo log ，数据库系统可以逆向执⾏事务的操作，将数据库还原到事务开始前的状态。\n实现 MVCC（多版本并发控制）关键因素之⼀。MVCC 是通过 ReadView + undo log 实现的。undo log 为每\n条记录保存多份历史数据，MySQL 在执⾏快照读（普通 select 语句）的时候，会根据事务的 Read View ⾥\n的信息，顺着 undo log 的版本链找到满⾜其可⻅性的记录。\n什么是redo log\nredo log 是物理⽇志，记录了某个数据⻚做了什么修改，⽐如对 XXX 表空间中的 YYY 数据⻚ ZZZ 偏移量的地⽅做\n了AAA 更新，每当执⾏⼀个事务就会产⽣这样的⼀条或者多条物理⽇志。在事务提交时，只要先将 redo log 持久\n化到磁盘即可\nredo log和undo log的区别是什么\nundo log 和 redo log 这两个⽇志都是 Innodb 存储引擎⽣成的。\nredo  log  记录了此次事务「完成后」的数据状态，记录的是更新之后的值；\nundo  log  记录了此次事务「开始前」的数据状态，记录的是更新之前的值；\n事务提交之前发⽣了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发⽣了崩溃，重启后会通过 redo log\n恢复事务\nroll_pointer\n什么是binlog\nMySQL 在完成⼀条更新操作后，Server 层还会⽣成⼀条 binlog，等之后事务提交的时候，会将该事物执⾏过程中\n产⽣的所有 binlog 统⼀写 ⼊ binlog ⽂件。\nbinlog ⽂件是记录了所有数据库表结构变更和表数据修改的⽇志，不会记录查询类的操作，⽐如 SELECT 和 SHOW\n操作。\nredo log和bin log有什么区别\n适⽤对象不同：binlog 是 MySQL 的 Server 层实现的，所有存储引擎都可以使⽤；redo log 是 Innodb 存储\n引擎实现的⽇志。\n⽂件格式不同：redo log 是物理⽇志，记录的是在某个数据⻚做了什么修改，⽐如对 XXX 表空间中的 YYY 数\n据⻚ ZZZ 偏移量的地⽅做了AAA 更新。⽽binlog 主要包括三种格式： Statement 、 Row 和 Mixed 。\n写⼊⽅式不同：binlog  是追加写，写满⼀个⽂件，就创建⼀个新的⽂件继续写，不会覆盖以前的⽇志，保存\n的是全量的⽇志。redo   log是循环写，⽇志空间⼤⼩是固定，全部写满就从头开始，保存未被刷⼊磁盘的脏⻚\n⽇志。\n⽤途不同：binlog ⽤于备份恢复、主从复制；redo log ⽤于掉电等故障恢复。\n为什么需要两阶段提交\n事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独⽴的逻辑，可能出现半成功的状态，造成两\n份⽇志之间的逻辑不⼀致。\n如果在将 redo log 刷⼊到磁盘之后， MySQL 突然宕机了，⽽ binlog 还没有来得及写⼊。MySQL 重启后，\n通过 redo log 能将 Buffer Pool 恢复到新值，但是 binlog ⾥⾯没有记录这条更新语句，在主从架构中，\nbinlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这⼀⾏是旧值，主从不⼀致。\n如果在将 binlog 刷⼊到磁盘之后， MySQL 突然宕机了，⽽ redo log 还没有来得及写⼊。由于 redo log 还\n没写，崩溃恢复以后这个事务⽆效，数据是旧值，⽽ binlog ⾥⾯记录了这条更新语句，在主从架构中，\nbinlog 会被复制到从库，从库执⾏了这条更新语句，这⼀⾏字段是新值，与主库的值不⼀致性。\n所以会造成主从环境的数据不⼀致性。因为 redo log 影响主库的数据，binlog 影响从库的数据，redo log 和\nbinlog 必须保持⼀致。\n两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是准备(Prepare)阶段和提交(Commit)阶段，每个阶段都\n由协调者(Coordinator)和参与者(Participant)共同完成。\n两阶段提交的过程\n在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog ⽇志与 InnoDB 的 redo\nlog，为了保证这两个⽇志的⼀致性，MySQL 使⽤了内部 XA 事务，内部 XA 事务由 binlog 作为协调者，存储引擎\n是参与者。\n当客户端执⾏ commit 语句或者在⾃动提交的情况下，MySQL 内部开启⼀个 XA 事务，分两阶段来完成 XA 事务的\n提交。\n事务的提交过程有两个阶段，将 redo log 的写⼊拆成了两个步骤：prepare 和 commit，中间再穿插写⼊\nbinlog：\nprepare 阶段：将 内部 XA 事务的 ID写⼊到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然\n后将 redo log 持久化到磁盘。\ncommit 阶段：把 内部 XA 事务的 ID写⼊到 binlog，然后将 binlog 持久化到磁盘，接着调⽤引擎的提交事务\n接⼝，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到⽂件系统的\npage cache 成功，只要 binlog 写磁盘成功，redo log 的状态还是 prepare 也没有关系，⼀样会被认为事务\n已经执⾏成功。\n执⾏引擎\n有哪些执⾏引擎\n在MySQL中，可以通过 SHOW ENGINES; 命令查看当前数据库⽀持的存储引擎。InnoDB是较为通⽤和常⽤的存储\n引擎。\nInnoDB : MySQL默认的事务性存储引擎，⽀持事务的提交（commit）和回滚（rollback），提供了⾏级锁\n定，⽀持外键约束和MVCC\nMyISAM : MyISAM 使⽤表级锁定, 不⽀持事务，⽀持全⽂索引，适⽤于以读操作为主的应⽤\nMemory : 将数据放在内存中，数据处理速度很快，但是当数据库重启或崩溃时，存储在内存中的数据将丢\n数据库引擎InnoDB与MyISAM的区别和适⽤场景？",
    "question": "## 乐观锁和悲观锁的适⽤场景",
    "answer": "（1） 乐观锁\n适合读操作多的场景，相对来说写的操作⽐较少。它的优点在于程序实现，不存在死锁问题，不过适⽤场景也会相\n对乐观，因为它阻⽌不了除了程序以外的数据库操作。\n（2） 悲观锁\n适合写操作多的场景，因为写的操作具有排它性。采⽤悲观锁的⽅式，可以在数据库层⾯阻⽌其他事务对该数据的\n操作权限，防⽌读 - 写和写 - 写的冲突。但是加锁的时间会⽐较⻓，可能会⻓时间限制其他⽤户的访问，也就是说\n他的并发访问性不好。\nInnodb使⽤表锁还是⾏锁\n对于Innodb，绝⼤部分情况应该使⽤⾏锁\n使⽤表锁的情况\n（1） 表⽐较⼤，事务需要更新全部或者⼤部分数据\n（2） 事务涉及到多个表，⽐较复杂，可能引起死锁，造成⼤量的事务回滚\n在前⾯中，我们提到了【更新语句】会设计到⽇志，具体包含下⾯⼏种\nundo log（回滚⽇志）：是 Innodb 存储引擎层⽣成的⽇志，实现了事务中的原⼦性，主要⽤于事务回滚和\nMVCC。\nredo log（重做⽇志）：是 Innodb 存储引擎层⽣成的⽇志，实现了事务中的持久性，主要⽤于掉电等故障恢\nbinlog （归档⽇志）：是 Server 层⽣成的⽇志，主要⽤于数据备份和主从复制；\n什么是undo logo\n当事务对数据库进⾏更新（插⼊、修改、删除）时，系统会记录相应的undo log ，以便在事务回滚或系统崩溃时\n进⾏数据恢复, 主要⽤于事务回滚和MVCC。 undo log 记录的信息包括操作类型（插⼊、删除还是更新），修改前\n的数据值，被修改的数据的位置，事务标识id等，⽐如在更新⼀条记录时，要把被更新的列的旧值记下来，这样之\n后回滚时再把这些列更新为旧值就好了。\n每⼀次更新操作产⽣的undo log 格式都有⼀个\n本链)和⼀个trx_id 事务id(记录是被哪个事务修改的)\n指针(将undo log 串成⼀个链表, 链表也被成为版\n事务回滚：如果事务在执⾏过程中出现错误或被⽤户显式地回滚，系统可以使⽤undo log 来还原事务所做的\n所有修改。通过undo log ，数据库系统可以逆向执⾏事务的操作，将数据库还原到事务开始前的状态。\n实现 MVCC（多版本并发控制）关键因素之⼀。MVCC 是通过 ReadView + undo log 实现的。undo log 为每\n条记录保存多份历史数据，MySQL 在执⾏快照读（普通 select 语句）的时候，会根据事务的 Read View ⾥\n的信息，顺着 undo log 的版本链找到满⾜其可⻅性的记录。\n什么是redo log\nredo log 是物理⽇志，记录了某个数据⻚做了什么修改，⽐如对 XXX 表空间中的 YYY 数据⻚ ZZZ 偏移量的地⽅做\n了AAA 更新，每当执⾏⼀个事务就会产⽣这样的⼀条或者多条物理⽇志。在事务提交时，只要先将 redo log 持久\n化到磁盘即可\nredo log和undo log的区别是什么\nundo log 和 redo log 这两个⽇志都是 Innodb 存储引擎⽣成的。\nredo  log  记录了此次事务「完成后」的数据状态，记录的是更新之后的值；\nundo  log  记录了此次事务「开始前」的数据状态，记录的是更新之前的值；\n事务提交之前发⽣了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发⽣了崩溃，重启后会通过 redo log\n恢复事务\nroll_pointer\n什么是binlog\nMySQL 在完成⼀条更新操作后，Server 层还会⽣成⼀条 binlog，等之后事务提交的时候，会将该事物执⾏过程中\n产⽣的所有 binlog 统⼀写 ⼊ binlog ⽂件。\nbinlog ⽂件是记录了所有数据库表结构变更和表数据修改的⽇志，不会记录查询类的操作，⽐如 SELECT 和 SHOW\n操作。\nredo log和bin log有什么区别\n适⽤对象不同：binlog 是 MySQL 的 Server 层实现的，所有存储引擎都可以使⽤；redo log 是 Innodb 存储\n引擎实现的⽇志。\n⽂件格式不同：redo log 是物理⽇志，记录的是在某个数据⻚做了什么修改，⽐如对 XXX 表空间中的 YYY 数\n据⻚ ZZZ 偏移量的地⽅做了AAA 更新。⽽binlog 主要包括三种格式： Statement 、 Row 和 Mixed 。\n写⼊⽅式不同：binlog  是追加写，写满⼀个⽂件，就创建⼀个新的⽂件继续写，不会覆盖以前的⽇志，保存\n的是全量的⽇志。redo   log是循环写，⽇志空间⼤⼩是固定，全部写满就从头开始，保存未被刷⼊磁盘的脏⻚\n⽇志。\n⽤途不同：binlog ⽤于备份恢复、主从复制；redo log ⽤于掉电等故障恢复。\n为什么需要两阶段提交\n事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独⽴的逻辑，可能出现半成功的状态，造成两\n份⽇志之间的逻辑不⼀致。\n如果在将 redo log 刷⼊到磁盘之后， MySQL 突然宕机了，⽽ binlog 还没有来得及写⼊。MySQL 重启后，\n通过 redo log 能将 Buffer Pool 恢复到新值，但是 binlog ⾥⾯没有记录这条更新语句，在主从架构中，\nbinlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这⼀⾏是旧值，主从不⼀致。\n如果在将 binlog 刷⼊到磁盘之后， MySQL 突然宕机了，⽽ redo log 还没有来得及写⼊。由于 redo log 还\n没写，崩溃恢复以后这个事务⽆效，数据是旧值，⽽ binlog ⾥⾯记录了这条更新语句，在主从架构中，\nbinlog 会被复制到从库，从库执⾏了这条更新语句，这⼀⾏字段是新值，与主库的值不⼀致性。\n所以会造成主从环境的数据不⼀致性。因为 redo log 影响主库的数据，binlog 影响从库的数据，redo log 和\nbinlog 必须保持⼀致。\n两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是准备(Prepare)阶段和提交(Commit)阶段，每个阶段都\n由协调者(Coordinator)和参与者(Participant)共同完成。\n两阶段提交的过程\n在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog ⽇志与 InnoDB 的 redo\nlog，为了保证这两个⽇志的⼀致性，MySQL 使⽤了内部 XA 事务，内部 XA 事务由 binlog 作为协调者，存储引擎\n是参与者。\n当客户端执⾏ commit 语句或者在⾃动提交的情况下，MySQL 内部开启⼀个 XA 事务，分两阶段来完成 XA 事务的\n提交。\n事务的提交过程有两个阶段，将 redo log 的写⼊拆成了两个步骤：prepare 和 commit，中间再穿插写⼊\nbinlog：\nprepare 阶段：将 内部 XA 事务的 ID写⼊到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然\n后将 redo log 持久化到磁盘。\ncommit 阶段：把 内部 XA 事务的 ID写⼊到 binlog，然后将 binlog 持久化到磁盘，接着调⽤引擎的提交事务\n接⼝，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到⽂件系统的\npage cache 成功，只要 binlog 写磁盘成功，redo log 的状态还是 prepare 也没有关系，⼀样会被认为事务\n已经执⾏成功。\n执⾏引擎\n有哪些执⾏引擎\n在MySQL中，可以通过 SHOW ENGINES; 命令查看当前数据库⽀持的存储引擎。InnoDB是较为通⽤和常⽤的存储\n引擎。\nInnoDB : MySQL默认的事务性存储引擎，⽀持事务的提交（commit）和回滚（rollback），提供了⾏级锁\n定，⽀持外键约束和MVCC\nMyISAM : MyISAM 使⽤表级锁定, 不⽀持事务，⽀持全⽂索引，适⽤于以读操作为主的应⽤\nMemory : 将数据放在内存中，数据处理速度很快，但是当数据库重启或崩溃时，存储在内存中的数据将丢\n数据库引擎InnoDB与MyISAM的区别和适⽤场景？",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3465,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000116",
    "content": "redo log和undo log的区别是什么\n\nundo log 和 redo log 这两个⽇志都是 Innodb 存储引擎⽣成的。\nredo  log  记录了此次事务「完成后」的数据状态，记录的是更新之后的值；\nundo  log  记录了此次事务「开始前」的数据状态，记录的是更新之前的值；\n事务提交之前发⽣了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发⽣了崩溃，重启后会通过 redo log\n恢复事务\nroll_pointer\n什么是binlog\nMySQL 在完成⼀条更新操作后，Server 层还会⽣成⼀条 binlog，等之后事务提交的时候，会将该事物执⾏过程中\n产⽣的所有 binlog 统⼀写 ⼊ binlog ⽂件。\nbinlog ⽂件是记录了所有数据库表结构变更和表数据修改的⽇志，不会记录查询类的操作，⽐如 SELECT 和 SHOW\n操作。",
    "question": "redo log和undo log的区别是什么",
    "answer": "undo log 和 redo log 这两个⽇志都是 Innodb 存储引擎⽣成的。\nredo  log  记录了此次事务「完成后」的数据状态，记录的是更新之后的值；\nundo  log  记录了此次事务「开始前」的数据状态，记录的是更新之前的值；\n事务提交之前发⽣了崩溃，重启后会通过 undo log 回滚事务，事务提交之后发⽣了崩溃，重启后会通过 redo log\n恢复事务\nroll_pointer\n什么是binlog\nMySQL 在完成⼀条更新操作后，Server 层还会⽣成⼀条 binlog，等之后事务提交的时候，会将该事物执⾏过程中\n产⽣的所有 binlog 统⼀写 ⼊ binlog ⽂件。\nbinlog ⽂件是记录了所有数据库表结构变更和表数据修改的⽇志，不会记录查询类的操作，⽐如 SELECT 和 SHOW\n操作。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 395,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000117",
    "content": "redo log和bin log有什么区别\n\n适⽤对象不同：binlog 是 MySQL 的 Server 层实现的，所有存储引擎都可以使⽤；redo log 是 Innodb 存储\n引擎实现的⽇志。\n⽂件格式不同：redo log 是物理⽇志，记录的是在某个数据⻚做了什么修改，⽐如对 XXX 表空间中的 YYY 数\n据⻚ ZZZ 偏移量的地⽅做了AAA 更新。⽽binlog 主要包括三种格式： Statement 、 Row 和 Mixed 。\n写⼊⽅式不同：binlog  是追加写，写满⼀个⽂件，就创建⼀个新的⽂件继续写，不会覆盖以前的⽇志，保存\n的是全量的⽇志。redo   log是循环写，⽇志空间⼤⼩是固定，全部写满就从头开始，保存未被刷⼊磁盘的脏⻚\n⽇志。\n⽤途不同：binlog ⽤于备份恢复、主从复制；redo log ⽤于掉电等故障恢复。\n为什么需要两阶段提交\n事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独⽴的逻辑，可能出现半成功的状态，造成两\n份⽇志之间的逻辑不⼀致。\n如果在将 redo log 刷⼊到磁盘之后， MySQL 突然宕机了，⽽ binlog 还没有来得及写⼊。MySQL 重启后，\n通过 redo log 能将 Buffer Pool 恢复到新值，但是 binlog ⾥⾯没有记录这条更新语句，在主从架构中，\nbinlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这⼀⾏是旧值，主从不⼀致。\n如果在将 binlog 刷⼊到磁盘之后， MySQL 突然宕机了，⽽ redo log 还没有来得及写⼊。由于 redo log 还\n没写，崩溃恢复以后这个事务⽆效，数据是旧值，⽽ binlog ⾥⾯记录了这条更新语句，在主从架构中，\nbinlog 会被复制到从库，从库执⾏了这条更新语句，这⼀⾏字段是新值，与主库的值不⼀致性。\n所以会造成主从环境的数据不⼀致性。因为 redo log 影响主库的数据，binlog 影响从库的数据，redo log 和\nbinlog 必须保持⼀致。\n两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是准备(Prepare)阶段和提交(Commit)阶段，每个阶段都\n由协调者(Coordinator)和参与者(Participant)共同完成。\n两阶段提交的过程\n在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog ⽇志与 InnoDB 的 redo\nlog，为了保证这两个⽇志的⼀致性，MySQL 使⽤了内部 XA 事务，内部 XA 事务由 binlog 作为协调者，存储引擎\n是参与者。\n当客户端执⾏ commit 语句或者在⾃动提交的情况下，MySQL 内部开启⼀个 XA 事务，分两阶段来完成 XA 事务的\n提交。\n事务的提交过程有两个阶段，将 redo log 的写⼊拆成了两个步骤：prepare 和 commit，中间再穿插写⼊\nbinlog：\nprepare 阶段：将 内部 XA 事务的 ID写⼊到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然\n后将 redo log 持久化到磁盘。\ncommit 阶段：把 内部 XA 事务的 ID写⼊到 binlog，然后将 binlog 持久化到磁盘，接着调⽤引擎的提交事务\n接⼝，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到⽂件系统的\npage cache 成功，只要 binlog 写磁盘成功，redo log 的状态还是 prepare 也没有关系，⼀样会被认为事务\n已经执⾏成功。\n执⾏引擎\n有哪些执⾏引擎\n在MySQL中，可以通过 SHOW ENGINES; 命令查看当前数据库⽀持的存储引擎。InnoDB是较为通⽤和常⽤的存储\n引擎。\nInnoDB : MySQL默认的事务性存储引擎，⽀持事务的提交（commit）和回滚（rollback），提供了⾏级锁\n定，⽀持外键约束和MVCC\nMyISAM : MyISAM 使⽤表级锁定, 不⽀持事务，⽀持全⽂索引，适⽤于以读操作为主的应⽤\nMemory : 将数据放在内存中，数据处理速度很快，但是当数据库重启或崩溃时，存储在内存中的数据将丢\n数据库引擎InnoDB与MyISAM的区别和适⽤场景？\n## 事务⽀持\n⽀持事务，具有ACID（原⼦性、⼀致性、隔离性、持久性）特性，适合需要数据⼀致性和完整性的\n应⽤，如银⾏系统或在线购物平台。\n不⽀持事务，不具备ACID特性，适⽤于读密集、写少的场景，如博客系统或新闻⽹站。\n## 锁\n## 外键约束:\n⾏级锁，多个事务可以同时访问同⼀表的不同⾏。\n表级锁，对整个表进⾏锁定，导致并发性能下降，特别是在有⼤量写操作时。\nInnoDB:   ⽀持外键约束，确保数据的⼀致性和完整性。\nMyISAM: 不⽀持外键约束\n## 崩溃恢复(Crash Recovery):\n⽀持崩溃恢复\n在崩溃后恢复可能会导致数据损失。\n## 全⽂索引(Full-text Indexing):\nInnoDB: ⽀持全⽂索引。\nMyISAM:  也⽀持全⽂索引，并且在这⽅⾯表现的更加好。\nInnoDB:   适⽤于需要事务⽀持、并发性能好、具有⾼写⼊需求的应⽤\nMyISAM: 适⽤于读操作频繁、写⼊操作较少的应⽤\nMySQL常⻅问题\n## 幻读连问\n1-1 ：什么是幻读？\n幻读是指在同⼀个事务中，存在前后两次查询同⼀个范围的数据，但是第⼆次查询却看到了第⼀次查询没看到的\n注意，幻读出现的场景：\n## 事务的隔离级别为可重复读，且是当前读\n## 幻读仅专指新插⼊的⾏\n1-2 ：幻读带来的问题？\n## 对⾏锁语义的破坏\n## 破坏了数据⼀致性\n1-3 ：怎么避免幻读？\n存储引擎采⽤加间隙锁的⽅式来避免出现幻读\n1-4 ：为啥会出现幻读？\n⾏锁只能锁定存在的⾏，针对新插⼊的操作没有限定\n1-5 ：间隙锁是啥？它怎么避免出现幻读的？它引⼊了什么新的问题？\n间隙锁：\n是专⻔⽤于解决幻读这种问题的锁，它锁的了⾏与⾏之间的间隙，能够阻塞新插⼊的操作\n间隙锁的引⼊也带来了⼀些新的问题，⽐如：降低并发度，可能导致死锁。\n注意，读读不互斥，读写/写读/写写是互斥的，但是间隙锁之间是不冲突的，间隙锁会阻塞插⼊操作\n另外，间隙锁在可重复读级别下才是有效的\n间隙锁和 next-key lock：\n⾏锁和间隙锁合称  next-key lock，这个锁是左开右闭的区间。\nMySQL 为了解决幻读问题，在线程更新数据并 next-key lock 的过程中，⾸先必须在可重复读的隔离级别下，执⾏以\n下的原则和优化：\n原则 1：加锁的基本单位是 next-key lock，next-key lock 是前开后闭区间。\n原则 2：查找过程中访问到的对象才会加锁。\n优化：\n优化 1：索引上的等值查询，给唯⼀索引加锁的时候，next-key lock 退化为⾏锁，如果不存在这个索引，退化为间\n隙锁。\n优化  2：索引上的等值查询，向右遍历时且最后⼀个值不满⾜等值条件的时候，next-key  lock  退化为间隙锁。\n注意：\nSELECT * FROM table LIMIT [offset,] rows | rows OFFSET offset;\n## 如果只给定⼀个参数，表示记录数。\nmysql> SELECT * FROM orange LIMIT 5;\n## 检索前5条记录(1-5)\nmysql> SELECT * from orange LIMIT 0,5;\nmysql> SELECT * FROM orange LIMIT 10,15; // 检索记录11-25\n## ⾮唯⼀索引的范围查询：范围查询都会访问到不满⾜条件的第⼀个值，并且不会执⾏上述的两个优化。唯⼀索\n引的范围查询仍旧会执⾏上述的优化。\n## delete  语句的和查询的加锁⽅式相同\n## limit 语句，遍历到满⾜条件的 n 条数据后，之后不再加 next-key lock\n死锁：不同线程可以给同⼀个间隙加锁。\n意思时只有我这个线程可以操控这个间隙，其他线程不能使⽤，加锁时不会检测是否冲突的，但是如果两个都给同\n⼀个间隙上锁，之后两个线程都没办法在这个间隙上更新数据了，都会陷⼊等待另⼀个线程的间隙锁释放，也就是\n死锁。\n如果使⽤读提交隔离级别，那么只加⾏锁，不加间隙锁，语句执⾏过程中加上的⾏锁，在语句执⾏完成后，就要把\n“不满⾜条件的⾏”上的⾏锁直接释放了，不需要等到事务提交才释放。\n## 事务\n2-1 ：for update的使⽤场景\n⼀般这些操作都是很⻓⼀串并且是开启事务的。\n如果库存刚开始读的时候是1，⽽⽴⻢另⼀个进程进⾏了update将库存更新为0了，⽽事务还没有结束，会将错的\n数据⼀直执⾏下去，就会有问题。\n需要 for upate 进⾏数据加锁防⽌⾼并发时候数据出错，即 使事务保持 当前读 状态。\n相当于\n两个参数，第⼀个参数表示offset,   第⼆个参数为记录数。\n如果你想要清除⼀些MySQL使⽤内部缓存，你应该使⽤FLUSH命令\n2-2 ：事务隔离\ninnodb ⽀持 RC 和 RR 隔离级别实现是⽤的⼀致性视图(consistent read view)\n事务在启动时会拍⼀个快照,这个快照是基于整个库的。\n基于整个库的意思就是说⼀个事务内,整个库的修改对于该事务都是不可⻅的(对于快照读的情况)\n如果在事务内 select t 表,另外的事务执⾏了DDL t表,根据发⽣时间,只有两种情况\n## 报错\n## 锁住\n事务是如何实现mvcc的？\n（1） 每个事务都有⼀个事务ID,叫做transaction  id(严格递增)\n（2） 事务在启动时,找到已提交的最⼤事务ID记为up_limit_id。\n（3） 事务在更新⼀条语句时\n⽐如 id=1 改为了 id=2.会把 id=1 和该⾏之前的 row trx_id 写到 undo log ⾥, 并且在数据⻚上把 id 的值改为 2,并\n且把修改这条语句的transaction id 记在该⾏⾏头\n（4） 再定⼀个规矩\n⼀个事务要查看⼀条数据时,必须先⽤该事务的 up_limit_id 与该⾏的transaction id 做⽐对\n如果 up_limit_id >= transaction id,那么可以看\n如果 up_limit_id < transaction id,则只能去 undo log ⾥去取。\n去 undo log 查找数据的时候,也需要做⽐对,必须 up_limit_id >  transaction id，才返回数据\n2-3 ：什么是当前读\n由于当前读都是先读后写,只能读当前的值,所以为当前读会更新事务内的 up_limit_id 为该事务的 transaction\n你提到了隐藏列有⼀个DB_ROW_ID，是⼲嘛的？那假设有10个update，到第九个回滚了，DB_ROLL_PTR如何做\n的，那提交了是否更新DB_ROLL_PTR？\n为什么 rr 能实现可重复读⽽ rc 不能,分两种情况\n（1） 快照读的情况下：\nrr不能更新事务内的 up_limit_id ,⽽ rc 每次会把 up_limit_id 更新为快照读之前最新已提交事务的 transaction id,\n则 rc 不能可重复读\n（2） 当前读的情况下：\nrr 是利⽤ record lock+gap lock来实现的,⽽ rc 没有 gap,所以 rc 不能可重复读\n2-4 ：选择普通索引还是唯⼀索引？\n## 对于查询过程来说：\n（1） 普通索引\n查到满⾜条件的第⼀个记录后，继续查找下⼀个记录，知道第⼀个不满⾜条件的记录\n（2） 唯⼀索引\n由于索引唯⼀性，查到第⼀个满⾜条件的记录后，停⽌检索\n但是，两者的性能差距微乎其微。因为InnoDB根据数据⻚来读写的。\n## 对于更新过程来说：\n概念：change buffer\n当需要更新⼀个数据⻚：\n如果数据⻚在内存中就直接更新\n如果不在内存中，在不影响数据⼀致性的前提下，InnoDB  会将这些更新操作缓存在change  buffer  中。\n下次查询需要访问这个数据⻚的时候，将数据⻚读⼊内存，然后执⾏  change  buffer  中的与这个⻚有关的操作。\nchange  buffer  是可以持久化的数据。在内存中有拷⻉，也会被写⼊到磁盘上\npurge：将 change buffer 中的操作应⽤到原数据⻚上，得到最新结果的过程，成为 purge\n访问这个数据⻚会触发 purge，系统有后台线程定期 purge，在数据库正常关闭的过程中，也会执⾏ purge\n唯⼀索引的更新不能使⽤ change buffer\nchange buffer ⽤的是 buffer pool ⾥的内存，change buffer 的⼤⼩，可以通过参数\ninnodb_change_buffer_max_size 来动态设置。这个参数设置为50的时候，表示 change buffer 的⼤⼩最多只能\n占⽤ buffer pool 的50%。\n将数据从磁盘读⼊内存涉及随机IO的访问，是数据库⾥⾯成本最⾼的操作之⼀。\nchange buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。\nchange buffer使⽤场景：\n在⼀个数据⻚做purge之前，change buffer记录的变更越多，收益就越⼤。\n对于写多读少的业务来说，⻚⾯在写完以后⻢上被访问到的概率⽐较⼩，此时change buffer的使⽤效果最好。这\n种业务模型常⻅的就是账单类、⽇志类的系统。\n反过来，假设⼀个业务的更新模式是写⼊之后⻢上会做查询，那么即使满⾜了条件，将更新先记录在change\nbuffer,但之后由于⻢上要访问这个数据⻚，会⽴即触发purge过程。\n这样随机访问IO的次数不会减少，反⽽增加了change  buffer的维护代价。所以，对于这种业务模式来说，change\nbuffer反⽽起到了副作⽤。\n索引的选择和实践：\n尽可能使⽤普通索引。\nredo  log主要节省的是随机写磁盘的IO消耗(转成顺序写)，⽽change  buffer主要节省的则是随机读磁盘的IO消耗。\n2-5 ：char 和 varchar 的区别？\nchar 是固定⻓度类型，⽐如：定义 char(10)，当你输⼊”abc”三个字符的时候，它们占的空间还是 10 个字节，其他\n7 个是空字节。varchar ⻓度可变\n存储情况不同\n以 compact ⾏格式为例：\n⼀条完整的记录由两部分组成\n## 变⻓字段的真正数据内容\n## 该变⻓字段所占⽤的字节数\n该变⻓字段所占⽤的字节数被放在变⻓字段列表中，并且按照列的顺序逆序存放。\n⽽ char 类型的数据则只需要存储其真正的数据内容。\n对于 类型为 char(M) 的列\n如果采⽤的是变⻓编码的字符集：\n那么该列的值占⽤的字节数也会被存储到变⻓字段列表中，采⽤ 变⻓编码字符集的 CHAR(M)  类型的值要求⾄少占\n⽤ M 个字节，但是 varchar(M) 没有这个要求。\n2-6 ：MySQL抖⼀下是什么意思？\n因为运⾏的不正常了，或者不稳定了，要花费更多的资需源处理别的事情，会使SQL语句的执⾏效率明显变慢。\n针对innoDB导致MySQL抖的原因，主要是InnoDB 会在后台刷脏⻚，⽽刷脏⻚的过程是要将内存⻚写⼊磁盘。所\n以，⽆论是你的查询语句在需要内存的时候可能要求淘汰⼀个脏⻚，还是由于刷脏⻚的逻辑会占⽤ IO 资源并可能\n影响到了你的更新语句，都可能是造成你从业务端感知MySQL“抖”了⼀下的原因。\n2-7 ：MySQL抖⼀下有啥问题？\n很明显系统不稳定，性能突然下降对业务端是很不友好的\n2-8 ：怎么让MySQL不抖？\n设置合理参数配配置，尤其是设置  好innodb_io_capacity  的值，并且平时要多关注脏⻚⽐例，不要让它经常接近\n75%\n## 脏⻚\n3-1 ：啥是脏⻚？\n当内存数据⻚跟磁盘数据⻚内容不⼀致的时候，我们称这个内存⻚为“脏⻚”。\n3-2 ：啥是⼲净⻚？\n内存数据写⼊到磁盘后，内存和磁盘上的数据⻚的内容就⼀致了，称为“⼲净⻚”。\n3-3 ：脏⻚是咋产⽣的？\n因为使⽤了WAL技术，这个技术会把数据库的随机写转化为顺序写，但副作⽤就是会产⽣脏⻚。\n3-4 ：啥是随机写？为啥那么耗性能？\n随机写我的理解是，这次写磁盘的那个扇区和上⼀次没啥关系，需要重新定位位置，机械运动是很慢的即使不是机\n械运动重新定位写磁盘的位置也是很耗时的。\n3-6 ：啥是顺序写？\n顺序写我的理解是，这次写磁盘那个扇区就在上⼀次的下⼀个位置，不需要重新定位写磁盘的位置速度当然会快⼀\n3-7 ：WAL怎么把随机写转化为顺序写的？\n写redolog是顺序写的，先写redolog等合适的时候再写磁盘，间接的将随机写变成了顺序写，性能确实会提⾼不\n3-8 ：为啥删除了表的⼀半数8据，表⽂⽂件⼤⼩没变化？  、\n因为delete 命令其实只是把记录的位置，或者数据⻚标记为了“可复⽤”，但磁盘⽂件的⼤⼩是不会变的。也可以认\n为是⼀种逻辑删除，所以物理空间没有实际释放，只是标记为可复⽤，表⽂件的⼤⼩当然是不变的啦！\nalter table t engine=InnoDB\noptimize table t( 等于 recreate+analyze)。\ntruntace table t (等于drop+create)\n## 表结构\n4-1 ：表的数据信息存在哪⾥？\n表数据信息可能较⼩也可能巨⼤⽆⽐，可以存储在共享表空间⾥，也可以单独存储在⼀个以.ibd为后缀的⽂件⾥，\n由参数 innodb_file_per_table 来控制，建议总是作为⼀个单独的⽂件来存储，这样⾮常容易管理，并且在不需要\n的时候，使⽤ drop table 命令也能直接把对应的⽂件删除，如果存储在共享空间之中即使表删除了空间也不会释\n4-2 ：表的结构信息存在哪⾥？\n⾸先，表结构定义占有的存储空间⽐较⼩\nMySQL8.0  之前：表结构的定义信息存在以.frm为后缀的⽂件⾥\nMySQL8.0  之后：则允许把表结构的定义信息存在系统数据表之中\n系统数据表，主要⽤于存储MySQL的系统数据，⽐如：数据字典、undo  log(默认)等⽂件\n4-3 ：如何才能删除表数据后，表⽂件⼤⼩就变⼩？\n重建表，消除表因为进⾏⼤量的增删改操作⽽产⽣的空洞，使⽤如下命令：\n## Count\n5-1 ：空洞是啥？咋产⽣的？\n空洞就是那些被标记可复⽤但是还没被使⽤的存储空间。\n使⽤delete命令删除数据会产⽣空洞，标记为可复⽤\n插⼊新的数据可能引起⻚分裂，也可能产⽣空洞\n修改操作，有时是⼀种先删后插的动作也可能产⽣空洞\n按照效率排序的话：\ncount(字段) < count(主键 id) < count(1) ≈ count(*)\n5-2 ：count(*)这么慢，我该怎么办？\n要么忍，要么⾃⼰动⼿记录。。。 5-3：\ncount() 的语义是啥？\n⾸先，不同的存储引擎实现⽅式不同\nMyISAM 引擎把⼀个表的总⾏数存在了磁盘上，因此执⾏  count(*)  的时候会直接返回这个数，效率很⾼；\n⽽ InnoDB 引擎就麻烦了，它执⾏ count(*) 的时候，需要把数据⼀⾏⼀⾏地从引擎⾥⾯读出来，然后累积计数。\n以下针对innodb来说\nselect city,name,age from t where city='杭州' order by name limit 1000;\ncount() 是⼀个聚合函数，对于返回的结果集，⼀⾏⾏地判断，如果 count 函数的参数不是 NULL，累计值就加 1，\n否则不加，最后返回累计值。\n5-4 ：count(字段)怎么计数？\n## 如果这个“字段”是定义为 not null 的话\n⼀⾏⾏地从记录⾥⾯读出这个字段，判断不能为 null，按⾏累加；\n## 如果这个“字段”定义允许为 null\n执⾏的时候，判断到有可能是 null，还要把值取出来再判断⼀下，不是 null 才累加。从\n引擎返回的字段会涉及到解析数据⾏，以及拷⻉字段值的操作。\n5-5 ：count(主键 id)怎么计数？\n对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每⼀⾏的 id 值都取出来，返回给 server 层。\nserver 层拿到 id 后，判断是不可能为空的，就按⾏累加。从引擎返回的 主键id 会涉及到解析数据⾏，以及拷⻉字段\n值的操作。\n5-5 ：count(1)怎么计数？\n对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每⼀⾏，放⼀个数字“1”进去，判\n断是不可能为空的，按⾏累加。\n5-6 ：count(*)怎么计数？\n对于count(*)来说，并不会把全部字段取出来，⽽是专⻔做了优化，不取值。\ncount(*) 肯定不是 null，按⾏累加。\n这些count()的原则如下：\nserver 层要什么就给什么；\nInnoDB 只给必要的值；\n现在的优化器只优化了  count(*)  的语义为“取⾏数”，其他“显⽽易⻅”的优化并没有做。\n## 查询效率\n6-1 ：order by 是怎样⼯作的？\nexample：\n涉及到⽤户语句的排序，mysql 会给每个线程分配⼀块内存⽤于排序，也就是 sort_buffer。\n这条语句的执⾏逻辑是：\n## 先初始化 sort_bufer\n## 然后放⼊ city,name,age 字段，不断地由主键id索引到整⾏再到三个字段的值，匹配查找的值存⼊ sort_buff\n## 然后按 name 排序，返回前 1000 个值\n但是如果  sort_buffer_size  设置的太⼩，⽆法存放所有匹配的字段，排序就⽆法在内存中完成\n需要借鉴磁盘临时⽂件辅助排序，可以通过 number_of_tmp_files 这个标识来判断是否使⽤，其实这个原理和对\n超⼤数据的排序相同。\n如果要记录的字段太⻓，这样内存⾥能够同时放下的⾏数很少，要分成很多个临时⽂件，排序的性能会很差。\n这时会换⼀个算法，叫做rowid排序，顾名思义，就是对主键 id 以及排序字段进⾏存放，这样就节省了空间，但是\n最后需要通过主键 id 去找到之前未取出的字段。对⽐全字段排序，rowid 排序多访问了⼀次表 t 的主键索引。\n结论：\n如果 MySQL 实在是担⼼排序内存太⼩，会影响排序效率，才会采⽤ rowid 排序算法，这样排序过程中⼀次可以排序\n更多⾏，但是需要再回到原表去取数据。\n如果 MySQL 认为内存⾜够⼤，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直\n接从内存⾥⾯返回查询结果了，不⽤再回到原表去取数据。\n如果想要避免排序，可以建⽴对应字段的索引。\n如果想要进⼀步避免主键 id 的回表查询，可以使⽤覆盖索引，这种情况的索引建⽴成本会⽐较⼤，需要你去⾃⼰\n权衡是否使⽤\n6-2 ：如何正确地显示随机消息？\nexample：\n英语学习 App ⾸⻚有⼀个随机显示单词的功能，也就是根据每个⽤户的级别有⼀个单词表，然后这个⽤户每次访",
    "question": "redo log和bin log有什么区别",
    "answer": "适⽤对象不同：binlog 是 MySQL 的 Server 层实现的，所有存储引擎都可以使⽤；redo log 是 Innodb 存储\n引擎实现的⽇志。\n⽂件格式不同：redo log 是物理⽇志，记录的是在某个数据⻚做了什么修改，⽐如对 XXX 表空间中的 YYY 数\n据⻚ ZZZ 偏移量的地⽅做了AAA 更新。⽽binlog 主要包括三种格式： Statement 、 Row 和 Mixed 。\n写⼊⽅式不同：binlog  是追加写，写满⼀个⽂件，就创建⼀个新的⽂件继续写，不会覆盖以前的⽇志，保存\n的是全量的⽇志。redo   log是循环写，⽇志空间⼤⼩是固定，全部写满就从头开始，保存未被刷⼊磁盘的脏⻚\n⽇志。\n⽤途不同：binlog ⽤于备份恢复、主从复制；redo log ⽤于掉电等故障恢复。\n为什么需要两阶段提交\n事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独⽴的逻辑，可能出现半成功的状态，造成两\n份⽇志之间的逻辑不⼀致。\n如果在将 redo log 刷⼊到磁盘之后， MySQL 突然宕机了，⽽ binlog 还没有来得及写⼊。MySQL 重启后，\n通过 redo log 能将 Buffer Pool 恢复到新值，但是 binlog ⾥⾯没有记录这条更新语句，在主从架构中，\nbinlog 会被复制到从库，由于 binlog 丢失了这条更新语句，从库的这⼀⾏是旧值，主从不⼀致。\n如果在将 binlog 刷⼊到磁盘之后， MySQL 突然宕机了，⽽ redo log 还没有来得及写⼊。由于 redo log 还\n没写，崩溃恢复以后这个事务⽆效，数据是旧值，⽽ binlog ⾥⾯记录了这条更新语句，在主从架构中，\nbinlog 会被复制到从库，从库执⾏了这条更新语句，这⼀⾏字段是新值，与主库的值不⼀致性。\n所以会造成主从环境的数据不⼀致性。因为 redo log 影响主库的数据，binlog 影响从库的数据，redo log 和\nbinlog 必须保持⼀致。\n两阶段提交把单个事务的提交拆分成了 2 个阶段，分别是准备(Prepare)阶段和提交(Commit)阶段，每个阶段都\n由协调者(Coordinator)和参与者(Participant)共同完成。\n两阶段提交的过程\n在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog ⽇志与 InnoDB 的 redo\nlog，为了保证这两个⽇志的⼀致性，MySQL 使⽤了内部 XA 事务，内部 XA 事务由 binlog 作为协调者，存储引擎\n是参与者。\n当客户端执⾏ commit 语句或者在⾃动提交的情况下，MySQL 内部开启⼀个 XA 事务，分两阶段来完成 XA 事务的\n提交。\n事务的提交过程有两个阶段，将 redo log 的写⼊拆成了两个步骤：prepare 和 commit，中间再穿插写⼊\nbinlog：\nprepare 阶段：将 内部 XA 事务的 ID写⼊到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然\n后将 redo log 持久化到磁盘。\ncommit 阶段：把 内部 XA 事务的 ID写⼊到 binlog，然后将 binlog 持久化到磁盘，接着调⽤引擎的提交事务\n接⼝，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到⽂件系统的\npage cache 成功，只要 binlog 写磁盘成功，redo log 的状态还是 prepare 也没有关系，⼀样会被认为事务\n已经执⾏成功。\n执⾏引擎\n有哪些执⾏引擎\n在MySQL中，可以通过 SHOW ENGINES; 命令查看当前数据库⽀持的存储引擎。InnoDB是较为通⽤和常⽤的存储\n引擎。\nInnoDB : MySQL默认的事务性存储引擎，⽀持事务的提交（commit）和回滚（rollback），提供了⾏级锁\n定，⽀持外键约束和MVCC\nMyISAM : MyISAM 使⽤表级锁定, 不⽀持事务，⽀持全⽂索引，适⽤于以读操作为主的应⽤\nMemory : 将数据放在内存中，数据处理速度很快，但是当数据库重启或崩溃时，存储在内存中的数据将丢\n数据库引擎InnoDB与MyISAM的区别和适⽤场景？\n## 事务⽀持\n⽀持事务，具有ACID（原⼦性、⼀致性、隔离性、持久性）特性，适合需要数据⼀致性和完整性的\n应⽤，如银⾏系统或在线购物平台。\n不⽀持事务，不具备ACID特性，适⽤于读密集、写少的场景，如博客系统或新闻⽹站。\n## 锁\n## 外键约束:\n⾏级锁，多个事务可以同时访问同⼀表的不同⾏。\n表级锁，对整个表进⾏锁定，导致并发性能下降，特别是在有⼤量写操作时。\nInnoDB:   ⽀持外键约束，确保数据的⼀致性和完整性。\nMyISAM: 不⽀持外键约束\n## 崩溃恢复(Crash Recovery):\n⽀持崩溃恢复\n在崩溃后恢复可能会导致数据损失。\n## 全⽂索引(Full-text Indexing):\nInnoDB: ⽀持全⽂索引。\nMyISAM:  也⽀持全⽂索引，并且在这⽅⾯表现的更加好。\nInnoDB:   适⽤于需要事务⽀持、并发性能好、具有⾼写⼊需求的应⽤\nMyISAM: 适⽤于读操作频繁、写⼊操作较少的应⽤\nMySQL常⻅问题\n## 幻读连问\n1-1 ：什么是幻读？\n幻读是指在同⼀个事务中，存在前后两次查询同⼀个范围的数据，但是第⼆次查询却看到了第⼀次查询没看到的\n注意，幻读出现的场景：\n## 事务的隔离级别为可重复读，且是当前读\n## 幻读仅专指新插⼊的⾏\n1-2 ：幻读带来的问题？\n## 对⾏锁语义的破坏\n## 破坏了数据⼀致性\n1-3 ：怎么避免幻读？\n存储引擎采⽤加间隙锁的⽅式来避免出现幻读\n1-4 ：为啥会出现幻读？\n⾏锁只能锁定存在的⾏，针对新插⼊的操作没有限定\n1-5 ：间隙锁是啥？它怎么避免出现幻读的？它引⼊了什么新的问题？\n间隙锁：\n是专⻔⽤于解决幻读这种问题的锁，它锁的了⾏与⾏之间的间隙，能够阻塞新插⼊的操作\n间隙锁的引⼊也带来了⼀些新的问题，⽐如：降低并发度，可能导致死锁。\n注意，读读不互斥，读写/写读/写写是互斥的，但是间隙锁之间是不冲突的，间隙锁会阻塞插⼊操作\n另外，间隙锁在可重复读级别下才是有效的\n间隙锁和 next-key lock：\n⾏锁和间隙锁合称  next-key lock，这个锁是左开右闭的区间。\nMySQL 为了解决幻读问题，在线程更新数据并 next-key lock 的过程中，⾸先必须在可重复读的隔离级别下，执⾏以\n下的原则和优化：\n原则 1：加锁的基本单位是 next-key lock，next-key lock 是前开后闭区间。\n原则 2：查找过程中访问到的对象才会加锁。\n优化：\n优化 1：索引上的等值查询，给唯⼀索引加锁的时候，next-key lock 退化为⾏锁，如果不存在这个索引，退化为间\n隙锁。\n优化  2：索引上的等值查询，向右遍历时且最后⼀个值不满⾜等值条件的时候，next-key  lock  退化为间隙锁。\n注意：\nSELECT * FROM table LIMIT [offset,] rows | rows OFFSET offset;\n## 如果只给定⼀个参数，表示记录数。\nmysql> SELECT * FROM orange LIMIT 5;\n## 检索前5条记录(1-5)\nmysql> SELECT * from orange LIMIT 0,5;\nmysql> SELECT * FROM orange LIMIT 10,15; // 检索记录11-25\n## ⾮唯⼀索引的范围查询：范围查询都会访问到不满⾜条件的第⼀个值，并且不会执⾏上述的两个优化。唯⼀索\n引的范围查询仍旧会执⾏上述的优化。\n## delete  语句的和查询的加锁⽅式相同\n## limit 语句，遍历到满⾜条件的 n 条数据后，之后不再加 next-key lock\n死锁：不同线程可以给同⼀个间隙加锁。\n意思时只有我这个线程可以操控这个间隙，其他线程不能使⽤，加锁时不会检测是否冲突的，但是如果两个都给同\n⼀个间隙上锁，之后两个线程都没办法在这个间隙上更新数据了，都会陷⼊等待另⼀个线程的间隙锁释放，也就是\n死锁。\n如果使⽤读提交隔离级别，那么只加⾏锁，不加间隙锁，语句执⾏过程中加上的⾏锁，在语句执⾏完成后，就要把\n“不满⾜条件的⾏”上的⾏锁直接释放了，不需要等到事务提交才释放。\n## 事务\n2-1 ：for update的使⽤场景\n⼀般这些操作都是很⻓⼀串并且是开启事务的。\n如果库存刚开始读的时候是1，⽽⽴⻢另⼀个进程进⾏了update将库存更新为0了，⽽事务还没有结束，会将错的\n数据⼀直执⾏下去，就会有问题。\n需要 for upate 进⾏数据加锁防⽌⾼并发时候数据出错，即 使事务保持 当前读 状态。\n相当于\n两个参数，第⼀个参数表示offset,   第⼆个参数为记录数。\n如果你想要清除⼀些MySQL使⽤内部缓存，你应该使⽤FLUSH命令\n2-2 ：事务隔离\ninnodb ⽀持 RC 和 RR 隔离级别实现是⽤的⼀致性视图(consistent read view)\n事务在启动时会拍⼀个快照,这个快照是基于整个库的。\n基于整个库的意思就是说⼀个事务内,整个库的修改对于该事务都是不可⻅的(对于快照读的情况)\n如果在事务内 select t 表,另外的事务执⾏了DDL t表,根据发⽣时间,只有两种情况\n## 报错\n## 锁住\n事务是如何实现mvcc的？\n（1） 每个事务都有⼀个事务ID,叫做transaction  id(严格递增)\n（2） 事务在启动时,找到已提交的最⼤事务ID记为up_limit_id。\n（3） 事务在更新⼀条语句时\n⽐如 id=1 改为了 id=2.会把 id=1 和该⾏之前的 row trx_id 写到 undo log ⾥, 并且在数据⻚上把 id 的值改为 2,并\n且把修改这条语句的transaction id 记在该⾏⾏头\n（4） 再定⼀个规矩\n⼀个事务要查看⼀条数据时,必须先⽤该事务的 up_limit_id 与该⾏的transaction id 做⽐对\n如果 up_limit_id >= transaction id,那么可以看\n如果 up_limit_id < transaction id,则只能去 undo log ⾥去取。\n去 undo log 查找数据的时候,也需要做⽐对,必须 up_limit_id >  transaction id，才返回数据\n2-3 ：什么是当前读\n由于当前读都是先读后写,只能读当前的值,所以为当前读会更新事务内的 up_limit_id 为该事务的 transaction\n你提到了隐藏列有⼀个DB_ROW_ID，是⼲嘛的？那假设有10个update，到第九个回滚了，DB_ROLL_PTR如何做\n的，那提交了是否更新DB_ROLL_PTR？\n为什么 rr 能实现可重复读⽽ rc 不能,分两种情况\n（1） 快照读的情况下：\nrr不能更新事务内的 up_limit_id ,⽽ rc 每次会把 up_limit_id 更新为快照读之前最新已提交事务的 transaction id,\n则 rc 不能可重复读\n（2） 当前读的情况下：\nrr 是利⽤ record lock+gap lock来实现的,⽽ rc 没有 gap,所以 rc 不能可重复读\n2-4 ：选择普通索引还是唯⼀索引？\n## 对于查询过程来说：\n（1） 普通索引\n查到满⾜条件的第⼀个记录后，继续查找下⼀个记录，知道第⼀个不满⾜条件的记录\n（2） 唯⼀索引\n由于索引唯⼀性，查到第⼀个满⾜条件的记录后，停⽌检索\n但是，两者的性能差距微乎其微。因为InnoDB根据数据⻚来读写的。\n## 对于更新过程来说：\n概念：change buffer\n当需要更新⼀个数据⻚：\n如果数据⻚在内存中就直接更新\n如果不在内存中，在不影响数据⼀致性的前提下，InnoDB  会将这些更新操作缓存在change  buffer  中。\n下次查询需要访问这个数据⻚的时候，将数据⻚读⼊内存，然后执⾏  change  buffer  中的与这个⻚有关的操作。\nchange  buffer  是可以持久化的数据。在内存中有拷⻉，也会被写⼊到磁盘上\npurge：将 change buffer 中的操作应⽤到原数据⻚上，得到最新结果的过程，成为 purge\n访问这个数据⻚会触发 purge，系统有后台线程定期 purge，在数据库正常关闭的过程中，也会执⾏ purge\n唯⼀索引的更新不能使⽤ change buffer\nchange buffer ⽤的是 buffer pool ⾥的内存，change buffer 的⼤⼩，可以通过参数\ninnodb_change_buffer_max_size 来动态设置。这个参数设置为50的时候，表示 change buffer 的⼤⼩最多只能\n占⽤ buffer pool 的50%。\n将数据从磁盘读⼊内存涉及随机IO的访问，是数据库⾥⾯成本最⾼的操作之⼀。\nchange buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。\nchange buffer使⽤场景：\n在⼀个数据⻚做purge之前，change buffer记录的变更越多，收益就越⼤。\n对于写多读少的业务来说，⻚⾯在写完以后⻢上被访问到的概率⽐较⼩，此时change buffer的使⽤效果最好。这\n种业务模型常⻅的就是账单类、⽇志类的系统。\n反过来，假设⼀个业务的更新模式是写⼊之后⻢上会做查询，那么即使满⾜了条件，将更新先记录在change\nbuffer,但之后由于⻢上要访问这个数据⻚，会⽴即触发purge过程。\n这样随机访问IO的次数不会减少，反⽽增加了change  buffer的维护代价。所以，对于这种业务模式来说，change\nbuffer反⽽起到了副作⽤。\n索引的选择和实践：\n尽可能使⽤普通索引。\nredo  log主要节省的是随机写磁盘的IO消耗(转成顺序写)，⽽change  buffer主要节省的则是随机读磁盘的IO消耗。\n2-5 ：char 和 varchar 的区别？\nchar 是固定⻓度类型，⽐如：定义 char(10)，当你输⼊”abc”三个字符的时候，它们占的空间还是 10 个字节，其他\n7 个是空字节。varchar ⻓度可变\n存储情况不同\n以 compact ⾏格式为例：\n⼀条完整的记录由两部分组成\n## 变⻓字段的真正数据内容\n## 该变⻓字段所占⽤的字节数\n该变⻓字段所占⽤的字节数被放在变⻓字段列表中，并且按照列的顺序逆序存放。\n⽽ char 类型的数据则只需要存储其真正的数据内容。\n对于 类型为 char(M) 的列\n如果采⽤的是变⻓编码的字符集：\n那么该列的值占⽤的字节数也会被存储到变⻓字段列表中，采⽤ 变⻓编码字符集的 CHAR(M)  类型的值要求⾄少占\n⽤ M 个字节，但是 varchar(M) 没有这个要求。\n2-6 ：MySQL抖⼀下是什么意思？\n因为运⾏的不正常了，或者不稳定了，要花费更多的资需源处理别的事情，会使SQL语句的执⾏效率明显变慢。\n针对innoDB导致MySQL抖的原因，主要是InnoDB 会在后台刷脏⻚，⽽刷脏⻚的过程是要将内存⻚写⼊磁盘。所\n以，⽆论是你的查询语句在需要内存的时候可能要求淘汰⼀个脏⻚，还是由于刷脏⻚的逻辑会占⽤ IO 资源并可能\n影响到了你的更新语句，都可能是造成你从业务端感知MySQL“抖”了⼀下的原因。\n2-7 ：MySQL抖⼀下有啥问题？\n很明显系统不稳定，性能突然下降对业务端是很不友好的\n2-8 ：怎么让MySQL不抖？\n设置合理参数配配置，尤其是设置  好innodb_io_capacity  的值，并且平时要多关注脏⻚⽐例，不要让它经常接近\n75%\n## 脏⻚\n3-1 ：啥是脏⻚？\n当内存数据⻚跟磁盘数据⻚内容不⼀致的时候，我们称这个内存⻚为“脏⻚”。\n3-2 ：啥是⼲净⻚？\n内存数据写⼊到磁盘后，内存和磁盘上的数据⻚的内容就⼀致了，称为“⼲净⻚”。\n3-3 ：脏⻚是咋产⽣的？\n因为使⽤了WAL技术，这个技术会把数据库的随机写转化为顺序写，但副作⽤就是会产⽣脏⻚。\n3-4 ：啥是随机写？为啥那么耗性能？\n随机写我的理解是，这次写磁盘的那个扇区和上⼀次没啥关系，需要重新定位位置，机械运动是很慢的即使不是机\n械运动重新定位写磁盘的位置也是很耗时的。\n3-6 ：啥是顺序写？\n顺序写我的理解是，这次写磁盘那个扇区就在上⼀次的下⼀个位置，不需要重新定位写磁盘的位置速度当然会快⼀\n3-7 ：WAL怎么把随机写转化为顺序写的？\n写redolog是顺序写的，先写redolog等合适的时候再写磁盘，间接的将随机写变成了顺序写，性能确实会提⾼不\n3-8 ：为啥删除了表的⼀半数8据，表⽂⽂件⼤⼩没变化？  、\n因为delete 命令其实只是把记录的位置，或者数据⻚标记为了“可复⽤”，但磁盘⽂件的⼤⼩是不会变的。也可以认\n为是⼀种逻辑删除，所以物理空间没有实际释放，只是标记为可复⽤，表⽂件的⼤⼩当然是不变的啦！\nalter table t engine=InnoDB\noptimize table t( 等于 recreate+analyze)。\ntruntace table t (等于drop+create)\n## 表结构\n4-1 ：表的数据信息存在哪⾥？\n表数据信息可能较⼩也可能巨⼤⽆⽐，可以存储在共享表空间⾥，也可以单独存储在⼀个以.ibd为后缀的⽂件⾥，\n由参数 innodb_file_per_table 来控制，建议总是作为⼀个单独的⽂件来存储，这样⾮常容易管理，并且在不需要\n的时候，使⽤ drop table 命令也能直接把对应的⽂件删除，如果存储在共享空间之中即使表删除了空间也不会释\n4-2 ：表的结构信息存在哪⾥？\n⾸先，表结构定义占有的存储空间⽐较⼩\nMySQL8.0  之前：表结构的定义信息存在以.frm为后缀的⽂件⾥\nMySQL8.0  之后：则允许把表结构的定义信息存在系统数据表之中\n系统数据表，主要⽤于存储MySQL的系统数据，⽐如：数据字典、undo  log(默认)等⽂件\n4-3 ：如何才能删除表数据后，表⽂件⼤⼩就变⼩？\n重建表，消除表因为进⾏⼤量的增删改操作⽽产⽣的空洞，使⽤如下命令：\n## Count\n5-1 ：空洞是啥？咋产⽣的？\n空洞就是那些被标记可复⽤但是还没被使⽤的存储空间。\n使⽤delete命令删除数据会产⽣空洞，标记为可复⽤\n插⼊新的数据可能引起⻚分裂，也可能产⽣空洞\n修改操作，有时是⼀种先删后插的动作也可能产⽣空洞\n按照效率排序的话：\ncount(字段) < count(主键 id) < count(1) ≈ count(*)\n5-2 ：count(*)这么慢，我该怎么办？\n要么忍，要么⾃⼰动⼿记录。。。 5-3：\ncount() 的语义是啥？\n⾸先，不同的存储引擎实现⽅式不同\nMyISAM 引擎把⼀个表的总⾏数存在了磁盘上，因此执⾏  count(*)  的时候会直接返回这个数，效率很⾼；\n⽽ InnoDB 引擎就麻烦了，它执⾏ count(*) 的时候，需要把数据⼀⾏⼀⾏地从引擎⾥⾯读出来，然后累积计数。\n以下针对innodb来说\nselect city,name,age from t where city='杭州' order by name limit 1000;\ncount() 是⼀个聚合函数，对于返回的结果集，⼀⾏⾏地判断，如果 count 函数的参数不是 NULL，累计值就加 1，\n否则不加，最后返回累计值。\n5-4 ：count(字段)怎么计数？\n## 如果这个“字段”是定义为 not null 的话\n⼀⾏⾏地从记录⾥⾯读出这个字段，判断不能为 null，按⾏累加；\n## 如果这个“字段”定义允许为 null\n执⾏的时候，判断到有可能是 null，还要把值取出来再判断⼀下，不是 null 才累加。从\n引擎返回的字段会涉及到解析数据⾏，以及拷⻉字段值的操作。\n5-5 ：count(主键 id)怎么计数？\n对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每⼀⾏的 id 值都取出来，返回给 server 层。\nserver 层拿到 id 后，判断是不可能为空的，就按⾏累加。从引擎返回的 主键id 会涉及到解析数据⾏，以及拷⻉字段\n值的操作。\n5-5 ：count(1)怎么计数？\n对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每⼀⾏，放⼀个数字“1”进去，判\n断是不可能为空的，按⾏累加。\n5-6 ：count(*)怎么计数？\n对于count(*)来说，并不会把全部字段取出来，⽽是专⻔做了优化，不取值。\ncount(*) 肯定不是 null，按⾏累加。\n这些count()的原则如下：\nserver 层要什么就给什么；\nInnoDB 只给必要的值；\n现在的优化器只优化了  count(*)  的语义为“取⾏数”，其他“显⽽易⻅”的优化并没有做。\n## 查询效率\n6-1 ：order by 是怎样⼯作的？\nexample：\n涉及到⽤户语句的排序，mysql 会给每个线程分配⼀块内存⽤于排序，也就是 sort_buffer。\n这条语句的执⾏逻辑是：\n## 先初始化 sort_bufer\n## 然后放⼊ city,name,age 字段，不断地由主键id索引到整⾏再到三个字段的值，匹配查找的值存⼊ sort_buff\n## 然后按 name 排序，返回前 1000 个值\n但是如果  sort_buffer_size  设置的太⼩，⽆法存放所有匹配的字段，排序就⽆法在内存中完成\n需要借鉴磁盘临时⽂件辅助排序，可以通过 number_of_tmp_files 这个标识来判断是否使⽤，其实这个原理和对\n超⼤数据的排序相同。\n如果要记录的字段太⻓，这样内存⾥能够同时放下的⾏数很少，要分成很多个临时⽂件，排序的性能会很差。\n这时会换⼀个算法，叫做rowid排序，顾名思义，就是对主键 id 以及排序字段进⾏存放，这样就节省了空间，但是\n最后需要通过主键 id 去找到之前未取出的字段。对⽐全字段排序，rowid 排序多访问了⼀次表 t 的主键索引。\n结论：\n如果 MySQL 实在是担⼼排序内存太⼩，会影响排序效率，才会采⽤ rowid 排序算法，这样排序过程中⼀次可以排序\n更多⾏，但是需要再回到原表去取数据。\n如果 MySQL 认为内存⾜够⼤，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直\n接从内存⾥⾯返回查询结果了，不⽤再回到原表去取数据。\n如果想要避免排序，可以建⽴对应字段的索引。\n如果想要进⼀步避免主键 id 的回表查询，可以使⽤覆盖索引，这种情况的索引建⽴成本会⽐较⼤，需要你去⾃⼰\n权衡是否使⽤\n6-2 ：如何正确地显示随机消息？\nexample：\n英语学习 App ⾸⻚有⼀个随机显示单词的功能，也就是根据每个⽤户的级别有⼀个单词表，然后这个⽤户每次访",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 9719,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000118",
    "content": "## 然后按 name 排序，返回前 1000 个值\n\n但是如果  sort_buffer_size  设置的太⼩，⽆法存放所有匹配的字段，排序就⽆法在内存中完成\n需要借鉴磁盘临时⽂件辅助排序，可以通过 number_of_tmp_files 这个标识来判断是否使⽤，其实这个原理和对\n超⼤数据的排序相同。\n如果要记录的字段太⻓，这样内存⾥能够同时放下的⾏数很少，要分成很多个临时⽂件，排序的性能会很差。\n这时会换⼀个算法，叫做rowid排序，顾名思义，就是对主键 id 以及排序字段进⾏存放，这样就节省了空间，但是\n最后需要通过主键 id 去找到之前未取出的字段。对⽐全字段排序，rowid 排序多访问了⼀次表 t 的主键索引。\n结论：\n如果 MySQL 实在是担⼼排序内存太⼩，会影响排序效率，才会采⽤ rowid 排序算法，这样排序过程中⼀次可以排序\n更多⾏，但是需要再回到原表去取数据。\n如果 MySQL 认为内存⾜够⼤，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直\n接从内存⾥⾯返回查询结果了，不⽤再回到原表去取数据。\n如果想要避免排序，可以建⽴对应字段的索引。\n如果想要进⼀步避免主键 id 的回表查询，可以使⽤覆盖索引，这种情况的索引建⽴成本会⽐较⼤，需要你去⾃⼰\n权衡是否使⽤\n6-2 ：如何正确地显示随机消息？\nexample：\n英语学习 App ⾸⻚有⼀个随机显示单词的功能，也就是根据每个⽤户的级别有⼀个单词表，然后这个⽤户每次访\n问⾸⻚的时候，都会随机滚动显示三个单词。他们发现随着单词表变⼤，选单词这个逻辑变得越来越慢，甚⾄影响\n到了⾸⻚的打开速度",
    "question": "## 然后按 name 排序，返回前 1000 个值",
    "answer": "但是如果  sort_buffer_size  设置的太⼩，⽆法存放所有匹配的字段，排序就⽆法在内存中完成\n需要借鉴磁盘临时⽂件辅助排序，可以通过 number_of_tmp_files 这个标识来判断是否使⽤，其实这个原理和对\n超⼤数据的排序相同。\n如果要记录的字段太⻓，这样内存⾥能够同时放下的⾏数很少，要分成很多个临时⽂件，排序的性能会很差。\n这时会换⼀个算法，叫做rowid排序，顾名思义，就是对主键 id 以及排序字段进⾏存放，这样就节省了空间，但是\n最后需要通过主键 id 去找到之前未取出的字段。对⽐全字段排序，rowid 排序多访问了⼀次表 t 的主键索引。\n结论：\n如果 MySQL 实在是担⼼排序内存太⼩，会影响排序效率，才会采⽤ rowid 排序算法，这样排序过程中⼀次可以排序\n更多⾏，但是需要再回到原表去取数据。\n如果 MySQL 认为内存⾜够⼤，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直\n接从内存⾥⾯返回查询结果了，不⽤再回到原表去取数据。\n如果想要避免排序，可以建⽴对应字段的索引。\n如果想要进⼀步避免主键 id 的回表查询，可以使⽤覆盖索引，这种情况的索引建⽴成本会⽐较⼤，需要你去⾃⼰\n权衡是否使⽤\n6-2 ：如何正确地显示随机消息？\nexample：\n英语学习 App ⾸⻚有⼀个随机显示单词的功能，也就是根据每个⽤户的级别有⼀个单词表，然后这个⽤户每次访\n问⾸⻚的时候，都会随机滚动显示三个单词。他们发现随着单词表变⼤，选单词这个逻辑变得越来越慢，甚⾄影响\n到了⾸⻚的打开速度",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 708,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000119",
    "content": "问⾸⻚的时候，都会随机滚动显示三个单词。他们发现随着单词表变⼤，选单词这个逻辑变得越来越慢，甚⾄影响\n\n到了⾸⻚的打开速度\n## order by rand() 实现\n创建临时表→按主键顺序取出所有的单词，并给他们⼀个随机⼩数→初始化 sort_buffer，从内存临时表取出数据\n放⼊ sort_buffer，按随机数排序，取出前三个，总扫描⾏数是2×n+3\n## 磁盘临时表\n如果 sort_buffer_size 设置的⼩，就会使⽤到磁盘临时表⽤于辅助排序，当然 mysql ⾼版本使⽤了优先队列排序的\n⽅法，就是只取三个值，构成⼀个堆，然后不断把剩下的值输⼊，⽤于更新队列。\n这个过程不需要临时⽂件，因此对应的 number_of_tmp_files 是 0。当然，如果堆的⼤⼩设置的很⼤，\nsort_buffer 放不下，就会舍弃优先队列，重新使⽤临时表+归并排序来实现，number_of_tmp_files 就不再为 0。\n## 随机id⽅法\n我们实际上并不需要真正的为每⾏赋予⼀个随机值，然后进⾏排序，这样的成本就太⾼了。\n可以借鉴主键id的唯⼀性，⽣成⼀个介于主键id最⼩值和最⼤值之间的随机数，然后取不⼩于这个随机数的主键id\n的那⼀⾏即可。总扫描⾏数是3，的那hi是如果主键id有空洞，就会导致选择不同⾏的概率不同，不是真正的随机\n## 严格随机id⽅法\n取出表的总⾏数，⽣成⼀个总⾏数对应的随机值，取不⼩于这个随机数的主键id的那⼀⾏，总扫描⾏数是C+Y+1\n6-3 ：为什么SQL语句逻辑相同，性能却差异巨⼤？\n案例⼀：条件字段函数操作\n并且在 t_modified 上建⽴了索引\n你以为对字段⽣成了索引，应该会返回的很快，但是mysql有⼀个规则：就是如果对字段做了函数计算，就⽤不上\n索引了。\n实际上，mysql使⽤的B+ 树提供的对于索引的快速定位能⼒，来源于同⼀层兄弟节点的有序性。对索引字段做函数\n操作，可能会破坏索引值的有序性，因此优化器就决定放弃⾛树搜索功能，转⽽进⾏全表扫描，所以运⾏就变慢了\n案例⼆：隐式类型转换：\n如果在限制语句中错误的将字符串与数字进⾏⽐较，mysql 会将可以转化成数字的字符串转化成数字，没法转换的\n话，就会变成数字 0，因此如果出现这种输⼊的失误，相当于调⽤了字符串转数字的函数，还是会使得优化器会放\n弃⾛树搜索功能，进⾏全表扫描\n案例三：隐式字符编码转换\n如果执⾏两个表的联合查询，两个表通过外键进⾏联结，如果两个表使⽤的字符集不同，会对低⽔平的字符集执⾏\n升级转换函数，（相当于将int赋给double的这个思路）。\n如果限制语句是 where d.tradeid=l.tradeid，如果d的字符集低⽔平，就会执⾏函数操作，使得优化器会放弃⾛树\n搜索功能，进⾏全表扫描\n总结：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃⾛树搜索功能\n6-4 ：为什么我只查⼀⾏的语句，也执⾏这么慢？\n原因从⼤到⼩可分为三种情况\n第⼀ MySQL 数据库本身被堵住了，⽐如：系统或⽹络资源不够\n第⼆ SQL 语句被堵住了，⽐如：表锁，⾏锁等，导致存储引擎不执⾏对应的 SQL 语句\n第三确实是索引使⽤不当，没有⾛索引，类⽐上⼀节\n第四是表中数据的特点导致的，⾛了索引，但由于⼀致性读，需要回滚多次才能读取出当前事务对应的值。\n6-5 ：为什么临时表可以重名？\n在实际应⽤中，临时表⼀般⽤于处理⽐较复杂的计算逻辑。\n由于临时表是每个线程⾃⼰可⻅的，所以不需要考虑多个线程执⾏同⼀个处理逻辑时，临时表的重名问题。在线程\n退出的时候，临时表也能⾃动删除，省去了收尾和异常处理的⼯作。\n在 binlog_format='row’的时候，临时表的操作不记录到 binlog 中，也省去了不少麻烦，防⽌出现主备不⼀致的情\n这⾥说到的临时表是⽤户临时表，⽽不是内存临时表\n6-5 ：group-by使⽤原则\n如果对 group by 语句的结果没有排序要求，要在语句后⾯加 order by null；\n尽量让 group by 过程⽤上表的索引，确认⽅法是 explain 结果⾥没有 Using temporary 和 Using filesort；\nselect count(*) from tradelog where month(t_modified)=7;\n如果 group by 需要统计的数据量不⼤，尽量只使⽤内存临时表；也可以通过适当调⼤ tmp_table_size 参数，来避\n免⽤到磁盘临时表；\n如果数据量实在太⼤，使⽤ SQL_BIG_RESULT 这个提示，来告诉优化器直接使⽤排序算法得到 group by 的结果，\n不要使⽤内存临时表。\n6-6 ：⼀张表可以存储多少条信息\n假设采⽤的是InnoDB引擎\n那么数据结构的⻆度来看，本着索引即数据的思路，就是求⼀个 B+树 能够存储多少数据，根据 B+树 定义也就转变\n成了 2 个⼦问题：\n## 每个叶⼦结点存储能存储多少条记录\n## ⼀共有多少个叶⼦结点\n## 每个叶⼦结点能存储多少条记录\n假设⼀条记录的⼤⼩为1kb，InnoDB中默认每⻚为16kb，则⼀个叶⼦节点可存储16条数据\n## ⼀共有多少个叶⼦结点\n根据B+树的形式，确定了该B+树为⼏阶的B+树，以及树的⾼度，就能确定叶⼦节点有最多有多少个。\n⾮叶⼦节点存储的数据为关键⼦+指针。关键字也就是我们常说的主键，如果为int类型则4字节，指针⼤⼩也假设\n为4字节。\n以关键字+指针为基本单位，那么⼀个⾮叶⼦节点最多能够存储 16384 /  8 =  2048 个，2048个指针能够引出2048\n个⼦节点，如果该B+树的⾼度为2，则存储的记录数量为2048 16 = 32768条记录，如果⾼度为3则有2048 2048 *\n16 = 67108864条记录。（也能反向得出，⼀般索引⾼度都在3左右吧）\n6-5：有⼀个联合索引(A,B,C),select * from test where a,c会不会使⽤索引？\n不会，根据索引的创建过程，这棵 b+ 树的叶⼦节点的记录以及 ⼆级索引记录 是按照 abc 的规则来排序的，也就是\n说，先按照 a的⼤⼩来排序，a 相等的情况下，再按照 b 的⼤⼩来排序，b 相等的话，最后再是 c 。这样的话，符\n合 where 条件的 记录不⼀定相邻，\n也就是说，并不能在某⼀个区间中找，还是得⼀条条找，查询效率并没有变⾼。\nMySQL分库分表\n## 单库太⼤\n单个数据库处理能⼒有限，所在的服务器上的磁盘空间也有限，单库存在I/O操作瓶颈。\n主要⽅案：切分成更多更⼩的库\n## 单表太⼤\nCRUD都成问题，索引膨胀，查询超时。\n主要⽅案：切分成多个数据集更⼩的表\n垂直分表\n商品表字段太多，每个字段访问频次不⼀样，浪费了IO资源，需要进⾏优化\n垂直分表介绍：\n也就是“⼤表拆⼩表”，基于列字段进⾏的，拆分原则⼀般是表中的字段较多，将不常⽤的或者数据较⼤，⻓度较⻓\n的拆分到“扩展表 如text类型字段，访问频次低、字段⼤的商品描述信息单独存放在⼀张表中，访问频次较⾼的商\n品基本信息单独放在⼀张表中。\n垂直拆分原则：\n## 把不常⽤的字段单独放在⼀张表;\n## 把text，blob等⼤字段拆分出来放在附表中;\n## 业务经常组合查询的列放在⼀张表中\n垂直分库\nC端项⽬⾥⾯，单个数据库的CPU、内存⻓期处于90%+的利⽤率，数据库连接经常不够，需要进⾏优化\n垂直分库讲解：\n垂直分库针对的是⼀个系统中的不同业务进⾏拆分，  数据库的连接资源⽐较宝贵且单机处理能⼒也有限，没拆分之前\n全部都是落到单⼀的库上的，单库处理能⼒成为瓶颈，还有磁盘空间，内存，tps等限制\n拆分之后，避免不同库竞争同⼀个物理机的CPU、内存、⽹络IO、磁盘，所以在⾼并发场景下，垂直分库⼀定程度\n上能够突破IO、连接数及单机硬件资源的瓶颈\n垂直分库可以更好解决业务层⾯的耦合，业务清晰，且⽅便管理和维护\n⼀般从单体项⽬升级改造为微服务项⽬，就是垂直分库\n仍然存在的问题：\n垂直分库分表可以提⾼并发，但是依然没有解决单表数据量过⼤的问题\n⽔平分表\n当⼀张表的数据达到⼏千万时，查询⼀次所花的时间⻓，需要进⾏优化，缩短查询时间\n都是⼤表拆⼩表\n垂直分表：表结构拆分\n⽔平分表：数据拆分\n⽔平分表：\n把⼀个表的数据分到⼀个数据库的多张表中，每个表只有这个表的部分数据，核⼼是把⼀个⼤表，分割N个⼩表，\n每个表的结构是⼀样的，数据不⼀样，全部表的数据合起来就是全部数据\n针对数据量巨⼤的单张表（⽐如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表⾥⾯去，但是这\n些表还是在同⼀个库中，所以单数据库操作还是有IO瓶颈，主要是解决单表数据量过⼤的问题\n减少锁表时间，没分表前，如果是DDL(create/alter/add等)语句，当需要添加⼀列的时候mysql会锁表，期间所\n有的读写操作只能等待\n⽔平分库\n⾼并发的项⽬中，⽔平分表后依旧在单个库上⾯，1个数据库资源瓶颈   CPU/内存/带宽等限制导致响应慢，需要进\n⾏优化\n⽔平分库：\n把同个表的数据按照⼀定规则分到不同的数据库中，数据库在不同的服务器上。\n⽔平分库是把不同表拆到不同数据库中，它是对数据⾏的拆分，不影响表结构，每个库的结构都⼀样,但每个库的数\n据都不⼀样，没有交集，所有库的并集就是全量数据\n⽔平分库的粒度，⽐⽔平分表更⼤\n⽔平分库分表切分规则：\nrange：  根据范围，⽐如0-1000⼀个表，1001到2000⼀个表\nhash取模：  ⽐如取ID，进⾏hash取模，根据模数分配到不同的数据库中\n地理区域： 按照地理范围进⾏划分\n时间范围： 按照时间进⾏切分\n分库分表总结\n## 技术负责⼈前瞻性思维\n## 需要提前考虑系统⼀年到两年左右的业务增⻓情况\n## 对数据库服务器的QPS、连接数、容量等做合理评估和规划\n## 很多⼈觉得“分库分表”是宜早不宜迟 ---- 其实不然\n常规开发⾥⾯单表建议1千万内，推荐是百万级别单表存储，常规sql和索引优化先⾏，然后结合缓存+异步\n+nosql+mq\n## 垂直⻆度（表结构不⼀样）\n垂直分表：\n将⼀个表字段拆分多个表，每个表存储部分字段\n避免IO时锁表的次数，分离热点字段和⾮热点字段，避免⼤字段IO导致性能下降\n业务经常组合查询的字段⼀个表；不常⽤字段⼀个表；text、blob类型字段作为附属表\n垂直分库：\n根据业务将表分类，放到不同的数据库服务器上\n避免表之间竞争同个物理机的资源，⽐如CPU/内存/硬盘/⽹络IO\n根据业务相关性进⾏划分，领域模型，微服务划分⼀般就是垂直分库\n## ⽔平⻆度（表结构⼀样）\n⽔平分库：\n把同个表的数据按照⼀定规则分到不同的数据库中，数据库在不同的服务器上\n多个数据库，降低了系统的IO和CPU压⼒\n选择合适的分⽚键和分⽚策略，和业务场景配合\n避免数据热点和访问不均衡、避免⼆次扩容难度⼤\n⽔平分表：\n同个数据库内，把⼀个表的数据按照⼀定规则拆分到多个表中，对数据进⾏拆分，不影响表结构\n单个表的数据量少了，业务SQL执⾏效率⾼，降低了系统的IO和CPU压⼒\n选择合适的分⽚键和分⽚策略，和业务场景配合\n避免数据热点和访问不均衡、避免⼆次扩容难度⼤\n## 互联⽹公司实际使⽤和跳槽⾯试\n公司业务稳定发展，多数情况是为了解决【单库单表】数据量过多问题\n重点是⽔平⻆度的【分库分表】\n分库分表的问题\n分库分表解决了问题，同时也带来了问题。\n如跨库查询、分布式事务、分库之后的排序（翻⻚，函数的计算问题）、全局主键问题、容量规划（⼆次扩容问\n题）、技术选型问题\n以下是⼀些常⻅的问题\n## 跨节点数据库Join关联查询\n数据库切分前：\n多表关联查询，可以通过sql join进⾏实现\n分库分表后：\n数据可能分布在不同的节点上，sql  join带来的问题就⽐较麻烦\n## 分库操作带来的分布式事务问题\n操作内容同时分布在不同库中，不可避免会带来跨库事务问题，即分布式事务\n## 执⾏的SQL排序、翻⻚、函数计算问题\n分库后：\n数据分布再不同的节点上，  跨节点多库进⾏查询时，会出现limit分⻚、order  by排序等问题\n⽽且当排序字段⾮分⽚字段时，更加复杂了，要在不同的分⽚节点中将数据进⾏排序并返回，然后将不同分⽚返回\n的结果集进⾏汇总和再次排序（也会带来更多的CPU/IO资源损耗）\n## 数据库全局主键重复问题\n常规表的id是使⽤⾃增id进⾏实现，分库分表后，由于表中数据同时存在不同数据库中，如果⽤⾃增id，则会出现\n冲突问题\n## 容量规划,分库分表后⼆次扩容问题\n业务发展快，初次分库分表后，满⾜不了数据存储，导致需要多次扩容\n## 分库分表技术选型问题\n市场分库分表中间件相对较多，框架各有各的优势与短板，应该如何选择\n数据库排序思路\n## 思路\n整体的思路和海量数据排序类似，不过考虑更加好⼀些\n正常思路：\n在分割段的阶段，使⽤内部排序，⽣成n个⼤⼩等于可⽤内存的顺串，最后再进⾏归并，使得数据整体有序。\n但是，为了避免I/O操作带来的影响，所以使⽤替换-选择排序的⽅式，可以使得在分割段阶段⽣成的顺串⼤⼩⼤于\n可⽤内存⼤⼩。\n同时为了能够再次减⼩I/O开销，合并阶段，可适量的增加归并的路数\n不过增⼤路数也就意味着内部每个缓冲区数量增加（⼀个缓冲区放⼀个顺串），每次要在更多的缓冲区中选取最⼩\n值，所以引⼊败者树（和堆排很像），减少增加归并路数，⽽影响内部归并。\n## 练习题与⼩总结\n## 练习内部排序的各种算法\nLC_排序数组\n## 练习⼆路归并\nLC_归并排序\n为了提升效率，避免速度不匹配的问题，真的是精益求情，OS⾥⾯有各种⾼速缓存、缓冲区等，数据库会利⽤磁\n盘的预读，顺序性读，以及设计特殊的数据结构。\nMySQL主从复制",
    "question": "问⾸⻚的时候，都会随机滚动显示三个单词。他们发现随着单词表变⼤，选单词这个逻辑变得越来越慢，甚⾄影响",
    "answer": "到了⾸⻚的打开速度\n## order by rand() 实现\n创建临时表→按主键顺序取出所有的单词，并给他们⼀个随机⼩数→初始化 sort_buffer，从内存临时表取出数据\n放⼊ sort_buffer，按随机数排序，取出前三个，总扫描⾏数是2×n+3\n## 磁盘临时表\n如果 sort_buffer_size 设置的⼩，就会使⽤到磁盘临时表⽤于辅助排序，当然 mysql ⾼版本使⽤了优先队列排序的\n⽅法，就是只取三个值，构成⼀个堆，然后不断把剩下的值输⼊，⽤于更新队列。\n这个过程不需要临时⽂件，因此对应的 number_of_tmp_files 是 0。当然，如果堆的⼤⼩设置的很⼤，\nsort_buffer 放不下，就会舍弃优先队列，重新使⽤临时表+归并排序来实现，number_of_tmp_files 就不再为 0。\n## 随机id⽅法\n我们实际上并不需要真正的为每⾏赋予⼀个随机值，然后进⾏排序，这样的成本就太⾼了。\n可以借鉴主键id的唯⼀性，⽣成⼀个介于主键id最⼩值和最⼤值之间的随机数，然后取不⼩于这个随机数的主键id\n的那⼀⾏即可。总扫描⾏数是3，的那hi是如果主键id有空洞，就会导致选择不同⾏的概率不同，不是真正的随机\n## 严格随机id⽅法\n取出表的总⾏数，⽣成⼀个总⾏数对应的随机值，取不⼩于这个随机数的主键id的那⼀⾏，总扫描⾏数是C+Y+1\n6-3 ：为什么SQL语句逻辑相同，性能却差异巨⼤？\n案例⼀：条件字段函数操作\n并且在 t_modified 上建⽴了索引\n你以为对字段⽣成了索引，应该会返回的很快，但是mysql有⼀个规则：就是如果对字段做了函数计算，就⽤不上\n索引了。\n实际上，mysql使⽤的B+ 树提供的对于索引的快速定位能⼒，来源于同⼀层兄弟节点的有序性。对索引字段做函数\n操作，可能会破坏索引值的有序性，因此优化器就决定放弃⾛树搜索功能，转⽽进⾏全表扫描，所以运⾏就变慢了\n案例⼆：隐式类型转换：\n如果在限制语句中错误的将字符串与数字进⾏⽐较，mysql 会将可以转化成数字的字符串转化成数字，没法转换的\n话，就会变成数字 0，因此如果出现这种输⼊的失误，相当于调⽤了字符串转数字的函数，还是会使得优化器会放\n弃⾛树搜索功能，进⾏全表扫描\n案例三：隐式字符编码转换\n如果执⾏两个表的联合查询，两个表通过外键进⾏联结，如果两个表使⽤的字符集不同，会对低⽔平的字符集执⾏\n升级转换函数，（相当于将int赋给double的这个思路）。\n如果限制语句是 where d.tradeid=l.tradeid，如果d的字符集低⽔平，就会执⾏函数操作，使得优化器会放弃⾛树\n搜索功能，进⾏全表扫描\n总结：对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃⾛树搜索功能\n6-4 ：为什么我只查⼀⾏的语句，也执⾏这么慢？\n原因从⼤到⼩可分为三种情况\n第⼀ MySQL 数据库本身被堵住了，⽐如：系统或⽹络资源不够\n第⼆ SQL 语句被堵住了，⽐如：表锁，⾏锁等，导致存储引擎不执⾏对应的 SQL 语句\n第三确实是索引使⽤不当，没有⾛索引，类⽐上⼀节\n第四是表中数据的特点导致的，⾛了索引，但由于⼀致性读，需要回滚多次才能读取出当前事务对应的值。\n6-5 ：为什么临时表可以重名？\n在实际应⽤中，临时表⼀般⽤于处理⽐较复杂的计算逻辑。\n由于临时表是每个线程⾃⼰可⻅的，所以不需要考虑多个线程执⾏同⼀个处理逻辑时，临时表的重名问题。在线程\n退出的时候，临时表也能⾃动删除，省去了收尾和异常处理的⼯作。\n在 binlog_format='row’的时候，临时表的操作不记录到 binlog 中，也省去了不少麻烦，防⽌出现主备不⼀致的情\n这⾥说到的临时表是⽤户临时表，⽽不是内存临时表\n6-5 ：group-by使⽤原则\n如果对 group by 语句的结果没有排序要求，要在语句后⾯加 order by null；\n尽量让 group by 过程⽤上表的索引，确认⽅法是 explain 结果⾥没有 Using temporary 和 Using filesort；\nselect count(*) from tradelog where month(t_modified)=7;\n如果 group by 需要统计的数据量不⼤，尽量只使⽤内存临时表；也可以通过适当调⼤ tmp_table_size 参数，来避\n免⽤到磁盘临时表；\n如果数据量实在太⼤，使⽤ SQL_BIG_RESULT 这个提示，来告诉优化器直接使⽤排序算法得到 group by 的结果，\n不要使⽤内存临时表。\n6-6 ：⼀张表可以存储多少条信息\n假设采⽤的是InnoDB引擎\n那么数据结构的⻆度来看，本着索引即数据的思路，就是求⼀个 B+树 能够存储多少数据，根据 B+树 定义也就转变\n成了 2 个⼦问题：\n## 每个叶⼦结点存储能存储多少条记录\n## ⼀共有多少个叶⼦结点\n## 每个叶⼦结点能存储多少条记录\n假设⼀条记录的⼤⼩为1kb，InnoDB中默认每⻚为16kb，则⼀个叶⼦节点可存储16条数据\n## ⼀共有多少个叶⼦结点\n根据B+树的形式，确定了该B+树为⼏阶的B+树，以及树的⾼度，就能确定叶⼦节点有最多有多少个。\n⾮叶⼦节点存储的数据为关键⼦+指针。关键字也就是我们常说的主键，如果为int类型则4字节，指针⼤⼩也假设\n为4字节。\n以关键字+指针为基本单位，那么⼀个⾮叶⼦节点最多能够存储 16384 /  8 =  2048 个，2048个指针能够引出2048\n个⼦节点，如果该B+树的⾼度为2，则存储的记录数量为2048 16 = 32768条记录，如果⾼度为3则有2048 2048 *\n16 = 67108864条记录。（也能反向得出，⼀般索引⾼度都在3左右吧）\n6-5：有⼀个联合索引(A,B,C),select * from test where a,c会不会使⽤索引？\n不会，根据索引的创建过程，这棵 b+ 树的叶⼦节点的记录以及 ⼆级索引记录 是按照 abc 的规则来排序的，也就是\n说，先按照 a的⼤⼩来排序，a 相等的情况下，再按照 b 的⼤⼩来排序，b 相等的话，最后再是 c 。这样的话，符\n合 where 条件的 记录不⼀定相邻，\n也就是说，并不能在某⼀个区间中找，还是得⼀条条找，查询效率并没有变⾼。\nMySQL分库分表\n## 单库太⼤\n单个数据库处理能⼒有限，所在的服务器上的磁盘空间也有限，单库存在I/O操作瓶颈。\n主要⽅案：切分成更多更⼩的库\n## 单表太⼤\nCRUD都成问题，索引膨胀，查询超时。\n主要⽅案：切分成多个数据集更⼩的表\n垂直分表\n商品表字段太多，每个字段访问频次不⼀样，浪费了IO资源，需要进⾏优化\n垂直分表介绍：\n也就是“⼤表拆⼩表”，基于列字段进⾏的，拆分原则⼀般是表中的字段较多，将不常⽤的或者数据较⼤，⻓度较⻓\n的拆分到“扩展表 如text类型字段，访问频次低、字段⼤的商品描述信息单独存放在⼀张表中，访问频次较⾼的商\n品基本信息单独放在⼀张表中。\n垂直拆分原则：\n## 把不常⽤的字段单独放在⼀张表;\n## 把text，blob等⼤字段拆分出来放在附表中;\n## 业务经常组合查询的列放在⼀张表中\n垂直分库\nC端项⽬⾥⾯，单个数据库的CPU、内存⻓期处于90%+的利⽤率，数据库连接经常不够，需要进⾏优化\n垂直分库讲解：\n垂直分库针对的是⼀个系统中的不同业务进⾏拆分，  数据库的连接资源⽐较宝贵且单机处理能⼒也有限，没拆分之前\n全部都是落到单⼀的库上的，单库处理能⼒成为瓶颈，还有磁盘空间，内存，tps等限制\n拆分之后，避免不同库竞争同⼀个物理机的CPU、内存、⽹络IO、磁盘，所以在⾼并发场景下，垂直分库⼀定程度\n上能够突破IO、连接数及单机硬件资源的瓶颈\n垂直分库可以更好解决业务层⾯的耦合，业务清晰，且⽅便管理和维护\n⼀般从单体项⽬升级改造为微服务项⽬，就是垂直分库\n仍然存在的问题：\n垂直分库分表可以提⾼并发，但是依然没有解决单表数据量过⼤的问题\n⽔平分表\n当⼀张表的数据达到⼏千万时，查询⼀次所花的时间⻓，需要进⾏优化，缩短查询时间\n都是⼤表拆⼩表\n垂直分表：表结构拆分\n⽔平分表：数据拆分\n⽔平分表：\n把⼀个表的数据分到⼀个数据库的多张表中，每个表只有这个表的部分数据，核⼼是把⼀个⼤表，分割N个⼩表，\n每个表的结构是⼀样的，数据不⼀样，全部表的数据合起来就是全部数据\n针对数据量巨⼤的单张表（⽐如订单表），按照某种规则（RANGE,HASH取模等），切分到多张表⾥⾯去，但是这\n些表还是在同⼀个库中，所以单数据库操作还是有IO瓶颈，主要是解决单表数据量过⼤的问题\n减少锁表时间，没分表前，如果是DDL(create/alter/add等)语句，当需要添加⼀列的时候mysql会锁表，期间所\n有的读写操作只能等待\n⽔平分库\n⾼并发的项⽬中，⽔平分表后依旧在单个库上⾯，1个数据库资源瓶颈   CPU/内存/带宽等限制导致响应慢，需要进\n⾏优化\n⽔平分库：\n把同个表的数据按照⼀定规则分到不同的数据库中，数据库在不同的服务器上。\n⽔平分库是把不同表拆到不同数据库中，它是对数据⾏的拆分，不影响表结构，每个库的结构都⼀样,但每个库的数\n据都不⼀样，没有交集，所有库的并集就是全量数据\n⽔平分库的粒度，⽐⽔平分表更⼤\n⽔平分库分表切分规则：\nrange：  根据范围，⽐如0-1000⼀个表，1001到2000⼀个表\nhash取模：  ⽐如取ID，进⾏hash取模，根据模数分配到不同的数据库中\n地理区域： 按照地理范围进⾏划分\n时间范围： 按照时间进⾏切分\n分库分表总结\n## 技术负责⼈前瞻性思维\n## 需要提前考虑系统⼀年到两年左右的业务增⻓情况\n## 对数据库服务器的QPS、连接数、容量等做合理评估和规划\n## 很多⼈觉得“分库分表”是宜早不宜迟 ---- 其实不然\n常规开发⾥⾯单表建议1千万内，推荐是百万级别单表存储，常规sql和索引优化先⾏，然后结合缓存+异步\n+nosql+mq\n## 垂直⻆度（表结构不⼀样）\n垂直分表：\n将⼀个表字段拆分多个表，每个表存储部分字段\n避免IO时锁表的次数，分离热点字段和⾮热点字段，避免⼤字段IO导致性能下降\n业务经常组合查询的字段⼀个表；不常⽤字段⼀个表；text、blob类型字段作为附属表\n垂直分库：\n根据业务将表分类，放到不同的数据库服务器上\n避免表之间竞争同个物理机的资源，⽐如CPU/内存/硬盘/⽹络IO\n根据业务相关性进⾏划分，领域模型，微服务划分⼀般就是垂直分库\n## ⽔平⻆度（表结构⼀样）\n⽔平分库：\n把同个表的数据按照⼀定规则分到不同的数据库中，数据库在不同的服务器上\n多个数据库，降低了系统的IO和CPU压⼒\n选择合适的分⽚键和分⽚策略，和业务场景配合\n避免数据热点和访问不均衡、避免⼆次扩容难度⼤\n⽔平分表：\n同个数据库内，把⼀个表的数据按照⼀定规则拆分到多个表中，对数据进⾏拆分，不影响表结构\n单个表的数据量少了，业务SQL执⾏效率⾼，降低了系统的IO和CPU压⼒\n选择合适的分⽚键和分⽚策略，和业务场景配合\n避免数据热点和访问不均衡、避免⼆次扩容难度⼤\n## 互联⽹公司实际使⽤和跳槽⾯试\n公司业务稳定发展，多数情况是为了解决【单库单表】数据量过多问题\n重点是⽔平⻆度的【分库分表】\n分库分表的问题\n分库分表解决了问题，同时也带来了问题。\n如跨库查询、分布式事务、分库之后的排序（翻⻚，函数的计算问题）、全局主键问题、容量规划（⼆次扩容问\n题）、技术选型问题\n以下是⼀些常⻅的问题\n## 跨节点数据库Join关联查询\n数据库切分前：\n多表关联查询，可以通过sql join进⾏实现\n分库分表后：\n数据可能分布在不同的节点上，sql  join带来的问题就⽐较麻烦\n## 分库操作带来的分布式事务问题\n操作内容同时分布在不同库中，不可避免会带来跨库事务问题，即分布式事务\n## 执⾏的SQL排序、翻⻚、函数计算问题\n分库后：\n数据分布再不同的节点上，  跨节点多库进⾏查询时，会出现limit分⻚、order  by排序等问题\n⽽且当排序字段⾮分⽚字段时，更加复杂了，要在不同的分⽚节点中将数据进⾏排序并返回，然后将不同分⽚返回\n的结果集进⾏汇总和再次排序（也会带来更多的CPU/IO资源损耗）\n## 数据库全局主键重复问题\n常规表的id是使⽤⾃增id进⾏实现，分库分表后，由于表中数据同时存在不同数据库中，如果⽤⾃增id，则会出现\n冲突问题\n## 容量规划,分库分表后⼆次扩容问题\n业务发展快，初次分库分表后，满⾜不了数据存储，导致需要多次扩容\n## 分库分表技术选型问题\n市场分库分表中间件相对较多，框架各有各的优势与短板，应该如何选择\n数据库排序思路\n## 思路\n整体的思路和海量数据排序类似，不过考虑更加好⼀些\n正常思路：\n在分割段的阶段，使⽤内部排序，⽣成n个⼤⼩等于可⽤内存的顺串，最后再进⾏归并，使得数据整体有序。\n但是，为了避免I/O操作带来的影响，所以使⽤替换-选择排序的⽅式，可以使得在分割段阶段⽣成的顺串⼤⼩⼤于\n可⽤内存⼤⼩。\n同时为了能够再次减⼩I/O开销，合并阶段，可适量的增加归并的路数\n不过增⼤路数也就意味着内部每个缓冲区数量增加（⼀个缓冲区放⼀个顺串），每次要在更多的缓冲区中选取最⼩\n值，所以引⼊败者树（和堆排很像），减少增加归并路数，⽽影响内部归并。\n## 练习题与⼩总结\n## 练习内部排序的各种算法\nLC_排序数组\n## 练习⼆路归并\nLC_归并排序\n为了提升效率，避免速度不匹配的问题，真的是精益求情，OS⾥⾯有各种⾼速缓存、缓冲区等，数据库会利⽤磁\n盘的预读，顺序性读，以及设计特殊的数据结构。\nMySQL主从复制",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 5727,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000120",
    "content": "## 概念\n\n数据可以从⼀个MySQL数据库服务器主节点复制到⼀个或者多个从节点。\nMySQL默认采⽤异步复制⽅式，这样从节点就不⽤⼀直访问主服务器来更新最新数据。\n从节点可以复制主节点数据库中的所有数据库、特定的数据库或者特定的表。\n## ⽤途\n## 数据实时备份\n当系统中某个节点发⽣故障时，可以⽅便故障切换\n## 读写分离\n在开发过程中，如果遇到某个sql语句需要锁表，导致暂时不能使⽤读的服务\n使⽤主从复制，让主数据库负责写，从数据库负责读，即使主库出现锁表的情景，也可以通过从库正常读数据\n## 架构扩展\n随着系统中业务访问量的增加，如果是单机部署数据，会导致I/O访问频率过⾼\n通过主从复制，增加多个数据存储结点，将负载分布在多个从节点上，降低单机的I/O访问频率，提⾼单机的I/O性",
    "question": "## 概念",
    "answer": "数据可以从⼀个MySQL数据库服务器主节点复制到⼀个或者多个从节点。\nMySQL默认采⽤异步复制⽅式，这样从节点就不⽤⼀直访问主服务器来更新最新数据。\n从节点可以复制主节点数据库中的所有数据库、特定的数据库或者特定的表。\n## ⽤途\n## 数据实时备份\n当系统中某个节点发⽣故障时，可以⽅便故障切换\n## 读写分离\n在开发过程中，如果遇到某个sql语句需要锁表，导致暂时不能使⽤读的服务\n使⽤主从复制，让主数据库负责写，从数据库负责读，即使主库出现锁表的情景，也可以通过从库正常读数据\n## 架构扩展\n随着系统中业务访问量的增加，如果是单机部署数据，会导致I/O访问频率过⾼\n通过主从复制，增加多个数据存储结点，将负载分布在多个从节点上，降低单机的I/O访问频率，提⾼单机的I/O性",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 348,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000121",
    "content": "## 原理\n\nMySQL主从复制涉及到三个线程\n⼀个运⾏在主节点： binary log dump thread\n两个运⾏在从节点： I/O thread、SQL thread\n## binary log dump\n当从节点连接主节点的时候，主节点创建该线程，⽤于发送bin-log内容\n## I/O thread\n当从节点执⾏“start slave”命令之后，从节点会创建⼀个I/O线程⽤来连接主节点，请求其中的数据。I/O线程接收到\n主节点binlog dump的更新数据之后，保存在本地的relay log中\n## SQL线程\n该线程负责读取relay  log中的内容，解析或具体的操作并执⾏，最终保证主从数据的⼀致性\n## 基本过程\n## 从节点I/O进程连接主节点\n请求指定⽇志⽂件的指定位置后⾯的内容\n## 主节点接收到请求之后\n通过负责复制的I/O进程根据请求的信息读取指定的⽇志位置之后的⽇志信息，返回给从节点。返回信息中除了⽇\n志所包含的指定⽇志信息还包含了本次返回信息的 bin-log file 以及 bin-log position\n## 从节点的I/O线程接收到内容之后\n将接收到的⽇志内容更新到本机的 relay log 中，并且把读取到的 binary log ⽂件名和位置保存到 master-info ⽂\n件中，⽅便下⼀次告知 master 从节点需要更新的位置\n## Slave 的 SQL 线程检测到 relay-log 中新增了内容\n将  relay-log  的内容解析成在主节点上实际执⾏的操作，并在数据库中执⾏\n## 主从复制模式\n## 异步模式\n## 半同步模式\n## 全同步模式\n## GTID复制模式\n## MySQL⾼可⽤⽅案类型\n（1） 基于主从复制\n⼀般情况下，采⽤双节点主从+ keepalived/heartbeat ⽅案\n在master节点发⽣故障以后，复⽤  keepalived/heartbeat 的⾼可⽤机制实现快速切换到slave节点\n（2） 基于Galera协议\n（3） 基于NDB协议\n（4） 基于中间件/proxy\n（5） 基于共享存储\n（6） 基于主机⾼可⽤\nMySQL架构升级之路\n数据库的演变升级\n## 单机\n（1） 请求量⼤查询慢\n（2） 单机故障导致业务不可⽤\n## 主从\n（1） 数据库主从同步，从库可以⽔平扩展，满⾜更⼤读需求\n（2） 但单服务器TPS，内存，IO都是有限的\n（3） 可以考虑⽤主节点负责业务，从节点负责统计\n## 双主\n（1） ⽤户量级上来后，写请求越来越多\n（2） ⼀个Master是不能解决问题的，添加多了个主节点进⾏写⼊\n（3） 多个主节点数据要保存⼀致性，写操作需要2个master之间同步更加复杂\n## 分库和分表\n⾃研⼯具类、tddl、shardingsphere、mycat等\n【⾯试题】业务增⻓-数据库性能优化：\n这边有个数据库-单表1千万数据，未来1年还会增⻓多500万，性能⽐较慢，说下你的优化思路？\n思路：\n千万不要⼀上来就说分库分表，这个是最忌讳的事项，⼀定要根据实际情况分析，两个⻆度思考\n不分库分表：\n（1） 软优化：\n## 数据库参数调优\n## 分析慢查询SQL语句，分析执⾏计划，进⾏sql改写和程序改写\n## 优化数据库索引结构\n## 优化数据表结构优化\n## 引⼊NOSQL和程序架构调整\n（2） 硬优化\n提升系统硬件（更快的IO、更多的内存）：带宽、CPU、硬盘\n（3） 分库分表\n根据业务情况⽽定，选择合适的分库分表策略（没有通⽤的策略），外卖、物流、电商领域。\n先看只分表是否满⾜业务的需求和未来增⻓，数据库分表能够解决单表数据量很⼤的时,数据查询的效率问题。\n⽆法给数据库的并发操作带来效率上的提⾼，分表的实质还是在⼀个数据库上进⾏的操作，受数据库IO性能的限制\n如果单分表满⾜不了需求，再分库分表⼀起。\n结论：在数据量及访问压⼒不是特别⼤的情况，⾸先考虑缓存、读写分离、索引技术等⽅案，如果数据量极⼤，且\n业务持续增⻓快，再考虑分库分表⽅案。\n## MySQL数据库分库分表后带来的优点\n分库分表解决的现状问题：\n可以解决数据库本身的瓶颈以及系统本身的瓶颈\n解决数据库本身瓶颈：\n连接数：连接数过多时，就会出现‘too many connections’的错误，访问量太⼤或者数据库设置的最⼤连接数太⼩",
    "question": "## 原理",
    "answer": "MySQL主从复制涉及到三个线程\n⼀个运⾏在主节点： binary log dump thread\n两个运⾏在从节点： I/O thread、SQL thread\n## binary log dump\n当从节点连接主节点的时候，主节点创建该线程，⽤于发送bin-log内容\n## I/O thread\n当从节点执⾏“start slave”命令之后，从节点会创建⼀个I/O线程⽤来连接主节点，请求其中的数据。I/O线程接收到\n主节点binlog dump的更新数据之后，保存在本地的relay log中\n## SQL线程\n该线程负责读取relay  log中的内容，解析或具体的操作并执⾏，最终保证主从数据的⼀致性\n## 基本过程\n## 从节点I/O进程连接主节点\n请求指定⽇志⽂件的指定位置后⾯的内容\n## 主节点接收到请求之后\n通过负责复制的I/O进程根据请求的信息读取指定的⽇志位置之后的⽇志信息，返回给从节点。返回信息中除了⽇\n志所包含的指定⽇志信息还包含了本次返回信息的 bin-log file 以及 bin-log position\n## 从节点的I/O线程接收到内容之后\n将接收到的⽇志内容更新到本机的 relay log 中，并且把读取到的 binary log ⽂件名和位置保存到 master-info ⽂\n件中，⽅便下⼀次告知 master 从节点需要更新的位置\n## Slave 的 SQL 线程检测到 relay-log 中新增了内容\n将  relay-log  的内容解析成在主节点上实际执⾏的操作，并在数据库中执⾏\n## 主从复制模式\n## 异步模式\n## 半同步模式\n## 全同步模式\n## GTID复制模式\n## MySQL⾼可⽤⽅案类型\n（1） 基于主从复制\n⼀般情况下，采⽤双节点主从+ keepalived/heartbeat ⽅案\n在master节点发⽣故障以后，复⽤  keepalived/heartbeat 的⾼可⽤机制实现快速切换到slave节点\n（2） 基于Galera协议\n（3） 基于NDB协议\n（4） 基于中间件/proxy\n（5） 基于共享存储\n（6） 基于主机⾼可⽤\nMySQL架构升级之路\n数据库的演变升级\n## 单机\n（1） 请求量⼤查询慢\n（2） 单机故障导致业务不可⽤\n## 主从\n（1） 数据库主从同步，从库可以⽔平扩展，满⾜更⼤读需求\n（2） 但单服务器TPS，内存，IO都是有限的\n（3） 可以考虑⽤主节点负责业务，从节点负责统计\n## 双主\n（1） ⽤户量级上来后，写请求越来越多\n（2） ⼀个Master是不能解决问题的，添加多了个主节点进⾏写⼊\n（3） 多个主节点数据要保存⼀致性，写操作需要2个master之间同步更加复杂\n## 分库和分表\n⾃研⼯具类、tddl、shardingsphere、mycat等\n【⾯试题】业务增⻓-数据库性能优化：\n这边有个数据库-单表1千万数据，未来1年还会增⻓多500万，性能⽐较慢，说下你的优化思路？\n思路：\n千万不要⼀上来就说分库分表，这个是最忌讳的事项，⼀定要根据实际情况分析，两个⻆度思考\n不分库分表：\n（1） 软优化：\n## 数据库参数调优\n## 分析慢查询SQL语句，分析执⾏计划，进⾏sql改写和程序改写\n## 优化数据库索引结构\n## 优化数据表结构优化\n## 引⼊NOSQL和程序架构调整\n（2） 硬优化\n提升系统硬件（更快的IO、更多的内存）：带宽、CPU、硬盘\n（3） 分库分表\n根据业务情况⽽定，选择合适的分库分表策略（没有通⽤的策略），外卖、物流、电商领域。\n先看只分表是否满⾜业务的需求和未来增⻓，数据库分表能够解决单表数据量很⼤的时,数据查询的效率问题。\n⽆法给数据库的并发操作带来效率上的提⾼，分表的实质还是在⼀个数据库上进⾏的操作，受数据库IO性能的限制\n如果单分表满⾜不了需求，再分库分表⼀起。\n结论：在数据量及访问压⼒不是特别⼤的情况，⾸先考虑缓存、读写分离、索引技术等⽅案，如果数据量极⼤，且\n业务持续增⻓快，再考虑分库分表⽅案。\n## MySQL数据库分库分表后带来的优点\n分库分表解决的现状问题：\n可以解决数据库本身的瓶颈以及系统本身的瓶颈\n解决数据库本身瓶颈：\n连接数：连接数过多时，就会出现‘too many connections’的错误，访问量太⼤或者数据库设置的最⼤连接数太⼩",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1832,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000122",
    "content": "## MySQL数据库分库分表后带来的优点\n\n分库分表解决的现状问题：\n可以解决数据库本身的瓶颈以及系统本身的瓶颈\n解决数据库本身瓶颈：\n连接数：连接数过多时，就会出现‘too many connections’的错误，访问量太⼤或者数据库设置的最⼤连接数太⼩\n的原因\nMysql默认的最⼤连接数为100可以修改，⽽mysql服务允许的最⼤连接数为16384。\n数据库分表可以解决单表海量数据的查询性能问题\n数据库分库可以解决单台数据库的并发访问压⼒问题\n解决系统本身IO、CPU瓶颈\n磁盘读写IO瓶颈，热点数据太多，尽管使⽤了数据库本身缓存，但是依旧有⼤量IO,导致sql执⾏速度慢\n⽹络IO瓶颈，请求的数据太多，数据传输⼤，⽹络带宽不够，链路响应时间变⻓\nCPU瓶颈，尤其在基础数据量⼤单机复杂SQL计算，SQL语句执⾏占⽤CPU使⽤率⾼，也有扫描⾏数⼤、锁冲突、\n锁等待等原因\n可以通过 show processlist; 、show full processlist，发现 CPU 使⽤率⽐较⾼的SQL\n常⻅的对于查询时间⻓，State 列值是 Sending data，Copying to tmp table，Copying to tmp table on disk，\nSorting result，Using filesort 等都是可能有性能问题SQL，清楚相关影响问题的情况可以kill掉\n也存在执⾏时间短，但是CPU占⽤率⾼的SQL，通过上⾯命令查询不到，这个时候最好通过执⾏计划分析explain进\n⾏分析\n排它锁和共享锁是什么，有什么区别？\n排它锁也叫独占锁、写锁或 X 锁，锁定的数据只允许进⾏锁定操作的事务使⽤，其他事务⽆法对已锁定的数\n据进⾏查询或修改。当我们对数据进⾏更新的时候，也就是INSERT、DELETE或者UPDATE的时候，数据库也\n会⾃动使⽤排它锁，防⽌其他事务对该数据⾏进⾏操作。\n共享锁也叫读锁或 S 锁 ，锁定的资源可以被其他⽤户读取，但不能修改。在进⾏SELECT的时候，会将对象进\n⾏共享锁锁定，当数据读取完毕之后，就会释放共享锁，这样就可以保证数据在读取时不被修改。\n排它锁是独占的，⼀次只能由⼀个事务持有。它阻⽌其他事务获取相同资源的任何锁。共享锁是⾮独占的，允\n许多个事务同时持有相同资源的共享锁。它允许多个事务同时读取相同的数据。\n排它锁通常⽤于写操作，例如更新或删除数据，共享锁通常⽤于读操作，例如查询数据。\nMySQL的⾏级锁有哪些？作⽤是什么？\nRecord Lock 记录锁，仅仅把⼀条记录锁上，记录锁分为排他锁和共享锁。\nGap Lock 间隙锁，锁定⼀个范围，但是不包含记录本身，只存在于可重复读隔离级别，⽬的是为了解决可重\n复读隔离级别下幻读的现象。间隙锁之间是兼容的，两个事务可以同时持有包含共同间隙范围的间隙锁，并不\n存在互斥关系。\nNext-Key Lock 临键锁：Record Lock + Gap Lock 的组合，锁定⼀个范围，并且锁定记录本身。next-key\nlock  即能保护该记录，⼜能阻⽌其他事务将新纪录插⼊到被保护记录前⾯的间隙中。\n数据库悲观锁和乐观锁的原理和使⽤场景有哪些？",
    "question": "## MySQL数据库分库分表后带来的优点",
    "answer": "分库分表解决的现状问题：\n可以解决数据库本身的瓶颈以及系统本身的瓶颈\n解决数据库本身瓶颈：\n连接数：连接数过多时，就会出现‘too many connections’的错误，访问量太⼤或者数据库设置的最⼤连接数太⼩\n的原因\nMysql默认的最⼤连接数为100可以修改，⽽mysql服务允许的最⼤连接数为16384。\n数据库分表可以解决单表海量数据的查询性能问题\n数据库分库可以解决单台数据库的并发访问压⼒问题\n解决系统本身IO、CPU瓶颈\n磁盘读写IO瓶颈，热点数据太多，尽管使⽤了数据库本身缓存，但是依旧有⼤量IO,导致sql执⾏速度慢\n⽹络IO瓶颈，请求的数据太多，数据传输⼤，⽹络带宽不够，链路响应时间变⻓\nCPU瓶颈，尤其在基础数据量⼤单机复杂SQL计算，SQL语句执⾏占⽤CPU使⽤率⾼，也有扫描⾏数⼤、锁冲突、\n锁等待等原因\n可以通过 show processlist; 、show full processlist，发现 CPU 使⽤率⽐较⾼的SQL\n常⻅的对于查询时间⻓，State 列值是 Sending data，Copying to tmp table，Copying to tmp table on disk，\nSorting result，Using filesort 等都是可能有性能问题SQL，清楚相关影响问题的情况可以kill掉\n也存在执⾏时间短，但是CPU占⽤率⾼的SQL，通过上⾯命令查询不到，这个时候最好通过执⾏计划分析explain进\n⾏分析\n排它锁和共享锁是什么，有什么区别？\n排它锁也叫独占锁、写锁或 X 锁，锁定的数据只允许进⾏锁定操作的事务使⽤，其他事务⽆法对已锁定的数\n据进⾏查询或修改。当我们对数据进⾏更新的时候，也就是INSERT、DELETE或者UPDATE的时候，数据库也\n会⾃动使⽤排它锁，防⽌其他事务对该数据⾏进⾏操作。\n共享锁也叫读锁或 S 锁 ，锁定的资源可以被其他⽤户读取，但不能修改。在进⾏SELECT的时候，会将对象进\n⾏共享锁锁定，当数据读取完毕之后，就会释放共享锁，这样就可以保证数据在读取时不被修改。\n排它锁是独占的，⼀次只能由⼀个事务持有。它阻⽌其他事务获取相同资源的任何锁。共享锁是⾮独占的，允\n许多个事务同时持有相同资源的共享锁。它允许多个事务同时读取相同的数据。\n排它锁通常⽤于写操作，例如更新或删除数据，共享锁通常⽤于读操作，例如查询数据。\nMySQL的⾏级锁有哪些？作⽤是什么？\nRecord Lock 记录锁，仅仅把⼀条记录锁上，记录锁分为排他锁和共享锁。\nGap Lock 间隙锁，锁定⼀个范围，但是不包含记录本身，只存在于可重复读隔离级别，⽬的是为了解决可重\n复读隔离级别下幻读的现象。间隙锁之间是兼容的，两个事务可以同时持有包含共同间隙范围的间隙锁，并不\n存在互斥关系。\nNext-Key Lock 临键锁：Record Lock + Gap Lock 的组合，锁定⼀个范围，并且锁定记录本身。next-key\nlock  即能保护该记录，⼜能阻⽌其他事务将新纪录插⼊到被保护记录前⾯的间隙中。\n数据库悲观锁和乐观锁的原理和使⽤场景有哪些？",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1342,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000123",
    "content": "的原因\n\nMysql默认的最⼤连接数为100可以修改，⽽mysql服务允许的最⼤连接数为16384。\n数据库分表可以解决单表海量数据的查询性能问题\n数据库分库可以解决单台数据库的并发访问压⼒问题\n解决系统本身IO、CPU瓶颈\n磁盘读写IO瓶颈，热点数据太多，尽管使⽤了数据库本身缓存，但是依旧有⼤量IO,导致sql执⾏速度慢\n⽹络IO瓶颈，请求的数据太多，数据传输⼤，⽹络带宽不够，链路响应时间变⻓\nCPU瓶颈，尤其在基础数据量⼤单机复杂SQL计算，SQL语句执⾏占⽤CPU使⽤率⾼，也有扫描⾏数⼤、锁冲突、",
    "question": "的原因",
    "answer": "Mysql默认的最⼤连接数为100可以修改，⽽mysql服务允许的最⼤连接数为16384。\n数据库分表可以解决单表海量数据的查询性能问题\n数据库分库可以解决单台数据库的并发访问压⼒问题\n解决系统本身IO、CPU瓶颈\n磁盘读写IO瓶颈，热点数据太多，尽管使⽤了数据库本身缓存，但是依旧有⼤量IO,导致sql执⾏速度慢\n⽹络IO瓶颈，请求的数据太多，数据传输⼤，⽹络带宽不够，链路响应时间变⻓\nCPU瓶颈，尤其在基础数据量⼤单机复杂SQL计算，SQL语句执⾏占⽤CPU使⽤率⾼，也有扫描⾏数⼤、锁冲突、",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 254,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000124",
    "content": "锁等待等原因\n\n可以通过 show processlist; 、show full processlist，发现 CPU 使⽤率⽐较⾼的SQL\n常⻅的对于查询时间⻓，State 列值是 Sending data，Copying to tmp table，Copying to tmp table on disk，\nSorting result，Using filesort 等都是可能有性能问题SQL，清楚相关影响问题的情况可以kill掉\n也存在执⾏时间短，但是CPU占⽤率⾼的SQL，通过上⾯命令查询不到，这个时候最好通过执⾏计划分析explain进\n⾏分析\n排它锁和共享锁是什么，有什么区别？\n排它锁也叫独占锁、写锁或 X 锁，锁定的数据只允许进⾏锁定操作的事务使⽤，其他事务⽆法对已锁定的数\n据进⾏查询或修改。当我们对数据进⾏更新的时候，也就是INSERT、DELETE或者UPDATE的时候，数据库也\n会⾃动使⽤排它锁，防⽌其他事务对该数据⾏进⾏操作。\n共享锁也叫读锁或 S 锁 ，锁定的资源可以被其他⽤户读取，但不能修改。在进⾏SELECT的时候，会将对象进\n⾏共享锁锁定，当数据读取完毕之后，就会释放共享锁，这样就可以保证数据在读取时不被修改。\n排它锁是独占的，⼀次只能由⼀个事务持有。它阻⽌其他事务获取相同资源的任何锁。共享锁是⾮独占的，允\n许多个事务同时持有相同资源的共享锁。它允许多个事务同时读取相同的数据。\n排它锁通常⽤于写操作，例如更新或删除数据，共享锁通常⽤于读操作，例如查询数据。\nMySQL的⾏级锁有哪些？作⽤是什么？\nRecord Lock 记录锁，仅仅把⼀条记录锁上，记录锁分为排他锁和共享锁。\nGap Lock 间隙锁，锁定⼀个范围，但是不包含记录本身，只存在于可重复读隔离级别，⽬的是为了解决可重\n复读隔离级别下幻读的现象。间隙锁之间是兼容的，两个事务可以同时持有包含共同间隙范围的间隙锁，并不\n存在互斥关系。\nNext-Key Lock 临键锁：Record Lock + Gap Lock 的组合，锁定⼀个范围，并且锁定记录本身。next-key\nlock  即能保护该记录，⼜能阻⽌其他事务将新纪录插⼊到被保护记录前⾯的间隙中。\n数据库悲观锁和乐观锁的原理和使⽤场景有哪些？\n## 乐观锁\n认为对同⼀数据的并发操作不会总发⽣，属于⼩概率事件，不⽤每次都对数据上锁，也就是不采⽤数据库⾃身的锁\n机制，⽽是通过程序来实现。在程序上，我们可以采⽤版本号机制或者时间戳机制实现。\n## 悲观锁（Pessimistic Locking）\n也是⼀种思想，对数据被其他事务的修改持保守态度，会通过数据库⾃身的锁机制来实现，从⽽保证数据操作的排\n它性。\n## 乐观锁和悲观锁的适⽤场景\n（1） 乐观锁\n适合读操作多的场景，相对来说写的操作⽐较少。它的优点在于程序实现，不存在死锁问题，不过适⽤场景也会相\n对乐观，因为它阻⽌不了除了程序以外的数据库操作。\n（2） 悲观锁\n适合写操作多的场景，因为写的操作具有排它性。采⽤悲观锁的⽅式，可以在数据库层⾯阻⽌其他事务对该数据的\n操作权限，防⽌读 - 写和写 - 写的冲突。但是加锁的时间会⽐较⻓，可能会⻓时间限制其他⽤户的访问，也就是说\n他的并发访问性不好。\n执⾏⼀条select语句，发⽣了什么？\n连接器：跟客户端建⽴连接、获取权限、维持和管理连接。\n查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执⾏。MySQL 8.0 已删除该模块；\nSQL，通过解析器对 SQL 查询语句进⾏词法分析、语法分析，然后构建语法树。\n执⾏ SQL：执⾏ SQL 共有三个阶段：\n预处理阶段：检查表或字段是否存在；将\n符号扩展为表上的所有列。\n优化阶段：基于查询成本的考虑，  选择查询成本最⼩的执⾏计划；\n执⾏阶段：根据执⾏计划执⾏ SQL 查询语句，从存储引擎读取记录，返回给客户端；\n事务的四⼤特性有哪些？【常考】\n事务的四⼤特性通常被称为 ACID 特性\n## 原⼦性：确保事务的所有操作要么全部执⾏成功，要么全部失败回滚，不存在部分成功的情况。\n## ⼀致性：事务在执⾏前后，数据库从⼀个⼀致性状态转变到另⼀个⼀致性状态。\n## 隔离性：多个事务并发执⾏时，每个事务都应该被隔离开来，⼀个事务的执⾏不应该影响其他事务的执⾏。\n## 持久性：⼀旦事务被提交，它对数据库的改变就是永久性的，即使在系统故障或崩溃后也能够保持。\n数据库的事务隔离级别有哪些？【常考】\n## 读未提交（Read Uncommitted）：\n允许⼀个事务读取另⼀个事务尚未提交的数据修改。\n最低的隔离级别，存在脏读、不可重复读和幻读的问题。\n## 读已提交（Read Committed）：\n⼀个事务只能读取已经提交的数据。其他事务的修改在该事务提交之后才可⻅。\n解决了脏读问题，但仍可能出现不可重复读和幻读。\n## 可重复读（Repeatable Read）：\n事务执⾏期间，多次读取同⼀数据会得到相同的结果，即在事务开始和结束之间，其他事务对数据的修\n改不可⻅。\n解决了不可重复读问题，但仍可能出现幻读。\n## 序列化（Serializable）：\n最⾼的隔离级别，确保事务之间的并发执⾏效果与串⾏执⾏的效果相同，即不会出现脏读、不可重复读\n和幻读。\n为什么MySQL索引使⽤B+树\nB+树的⾮叶⼦节点不存放实际的记录数据，仅存放索引，所以数据量相同的情况下，相⽐存储即存索引⼜存\n记录的 B 树，B+树的⾮叶⼦节点可以存放更多的索引，因此 B+ 树可以⽐ B 树更「矮胖」，查询底层节点的\n磁盘 I/O次数会更少。\nB+ 树有⼤量的冗余节点（所有⾮叶⼦节点都是冗余索引），这些冗余索引让 B+ 树在插⼊、删除的效率都更\n⾼，⽐如删除根节点的时候，不会像 B 树那样会发⽣复杂的树的变化；\nselect *\nB+ 树叶⼦节点之间⽤链表连接了起来，有利于范围查询，⽽ B 树要实现范围查询，因此只能通过树的遍历来\n完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。\n你对关系范式有哪些了解\n关系数据库设计中，关系范式是⼀种规范化的设计⽅法，它的⽬标是减少数据冗余、提⾼数据⼀致性和避免插⼊、\n更新和删除操作中的异常。最常⻅的是第⼀范式（1NF）、第⼆范式（2NF）和第三范式（3NF）。\n第⼀范式(1NF)：⽤来确保每列的原⼦性，要求每列（或者每个属性值）都是不可再分的最⼩数据单元（也称为最\n⼩的原⼦单元）。\n第⼆范式(2NF)：在第⼀范式的基础上更进⼀层，要求表中的每列都和主键相关，即要求实体的唯⼀性。如果⼀个\n表满⾜第⼀范式，并且除了主键以外的其他列全部都依赖于该主键，那么该表满⾜第⼆范式。\n第三范式(3NF)：在第⼆范式的基础上更进⼀层，第三范式是确保每列都和主键列直接相关，⽽不是间接相关，即\n限制列的冗余性。如果⼀个关系满⾜第⼆范式，并且除了主键以外的其他列都依赖于主键列，列和列之间不存在相\n互依赖关系，则满⾜第三范式。\n可以对数据库表做那些优化？\n## 合理使⽤数据库分表\n对于⼀些特别⼤的表，可以考虑将其拆分成多个⼦表，从⽽更好地管理数据。\n## 建⽴索引\n在经常被查询的列上建⽴索引，提⾼查询性能。但是也要注意过多的索引影响插⼊、更新和删除的性能。\n## 避免使⽤\n只选择需要的列⽽不是使⽤SELECT *\n## 选择合适的数据类型\n尽量使⽤TINYINT，SMALLINT，MEDIUM_INT替代INT类型，如果是⾮负则加上UNSIGNED\nVARCHAR 的⻓度只分配真正需要的空间\n尽量使⽤整数或者枚举替代字符串类型\n时间类型尽量使⽤TIMESTAMP ⽽⾮DATETIME\n单表不要放太多字段\n尽量少使⽤NULL，很难查询优化⽽且占⽤额外索引空间",
    "question": "锁等待等原因",
    "answer": "可以通过 show processlist; 、show full processlist，发现 CPU 使⽤率⽐较⾼的SQL\n常⻅的对于查询时间⻓，State 列值是 Sending data，Copying to tmp table，Copying to tmp table on disk，\nSorting result，Using filesort 等都是可能有性能问题SQL，清楚相关影响问题的情况可以kill掉\n也存在执⾏时间短，但是CPU占⽤率⾼的SQL，通过上⾯命令查询不到，这个时候最好通过执⾏计划分析explain进\n⾏分析\n排它锁和共享锁是什么，有什么区别？\n排它锁也叫独占锁、写锁或 X 锁，锁定的数据只允许进⾏锁定操作的事务使⽤，其他事务⽆法对已锁定的数\n据进⾏查询或修改。当我们对数据进⾏更新的时候，也就是INSERT、DELETE或者UPDATE的时候，数据库也\n会⾃动使⽤排它锁，防⽌其他事务对该数据⾏进⾏操作。\n共享锁也叫读锁或 S 锁 ，锁定的资源可以被其他⽤户读取，但不能修改。在进⾏SELECT的时候，会将对象进\n⾏共享锁锁定，当数据读取完毕之后，就会释放共享锁，这样就可以保证数据在读取时不被修改。\n排它锁是独占的，⼀次只能由⼀个事务持有。它阻⽌其他事务获取相同资源的任何锁。共享锁是⾮独占的，允\n许多个事务同时持有相同资源的共享锁。它允许多个事务同时读取相同的数据。\n排它锁通常⽤于写操作，例如更新或删除数据，共享锁通常⽤于读操作，例如查询数据。\nMySQL的⾏级锁有哪些？作⽤是什么？\nRecord Lock 记录锁，仅仅把⼀条记录锁上，记录锁分为排他锁和共享锁。\nGap Lock 间隙锁，锁定⼀个范围，但是不包含记录本身，只存在于可重复读隔离级别，⽬的是为了解决可重\n复读隔离级别下幻读的现象。间隙锁之间是兼容的，两个事务可以同时持有包含共同间隙范围的间隙锁，并不\n存在互斥关系。\nNext-Key Lock 临键锁：Record Lock + Gap Lock 的组合，锁定⼀个范围，并且锁定记录本身。next-key\nlock  即能保护该记录，⼜能阻⽌其他事务将新纪录插⼊到被保护记录前⾯的间隙中。\n数据库悲观锁和乐观锁的原理和使⽤场景有哪些？\n## 乐观锁\n认为对同⼀数据的并发操作不会总发⽣，属于⼩概率事件，不⽤每次都对数据上锁，也就是不采⽤数据库⾃身的锁\n机制，⽽是通过程序来实现。在程序上，我们可以采⽤版本号机制或者时间戳机制实现。\n## 悲观锁（Pessimistic Locking）\n也是⼀种思想，对数据被其他事务的修改持保守态度，会通过数据库⾃身的锁机制来实现，从⽽保证数据操作的排\n它性。\n## 乐观锁和悲观锁的适⽤场景\n（1） 乐观锁\n适合读操作多的场景，相对来说写的操作⽐较少。它的优点在于程序实现，不存在死锁问题，不过适⽤场景也会相\n对乐观，因为它阻⽌不了除了程序以外的数据库操作。\n（2） 悲观锁\n适合写操作多的场景，因为写的操作具有排它性。采⽤悲观锁的⽅式，可以在数据库层⾯阻⽌其他事务对该数据的\n操作权限，防⽌读 - 写和写 - 写的冲突。但是加锁的时间会⽐较⻓，可能会⻓时间限制其他⽤户的访问，也就是说\n他的并发访问性不好。\n执⾏⼀条select语句，发⽣了什么？\n连接器：跟客户端建⽴连接、获取权限、维持和管理连接。\n查询缓存：查询语句如果命中查询缓存则直接返回，否则继续往下执⾏。MySQL 8.0 已删除该模块；\nSQL，通过解析器对 SQL 查询语句进⾏词法分析、语法分析，然后构建语法树。\n执⾏ SQL：执⾏ SQL 共有三个阶段：\n预处理阶段：检查表或字段是否存在；将\n符号扩展为表上的所有列。\n优化阶段：基于查询成本的考虑，  选择查询成本最⼩的执⾏计划；\n执⾏阶段：根据执⾏计划执⾏ SQL 查询语句，从存储引擎读取记录，返回给客户端；\n事务的四⼤特性有哪些？【常考】\n事务的四⼤特性通常被称为 ACID 特性\n## 原⼦性：确保事务的所有操作要么全部执⾏成功，要么全部失败回滚，不存在部分成功的情况。\n## ⼀致性：事务在执⾏前后，数据库从⼀个⼀致性状态转变到另⼀个⼀致性状态。\n## 隔离性：多个事务并发执⾏时，每个事务都应该被隔离开来，⼀个事务的执⾏不应该影响其他事务的执⾏。\n## 持久性：⼀旦事务被提交，它对数据库的改变就是永久性的，即使在系统故障或崩溃后也能够保持。\n数据库的事务隔离级别有哪些？【常考】\n## 读未提交（Read Uncommitted）：\n允许⼀个事务读取另⼀个事务尚未提交的数据修改。\n最低的隔离级别，存在脏读、不可重复读和幻读的问题。\n## 读已提交（Read Committed）：\n⼀个事务只能读取已经提交的数据。其他事务的修改在该事务提交之后才可⻅。\n解决了脏读问题，但仍可能出现不可重复读和幻读。\n## 可重复读（Repeatable Read）：\n事务执⾏期间，多次读取同⼀数据会得到相同的结果，即在事务开始和结束之间，其他事务对数据的修\n改不可⻅。\n解决了不可重复读问题，但仍可能出现幻读。\n## 序列化（Serializable）：\n最⾼的隔离级别，确保事务之间的并发执⾏效果与串⾏执⾏的效果相同，即不会出现脏读、不可重复读\n和幻读。\n为什么MySQL索引使⽤B+树\nB+树的⾮叶⼦节点不存放实际的记录数据，仅存放索引，所以数据量相同的情况下，相⽐存储即存索引⼜存\n记录的 B 树，B+树的⾮叶⼦节点可以存放更多的索引，因此 B+ 树可以⽐ B 树更「矮胖」，查询底层节点的\n磁盘 I/O次数会更少。\nB+ 树有⼤量的冗余节点（所有⾮叶⼦节点都是冗余索引），这些冗余索引让 B+ 树在插⼊、删除的效率都更\n⾼，⽐如删除根节点的时候，不会像 B 树那样会发⽣复杂的树的变化；\nselect *\nB+ 树叶⼦节点之间⽤链表连接了起来，有利于范围查询，⽽ B 树要实现范围查询，因此只能通过树的遍历来\n完成范围查询，这会涉及多个节点的磁盘 I/O 操作，范围查询效率不如 B+ 树。\n你对关系范式有哪些了解\n关系数据库设计中，关系范式是⼀种规范化的设计⽅法，它的⽬标是减少数据冗余、提⾼数据⼀致性和避免插⼊、\n更新和删除操作中的异常。最常⻅的是第⼀范式（1NF）、第⼆范式（2NF）和第三范式（3NF）。\n第⼀范式(1NF)：⽤来确保每列的原⼦性，要求每列（或者每个属性值）都是不可再分的最⼩数据单元（也称为最\n⼩的原⼦单元）。\n第⼆范式(2NF)：在第⼀范式的基础上更进⼀层，要求表中的每列都和主键相关，即要求实体的唯⼀性。如果⼀个\n表满⾜第⼀范式，并且除了主键以外的其他列全部都依赖于该主键，那么该表满⾜第⼆范式。\n第三范式(3NF)：在第⼆范式的基础上更进⼀层，第三范式是确保每列都和主键列直接相关，⽽不是间接相关，即\n限制列的冗余性。如果⼀个关系满⾜第⼆范式，并且除了主键以外的其他列都依赖于主键列，列和列之间不存在相\n互依赖关系，则满⾜第三范式。\n可以对数据库表做那些优化？\n## 合理使⽤数据库分表\n对于⼀些特别⼤的表，可以考虑将其拆分成多个⼦表，从⽽更好地管理数据。\n## 建⽴索引\n在经常被查询的列上建⽴索引，提⾼查询性能。但是也要注意过多的索引影响插⼊、更新和删除的性能。\n## 避免使⽤\n只选择需要的列⽽不是使⽤SELECT *\n## 选择合适的数据类型\n尽量使⽤TINYINT，SMALLINT，MEDIUM_INT替代INT类型，如果是⾮负则加上UNSIGNED\nVARCHAR 的⻓度只分配真正需要的空间\n尽量使⽤整数或者枚举替代字符串类型\n时间类型尽量使⽤TIMESTAMP ⽽⾮DATETIME\n单表不要放太多字段\n尽量少使⽤NULL，很难查询优化⽽且占⽤额外索引空间",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3231,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000125",
    "content": "## 选择合适的数据类型\n\n尽量使⽤TINYINT，SMALLINT，MEDIUM_INT替代INT类型，如果是⾮负则加上UNSIGNED\nVARCHAR 的⻓度只分配真正需要的空间\n尽量使⽤整数或者枚举替代字符串类型\n时间类型尽量使⽤TIMESTAMP ⽽⾮DATETIME\n单表不要放太多字段\n尽量少使⽤NULL，很难查询优化⽽且占⽤额外索引空间\n了解MongoDB嘛，它和MySQL有哪些区别\n关系型数据库，数据以表格的形式存储，每个表包含多个⾏和列，其中每⼀⾏是⼀个记录。 MongoDB：⾮关系\n型数据库(⽂档型数据库)，数据以BSON（Binary JSON）⽂档的形式存储，⽂档可以包含嵌套结构和数组。每个\n⽂档都有⼀个唯⼀的_id字段作为主键。\n查询语句                  MySQL：\n使⽤结构化查询语⾔（SQL）进⾏查询 MongoDB：\n使⽤MongoDB⾃⼰的查询⽅式\n模式设计\nSelect *\nMySQL： MySQL是有模式的数据库，表结构需要在设计时明确定义，包括字段名、数据类型。\nMongoDB： MongoDB是⽆模式的数据库，⽂档可以根据需要动态添加字段，没有固定的表结构。\n存储引擎\nMySQL：MySQL⽀持多种存储引擎，如InnoDB、MyISAM等，每个引擎有不同的特性和适⽤场景。\nMongoDB：  MongoDB使⽤存储引擎WiredTiger，默认提供⾼性能的读写能⼒和压缩特性。\n适⽤场景\nMySQL：  适⽤于需要处理结构化数据，⽀持事务处理和复杂查询的应⽤。\nMongoDB： 适⽤于需要处理⼤量⾮结构化或半结构化数据扩\nMySQL：  通常使⽤主从复制和垂直分区来实现扩展性。\nMongoDB：  具有较好的横向扩展性，通过分⽚可以在多台机器上分布数据。\n总结：如果数据是结构化的且需要复杂的事务⽀持，MySQL更适合；如果数据是⾮结构化或半结构化的，且需要横\n向扩展性，MongoDB更适合。\n数据库\n什么是慢查询？原因是什么？可以怎么优化？【常考】\n数据库查询的执⾏时间超过指定的超时时间时（long_query_time：默认10秒  ），就被称为慢查询。\n原因：\n查询语句⽐较复杂：查询涉及多个表，包含复杂的连接和⼦查询，可能导致执⾏时间较⻓。\n查询数据量⼤：当查询的数据量庞⼤时，即使查询本身并不复杂，也可能导致较⻓的执⾏时间。\n缺少索引：如果查询的表没有合适的索引，需要遍历整张表才能找到结果，查询速度较慢。\n数据库设计不合理：数据库表设计庞⼤，查询时可能需要较多时间。\n并发冲突：当多个查询同时访问相同的资源时，可能发⽣并发冲突，导致查询变慢。\n硬件资源不⾜：如果MySQL服务器上同时运⾏了太多的查询，会导致服务器负载过⾼，从⽽导致查询变慢\n优化：",
    "question": "## 选择合适的数据类型",
    "answer": "尽量使⽤TINYINT，SMALLINT，MEDIUM_INT替代INT类型，如果是⾮负则加上UNSIGNED\nVARCHAR 的⻓度只分配真正需要的空间\n尽量使⽤整数或者枚举替代字符串类型\n时间类型尽量使⽤TIMESTAMP ⽽⾮DATETIME\n单表不要放太多字段\n尽量少使⽤NULL，很难查询优化⽽且占⽤额外索引空间\n了解MongoDB嘛，它和MySQL有哪些区别\n关系型数据库，数据以表格的形式存储，每个表包含多个⾏和列，其中每⼀⾏是⼀个记录。 MongoDB：⾮关系\n型数据库(⽂档型数据库)，数据以BSON（Binary JSON）⽂档的形式存储，⽂档可以包含嵌套结构和数组。每个\n⽂档都有⼀个唯⼀的_id字段作为主键。\n查询语句                  MySQL：\n使⽤结构化查询语⾔（SQL）进⾏查询 MongoDB：\n使⽤MongoDB⾃⼰的查询⽅式\n模式设计\nSelect *\nMySQL： MySQL是有模式的数据库，表结构需要在设计时明确定义，包括字段名、数据类型。\nMongoDB： MongoDB是⽆模式的数据库，⽂档可以根据需要动态添加字段，没有固定的表结构。\n存储引擎\nMySQL：MySQL⽀持多种存储引擎，如InnoDB、MyISAM等，每个引擎有不同的特性和适⽤场景。\nMongoDB：  MongoDB使⽤存储引擎WiredTiger，默认提供⾼性能的读写能⼒和压缩特性。\n适⽤场景\nMySQL：  适⽤于需要处理结构化数据，⽀持事务处理和复杂查询的应⽤。\nMongoDB： 适⽤于需要处理⼤量⾮结构化或半结构化数据扩\nMySQL：  通常使⽤主从复制和垂直分区来实现扩展性。\nMongoDB：  具有较好的横向扩展性，通过分⽚可以在多台机器上分布数据。\n总结：如果数据是结构化的且需要复杂的事务⽀持，MySQL更适合；如果数据是⾮结构化或半结构化的，且需要横\n向扩展性，MongoDB更适合。\n数据库\n什么是慢查询？原因是什么？可以怎么优化？【常考】\n数据库查询的执⾏时间超过指定的超时时间时（long_query_time：默认10秒  ），就被称为慢查询。\n原因：\n查询语句⽐较复杂：查询涉及多个表，包含复杂的连接和⼦查询，可能导致执⾏时间较⻓。\n查询数据量⼤：当查询的数据量庞⼤时，即使查询本身并不复杂，也可能导致较⻓的执⾏时间。\n缺少索引：如果查询的表没有合适的索引，需要遍历整张表才能找到结果，查询速度较慢。\n数据库设计不合理：数据库表设计庞⼤，查询时可能需要较多时间。\n并发冲突：当多个查询同时访问相同的资源时，可能发⽣并发冲突，导致查询变慢。\n硬件资源不⾜：如果MySQL服务器上同时运⾏了太多的查询，会导致服务器负载过⾼，从⽽导致查询变慢\n优化：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1172,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000126",
    "content": "了解MongoDB嘛，它和MySQL有哪些区别\n\n关系型数据库，数据以表格的形式存储，每个表包含多个⾏和列，其中每⼀⾏是⼀个记录。 MongoDB：⾮关系\n型数据库(⽂档型数据库)，数据以BSON（Binary JSON）⽂档的形式存储，⽂档可以包含嵌套结构和数组。每个\n⽂档都有⼀个唯⼀的_id字段作为主键。\n查询语句                  MySQL：\n使⽤结构化查询语⾔（SQL）进⾏查询 MongoDB：\n使⽤MongoDB⾃⼰的查询⽅式\n模式设计\nSelect *\nMySQL： MySQL是有模式的数据库，表结构需要在设计时明确定义，包括字段名、数据类型。\nMongoDB： MongoDB是⽆模式的数据库，⽂档可以根据需要动态添加字段，没有固定的表结构。\n存储引擎\nMySQL：MySQL⽀持多种存储引擎，如InnoDB、MyISAM等，每个引擎有不同的特性和适⽤场景。\nMongoDB：  MongoDB使⽤存储引擎WiredTiger，默认提供⾼性能的读写能⼒和压缩特性。\n适⽤场景\nMySQL：  适⽤于需要处理结构化数据，⽀持事务处理和复杂查询的应⽤。\nMongoDB： 适⽤于需要处理⼤量⾮结构化或半结构化数据扩\nMySQL：  通常使⽤主从复制和垂直分区来实现扩展性。\nMongoDB：  具有较好的横向扩展性，通过分⽚可以在多台机器上分布数据。\n总结：如果数据是结构化的且需要复杂的事务⽀持，MySQL更适合；如果数据是⾮结构化或半结构化的，且需要横\n向扩展性，MongoDB更适合。\n数据库\n什么是慢查询？原因是什么？可以怎么优化？【常考】\n数据库查询的执⾏时间超过指定的超时时间时（long_query_time：默认10秒  ），就被称为慢查询。\n原因：\n查询语句⽐较复杂：查询涉及多个表，包含复杂的连接和⼦查询，可能导致执⾏时间较⻓。\n查询数据量⼤：当查询的数据量庞⼤时，即使查询本身并不复杂，也可能导致较⻓的执⾏时间。\n缺少索引：如果查询的表没有合适的索引，需要遍历整张表才能找到结果，查询速度较慢。\n数据库设计不合理：数据库表设计庞⼤，查询时可能需要较多时间。\n并发冲突：当多个查询同时访问相同的资源时，可能发⽣并发冲突，导致查询变慢。\n硬件资源不⾜：如果MySQL服务器上同时运⾏了太多的查询，会导致服务器负载过⾼，从⽽导致查询变慢\n优化：\n## 运⾏语句，找到慢查询的sql\n## 查询区分度最⾼的字段\n## explain：显示mysql如何使⽤索引来处理select语句以及连接表，可以帮助选择更好的索引、写出更优化的查\n询语句\n## order by limit 形式的sql语句，让排序的表优先查\n## 考虑建⽴索引原则\n## 了解业务使⽤场景\n数据库-Redis\nRedis基础",
    "question": "了解MongoDB嘛，它和MySQL有哪些区别",
    "answer": "关系型数据库，数据以表格的形式存储，每个表包含多个⾏和列，其中每⼀⾏是⼀个记录。 MongoDB：⾮关系\n型数据库(⽂档型数据库)，数据以BSON（Binary JSON）⽂档的形式存储，⽂档可以包含嵌套结构和数组。每个\n⽂档都有⼀个唯⼀的_id字段作为主键。\n查询语句                  MySQL：\n使⽤结构化查询语⾔（SQL）进⾏查询 MongoDB：\n使⽤MongoDB⾃⼰的查询⽅式\n模式设计\nSelect *\nMySQL： MySQL是有模式的数据库，表结构需要在设计时明确定义，包括字段名、数据类型。\nMongoDB： MongoDB是⽆模式的数据库，⽂档可以根据需要动态添加字段，没有固定的表结构。\n存储引擎\nMySQL：MySQL⽀持多种存储引擎，如InnoDB、MyISAM等，每个引擎有不同的特性和适⽤场景。\nMongoDB：  MongoDB使⽤存储引擎WiredTiger，默认提供⾼性能的读写能⼒和压缩特性。\n适⽤场景\nMySQL：  适⽤于需要处理结构化数据，⽀持事务处理和复杂查询的应⽤。\nMongoDB： 适⽤于需要处理⼤量⾮结构化或半结构化数据扩\nMySQL：  通常使⽤主从复制和垂直分区来实现扩展性。\nMongoDB：  具有较好的横向扩展性，通过分⽚可以在多台机器上分布数据。\n总结：如果数据是结构化的且需要复杂的事务⽀持，MySQL更适合；如果数据是⾮结构化或半结构化的，且需要横\n向扩展性，MongoDB更适合。\n数据库\n什么是慢查询？原因是什么？可以怎么优化？【常考】\n数据库查询的执⾏时间超过指定的超时时间时（long_query_time：默认10秒  ），就被称为慢查询。\n原因：\n查询语句⽐较复杂：查询涉及多个表，包含复杂的连接和⼦查询，可能导致执⾏时间较⻓。\n查询数据量⼤：当查询的数据量庞⼤时，即使查询本身并不复杂，也可能导致较⻓的执⾏时间。\n缺少索引：如果查询的表没有合适的索引，需要遍历整张表才能找到结果，查询速度较慢。\n数据库设计不合理：数据库表设计庞⼤，查询时可能需要较多时间。\n并发冲突：当多个查询同时访问相同的资源时，可能发⽣并发冲突，导致查询变慢。\n硬件资源不⾜：如果MySQL服务器上同时运⾏了太多的查询，会导致服务器负载过⾼，从⽽导致查询变慢\n优化：\n## 运⾏语句，找到慢查询的sql\n## 查询区分度最⾼的字段\n## explain：显示mysql如何使⽤索引来处理select语句以及连接表，可以帮助选择更好的索引、写出更优化的查\n询语句\n## order by limit 形式的sql语句，让排序的表优先查\n## 考虑建⽴索引原则\n## 了解业务使⽤场景\n数据库-Redis\nRedis基础",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1172,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000127",
    "content": "## 了解业务使⽤场景\n\n数据库-Redis\nRedis基础\nRedis是什么，有哪些特点\nRedis是⼀个开源的基于内存的数据库，读写速度⾮常快，通常被⽤作缓存、消息队列、分布式锁和键值存储数据\n库。它⽀持多种数据结构，如字符串、哈希表、列表、集合、有序集合等，除此之外，Redis 还⽀持事务 、持久\n化、Lua 脚本、多种集群⽅案（主从复制模式、哨兵模式、切⽚机群模式）、发布/订阅模式，内存淘汰机制、过\n期删除机制等。\n具有以下特点：\n基于内存： Redis 将数据存储在内存中，使得它具有快速的读写访问速度。这也使得 Redis 适⽤于需要⾼性\n能的应⽤场景，⽐如缓存。\n持久性：虽然 Redis 主要是内存中的存储系统，但它可以通过将数据持久化到磁盘上的快照和⽇志⽂件来保\n证数据的持久性，以防⽌数据丢失。\n多数据结构：Redis 不仅⽀持简单的键值对存储，还提供了丰富的数据结构，如列表、哈希表、集合等，使得\n它更灵活地适应不同的应⽤场景。\n原⼦性操作： Redis ⽀持原⼦性操作，这意味着它可以保证⼀个操作是原⼦的，要么执⾏成功，要么完全不\n执⾏，这对于并发环境下的数据⼀致性很重要。\n分布式：  Redis  提供了分布式特性，可以将数据分布在多个节点上，以提⾼可扩展性和可⽤性。\n为什么要使⽤ Redis ⽽不仅仅依赖 MySQL\nRedis 具备「⾼性能」和「⾼并发」两种特性\nRedis读写⾮常快速，对于需要频繁读写的数据，特别是缓存数据，Redis  的性能优势⾮常明显，将⼀部分常\n⽤的、频繁访问的数据存储在 Redis 中，可以有效减轻对 MySQL 等持久性数据库的压⼒。\nRedis 提供了丰富的数据结构，这使得 Redis 在处理特定类型数据和实现特定功能时更为灵活。\nRedis 能够更好地处理⾼并发请求，尤其适⽤于⼀些需要快速响应的场景。通过缓存和原⼦性操作，可以降低\n数据库的并发压⼒\nRedis 更适合处理⾼速、⾼并发的数据访问，以及需要复杂数据结构和功能的场景，在实际应⽤中，很多系统会同\n时使⽤ MySQL 和 Redis。\nRedis是单线程吗\nRedis 是单线程的，但是Redis 单线程指的是⽹络请求模块使⽤单线程进⾏处理，其他模块仍⽤多个线程，Redis程\n序并不是单线程的，在启动的时候，会启动后台线程。\nRedis 在 2.6 版本，会启动 2 个后台线程，分别处理关闭⽂件、AOF 刷盘这两个任务；\nRedis 在 4.0 版本之后，新增了⼀个新的后台线程，⽤来异步释放 Redis 内存，也就是 lazyfree 线程。\n之所以 Redis 为「关闭⽂件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是\n很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发⽣阻塞，这样就⽆法处理后续的请\n求了。\n为了提⾼⽹络 I/O 的并⾏度，Redis 6.0 采⽤了多个 I/O 线程来处理⽹络请求，但是对于命令的执⾏，Redis 仍然使\n⽤单线程来处理。\nRedis单线程为什么还这么快\n基于内存存储：Redis  将数据存储在内存中，⽽不是磁盘上。内存访问速度远远快于磁盘访问速度，因此\nRedis 能够快速读取和写⼊数据。\n⾮阻塞单线程： Redis 使⽤单线程模型，不需要进⾏多线程间的上下⽂切换，避免了多线程带来的竞争和同\n步开销。此外，Redis 使⽤了⾮阻塞 I/O，可以更⾼效地处理并发请求。\n⾼效的数据结构：Redis专⻔设计了STRING、LIST、HASH等⾼效的数据结构，依赖各种数据结构提升了读写\n的效率。\nI/O多路复⽤：采⽤I/O多路复⽤机制同时监听多个Socket，内核会⼀直监听这些 Socket 上的连接请求或数据\n请求。⼀旦有请求到达，就会根据Socket上的事件来选择对应的事件处理器进⾏处理，这就实现了⼀个 Redis\n线程处理多个 IO 流的效果。\nRedis数据类型和数据结构\nRedis五种数据结构和应⽤场景\nRedis 提供了丰富的数据类型，常⻅的有五种数据类型：String（字符串），Hash（哈希），List（列表），Set\n（集合）、Zset（有序集合）。",
    "question": "## 了解业务使⽤场景",
    "answer": "数据库-Redis\nRedis基础\nRedis是什么，有哪些特点\nRedis是⼀个开源的基于内存的数据库，读写速度⾮常快，通常被⽤作缓存、消息队列、分布式锁和键值存储数据\n库。它⽀持多种数据结构，如字符串、哈希表、列表、集合、有序集合等，除此之外，Redis 还⽀持事务 、持久\n化、Lua 脚本、多种集群⽅案（主从复制模式、哨兵模式、切⽚机群模式）、发布/订阅模式，内存淘汰机制、过\n期删除机制等。\n具有以下特点：\n基于内存： Redis 将数据存储在内存中，使得它具有快速的读写访问速度。这也使得 Redis 适⽤于需要⾼性\n能的应⽤场景，⽐如缓存。\n持久性：虽然 Redis 主要是内存中的存储系统，但它可以通过将数据持久化到磁盘上的快照和⽇志⽂件来保\n证数据的持久性，以防⽌数据丢失。\n多数据结构：Redis 不仅⽀持简单的键值对存储，还提供了丰富的数据结构，如列表、哈希表、集合等，使得\n它更灵活地适应不同的应⽤场景。\n原⼦性操作： Redis ⽀持原⼦性操作，这意味着它可以保证⼀个操作是原⼦的，要么执⾏成功，要么完全不\n执⾏，这对于并发环境下的数据⼀致性很重要。\n分布式：  Redis  提供了分布式特性，可以将数据分布在多个节点上，以提⾼可扩展性和可⽤性。\n为什么要使⽤ Redis ⽽不仅仅依赖 MySQL\nRedis 具备「⾼性能」和「⾼并发」两种特性\nRedis读写⾮常快速，对于需要频繁读写的数据，特别是缓存数据，Redis  的性能优势⾮常明显，将⼀部分常\n⽤的、频繁访问的数据存储在 Redis 中，可以有效减轻对 MySQL 等持久性数据库的压⼒。\nRedis 提供了丰富的数据结构，这使得 Redis 在处理特定类型数据和实现特定功能时更为灵活。\nRedis 能够更好地处理⾼并发请求，尤其适⽤于⼀些需要快速响应的场景。通过缓存和原⼦性操作，可以降低\n数据库的并发压⼒\nRedis 更适合处理⾼速、⾼并发的数据访问，以及需要复杂数据结构和功能的场景，在实际应⽤中，很多系统会同\n时使⽤ MySQL 和 Redis。\nRedis是单线程吗\nRedis 是单线程的，但是Redis 单线程指的是⽹络请求模块使⽤单线程进⾏处理，其他模块仍⽤多个线程，Redis程\n序并不是单线程的，在启动的时候，会启动后台线程。\nRedis 在 2.6 版本，会启动 2 个后台线程，分别处理关闭⽂件、AOF 刷盘这两个任务；\nRedis 在 4.0 版本之后，新增了⼀个新的后台线程，⽤来异步释放 Redis 内存，也就是 lazyfree 线程。\n之所以 Redis 为「关闭⽂件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是\n很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发⽣阻塞，这样就⽆法处理后续的请\n求了。\n为了提⾼⽹络 I/O 的并⾏度，Redis 6.0 采⽤了多个 I/O 线程来处理⽹络请求，但是对于命令的执⾏，Redis 仍然使\n⽤单线程来处理。\nRedis单线程为什么还这么快\n基于内存存储：Redis  将数据存储在内存中，⽽不是磁盘上。内存访问速度远远快于磁盘访问速度，因此\nRedis 能够快速读取和写⼊数据。\n⾮阻塞单线程： Redis 使⽤单线程模型，不需要进⾏多线程间的上下⽂切换，避免了多线程带来的竞争和同\n步开销。此外，Redis 使⽤了⾮阻塞 I/O，可以更⾼效地处理并发请求。\n⾼效的数据结构：Redis专⻔设计了STRING、LIST、HASH等⾼效的数据结构，依赖各种数据结构提升了读写\n的效率。\nI/O多路复⽤：采⽤I/O多路复⽤机制同时监听多个Socket，内核会⼀直监听这些 Socket 上的连接请求或数据\n请求。⼀旦有请求到达，就会根据Socket上的事件来选择对应的事件处理器进⾏处理，这就实现了⼀个 Redis\n线程处理多个 IO 流的效果。\nRedis数据类型和数据结构\nRedis五种数据结构和应⽤场景\nRedis 提供了丰富的数据类型，常⻅的有五种数据类型：String（字符串），Hash（哈希），List（列表），Set\n（集合）、Zset（有序集合）。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1764,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000128",
    "content": "Redis是什么，有哪些特点\n\nRedis是⼀个开源的基于内存的数据库，读写速度⾮常快，通常被⽤作缓存、消息队列、分布式锁和键值存储数据\n库。它⽀持多种数据结构，如字符串、哈希表、列表、集合、有序集合等，除此之外，Redis 还⽀持事务 、持久\n化、Lua 脚本、多种集群⽅案（主从复制模式、哨兵模式、切⽚机群模式）、发布/订阅模式，内存淘汰机制、过\n期删除机制等。\n具有以下特点：\n基于内存： Redis 将数据存储在内存中，使得它具有快速的读写访问速度。这也使得 Redis 适⽤于需要⾼性\n能的应⽤场景，⽐如缓存。\n持久性：虽然 Redis 主要是内存中的存储系统，但它可以通过将数据持久化到磁盘上的快照和⽇志⽂件来保\n证数据的持久性，以防⽌数据丢失。\n多数据结构：Redis 不仅⽀持简单的键值对存储，还提供了丰富的数据结构，如列表、哈希表、集合等，使得\n它更灵活地适应不同的应⽤场景。\n原⼦性操作： Redis ⽀持原⼦性操作，这意味着它可以保证⼀个操作是原⼦的，要么执⾏成功，要么完全不\n执⾏，这对于并发环境下的数据⼀致性很重要。\n分布式：  Redis  提供了分布式特性，可以将数据分布在多个节点上，以提⾼可扩展性和可⽤性。\n为什么要使⽤ Redis ⽽不仅仅依赖 MySQL\nRedis 具备「⾼性能」和「⾼并发」两种特性\nRedis读写⾮常快速，对于需要频繁读写的数据，特别是缓存数据，Redis  的性能优势⾮常明显，将⼀部分常\n⽤的、频繁访问的数据存储在 Redis 中，可以有效减轻对 MySQL 等持久性数据库的压⼒。\nRedis 提供了丰富的数据结构，这使得 Redis 在处理特定类型数据和实现特定功能时更为灵活。\nRedis 能够更好地处理⾼并发请求，尤其适⽤于⼀些需要快速响应的场景。通过缓存和原⼦性操作，可以降低\n数据库的并发压⼒\nRedis 更适合处理⾼速、⾼并发的数据访问，以及需要复杂数据结构和功能的场景，在实际应⽤中，很多系统会同\n时使⽤ MySQL 和 Redis。\nRedis是单线程吗\nRedis 是单线程的，但是Redis 单线程指的是⽹络请求模块使⽤单线程进⾏处理，其他模块仍⽤多个线程，Redis程\n序并不是单线程的，在启动的时候，会启动后台线程。\nRedis 在 2.6 版本，会启动 2 个后台线程，分别处理关闭⽂件、AOF 刷盘这两个任务；\nRedis 在 4.0 版本之后，新增了⼀个新的后台线程，⽤来异步释放 Redis 内存，也就是 lazyfree 线程。\n之所以 Redis 为「关闭⽂件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是\n很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发⽣阻塞，这样就⽆法处理后续的请\n求了。\n为了提⾼⽹络 I/O 的并⾏度，Redis 6.0 采⽤了多个 I/O 线程来处理⽹络请求，但是对于命令的执⾏，Redis 仍然使\n⽤单线程来处理。\nRedis单线程为什么还这么快\n基于内存存储：Redis  将数据存储在内存中，⽽不是磁盘上。内存访问速度远远快于磁盘访问速度，因此\nRedis 能够快速读取和写⼊数据。\n⾮阻塞单线程： Redis 使⽤单线程模型，不需要进⾏多线程间的上下⽂切换，避免了多线程带来的竞争和同\n步开销。此外，Redis 使⽤了⾮阻塞 I/O，可以更⾼效地处理并发请求。\n⾼效的数据结构：Redis专⻔设计了STRING、LIST、HASH等⾼效的数据结构，依赖各种数据结构提升了读写\n的效率。\nI/O多路复⽤：采⽤I/O多路复⽤机制同时监听多个Socket，内核会⼀直监听这些 Socket 上的连接请求或数据\n请求。⼀旦有请求到达，就会根据Socket上的事件来选择对应的事件处理器进⾏处理，这就实现了⼀个 Redis\n线程处理多个 IO 流的效果。\nRedis数据类型和数据结构\nRedis五种数据结构和应⽤场景\nRedis 提供了丰富的数据类型，常⻅的有五种数据类型：String（字符串），Hash（哈希），List（列表），Set\n（集合）、Zset（有序集合）。\n## String\nString类型的底层的数据结构实现主要是SDS(简单动态字符串)。应⽤场景主要有：\n缓存对象：例如可以⽤STRING缓存整个对象的JSON。\n计数：Redis处理命令是单线程，所以执⾏命令的过程是原⼦的，因此String数据类型适合计数场景，⽐如计\n算访问次数、点赞、转发、库存数量等等。\n分布式锁：可以利⽤SETNX命令。\n共享Session信息：服务器都会去同⼀个Redis获取相关的Session信息，解决了分布式系统下Session存储的",
    "question": "Redis是什么，有哪些特点",
    "answer": "Redis是⼀个开源的基于内存的数据库，读写速度⾮常快，通常被⽤作缓存、消息队列、分布式锁和键值存储数据\n库。它⽀持多种数据结构，如字符串、哈希表、列表、集合、有序集合等，除此之外，Redis 还⽀持事务 、持久\n化、Lua 脚本、多种集群⽅案（主从复制模式、哨兵模式、切⽚机群模式）、发布/订阅模式，内存淘汰机制、过\n期删除机制等。\n具有以下特点：\n基于内存： Redis 将数据存储在内存中，使得它具有快速的读写访问速度。这也使得 Redis 适⽤于需要⾼性\n能的应⽤场景，⽐如缓存。\n持久性：虽然 Redis 主要是内存中的存储系统，但它可以通过将数据持久化到磁盘上的快照和⽇志⽂件来保\n证数据的持久性，以防⽌数据丢失。\n多数据结构：Redis 不仅⽀持简单的键值对存储，还提供了丰富的数据结构，如列表、哈希表、集合等，使得\n它更灵活地适应不同的应⽤场景。\n原⼦性操作： Redis ⽀持原⼦性操作，这意味着它可以保证⼀个操作是原⼦的，要么执⾏成功，要么完全不\n执⾏，这对于并发环境下的数据⼀致性很重要。\n分布式：  Redis  提供了分布式特性，可以将数据分布在多个节点上，以提⾼可扩展性和可⽤性。\n为什么要使⽤ Redis ⽽不仅仅依赖 MySQL\nRedis 具备「⾼性能」和「⾼并发」两种特性\nRedis读写⾮常快速，对于需要频繁读写的数据，特别是缓存数据，Redis  的性能优势⾮常明显，将⼀部分常\n⽤的、频繁访问的数据存储在 Redis 中，可以有效减轻对 MySQL 等持久性数据库的压⼒。\nRedis 提供了丰富的数据结构，这使得 Redis 在处理特定类型数据和实现特定功能时更为灵活。\nRedis 能够更好地处理⾼并发请求，尤其适⽤于⼀些需要快速响应的场景。通过缓存和原⼦性操作，可以降低\n数据库的并发压⼒\nRedis 更适合处理⾼速、⾼并发的数据访问，以及需要复杂数据结构和功能的场景，在实际应⽤中，很多系统会同\n时使⽤ MySQL 和 Redis。\nRedis是单线程吗\nRedis 是单线程的，但是Redis 单线程指的是⽹络请求模块使⽤单线程进⾏处理，其他模块仍⽤多个线程，Redis程\n序并不是单线程的，在启动的时候，会启动后台线程。\nRedis 在 2.6 版本，会启动 2 个后台线程，分别处理关闭⽂件、AOF 刷盘这两个任务；\nRedis 在 4.0 版本之后，新增了⼀个新的后台线程，⽤来异步释放 Redis 内存，也就是 lazyfree 线程。\n之所以 Redis 为「关闭⽂件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是\n很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发⽣阻塞，这样就⽆法处理后续的请\n求了。\n为了提⾼⽹络 I/O 的并⾏度，Redis 6.0 采⽤了多个 I/O 线程来处理⽹络请求，但是对于命令的执⾏，Redis 仍然使\n⽤单线程来处理。\nRedis单线程为什么还这么快\n基于内存存储：Redis  将数据存储在内存中，⽽不是磁盘上。内存访问速度远远快于磁盘访问速度，因此\nRedis 能够快速读取和写⼊数据。\n⾮阻塞单线程： Redis 使⽤单线程模型，不需要进⾏多线程间的上下⽂切换，避免了多线程带来的竞争和同\n步开销。此外，Redis 使⽤了⾮阻塞 I/O，可以更⾼效地处理并发请求。\n⾼效的数据结构：Redis专⻔设计了STRING、LIST、HASH等⾼效的数据结构，依赖各种数据结构提升了读写\n的效率。\nI/O多路复⽤：采⽤I/O多路复⽤机制同时监听多个Socket，内核会⼀直监听这些 Socket 上的连接请求或数据\n请求。⼀旦有请求到达，就会根据Socket上的事件来选择对应的事件处理器进⾏处理，这就实现了⼀个 Redis\n线程处理多个 IO 流的效果。\nRedis数据类型和数据结构\nRedis五种数据结构和应⽤场景\nRedis 提供了丰富的数据类型，常⻅的有五种数据类型：String（字符串），Hash（哈希），List（列表），Set\n（集合）、Zset（有序集合）。\n## String\nString类型的底层的数据结构实现主要是SDS(简单动态字符串)。应⽤场景主要有：\n缓存对象：例如可以⽤STRING缓存整个对象的JSON。\n计数：Redis处理命令是单线程，所以执⾏命令的过程是原⼦的，因此String数据类型适合计数场景，⽐如计\n算访问次数、点赞、转发、库存数量等等。\n分布式锁：可以利⽤SETNX命令。\n共享Session信息：服务器都会去同⼀个Redis获取相关的Session信息，解决了分布式系统下Session存储的",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1969,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000129",
    "content": "## String\n\nString类型的底层的数据结构实现主要是SDS(简单动态字符串)。应⽤场景主要有：\n缓存对象：例如可以⽤STRING缓存整个对象的JSON。\n计数：Redis处理命令是单线程，所以执⾏命令的过程是原⼦的，因此String数据类型适合计数场景，⽐如计\n算访问次数、点赞、转发、库存数量等等。\n分布式锁：可以利⽤SETNX命令。\n共享Session信息：服务器都会去同⼀个Redis获取相关的Session信息，解决了分布式系统下Session存储的\n问题。\nget、set、del",
    "question": "## String",
    "answer": "String类型的底层的数据结构实现主要是SDS(简单动态字符串)。应⽤场景主要有：\n缓存对象：例如可以⽤STRING缓存整个对象的JSON。\n计数：Redis处理命令是单线程，所以执⾏命令的过程是原⼦的，因此String数据类型适合计数场景，⽐如计\n算访问次数、点赞、转发、库存数量等等。\n分布式锁：可以利⽤SETNX命令。\n共享Session信息：服务器都会去同⼀个Redis获取相关的Session信息，解决了分布式系统下Session存储的\n问题。\nget、set、del",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 251,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000130",
    "content": "问题。\n\nget、set、del\n## List\nList  类型的底层数据结构是由双向链表或压缩列表实现的：\n如果列表的元素个数⼩于 512 个，列表每个元素的值都⼩于 64 字节，Redis 会使⽤压缩列表作为 List 类型的\n底层数据结构；\n如果列表的元素不满⾜上⾯的条件，Redis 会使⽤双向链表作为 List 类型的底层数据结构；\n在 Redis 3.2 版本之后，List 数据类型底层数据结构只由 quicklist 实现，替代了双向链表和压缩列表。在 Redis\n## 中，压缩列表数据结构被废弃，由 listpack 来实现。应⽤场景主要有：\n微信朋友圈点赞：要求按照点赞顺序显示点赞好友信息，如果取消点赞，移除对应好友信息。\n消息队列：可以使⽤左进右出的命令组成来完成队列的设计。⽐如：数据的⽣产者可以通过Lpush命令从左边\n插⼊数据，多个数据消费者，可以使⽤BRpop命令阻塞的”抢”列表尾部的数据。\nrpush、lrange、index、lpop\n## Set\nSet  类型的底层数据结构是由哈希表或整数集合实现的：\n如果集合中的元素都是整数且元素个数⼩于 512个，Redis 会使⽤整数集合作为 Set 类型的底层数据结构；\n如果集合中的元素不满⾜上⾯条件，则 Redis 使⽤哈希表作为 Set 类型的底层数据结构。\n应⽤场景主要有：\n点赞：key 是⽂章id，value 是⽤户id。\n共同关注：Set 类型⽀持交集运算，所以可以⽤来计算共同关注的好友、公众号等。key 可以是⽤户id，value\n则是已关注的公众号的id。\n抽奖活动：存储某活动中中奖的⽤户名  ，Set  类型因为有去重功能，可以保证同⼀个⽤户不会中奖两次。\nsadd、smember、sismember、srem\n## Hash\nHash  类型的底层数据结构是由压缩列表或哈希表实现的：\n如果哈希类型元素个数⼩于 512 个，所有值⼩于 64 字节的话，Redis 会使⽤压缩列表作为 Hash 类型的底层\n数据结构；\n如果哈希类型元素不满⾜上⾯条件，Redis 会使⽤哈希表作为 Hash 类型的底层数据结构。\n在Redis 7.0 中，压缩列表数据结构被废弃，交由 listpack 来实现。应⽤场景主要有：\n缓存对象：⼀般对象⽤ String +  Json 存储，对象中某些频繁变化的属性可以考虑抽出来⽤ Hash 类型存储。\n购物⻋：以⽤户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物⻋的3个要素。\nhset、hget、hgetall、hdel\n## Zset\nZset类型(Sorted Set，有序集合)可以根据元素的权重来排序，可以⾃⼰来决定每个元素的权重值。⽐如说，可以\n根据元素插⼊Sorted Set 的时间确定权重值，先插⼊的元素权重⼩，后插⼊的元素权重⼤。\nZset 类型的底层数据结构是由压缩列表或跳表实现的, 应⽤场景主要有：\n在⾯对需要展示最新列表、排⾏榜等场景时，如果数据更新频繁或者需要分⻚显示，可以优先考虑使⽤\nZset。\n排⾏榜：有序集合⽐较典型的使⽤场景就是排⾏榜。例如学⽣成绩的排名榜、游戏积分排⾏榜、视频播放排\n名、电商系统中商品的销量排名等。\nzadd、zrange、zrangebyscore、zrem\n随着 Redis 版本的更新，后⾯⼜⽀持了四种数据类型： BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、\nGEO（3.2 版新增）、Stream（5.0 版新增）\nBitMap\nbit 是计算机中最⼩的单位，使⽤它进⾏储存将⾮常节省空间，特别适合⼀些数据量⼤且使⽤⼆值统计的场景。可\n以⽤于签到统计、判断⽤户登陆态等操作。\nHyperLogLog\nHyperLogLog⽤于基数统计，统计规则是基于概率完成的，不准确，标准误算率是 0.81%。优点是，在输⼊元素的\n数量或者体积⾮常⾮常⼤时，所需的内存空间总是固定的、并且很⼩。⽐如百万级⽹⻚ UV 计数等；\nGEO\n主要⽤于存储地理位置信息，并对存储的信息进⾏操作。底层是由Zset实现的，使⽤GeoHash编码⽅法实现了经纬\n度到Zset中元素权重分数的转换，这其中的两个关键机制就是「对⼆维地图做区间划分」和「对区间进⾏编码」。\n⼀组经纬度落在某个区间后，就⽤区间的编码值来表示，并把编码值作为Zset元素的权重分数。\nStream\nRedis专⻔为消息队列设计的数据类型。相⽐于基于 List 类型实现的消息队列，有这两个特有的特性：⾃动⽣成全\n局唯⼀消息ID，⽀持以消费组形式消费数据。\n之前⽅法缺陷：不能持久化，⽆法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息。\nRedis底层数据结构\n## SDS: 简单动态字符串\nSDS 可以存储字符串，还可以存储⼆进制数据，包括空字符。这使得SDS在处理⼆进制数据时更为灵活，不受\n空字符的限制。\n缓存⻓度信息：SDS在头部保存了字符串的⻓度信息，因此可以在O(1)的时间复杂度内获取字符串的⻓度。这\n样，不需要遍历整个字符串来计算⻓度，提⾼了获取⻓度的效率。\n动态扩容：SDS可以根据实际存储的数据动态扩容。当字符串⻓度变⻓时，SDS会⾃动进⾏内存的扩展，⽽不\n需要像C语⾔中的传统字符串那样⼿动管理内存。\n## 双端链表\nRedis中的List 就是⽤双端链表实现的，双端链表的链表节点可以保存不同类型的值，⽀持在两端进⾏元素的快速\n插⼊和删除，并且链表结构提供了表头指针和表尾指针，获取链表的表头节点和表尾节点的时间复杂度只需O(1)；\n获取链表数量的时间复杂度也只需O(1);\n缺陷：\n链表每个节点之间的内存都是不连续的，意味着⽆法很好利⽤ CPU 缓存\n保存⼀个链表节点的值都需要⼀个链表节点结构头的分配，内存开销较⼤。\n## 压缩列表\n压缩列表是⼀种紧凑的、可变⻓度，由连续内存块组成的顺序型数据结构，类似于数组，被⽤于存储列表和哈希表\n的数据。压缩列表在内存使⽤效率上相对较⾼，它可以根据数据⼤⼩进⾏灵活的扩容和收缩。\n缺陷：\n空间扩展操作也就是重新分配内存，因此连锁更新⼀旦发⽣，就会导致压缩列表占⽤的内存空间要多次重新分\n配，直接影响到压缩列表的访问性能。\n如果保存的元素数量增加了，或是元素变⼤了，会导致内存重新分配，会有连锁更新的问题。\n压缩列表只会⽤于保存的节点数量不多的场景，只要节点数量⾜够⼩，即使发⽣连锁更新也能接受。\n## 哈希表\n哈希表是⼀种保存键值对(key-value)的数据结构。优点在于能以O(1)的复杂度快速查询数据。Redis 采⽤了拉链法\n来解决哈希冲突，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链接。\n## 整数集合\n整数集合是⼀种专⻔⽤于存储整数值的数据结构，通过紧凑的⼆进制表示，提⾼了整数存储的效率。整数集合被⽤\n于存储Redis中的集合数据结构的整数元素。\n## 跳表\n跳跃表是⼀种在链表基础上改进过来的，实现了⼀种「多层」的有序链表，当数据量很⼤时，跳表的查找复杂度就\n是O(logN)。⽤于实现有序集合（Sorted Set）。\n跳表的查找过程？\n查找⼀个跳表节点的过程时，跳表会从头节点的最⾼层开始，逐⼀遍历每⼀层。在遍历某⼀层的跳表节点时，会⽤\n跳表节点中的 SDS 类型的元素和元素的权重来进⾏判断：\n如果当前节点的权重⼩于要查找的权重时，跳表就会访问该层上的下⼀个节点。\n如果当前节点的权重等于要查找的权重时，并且当前节点的 SDS 类型数据⼩于要查找的数据时，跳表就会访问\n该层上的下⼀个节点。\n如果上⾯两个条件都不满⾜，或者下⼀个节点为空时，跳表就会使⽤⽬前遍历到的节点的 level 数组⾥的下⼀层指\n针，然后沿着下⼀层指针继续查找。",
    "question": "问题。",
    "answer": "get、set、del\n## List\nList  类型的底层数据结构是由双向链表或压缩列表实现的：\n如果列表的元素个数⼩于 512 个，列表每个元素的值都⼩于 64 字节，Redis 会使⽤压缩列表作为 List 类型的\n底层数据结构；\n如果列表的元素不满⾜上⾯的条件，Redis 会使⽤双向链表作为 List 类型的底层数据结构；\n在 Redis 3.2 版本之后，List 数据类型底层数据结构只由 quicklist 实现，替代了双向链表和压缩列表。在 Redis\n## 中，压缩列表数据结构被废弃，由 listpack 来实现。应⽤场景主要有：\n微信朋友圈点赞：要求按照点赞顺序显示点赞好友信息，如果取消点赞，移除对应好友信息。\n消息队列：可以使⽤左进右出的命令组成来完成队列的设计。⽐如：数据的⽣产者可以通过Lpush命令从左边\n插⼊数据，多个数据消费者，可以使⽤BRpop命令阻塞的”抢”列表尾部的数据。\nrpush、lrange、index、lpop\n## Set\nSet  类型的底层数据结构是由哈希表或整数集合实现的：\n如果集合中的元素都是整数且元素个数⼩于 512个，Redis 会使⽤整数集合作为 Set 类型的底层数据结构；\n如果集合中的元素不满⾜上⾯条件，则 Redis 使⽤哈希表作为 Set 类型的底层数据结构。\n应⽤场景主要有：\n点赞：key 是⽂章id，value 是⽤户id。\n共同关注：Set 类型⽀持交集运算，所以可以⽤来计算共同关注的好友、公众号等。key 可以是⽤户id，value\n则是已关注的公众号的id。\n抽奖活动：存储某活动中中奖的⽤户名  ，Set  类型因为有去重功能，可以保证同⼀个⽤户不会中奖两次。\nsadd、smember、sismember、srem\n## Hash\nHash  类型的底层数据结构是由压缩列表或哈希表实现的：\n如果哈希类型元素个数⼩于 512 个，所有值⼩于 64 字节的话，Redis 会使⽤压缩列表作为 Hash 类型的底层\n数据结构；\n如果哈希类型元素不满⾜上⾯条件，Redis 会使⽤哈希表作为 Hash 类型的底层数据结构。\n在Redis 7.0 中，压缩列表数据结构被废弃，交由 listpack 来实现。应⽤场景主要有：\n缓存对象：⼀般对象⽤ String +  Json 存储，对象中某些频繁变化的属性可以考虑抽出来⽤ Hash 类型存储。\n购物⻋：以⽤户 id 为 key，商品 id 为 field，商品数量为 value，恰好构成了购物⻋的3个要素。\nhset、hget、hgetall、hdel\n## Zset\nZset类型(Sorted Set，有序集合)可以根据元素的权重来排序，可以⾃⼰来决定每个元素的权重值。⽐如说，可以\n根据元素插⼊Sorted Set 的时间确定权重值，先插⼊的元素权重⼩，后插⼊的元素权重⼤。\nZset 类型的底层数据结构是由压缩列表或跳表实现的, 应⽤场景主要有：\n在⾯对需要展示最新列表、排⾏榜等场景时，如果数据更新频繁或者需要分⻚显示，可以优先考虑使⽤\nZset。\n排⾏榜：有序集合⽐较典型的使⽤场景就是排⾏榜。例如学⽣成绩的排名榜、游戏积分排⾏榜、视频播放排\n名、电商系统中商品的销量排名等。\nzadd、zrange、zrangebyscore、zrem\n随着 Redis 版本的更新，后⾯⼜⽀持了四种数据类型： BitMap（2.2 版新增）、HyperLogLog（2.8 版新增）、\nGEO（3.2 版新增）、Stream（5.0 版新增）\nBitMap\nbit 是计算机中最⼩的单位，使⽤它进⾏储存将⾮常节省空间，特别适合⼀些数据量⼤且使⽤⼆值统计的场景。可\n以⽤于签到统计、判断⽤户登陆态等操作。\nHyperLogLog\nHyperLogLog⽤于基数统计，统计规则是基于概率完成的，不准确，标准误算率是 0.81%。优点是，在输⼊元素的\n数量或者体积⾮常⾮常⼤时，所需的内存空间总是固定的、并且很⼩。⽐如百万级⽹⻚ UV 计数等；\nGEO\n主要⽤于存储地理位置信息，并对存储的信息进⾏操作。底层是由Zset实现的，使⽤GeoHash编码⽅法实现了经纬\n度到Zset中元素权重分数的转换，这其中的两个关键机制就是「对⼆维地图做区间划分」和「对区间进⾏编码」。\n⼀组经纬度落在某个区间后，就⽤区间的编码值来表示，并把编码值作为Zset元素的权重分数。\nStream\nRedis专⻔为消息队列设计的数据类型。相⽐于基于 List 类型实现的消息队列，有这两个特有的特性：⾃动⽣成全\n局唯⼀消息ID，⽀持以消费组形式消费数据。\n之前⽅法缺陷：不能持久化，⽆法可靠的保存消息，并且对于离线重连的客户端不能读取历史消息。\nRedis底层数据结构\n## SDS: 简单动态字符串\nSDS 可以存储字符串，还可以存储⼆进制数据，包括空字符。这使得SDS在处理⼆进制数据时更为灵活，不受\n空字符的限制。\n缓存⻓度信息：SDS在头部保存了字符串的⻓度信息，因此可以在O(1)的时间复杂度内获取字符串的⻓度。这\n样，不需要遍历整个字符串来计算⻓度，提⾼了获取⻓度的效率。\n动态扩容：SDS可以根据实际存储的数据动态扩容。当字符串⻓度变⻓时，SDS会⾃动进⾏内存的扩展，⽽不\n需要像C语⾔中的传统字符串那样⼿动管理内存。\n## 双端链表\nRedis中的List 就是⽤双端链表实现的，双端链表的链表节点可以保存不同类型的值，⽀持在两端进⾏元素的快速\n插⼊和删除，并且链表结构提供了表头指针和表尾指针，获取链表的表头节点和表尾节点的时间复杂度只需O(1)；\n获取链表数量的时间复杂度也只需O(1);\n缺陷：\n链表每个节点之间的内存都是不连续的，意味着⽆法很好利⽤ CPU 缓存\n保存⼀个链表节点的值都需要⼀个链表节点结构头的分配，内存开销较⼤。\n## 压缩列表\n压缩列表是⼀种紧凑的、可变⻓度，由连续内存块组成的顺序型数据结构，类似于数组，被⽤于存储列表和哈希表\n的数据。压缩列表在内存使⽤效率上相对较⾼，它可以根据数据⼤⼩进⾏灵活的扩容和收缩。\n缺陷：\n空间扩展操作也就是重新分配内存，因此连锁更新⼀旦发⽣，就会导致压缩列表占⽤的内存空间要多次重新分\n配，直接影响到压缩列表的访问性能。\n如果保存的元素数量增加了，或是元素变⼤了，会导致内存重新分配，会有连锁更新的问题。\n压缩列表只会⽤于保存的节点数量不多的场景，只要节点数量⾜够⼩，即使发⽣连锁更新也能接受。\n## 哈希表\n哈希表是⼀种保存键值对(key-value)的数据结构。优点在于能以O(1)的复杂度快速查询数据。Redis 采⽤了拉链法\n来解决哈希冲突，在不扩容哈希表的前提下，将具有相同哈希值的数据串起来，形成链接。\n## 整数集合\n整数集合是⼀种专⻔⽤于存储整数值的数据结构，通过紧凑的⼆进制表示，提⾼了整数存储的效率。整数集合被⽤\n于存储Redis中的集合数据结构的整数元素。\n## 跳表\n跳跃表是⼀种在链表基础上改进过来的，实现了⼀种「多层」的有序链表，当数据量很⼤时，跳表的查找复杂度就\n是O(logN)。⽤于实现有序集合（Sorted Set）。\n跳表的查找过程？\n查找⼀个跳表节点的过程时，跳表会从头节点的最⾼层开始，逐⼀遍历每⼀层。在遍历某⼀层的跳表节点时，会⽤\n跳表节点中的 SDS 类型的元素和元素的权重来进⾏判断：\n如果当前节点的权重⼩于要查找的权重时，跳表就会访问该层上的下⼀个节点。\n如果当前节点的权重等于要查找的权重时，并且当前节点的 SDS 类型数据⼩于要查找的数据时，跳表就会访问\n该层上的下⼀个节点。\n如果上⾯两个条件都不满⾜，或者下⼀个节点为空时，跳表就会使⽤⽬前遍历到的节点的 level 数组⾥的下⼀层指\n针，然后沿着下⼀层指针继续查找。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3242,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000131",
    "content": "## 跳表\n\n跳跃表是⼀种在链表基础上改进过来的，实现了⼀种「多层」的有序链表，当数据量很⼤时，跳表的查找复杂度就\n是O(logN)。⽤于实现有序集合（Sorted Set）。\n跳表的查找过程？\n查找⼀个跳表节点的过程时，跳表会从头节点的最⾼层开始，逐⼀遍历每⼀层。在遍历某⼀层的跳表节点时，会⽤\n跳表节点中的 SDS 类型的元素和元素的权重来进⾏判断：\n如果当前节点的权重⼩于要查找的权重时，跳表就会访问该层上的下⼀个节点。\n如果当前节点的权重等于要查找的权重时，并且当前节点的 SDS 类型数据⼩于要查找的数据时，跳表就会访问\n该层上的下⼀个节点。\n如果上⾯两个条件都不满⾜，或者下⼀个节点为空时，跳表就会使⽤⽬前遍历到的节点的 level 数组⾥的下⼀层指\n针，然后沿着下⼀层指针继续查找。\nquicklist 就是双向链表 + 压缩列表组合，quicklist 就是⼀个链表，⽽链表中的每个元素⼜是⼀个压缩列\n表。 quicklist 解决办法，通过控制每个链表节点中的压缩列表的⼤⼩或者元素个数，来规避连锁更新的问题。\n因为压缩列表元素越少或越⼩，连锁更新带来的影响就越⼩，从⽽提供了更好的访问性能。\nlistpack 没有压缩列表中记录前⼀个节点⻓度的字段，listpack 只记录当前节点的⻓度，当我们向 listpack 加⼊⼀\n个新元素的时候，不会影响其他节点的⻓度字段的变化，从⽽避免了压缩列表的连锁更新问题。\nRedis持久化\nRedis如何实现数据不丢失\nRedis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。\nRedis 共有三种数据持久化的⽅式：\nAOF  ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥；\nRDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；\n混合持久化⽅式：Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；\nquicklist\nlistpack\nAOF⽇志\n以⽇志的形式记录服务器所处理的每⼀个写操作，redis服务器启动之初，会读取该⽇志来重新构建数据库，以保\n证启动后的数据库是完整的。\nAOF ⽇志是写后⽇志，\"写后\" 的意思是 Redis 是先执⾏命令，把数据写⼊内存，然后才记录⽇志，Redis是内存和\n⽇志(写后⽇志)，mysql是磁盘数据和⽇志(写前⽇志)。\nRedis 使⽤写后⽇志这⼀⽅式的好处：",
    "question": "## 跳表",
    "answer": "跳跃表是⼀种在链表基础上改进过来的，实现了⼀种「多层」的有序链表，当数据量很⼤时，跳表的查找复杂度就\n是O(logN)。⽤于实现有序集合（Sorted Set）。\n跳表的查找过程？\n查找⼀个跳表节点的过程时，跳表会从头节点的最⾼层开始，逐⼀遍历每⼀层。在遍历某⼀层的跳表节点时，会⽤\n跳表节点中的 SDS 类型的元素和元素的权重来进⾏判断：\n如果当前节点的权重⼩于要查找的权重时，跳表就会访问该层上的下⼀个节点。\n如果当前节点的权重等于要查找的权重时，并且当前节点的 SDS 类型数据⼩于要查找的数据时，跳表就会访问\n该层上的下⼀个节点。\n如果上⾯两个条件都不满⾜，或者下⼀个节点为空时，跳表就会使⽤⽬前遍历到的节点的 level 数组⾥的下⼀层指\n针，然后沿着下⼀层指针继续查找。\nquicklist 就是双向链表 + 压缩列表组合，quicklist 就是⼀个链表，⽽链表中的每个元素⼜是⼀个压缩列\n表。 quicklist 解决办法，通过控制每个链表节点中的压缩列表的⼤⼩或者元素个数，来规避连锁更新的问题。\n因为压缩列表元素越少或越⼩，连锁更新带来的影响就越⼩，从⽽提供了更好的访问性能。\nlistpack 没有压缩列表中记录前⼀个节点⻓度的字段，listpack 只记录当前节点的⻓度，当我们向 listpack 加⼊⼀\n个新元素的时候，不会影响其他节点的⻓度字段的变化，从⽽避免了压缩列表的连锁更新问题。\nRedis持久化\nRedis如何实现数据不丢失\nRedis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。\nRedis 共有三种数据持久化的⽅式：\nAOF  ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥；\nRDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；\n混合持久化⽅式：Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；\nquicklist\nlistpack\nAOF⽇志\n以⽇志的形式记录服务器所处理的每⼀个写操作，redis服务器启动之初，会读取该⽇志来重新构建数据库，以保\n证启动后的数据库是完整的。\nAOF ⽇志是写后⽇志，\"写后\" 的意思是 Redis 是先执⾏命令，把数据写⼊内存，然后才记录⽇志，Redis是内存和\n⽇志(写后⽇志)，mysql是磁盘数据和⽇志(写前⽇志)。\nRedis 使⽤写后⽇志这⼀⽅式的好处：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1037,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000132",
    "content": "quicklist 就是双向链表 + 压缩列表组合，quicklist 就是⼀个链表，⽽链表中的每个元素⼜是⼀个压缩列\n\n表。 quicklist 解决办法，通过控制每个链表节点中的压缩列表的⼤⼩或者元素个数，来规避连锁更新的问题。\n因为压缩列表元素越少或越⼩，连锁更新带来的影响就越⼩，从⽽提供了更好的访问性能。\nlistpack 没有压缩列表中记录前⼀个节点⻓度的字段，listpack 只记录当前节点的⻓度，当我们向 listpack 加⼊⼀\n个新元素的时候，不会影响其他节点的⻓度字段的变化，从⽽避免了压缩列表的连锁更新问题。\nRedis持久化\nRedis如何实现数据不丢失\nRedis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。\nRedis 共有三种数据持久化的⽅式：\nAOF  ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥；\nRDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；\n混合持久化⽅式：Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；",
    "question": "quicklist 就是双向链表 + 压缩列表组合，quicklist 就是⼀个链表，⽽链表中的每个元素⼜是⼀个压缩列",
    "answer": "表。 quicklist 解决办法，通过控制每个链表节点中的压缩列表的⼤⼩或者元素个数，来规避连锁更新的问题。\n因为压缩列表元素越少或越⼩，连锁更新带来的影响就越⼩，从⽽提供了更好的访问性能。\nlistpack 没有压缩列表中记录前⼀个节点⻓度的字段，listpack 只记录当前节点的⻓度，当我们向 listpack 加⼊⼀\n个新元素的时候，不会影响其他节点的⻓度字段的变化，从⽽避免了压缩列表的连锁更新问题。\nRedis持久化\nRedis如何实现数据不丢失\nRedis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。\nRedis 共有三种数据持久化的⽅式：\nAOF  ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥；\nRDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；\n混合持久化⽅式：Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 485,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000133",
    "content": "quicklist\n\nlistpack\nAOF⽇志\n以⽇志的形式记录服务器所处理的每⼀个写操作，redis服务器启动之初，会读取该⽇志来重新构建数据库，以保\n证启动后的数据库是完整的。\nAOF ⽇志是写后⽇志，\"写后\" 的意思是 Redis 是先执⾏命令，把数据写⼊内存，然后才记录⽇志，Redis是内存和\n⽇志(写后⽇志)，mysql是磁盘数据和⽇志(写前⽇志)。\nRedis 使⽤写后⽇志这⼀⽅式的好处：\n## 可以避免出现记录错误命令的情况。\n## 它是在命令执⾏后才记录⽇志，所以不会阻塞当前的写操作。\nAOF的三种写回测策略\nAlways，同步写回；\nEverysec，每秒写回； No，\n操作系统控制的写回。\nAlways是每次写操作命令执⾏完后，同步将 AOF ⽇志数据写回硬盘；Everysec每次写操作命令执⾏完后，先将\n命令写⼊到 AOF ⽂件的内核缓冲区，然后每隔⼀秒将缓冲区⾥的内容写回到硬盘；No就是不控制写回硬盘的时\n机。每次写操作命令执⾏完后，先将命令写⼊到 AOF ⽂件的内核缓冲区，再由操作系统决定何时将缓冲区内容写\n回硬盘。\n写回策略选择：\n想要获得⾼性能，就选择 No 策略；如果想要得到⾼可靠性保证，就选择 Always 策略；如果允许数据有⼀点丢\n失，⼜希望性能别受太⼤影响的话，那么就选择 Everysec 策略。\nAOF的磁盘重写机制\n随着执⾏的命令越多，AOF ⽂件的体积⾃然也会越来越⼤，为了避免⽇志⽂件过⼤， Redis 提供了 AOF 重写机  制，\n它会直接扫描数据中所有的键值对数据，然后为每⼀个键值对⽣成⼀条写操作命令，接着将该命令写⼊到新的 AOF\n⽂件，重写完成后，就替换掉现有的 AOF ⽇志。重写的过程是由后台⼦进程完成的，这样可以使得主进程可以继\n续正常处理命令。\nAOF重写过程：⼀处拷⻉，两处⽇志\nAOF 重写的四个触发时机：\n时机⼀：bgrewriteaof  命令被执⾏。\n时机⼆：主从复制完成 RDB ⽂件解析和加载（⽆论是否成功）。\n时机三：AOF 重写被设置为待调度执⾏。\n时机四：AOF 被启⽤，同时 AOF ⽂件的⼤⼩⽐例超出阈值，以及 AOF ⽂件的⼤⼩绝对值超出阈值。\n另外，这⾥还需要注意，在这四个时机下，其实都不能有正在执⾏的 RDB ⼦进程和 AOF 重写⼦进程，否则的话，\nAOF 重写就⽆法执⾏了。\nAOF 重写的基本执⾏过程。AOF 重写和 RDB 创建的过程类似，它也是创建了⼀个⼦进程来完成重写⼯作。这是因\n为 AOF 重写操作，实际上需要遍历 Redis server 上的所有数据库，把每个键值对以插⼊操作的形式写⼊⽇志⽂\n件，⽽⽇志⽂件⼜要进⾏写盘操作。所以，Redis 源码使⽤⼦进程来实现 AOF 重写，这就避免了阻塞主线程，也减\n少了对 Redis 整体性能的影响。\nRDB快照\nRDB 快照就是记录某⼀个瞬间的内存数据，记录的是实际数据。每次执⾏快照，都是把内存中的「所有数据」都记\n录到磁盘中。如果频率太频繁，可能会对 Redis 性能产⽣影响。如果频率太低，服务器故障时，丢失的数据会更\n多。通常可能设置⾄少 5 分钟才保存⼀次快照。\nRedis 提供了两个命令来⽣成 RDB ⽂件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」⾥执⾏：\n执⾏了 save 命令，就会在主线程⽣成 RDB ⽂件，由于和执⾏操作命令在同⼀个线程，所以如果写⼊ RDB ⽂\n件的时间太⻓，会阻塞主线程；\n执⾏了 bgsave 命令，会创建⼀个⼦进程来⽣成 RDB ⽂件，这样可以避免主线程的阻塞；\n混合持久化\nRDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会⽐较多，频率太⾼，就会影响\n性能。AOF 优点是丢失数据少，但是数据恢复不快。为了集成了两者的优点， Redis 4.0 提出了混合使⽤ AOF ⽇志\n和内存快照，也叫混合持久化，既保证了 Redis 重启速度，⼜降低数据丢失⻛险。\n混合持久化⼯作在 AOF ⽇志重写过程，在 AOF 重写⽇志时，fork出来的重写⼦进程会先将与主线程共享的内存数\n据以 RDB ⽅式写⼊到 AOF ⽂件，然后主线程处理的操作命令会被记录在重写缓冲区⾥，重写缓冲区⾥的增量命令\n会以 AOF ⽅式写⼊到 AOF ⽂件，写⼊完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF ⽂件替换旧的的\nAOF ⽂件。⽂件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。\n这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。加载完\nRDB 的内容后，才会加载后半部分的 AOF 内容，这⾥的内容是 Redis 后台⼦进程重写 AOF 期间，主线程处理的操\n作命令，可以使得数据更少的丢失。\n混合持久化的缺点是AOF⽂件的可读性变差了，以及兼容性⽐较差（Redis4.0之前版本不⽀持）\nRedis功能\nRedis集群\nRedi如何实现⾼可⽤\n## 主从复制\nRedis 提供了主从库模式，以保证数据副本的⼀致，主从库之间采⽤的是读写分离的⽅式。\n读操作：主库、从库都可以接收；\n写操作：⾸先到主库执⾏，然后，主库将写操作同步给从库。\n全量复制\n主从库间进⾏第⼀次复制操作（全量复制）\n第⼀阶段是从库和主库建⽴起连接，并告诉主库即将进⾏同步，主库确认回复后，主从库间就可以开始同步了。\n第⼆阶段主库收到 psync 命令后，会⽤ FULLRESYNC 响应命令带上两个参数：主库 runID 和主库⽬前的复制进度\noffset，返回给从库。\n第三个阶段，主库会把第⼆阶段执⾏过程中新收到的写命令，再发送给从库。\n增量复制\n从库发⽣宕机，重新连接后数据的同步操作（增量复制）\n若从库发⽣宕机，主库会把断连期间收到的写操作命令，写到repl_backlog_buffer中，当从库重连后，从库⾸先会\n给主库发送 psync 命令，并把⾃⼰当前的 slave_repl_offset 发给主库，主库会判断⾃⼰的 master_repl_offset 和\nslave_repl_offset 之间的差距。若此时从库相差 > repl_backlog_buffer说明可能⼀个从库如果和主库断连时间过\n⻓，不能够进⾏增量复制(因为前⾯的值被覆盖的了，会导致数据不⼀致)，所以直接进⾏全量复制。\n⽽从库相差 < repl_backlog_buffer，则将master_repl_offset 和 slave_repl_offset 之间的差距发送给从库进⾏执\nRedis   的主从库同步的基本原理，总结来说，有三种模式：全量复制、基于⻓连接的命令传播，以及增量复制。\n第⼀次同步(本来就是全量复制)或者增量复制时master_repl_offset  和  slave_repl_offset差值\n>repl_backlog_buffer时(repl_backlog_size这个配置参数)  就⽆法增量复制，就被迫导致全量复制。\n主从库正常运⾏后的常规同步阶段，在这个阶段中，主从库之间通过命令传播实现同步。\n从库断开重连后进⾏增量复制。\n主从全量同步使⽤RDB⽽不使⽤AOF的原因：\n## RDB⽂件内容是经过压缩的⼆进制数据（不同数据类型数据做了针对性优化），⽂件很⼩。⽽AOF⽂件记录的\n是每⼀次写操作的命令，写操作越多⽂件会变得很⼤，其中还包括很多对同⼀个key的多次冗余操作。\n## 打开AOF就要选择⽂件刷盘的策略，选择不当会严重影响Redis性能。⽽RDB只有在需要定时备份和主从全量同\n步数据时才会触发⽣成⼀次快照。\n## 哨兵模式\n当 Redis 的主从服务器出现故障宕机时，需要⼿动进⾏恢复，为了解决这个问题，Redis 增加了哨兵模式，哨兵监\n控主从服务器，并且提供主从节点故障转移的功能。\n监控：\n监控主从是否正常\n通知：\n出现问题的时候，通知相关⼈员\n故障迁移：\n⾃动主从切换\n统⼀的配置管理：获取主从地址\n## 切⽚集群\n当数据量⼤到⼀台服务器⽆法承载，需要使⽤Redis切⽚集群⽅案，它将数据分布在不同的服务器上，以此来降低\n系统对单主节点的依赖，提⾼ Redis 服务的读写性能。\n什么是Redis主从复制\n主从复制将⼀个Redis服务器的数据复制到其他服务器，其中⼀个被视为主节点（master），⽽其他的是从节点\n（slave）\n主服务器上可以进⾏读写操作，当发⽣写操作时⾃动将写操作同步给从服务器\n从服务器⼀般只读，并接受主服务器同步过来写操作命令，然后执⾏这条命令。\n主从复制的同步过程\n## 建⽴连接\n从节点通过向主节点发送SYNC命令请求建⽴连接。如果是初次同步，主节点会创建⼀个专⻔的后台线程进⾏数据\n传输。\n## 主节点创建RDB快照\n如果是初次同步，主节点会执⾏BGSAVE命令，创建⼀个RDB（Redis Database Dump）快照，将当前内存中的数\n据保存到⼀个⽂件中。\n## 主节点发送RDB⽂件和AOF缓冲区内容：\n主节点在创建RDB快照后，会将这个RDB⽂件发送给从节点。同时，主节点将AOF缓冲区中的写命令也发送给从节\n点。这确保了从节点在收到RDB⽂件后，能够通过执⾏AOF缓冲区中的写命令将数据更新⾄主节点执⾏BGSAVE时\n的状态。\n## 从节点载⼊RDB⽂件和执⾏AOF缓冲区命令：\n从节点收到RDB⽂件后，会载⼊这个⽂件，将⾃⼰的数据状态更新为主节点在执⾏BGSAVE时的状态。接着，从节\n点会执⾏AOF缓冲区中的写命令，以追赶主节点的最新状态。\n## 增量复制：\n⼀旦初次同步完成，从节点就会转⼊增量复制的阶段。主节点会实时将写⼊命令发送给从节点，从节点接收并执⾏\n这些写⼊命令，保持和主节点数据的⼀致性。\n## ⼼跳和命令传播\n主节点和从节点之间会维持⼼跳连接，以检测对⽅的存活状态。主节点将写⼊命令通过命令传播机制发送给从节\n点，确保数据的实时同步。",
    "question": "quicklist",
    "answer": "listpack\nAOF⽇志\n以⽇志的形式记录服务器所处理的每⼀个写操作，redis服务器启动之初，会读取该⽇志来重新构建数据库，以保\n证启动后的数据库是完整的。\nAOF ⽇志是写后⽇志，\"写后\" 的意思是 Redis 是先执⾏命令，把数据写⼊内存，然后才记录⽇志，Redis是内存和\n⽇志(写后⽇志)，mysql是磁盘数据和⽇志(写前⽇志)。\nRedis 使⽤写后⽇志这⼀⽅式的好处：\n## 可以避免出现记录错误命令的情况。\n## 它是在命令执⾏后才记录⽇志，所以不会阻塞当前的写操作。\nAOF的三种写回测策略\nAlways，同步写回；\nEverysec，每秒写回； No，\n操作系统控制的写回。\nAlways是每次写操作命令执⾏完后，同步将 AOF ⽇志数据写回硬盘；Everysec每次写操作命令执⾏完后，先将\n命令写⼊到 AOF ⽂件的内核缓冲区，然后每隔⼀秒将缓冲区⾥的内容写回到硬盘；No就是不控制写回硬盘的时\n机。每次写操作命令执⾏完后，先将命令写⼊到 AOF ⽂件的内核缓冲区，再由操作系统决定何时将缓冲区内容写\n回硬盘。\n写回策略选择：\n想要获得⾼性能，就选择 No 策略；如果想要得到⾼可靠性保证，就选择 Always 策略；如果允许数据有⼀点丢\n失，⼜希望性能别受太⼤影响的话，那么就选择 Everysec 策略。\nAOF的磁盘重写机制\n随着执⾏的命令越多，AOF ⽂件的体积⾃然也会越来越⼤，为了避免⽇志⽂件过⼤， Redis 提供了 AOF 重写机  制，\n它会直接扫描数据中所有的键值对数据，然后为每⼀个键值对⽣成⼀条写操作命令，接着将该命令写⼊到新的 AOF\n⽂件，重写完成后，就替换掉现有的 AOF ⽇志。重写的过程是由后台⼦进程完成的，这样可以使得主进程可以继\n续正常处理命令。\nAOF重写过程：⼀处拷⻉，两处⽇志\nAOF 重写的四个触发时机：\n时机⼀：bgrewriteaof  命令被执⾏。\n时机⼆：主从复制完成 RDB ⽂件解析和加载（⽆论是否成功）。\n时机三：AOF 重写被设置为待调度执⾏。\n时机四：AOF 被启⽤，同时 AOF ⽂件的⼤⼩⽐例超出阈值，以及 AOF ⽂件的⼤⼩绝对值超出阈值。\n另外，这⾥还需要注意，在这四个时机下，其实都不能有正在执⾏的 RDB ⼦进程和 AOF 重写⼦进程，否则的话，\nAOF 重写就⽆法执⾏了。\nAOF 重写的基本执⾏过程。AOF 重写和 RDB 创建的过程类似，它也是创建了⼀个⼦进程来完成重写⼯作。这是因\n为 AOF 重写操作，实际上需要遍历 Redis server 上的所有数据库，把每个键值对以插⼊操作的形式写⼊⽇志⽂\n件，⽽⽇志⽂件⼜要进⾏写盘操作。所以，Redis 源码使⽤⼦进程来实现 AOF 重写，这就避免了阻塞主线程，也减\n少了对 Redis 整体性能的影响。\nRDB快照\nRDB 快照就是记录某⼀个瞬间的内存数据，记录的是实际数据。每次执⾏快照，都是把内存中的「所有数据」都记\n录到磁盘中。如果频率太频繁，可能会对 Redis 性能产⽣影响。如果频率太低，服务器故障时，丢失的数据会更\n多。通常可能设置⾄少 5 分钟才保存⼀次快照。\nRedis 提供了两个命令来⽣成 RDB ⽂件，分别是 save 和 bgsave，他们的区别就在于是否在「主线程」⾥执⾏：\n执⾏了 save 命令，就会在主线程⽣成 RDB ⽂件，由于和执⾏操作命令在同⼀个线程，所以如果写⼊ RDB ⽂\n件的时间太⻓，会阻塞主线程；\n执⾏了 bgsave 命令，会创建⼀个⼦进程来⽣成 RDB ⽂件，这样可以避免主线程的阻塞；\n混合持久化\nRDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会⽐较多，频率太⾼，就会影响\n性能。AOF 优点是丢失数据少，但是数据恢复不快。为了集成了两者的优点， Redis 4.0 提出了混合使⽤ AOF ⽇志\n和内存快照，也叫混合持久化，既保证了 Redis 重启速度，⼜降低数据丢失⻛险。\n混合持久化⼯作在 AOF ⽇志重写过程，在 AOF 重写⽇志时，fork出来的重写⼦进程会先将与主线程共享的内存数\n据以 RDB ⽅式写⼊到 AOF ⽂件，然后主线程处理的操作命令会被记录在重写缓冲区⾥，重写缓冲区⾥的增量命令\n会以 AOF ⽅式写⼊到 AOF ⽂件，写⼊完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF ⽂件替换旧的的\nAOF ⽂件。⽂件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。\n这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。加载完\nRDB 的内容后，才会加载后半部分的 AOF 内容，这⾥的内容是 Redis 后台⼦进程重写 AOF 期间，主线程处理的操\n作命令，可以使得数据更少的丢失。\n混合持久化的缺点是AOF⽂件的可读性变差了，以及兼容性⽐较差（Redis4.0之前版本不⽀持）\nRedis功能\nRedis集群\nRedi如何实现⾼可⽤\n## 主从复制\nRedis 提供了主从库模式，以保证数据副本的⼀致，主从库之间采⽤的是读写分离的⽅式。\n读操作：主库、从库都可以接收；\n写操作：⾸先到主库执⾏，然后，主库将写操作同步给从库。\n全量复制\n主从库间进⾏第⼀次复制操作（全量复制）\n第⼀阶段是从库和主库建⽴起连接，并告诉主库即将进⾏同步，主库确认回复后，主从库间就可以开始同步了。\n第⼆阶段主库收到 psync 命令后，会⽤ FULLRESYNC 响应命令带上两个参数：主库 runID 和主库⽬前的复制进度\noffset，返回给从库。\n第三个阶段，主库会把第⼆阶段执⾏过程中新收到的写命令，再发送给从库。\n增量复制\n从库发⽣宕机，重新连接后数据的同步操作（增量复制）\n若从库发⽣宕机，主库会把断连期间收到的写操作命令，写到repl_backlog_buffer中，当从库重连后，从库⾸先会\n给主库发送 psync 命令，并把⾃⼰当前的 slave_repl_offset 发给主库，主库会判断⾃⼰的 master_repl_offset 和\nslave_repl_offset 之间的差距。若此时从库相差 > repl_backlog_buffer说明可能⼀个从库如果和主库断连时间过\n⻓，不能够进⾏增量复制(因为前⾯的值被覆盖的了，会导致数据不⼀致)，所以直接进⾏全量复制。\n⽽从库相差 < repl_backlog_buffer，则将master_repl_offset 和 slave_repl_offset 之间的差距发送给从库进⾏执\nRedis   的主从库同步的基本原理，总结来说，有三种模式：全量复制、基于⻓连接的命令传播，以及增量复制。\n第⼀次同步(本来就是全量复制)或者增量复制时master_repl_offset  和  slave_repl_offset差值\n>repl_backlog_buffer时(repl_backlog_size这个配置参数)  就⽆法增量复制，就被迫导致全量复制。\n主从库正常运⾏后的常规同步阶段，在这个阶段中，主从库之间通过命令传播实现同步。\n从库断开重连后进⾏增量复制。\n主从全量同步使⽤RDB⽽不使⽤AOF的原因：\n## RDB⽂件内容是经过压缩的⼆进制数据（不同数据类型数据做了针对性优化），⽂件很⼩。⽽AOF⽂件记录的\n是每⼀次写操作的命令，写操作越多⽂件会变得很⼤，其中还包括很多对同⼀个key的多次冗余操作。\n## 打开AOF就要选择⽂件刷盘的策略，选择不当会严重影响Redis性能。⽽RDB只有在需要定时备份和主从全量同\n步数据时才会触发⽣成⼀次快照。\n## 哨兵模式\n当 Redis 的主从服务器出现故障宕机时，需要⼿动进⾏恢复，为了解决这个问题，Redis 增加了哨兵模式，哨兵监\n控主从服务器，并且提供主从节点故障转移的功能。\n监控：\n监控主从是否正常\n通知：\n出现问题的时候，通知相关⼈员\n故障迁移：\n⾃动主从切换\n统⼀的配置管理：获取主从地址\n## 切⽚集群\n当数据量⼤到⼀台服务器⽆法承载，需要使⽤Redis切⽚集群⽅案，它将数据分布在不同的服务器上，以此来降低\n系统对单主节点的依赖，提⾼ Redis 服务的读写性能。\n什么是Redis主从复制\n主从复制将⼀个Redis服务器的数据复制到其他服务器，其中⼀个被视为主节点（master），⽽其他的是从节点\n（slave）\n主服务器上可以进⾏读写操作，当发⽣写操作时⾃动将写操作同步给从服务器\n从服务器⼀般只读，并接受主服务器同步过来写操作命令，然后执⾏这条命令。\n主从复制的同步过程\n## 建⽴连接\n从节点通过向主节点发送SYNC命令请求建⽴连接。如果是初次同步，主节点会创建⼀个专⻔的后台线程进⾏数据\n传输。\n## 主节点创建RDB快照\n如果是初次同步，主节点会执⾏BGSAVE命令，创建⼀个RDB（Redis Database Dump）快照，将当前内存中的数\n据保存到⼀个⽂件中。\n## 主节点发送RDB⽂件和AOF缓冲区内容：\n主节点在创建RDB快照后，会将这个RDB⽂件发送给从节点。同时，主节点将AOF缓冲区中的写命令也发送给从节\n点。这确保了从节点在收到RDB⽂件后，能够通过执⾏AOF缓冲区中的写命令将数据更新⾄主节点执⾏BGSAVE时\n的状态。\n## 从节点载⼊RDB⽂件和执⾏AOF缓冲区命令：\n从节点收到RDB⽂件后，会载⼊这个⽂件，将⾃⼰的数据状态更新为主节点在执⾏BGSAVE时的状态。接着，从节\n点会执⾏AOF缓冲区中的写命令，以追赶主节点的最新状态。\n## 增量复制：\n⼀旦初次同步完成，从节点就会转⼊增量复制的阶段。主节点会实时将写⼊命令发送给从节点，从节点接收并执⾏\n这些写⼊命令，保持和主节点数据的⼀致性。\n## ⼼跳和命令传播\n主节点和从节点之间会维持⼼跳连接，以检测对⽅的存活状态。主节点将写⼊命令通过命令传播机制发送给从节\n点，确保数据的实时同步。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 4154,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000134",
    "content": "## ⼼跳和命令传播\n\n主节点和从节点之间会维持⼼跳连接，以检测对⽅的存活状态。主节点将写⼊命令通过命令传播机制发送给从节\n点，确保数据的实时同步。\nRedis哨兵机制是什么\nRedis的哨兵⽤于监控和管理Redis实例，它可以实现⾃动故障转移和⾼可⽤性。哨兵系统由⼀组独⽴运⾏的进程组\n成，这些进程定期检查Redis主节点和从节点的状态，并在主节点宕机时选择⼀个从节点升级为新的主节点。\n如何避免主从数据的不⼀致\n持久化和复制配置：确保在主节点和从节点上都启⽤了持久化（如RDB快照和AOF⽂件）以及复制配置。这样\n可以保证从节点在重启后能够通过持久化⽂件进⾏数据的完整恢复。\n保证⽹络稳定性：确保主节点和从节点之间的⽹络连接是稳定的，⽐如让主从节点处于同⼀机房，降低⽹络延\n监控和报警：使⽤监控系统来实时监测主从节点的状态，包括复制延迟、连接状态等。设置报警机制。\n哨兵机制的⼯作原理",
    "question": "## ⼼跳和命令传播",
    "answer": "主节点和从节点之间会维持⼼跳连接，以检测对⽅的存活状态。主节点将写⼊命令通过命令传播机制发送给从节\n点，确保数据的实时同步。\nRedis哨兵机制是什么\nRedis的哨兵⽤于监控和管理Redis实例，它可以实现⾃动故障转移和⾼可⽤性。哨兵系统由⼀组独⽴运⾏的进程组\n成，这些进程定期检查Redis主节点和从节点的状态，并在主节点宕机时选择⼀个从节点升级为新的主节点。\n如何避免主从数据的不⼀致\n持久化和复制配置：确保在主节点和从节点上都启⽤了持久化（如RDB快照和AOF⽂件）以及复制配置。这样\n可以保证从节点在重启后能够通过持久化⽂件进⾏数据的完整恢复。\n保证⽹络稳定性：确保主节点和从节点之间的⽹络连接是稳定的，⽐如让主从节点处于同⼀机房，降低⽹络延\n监控和报警：使⽤监控系统来实时监测主从节点的状态，包括复制延迟、连接状态等。设置报警机制。\n哨兵机制的⼯作原理",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 394,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000135",
    "content": "Redis哨兵机制是什么\n\nRedis的哨兵⽤于监控和管理Redis实例，它可以实现⾃动故障转移和⾼可⽤性。哨兵系统由⼀组独⽴运⾏的进程组\n成，这些进程定期检查Redis主节点和从节点的状态，并在主节点宕机时选择⼀个从节点升级为新的主节点。\n如何避免主从数据的不⼀致\n持久化和复制配置：确保在主节点和从节点上都启⽤了持久化（如RDB快照和AOF⽂件）以及复制配置。这样\n可以保证从节点在重启后能够通过持久化⽂件进⾏数据的完整恢复。\n保证⽹络稳定性：确保主节点和从节点之间的⽹络连接是稳定的，⽐如让主从节点处于同⼀机房，降低⽹络延\n监控和报警：使⽤监控系统来实时监测主从节点的状态，包括复制延迟、连接状态等。设置报警机制。",
    "question": "Redis哨兵机制是什么",
    "answer": "Redis的哨兵⽤于监控和管理Redis实例，它可以实现⾃动故障转移和⾼可⽤性。哨兵系统由⼀组独⽴运⾏的进程组\n成，这些进程定期检查Redis主节点和从节点的状态，并在主节点宕机时选择⼀个从节点升级为新的主节点。\n如何避免主从数据的不⼀致\n持久化和复制配置：确保在主节点和从节点上都启⽤了持久化（如RDB快照和AOF⽂件）以及复制配置。这样\n可以保证从节点在重启后能够通过持久化⽂件进⾏数据的完整恢复。\n保证⽹络稳定性：确保主节点和从节点之间的⽹络连接是稳定的，⽐如让主从节点处于同⼀机房，降低⽹络延\n监控和报警：使⽤监控系统来实时监测主从节点的状态，包括复制延迟、连接状态等。设置报警机制。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 310,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000136",
    "content": "哨兵机制的⼯作原理\n\n## 监控\n哨兵定期检查与其关联的所有Redis实例的健康状况，包括主节点和从节点。\n## 故障检测\n当哨兵检测到主节点不可⽤（宕机）时，会尝试选举⼀个新的主节点。\n## 故障转移\n选举新主节点后，哨兵会通知所有相关的从节点更新其配置，使其将选出的新主节点作为其新的主节点。\n## ⾃动恢复\n⼀旦主节点重新可⽤，哨兵会将其重新添加到系统中，并根据需要将其配置为从节点，以提供故障恢复和负载分\n哨兵机制使得Redis在主节点发⽣故障时能够快速进⾏⾃动故障转移，确保系统的⾼可⽤性。",
    "question": "哨兵机制的⼯作原理",
    "answer": "## 监控\n哨兵定期检查与其关联的所有Redis实例的健康状况，包括主节点和从节点。\n## 故障检测\n当哨兵检测到主节点不可⽤（宕机）时，会尝试选举⼀个新的主节点。\n## 故障转移\n选举新主节点后，哨兵会通知所有相关的从节点更新其配置，使其将选出的新主节点作为其新的主节点。\n## ⾃动恢复\n⼀旦主节点重新可⽤，哨兵会将其重新添加到系统中，并根据需要将其配置为从节点，以提供故障恢复和负载分\n哨兵机制使得Redis在主节点发⽣故障时能够快速进⾏⾃动故障转移，确保系统的⾼可⽤性。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 250,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000137",
    "content": "## ⾃动恢复\n\n⼀旦主节点重新可⽤，哨兵会将其重新添加到系统中，并根据需要将其配置为从节点，以提供故障恢复和负载分\n哨兵机制使得Redis在主节点发⽣故障时能够快速进⾏⾃动故障转移，确保系统的⾼可⽤性。\nRedis切⽚集群的⼯作原理\n当 Redis 缓存数据量⼤到⼀台服务器⽆法缓存时，就需要使⽤ Redis 切⽚集群（Redis Cluster ）⽅案，它将数据\n分布在不同的服务器上，以此来降低系统对单主节点的依赖，从⽽提⾼ Redis 服务的读写性能。",
    "question": "## ⾃动恢复",
    "answer": "⼀旦主节点重新可⽤，哨兵会将其重新添加到系统中，并根据需要将其配置为从节点，以提供故障恢复和负载分\n哨兵机制使得Redis在主节点发⽣故障时能够快速进⾏⾃动故障转移，确保系统的⾼可⽤性。\nRedis切⽚集群的⼯作原理\n当 Redis 缓存数据量⼤到⼀台服务器⽆法缓存时，就需要使⽤ Redis 切⽚集群（Redis Cluster ）⽅案，它将数据\n分布在不同的服务器上，以此来降低系统对单主节点的依赖，从⽽提⾼ Redis 服务的读写性能。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 230,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000138",
    "content": "Redis切⽚集群的⼯作原理\n\n当 Redis 缓存数据量⼤到⼀台服务器⽆法缓存时，就需要使⽤ Redis 切⽚集群（Redis Cluster ）⽅案，它将数据\n分布在不同的服务器上，以此来降低系统对单主节点的依赖，从⽽提⾼ Redis 服务的读写性能。\n## 数据分⽚\n切⽚集群将整个数据集划分为16384个槽（slot），每个槽对应⼀个整数值。每个节点负责管理其中⼀部分槽的数\n## 节点间通信\n切⽚集群中的节点通过gossip协议相互通信，分享节点信息和集群状态。节点使⽤PING、PONG等消息保持通信，\n并通过定期的集群信息交换来保持⼀致性。\n## 数据分布\n当⼀个新的键值对被添加到切⽚集群时，根据键的CRC16哈希值确定它属于哪个槽，然后将数据存储到负责该槽的\n节点上。这确保了数据在集群中均匀分布。\n## 故障检测\n切⽚集群使⽤哨兵机制来检测节点的健康状态。当⼀个节点不可⽤时，其他节点会发起故障检测流程，重新分配槽\n到可⽤节点，并选举⼀个新的主节点。\n## 客户端路由\n客户端连接到切⽚集群时，通过计算键的CRC16哈希值确定它所属的槽，然后将请求发送到负责该槽的节点上。这\n样，客户端可以直接与负责相应数据的节点通信，⽽⽆需中间代理。\n## 数据复制\n切⽚集群使⽤主从复制机制，每个槽都有⼀个主节点和若⼲个从节点。数据在主节点上写⼊后，会被异步地复制到\n从节点上，确保数据的持久性和⾼可⽤性。\n什么是集群脑裂\n如果主节点的⽹络突然发⽣了问题与所有的从节点都失联了，但此时的主节点和客户端的⽹络是正常的，客户端不\n知道集群内部已经出现了问题，还在向这个失联的主节点写数据，此时这些数据被主节点缓存到了缓冲区⾥。哨兵\n也发现主节点失联了，就会在从节点中选举出⼀个leader作为主节点，会导致集群有两个主节点。\n⽹络恢复后哨兵因为之前已经选举出⼀个新主节点了，它就会把旧主节点降级，然后从旧主节点会向新主节点请求\n数据同步，因为第⼀次同步是全量同步的⽅式，旧主节点会清空掉⾃⼰本地的数据。客户端在过程之前写⼊的数据\n就会丢失了。所以脑裂会导致集群数据的丢失。\n集群脑裂带来数据丢失怎么办\n当主节点发现从节点下线或者通信超时的总数量⼩于阈值时，那么禁⽌主节点进⾏写数据，直接把错误返回给客户\n端。设置主节点连接的从节点中⾄少有 N 个从节点，并且主节点进⾏数据复制时的 ACK 消息延迟不能超过 T 秒，\n否则，主节点就不会再接收客户端的写请求了。等到新主节点上线时，就只有新主节点能接收和处理客户端请求，\n此时，新写的数据会被直接写到新主节点中。⽽原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有\n新数据丢失。\nRedis过期删除\n在Redis中，可以为键设置过期时间，使得键在⼀定时间后⾃动过期并被删除。你可以使⽤EXPIRE 命令或SET 命\n令的EX 选项来设置过期时间，因此需要有相应的机制将已过期的键值对删除，⽽做这个⼯作的就是过期键值删除\n策略。",
    "question": "Redis切⽚集群的⼯作原理",
    "answer": "当 Redis 缓存数据量⼤到⼀台服务器⽆法缓存时，就需要使⽤ Redis 切⽚集群（Redis Cluster ）⽅案，它将数据\n分布在不同的服务器上，以此来降低系统对单主节点的依赖，从⽽提⾼ Redis 服务的读写性能。\n## 数据分⽚\n切⽚集群将整个数据集划分为16384个槽（slot），每个槽对应⼀个整数值。每个节点负责管理其中⼀部分槽的数\n## 节点间通信\n切⽚集群中的节点通过gossip协议相互通信，分享节点信息和集群状态。节点使⽤PING、PONG等消息保持通信，\n并通过定期的集群信息交换来保持⼀致性。\n## 数据分布\n当⼀个新的键值对被添加到切⽚集群时，根据键的CRC16哈希值确定它属于哪个槽，然后将数据存储到负责该槽的\n节点上。这确保了数据在集群中均匀分布。\n## 故障检测\n切⽚集群使⽤哨兵机制来检测节点的健康状态。当⼀个节点不可⽤时，其他节点会发起故障检测流程，重新分配槽\n到可⽤节点，并选举⼀个新的主节点。\n## 客户端路由\n客户端连接到切⽚集群时，通过计算键的CRC16哈希值确定它所属的槽，然后将请求发送到负责该槽的节点上。这\n样，客户端可以直接与负责相应数据的节点通信，⽽⽆需中间代理。\n## 数据复制\n切⽚集群使⽤主从复制机制，每个槽都有⼀个主节点和若⼲个从节点。数据在主节点上写⼊后，会被异步地复制到\n从节点上，确保数据的持久性和⾼可⽤性。\n什么是集群脑裂\n如果主节点的⽹络突然发⽣了问题与所有的从节点都失联了，但此时的主节点和客户端的⽹络是正常的，客户端不\n知道集群内部已经出现了问题，还在向这个失联的主节点写数据，此时这些数据被主节点缓存到了缓冲区⾥。哨兵\n也发现主节点失联了，就会在从节点中选举出⼀个leader作为主节点，会导致集群有两个主节点。\n⽹络恢复后哨兵因为之前已经选举出⼀个新主节点了，它就会把旧主节点降级，然后从旧主节点会向新主节点请求\n数据同步，因为第⼀次同步是全量同步的⽅式，旧主节点会清空掉⾃⼰本地的数据。客户端在过程之前写⼊的数据\n就会丢失了。所以脑裂会导致集群数据的丢失。\n集群脑裂带来数据丢失怎么办\n当主节点发现从节点下线或者通信超时的总数量⼩于阈值时，那么禁⽌主节点进⾏写数据，直接把错误返回给客户\n端。设置主节点连接的从节点中⾄少有 N 个从节点，并且主节点进⾏数据复制时的 ACK 消息延迟不能超过 T 秒，\n否则，主节点就不会再接收客户端的写请求了。等到新主节点上线时，就只有新主节点能接收和处理客户端请求，\n此时，新写的数据会被直接写到新主节点中。⽽原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有\n新数据丢失。\nRedis过期删除\n在Redis中，可以为键设置过期时间，使得键在⼀定时间后⾃动过期并被删除。你可以使⽤EXPIRE 命令或SET 命\n令的EX 选项来设置过期时间，因此需要有相应的机制将已过期的键值对删除，⽽做这个⼯作的就是过期键值删除\n策略。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1243,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000139",
    "content": "## 数据复制\n\n切⽚集群使⽤主从复制机制，每个槽都有⼀个主节点和若⼲个从节点。数据在主节点上写⼊后，会被异步地复制到\n从节点上，确保数据的持久性和⾼可⽤性。\n什么是集群脑裂\n如果主节点的⽹络突然发⽣了问题与所有的从节点都失联了，但此时的主节点和客户端的⽹络是正常的，客户端不\n知道集群内部已经出现了问题，还在向这个失联的主节点写数据，此时这些数据被主节点缓存到了缓冲区⾥。哨兵\n也发现主节点失联了，就会在从节点中选举出⼀个leader作为主节点，会导致集群有两个主节点。\n⽹络恢复后哨兵因为之前已经选举出⼀个新主节点了，它就会把旧主节点降级，然后从旧主节点会向新主节点请求\n数据同步，因为第⼀次同步是全量同步的⽅式，旧主节点会清空掉⾃⼰本地的数据。客户端在过程之前写⼊的数据\n就会丢失了。所以脑裂会导致集群数据的丢失。\n集群脑裂带来数据丢失怎么办\n当主节点发现从节点下线或者通信超时的总数量⼩于阈值时，那么禁⽌主节点进⾏写数据，直接把错误返回给客户\n端。设置主节点连接的从节点中⾄少有 N 个从节点，并且主节点进⾏数据复制时的 ACK 消息延迟不能超过 T 秒，\n否则，主节点就不会再接收客户端的写请求了。等到新主节点上线时，就只有新主节点能接收和处理客户端请求，\n此时，新写的数据会被直接写到新主节点中。⽽原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有\n新数据丢失。\nRedis过期删除\n在Redis中，可以为键设置过期时间，使得键在⼀定时间后⾃动过期并被删除。你可以使⽤EXPIRE 命令或SET 命\n令的EX 选项来设置过期时间，因此需要有相应的机制将已过期的键值对删除，⽽做这个⼯作的就是过期键值删除\n策略。\n过期删除策略有哪些\n定时删除：设置 key 的过期时间时，同时创建⼀个定时事件，当时间到达时，由事件处理器⾃动执⾏ key 的\n删除操作。这样可以保证过期的 key 会被尽快删除，但删除过期 key 会占⽤⼀部分 CPU 时间，对CPU不友\n惰性删除： 不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n这样会使⽤很少的系统资源，对CPU友好，但是可能会导致过期key⻓期不被删除，浪费内存空间。\n定期删除：每隔⼀段时间「随机」从数据库中取出⼀定数量的 key 进⾏检查，并删除其中的过期key。这种\n⽅法减少了删除操作对cpu的影响，也减少了内存空间的浪费，但是效果也没有两者好，且难以确定删除操作\n执⾏的时⻓和频率。\nRedis过期删除策略是什么\nRedis 选择「惰性删除+定期删除」这两种策略配和使⽤，以求在合理使⽤ CPU 时间和避免内存浪费之间取得平",
    "question": "## 数据复制",
    "answer": "切⽚集群使⽤主从复制机制，每个槽都有⼀个主节点和若⼲个从节点。数据在主节点上写⼊后，会被异步地复制到\n从节点上，确保数据的持久性和⾼可⽤性。\n什么是集群脑裂\n如果主节点的⽹络突然发⽣了问题与所有的从节点都失联了，但此时的主节点和客户端的⽹络是正常的，客户端不\n知道集群内部已经出现了问题，还在向这个失联的主节点写数据，此时这些数据被主节点缓存到了缓冲区⾥。哨兵\n也发现主节点失联了，就会在从节点中选举出⼀个leader作为主节点，会导致集群有两个主节点。\n⽹络恢复后哨兵因为之前已经选举出⼀个新主节点了，它就会把旧主节点降级，然后从旧主节点会向新主节点请求\n数据同步，因为第⼀次同步是全量同步的⽅式，旧主节点会清空掉⾃⼰本地的数据。客户端在过程之前写⼊的数据\n就会丢失了。所以脑裂会导致集群数据的丢失。\n集群脑裂带来数据丢失怎么办\n当主节点发现从节点下线或者通信超时的总数量⼩于阈值时，那么禁⽌主节点进⾏写数据，直接把错误返回给客户\n端。设置主节点连接的从节点中⾄少有 N 个从节点，并且主节点进⾏数据复制时的 ACK 消息延迟不能超过 T 秒，\n否则，主节点就不会再接收客户端的写请求了。等到新主节点上线时，就只有新主节点能接收和处理客户端请求，\n此时，新写的数据会被直接写到新主节点中。⽽原主节点会被哨兵降为从节点，即使它的数据被清空了，也不会有\n新数据丢失。\nRedis过期删除\n在Redis中，可以为键设置过期时间，使得键在⼀定时间后⾃动过期并被删除。你可以使⽤EXPIRE 命令或SET 命\n令的EX 选项来设置过期时间，因此需要有相应的机制将已过期的键值对删除，⽽做这个⼯作的就是过期键值删除\n策略。\n过期删除策略有哪些\n定时删除：设置 key 的过期时间时，同时创建⼀个定时事件，当时间到达时，由事件处理器⾃动执⾏ key 的\n删除操作。这样可以保证过期的 key 会被尽快删除，但删除过期 key 会占⽤⼀部分 CPU 时间，对CPU不友\n惰性删除： 不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n这样会使⽤很少的系统资源，对CPU友好，但是可能会导致过期key⻓期不被删除，浪费内存空间。\n定期删除：每隔⼀段时间「随机」从数据库中取出⼀定数量的 key 进⾏检查，并删除其中的过期key。这种\n⽅法减少了删除操作对cpu的影响，也减少了内存空间的浪费，但是效果也没有两者好，且难以确定删除操作\n执⾏的时⻓和频率。\nRedis过期删除策略是什么\nRedis 选择「惰性删除+定期删除」这两种策略配和使⽤，以求在合理使⽤ CPU 时间和避免内存浪费之间取得平",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1123,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000140",
    "content": "过期删除策略有哪些\n\n定时删除：设置 key 的过期时间时，同时创建⼀个定时事件，当时间到达时，由事件处理器⾃动执⾏ key 的\n删除操作。这样可以保证过期的 key 会被尽快删除，但删除过期 key 会占⽤⼀部分 CPU 时间，对CPU不友\n惰性删除： 不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n这样会使⽤很少的系统资源，对CPU友好，但是可能会导致过期key⻓期不被删除，浪费内存空间。\n定期删除：每隔⼀段时间「随机」从数据库中取出⼀定数量的 key 进⾏检查，并删除其中的过期key。这种\n⽅法减少了删除操作对cpu的影响，也减少了内存空间的浪费，但是效果也没有两者好，且难以确定删除操作\n执⾏的时⻓和频率。",
    "question": "过期删除策略有哪些",
    "answer": "定时删除：设置 key 的过期时间时，同时创建⼀个定时事件，当时间到达时，由事件处理器⾃动执⾏ key 的\n删除操作。这样可以保证过期的 key 会被尽快删除，但删除过期 key 会占⽤⼀部分 CPU 时间，对CPU不友\n惰性删除： 不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n这样会使⽤很少的系统资源，对CPU友好，但是可能会导致过期key⻓期不被删除，浪费内存空间。\n定期删除：每隔⼀段时间「随机」从数据库中取出⼀定数量的 key 进⾏检查，并删除其中的过期key。这种\n⽅法减少了删除操作对cpu的影响，也减少了内存空间的浪费，但是效果也没有两者好，且难以确定删除操作\n执⾏的时⻓和频率。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 337,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000141",
    "content": "Redis过期删除策略是什么\n\nRedis 选择「惰性删除+定期删除」这两种策略配和使⽤，以求在合理使⽤ CPU 时间和避免内存浪费之间取得平\n## 惰性删除依据expireIfNeeded 函数来实现，每次返回或者修改key之前，都会调⽤该函数检查key 是否过期\n如果过期，删除该key,  lazyfree_lazy_expire 参数决定是同步删除还是异步删除，然后返回null 给\n客户端\n如果没有过期，则返回正常的键给客户端\n## 定期删除的做法是每隔⼀段时间「随机」从数据库中取出⼀定数量的  key 进⾏检查，并删除其中的过期\nkey。\n默认每隔10s检查⼀次数据库，配置键为 hz: 10\n随机抽查的数量是20个key\n定期删除的流程：\n从过期字典中随机抽取 20 个 key\n检查这 20 个 key 是否过期，并删除已过期的 key；\n如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占⽐「随机抽取 key\n的数量」⼤于 25%，则继续重复步骤 1；如果已过期的 key ⽐例⼩于 25%，则停⽌继续删除过期 key，然后\n等待下⼀轮再检查。\nRedis内存淘汰\nRedis通过参数\n删除⼀些键以释放内存。\n内存淘汰策略\n## 不进⾏数据淘汰\n来设定最⼤运⾏内存。当系统内存不⾜时，Redis会根据配置的淘汰策略来\nNoEviction： 如果内存不⾜以执⾏写操作，Redis将返回错误，默认的淘汰策略。\n## 进⾏数据淘汰\nVolatileTTL：优先淘汰更早过期的键值。\nVolatitleLRU: 只对带有过期时间的键使⽤LRU策略，其他键使⽤NoEviction策略。\nVolatitleRandom： 只对带有过期时间的键使⽤随机淘汰，其他键使⽤NoEviction策略。\nVolatitleLFU: 只对带有过期时间的键使⽤LFU策略，其他键使⽤NoEviction策略。\nAllKeysLRU： 根据最近最少使⽤的原则淘汰最久未使⽤的键。\nmaxmemory <bytes>\nAllKeysRandom： 随机选择⼀个键进⾏淘汰。\nAllKeysLFU： 根据最少频繁使⽤的原则淘汰最少使⽤的键。\n可以使⽤\n命令，来查看当前 Redis 的内存淘汰策略",
    "question": "Redis过期删除策略是什么",
    "answer": "Redis 选择「惰性删除+定期删除」这两种策略配和使⽤，以求在合理使⽤ CPU 时间和避免内存浪费之间取得平\n## 惰性删除依据expireIfNeeded 函数来实现，每次返回或者修改key之前，都会调⽤该函数检查key 是否过期\n如果过期，删除该key,  lazyfree_lazy_expire 参数决定是同步删除还是异步删除，然后返回null 给\n客户端\n如果没有过期，则返回正常的键给客户端\n## 定期删除的做法是每隔⼀段时间「随机」从数据库中取出⼀定数量的  key 进⾏检查，并删除其中的过期\nkey。\n默认每隔10s检查⼀次数据库，配置键为 hz: 10\n随机抽查的数量是20个key\n定期删除的流程：\n从过期字典中随机抽取 20 个 key\n检查这 20 个 key 是否过期，并删除已过期的 key；\n如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占⽐「随机抽取 key\n的数量」⼤于 25%，则继续重复步骤 1；如果已过期的 key ⽐例⼩于 25%，则停⽌继续删除过期 key，然后\n等待下⼀轮再检查。\nRedis内存淘汰\nRedis通过参数\n删除⼀些键以释放内存。\n内存淘汰策略\n## 不进⾏数据淘汰\n来设定最⼤运⾏内存。当系统内存不⾜时，Redis会根据配置的淘汰策略来\nNoEviction： 如果内存不⾜以执⾏写操作，Redis将返回错误，默认的淘汰策略。\n## 进⾏数据淘汰\nVolatileTTL：优先淘汰更早过期的键值。\nVolatitleLRU: 只对带有过期时间的键使⽤LRU策略，其他键使⽤NoEviction策略。\nVolatitleRandom： 只对带有过期时间的键使⽤随机淘汰，其他键使⽤NoEviction策略。\nVolatitleLFU: 只对带有过期时间的键使⽤LFU策略，其他键使⽤NoEviction策略。\nAllKeysLRU： 根据最近最少使⽤的原则淘汰最久未使⽤的键。\nmaxmemory <bytes>\nAllKeysRandom： 随机选择⼀个键进⾏淘汰。\nAllKeysLFU： 根据最少频繁使⽤的原则淘汰最少使⽤的键。\n可以使⽤\n命令，来查看当前 Redis 的内存淘汰策略",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 968,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000142",
    "content": "## 进⾏数据淘汰\n\nVolatileTTL：优先淘汰更早过期的键值。\nVolatitleLRU: 只对带有过期时间的键使⽤LRU策略，其他键使⽤NoEviction策略。\nVolatitleRandom： 只对带有过期时间的键使⽤随机淘汰，其他键使⽤NoEviction策略。\nVolatitleLFU: 只对带有过期时间的键使⽤LFU策略，其他键使⽤NoEviction策略。\nAllKeysLRU： 根据最近最少使⽤的原则淘汰最久未使⽤的键。\nmaxmemory <bytes>\nAllKeysRandom： 随机选择⼀个键进⾏淘汰。\nAllKeysLFU： 根据最少频繁使⽤的原则淘汰最少使⽤的键。\n可以使⽤\n命令，来查看当前 Redis 的内存淘汰策略\nRedis的LRU算法和LFU算法有什么区别",
    "question": "## 进⾏数据淘汰",
    "answer": "VolatileTTL：优先淘汰更早过期的键值。\nVolatitleLRU: 只对带有过期时间的键使⽤LRU策略，其他键使⽤NoEviction策略。\nVolatitleRandom： 只对带有过期时间的键使⽤随机淘汰，其他键使⽤NoEviction策略。\nVolatitleLFU: 只对带有过期时间的键使⽤LFU策略，其他键使⽤NoEviction策略。\nAllKeysLRU： 根据最近最少使⽤的原则淘汰最久未使⽤的键。\nmaxmemory <bytes>\nAllKeysRandom： 随机选择⼀个键进⾏淘汰。\nAllKeysLFU： 根据最少频繁使⽤的原则淘汰最少使⽤的键。\n可以使⽤\n命令，来查看当前 Redis 的内存淘汰策略\nRedis的LRU算法和LFU算法有什么区别",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 354,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000143",
    "content": "Redis的LRU算法和LFU算法有什么区别\n\n## LRU（Least Recently Used）：\nLRU算法假设最近被访问的数据更有可能在未来被再次访问，所以选择最近最少被使⽤的对象进⾏淘\nRedis 实现的是⼀种近似 LRU 算法，在 Redis 的对象结构体中添加⼀个额外的字段，⽤于记录此数据的\n最后⼀次访问时间。当 Redis 进⾏内存淘汰时，会使⽤随机采样的⽅式来淘汰数据，它是随机取 5 个值\n（此值可配置），然后淘汰最久没有使⽤的那个。\n## LFU（Least Frequently Used）：\nLFU算法假设使⽤频率较低的对象在未来仍然会较少被访问，所以选择使⽤频率最低的对象进⾏淘汰。\nLFU维护⼀个使⽤计数，每当⼀个对象被访问时，其使⽤计数增加。在需要淘汰对象时，选择使⽤计数\n最低的对象淘汰。\nLRU关注的是最近的访问情况，认为最近被访问的对象更可能在未来被再次访问。\nLFU关注的是使⽤频率，认为使⽤频率较低的对象在未来仍然会较少被访问。\nRedis缓存\n因为⽤户请求访问数据库的请求数量⽐较多时，数据库很容易崩溃，所以⼀般将Re  dis作为数据库的缓存层，\n什么是缓存雪崩\n缓存雪崩：在某个时间点，缓存中的⼤量数据同时失效，⼤量请求都需要重新计算或重新获取数据，数据库压⼒剧\n增。这可能是由于缓存的过期时间设置相近，导致在某个时间点同时失效。或者Redis故障宕机。\n## ⼤量数据同时过期\n针对⼤量数据同时过期⽽引发缓存雪崩问题，常⻅的应对⽅法有以下⼏种：\n均匀设置过期时间: 避免将⼤量数据设置成同⼀个过期时间，可以给这些数据的过期时间加⼀个随机数。\n互斥锁：如果发现访问的数据不在 Redis ⾥，就加个互斥锁，保证同⼀时间内只有⼀个请求来构建缓存\n后台更新缓存：让缓存“永久有效”，并将更新缓存的⼯作交由后台线程定时更新。\n## Redis故障宕机\n针对 Redis 故障宕机⽽引发的缓存雪崩问题，常⻅的应对⽅法有下⾯这⼏种：\n服务熔断或请求限流机制：\n服务熔断：暂停业务应⽤对缓存服务的访问，直接返回错误\n请求限流：只将少部分请求发送到数据库进⾏处理，再多的请求就在⼊⼝直接拒绝服务\n构建Redis缓存⾼可靠集群：\n通过主从节点的⽅式构建 Redis 缓存⾼可靠集群，\n如果  Redis  缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于\nRedis 故障宕机⽽导致的缓存雪崩问题。\nconfig get maxmemory-policy\n什么是缓存击穿\n缓存击穿：当某个“热点数据”过期时，⼤量并发请求查询这个缓存不存在的数据时，导致请求直接访问数据库，增\n加数据库的负载。缓存击穿是缓存雪崩的⼀个⼦集，可以使⽤前⾯说到的⽅案，添加互斥锁或者后台更新缓存。\n什么是缓存穿透\n缓存穿透要访问的数据既不在缓存中，也不在数据库中，这样就⽆法构建缓存数据，后续所有的请求都会向数据库\n查找，增加数据库的负载。\n出现缓存穿透⼀般是因为以下两种原因：\n业务误操作，缓存中的数据和数据库中的数据都被误删除了\n恶意攻击，通过构造不存在的 key ⼤量访问缓存，导致对数据库的频繁查询。\n对应的解决办法\n3种：\n对⾮法请求做限制\n针对查询的数据，在缓存中设置⼀个空值或者默认值\n使⽤布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。\n如何保证数据库和缓存的⼀致性\nCache Aside策略\n细分为「读策略」和「写策略」\n写策略的步骤：\n更新数据库中的数据；\n删除缓存中的数据。\n读策略的步骤：\n如果读取的数据命中了缓存，则直接返回数据；\n如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写⼊到缓存，并且返回给⽤户。\n「先更新数据库 + 再删除缓存」的⽅案，是可以保证数据⼀致性的，但是每次更新数据的时候，缓存的数据都会被\n删除，这样会对缓存的命中率带来影响。\n如果业务对缓存命中率有很⾼的要求，我们可以采⽤「更新数据库 + 更新缓存（不是删除缓存，⽽是更新缓存）」\n的⽅案，因为更新缓存并不会出现缓存未命中的情况，但是在两个更新请求并发执⾏的时候，会出现数据不⼀致的",
    "question": "Redis的LRU算法和LFU算法有什么区别",
    "answer": "## LRU（Least Recently Used）：\nLRU算法假设最近被访问的数据更有可能在未来被再次访问，所以选择最近最少被使⽤的对象进⾏淘\nRedis 实现的是⼀种近似 LRU 算法，在 Redis 的对象结构体中添加⼀个额外的字段，⽤于记录此数据的\n最后⼀次访问时间。当 Redis 进⾏内存淘汰时，会使⽤随机采样的⽅式来淘汰数据，它是随机取 5 个值\n（此值可配置），然后淘汰最久没有使⽤的那个。\n## LFU（Least Frequently Used）：\nLFU算法假设使⽤频率较低的对象在未来仍然会较少被访问，所以选择使⽤频率最低的对象进⾏淘汰。\nLFU维护⼀个使⽤计数，每当⼀个对象被访问时，其使⽤计数增加。在需要淘汰对象时，选择使⽤计数\n最低的对象淘汰。\nLRU关注的是最近的访问情况，认为最近被访问的对象更可能在未来被再次访问。\nLFU关注的是使⽤频率，认为使⽤频率较低的对象在未来仍然会较少被访问。\nRedis缓存\n因为⽤户请求访问数据库的请求数量⽐较多时，数据库很容易崩溃，所以⼀般将Re  dis作为数据库的缓存层，\n什么是缓存雪崩\n缓存雪崩：在某个时间点，缓存中的⼤量数据同时失效，⼤量请求都需要重新计算或重新获取数据，数据库压⼒剧\n增。这可能是由于缓存的过期时间设置相近，导致在某个时间点同时失效。或者Redis故障宕机。\n## ⼤量数据同时过期\n针对⼤量数据同时过期⽽引发缓存雪崩问题，常⻅的应对⽅法有以下⼏种：\n均匀设置过期时间: 避免将⼤量数据设置成同⼀个过期时间，可以给这些数据的过期时间加⼀个随机数。\n互斥锁：如果发现访问的数据不在 Redis ⾥，就加个互斥锁，保证同⼀时间内只有⼀个请求来构建缓存\n后台更新缓存：让缓存“永久有效”，并将更新缓存的⼯作交由后台线程定时更新。\n## Redis故障宕机\n针对 Redis 故障宕机⽽引发的缓存雪崩问题，常⻅的应对⽅法有下⾯这⼏种：\n服务熔断或请求限流机制：\n服务熔断：暂停业务应⽤对缓存服务的访问，直接返回错误\n请求限流：只将少部分请求发送到数据库进⾏处理，再多的请求就在⼊⼝直接拒绝服务\n构建Redis缓存⾼可靠集群：\n通过主从节点的⽅式构建 Redis 缓存⾼可靠集群，\n如果  Redis  缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于\nRedis 故障宕机⽽导致的缓存雪崩问题。\nconfig get maxmemory-policy\n什么是缓存击穿\n缓存击穿：当某个“热点数据”过期时，⼤量并发请求查询这个缓存不存在的数据时，导致请求直接访问数据库，增\n加数据库的负载。缓存击穿是缓存雪崩的⼀个⼦集，可以使⽤前⾯说到的⽅案，添加互斥锁或者后台更新缓存。\n什么是缓存穿透\n缓存穿透要访问的数据既不在缓存中，也不在数据库中，这样就⽆法构建缓存数据，后续所有的请求都会向数据库\n查找，增加数据库的负载。\n出现缓存穿透⼀般是因为以下两种原因：\n业务误操作，缓存中的数据和数据库中的数据都被误删除了\n恶意攻击，通过构造不存在的 key ⼤量访问缓存，导致对数据库的频繁查询。\n对应的解决办法\n3种：\n对⾮法请求做限制\n针对查询的数据，在缓存中设置⼀个空值或者默认值\n使⽤布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。\n如何保证数据库和缓存的⼀致性\nCache Aside策略\n细分为「读策略」和「写策略」\n写策略的步骤：\n更新数据库中的数据；\n删除缓存中的数据。\n读策略的步骤：\n如果读取的数据命中了缓存，则直接返回数据；\n如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写⼊到缓存，并且返回给⽤户。\n「先更新数据库 + 再删除缓存」的⽅案，是可以保证数据⼀致性的，但是每次更新数据的时候，缓存的数据都会被\n删除，这样会对缓存的命中率带来影响。\n如果业务对缓存命中率有很⾼的要求，我们可以采⽤「更新数据库 + 更新缓存（不是删除缓存，⽽是更新缓存）」\n的⽅案，因为更新缓存并不会出现缓存未命中的情况，但是在两个更新请求并发执⾏的时候，会出现数据不⼀致的",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1732,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000144",
    "content": "## Redis故障宕机\n\n针对 Redis 故障宕机⽽引发的缓存雪崩问题，常⻅的应对⽅法有下⾯这⼏种：\n服务熔断或请求限流机制：\n服务熔断：暂停业务应⽤对缓存服务的访问，直接返回错误\n请求限流：只将少部分请求发送到数据库进⾏处理，再多的请求就在⼊⼝直接拒绝服务\n构建Redis缓存⾼可靠集群：\n通过主从节点的⽅式构建 Redis 缓存⾼可靠集群，\n如果  Redis  缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于\nRedis 故障宕机⽽导致的缓存雪崩问题。\nconfig get maxmemory-policy\n什么是缓存击穿\n缓存击穿：当某个“热点数据”过期时，⼤量并发请求查询这个缓存不存在的数据时，导致请求直接访问数据库，增\n加数据库的负载。缓存击穿是缓存雪崩的⼀个⼦集，可以使⽤前⾯说到的⽅案，添加互斥锁或者后台更新缓存。\n什么是缓存穿透\n缓存穿透要访问的数据既不在缓存中，也不在数据库中，这样就⽆法构建缓存数据，后续所有的请求都会向数据库\n查找，增加数据库的负载。\n出现缓存穿透⼀般是因为以下两种原因：\n业务误操作，缓存中的数据和数据库中的数据都被误删除了\n恶意攻击，通过构造不存在的 key ⼤量访问缓存，导致对数据库的频繁查询。\n对应的解决办法\n3种：\n对⾮法请求做限制\n针对查询的数据，在缓存中设置⼀个空值或者默认值\n使⽤布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。\n如何保证数据库和缓存的⼀致性\nCache Aside策略\n细分为「读策略」和「写策略」\n写策略的步骤：\n更新数据库中的数据；\n删除缓存中的数据。\n读策略的步骤：\n如果读取的数据命中了缓存，则直接返回数据；\n如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写⼊到缓存，并且返回给⽤户。\n「先更新数据库 + 再删除缓存」的⽅案，是可以保证数据⼀致性的，但是每次更新数据的时候，缓存的数据都会被\n删除，这样会对缓存的命中率带来影响。\n如果业务对缓存命中率有很⾼的要求，我们可以采⽤「更新数据库 + 更新缓存（不是删除缓存，⽽是更新缓存）」\n的⽅案，因为更新缓存并不会出现缓存未命中的情况，但是在两个更新请求并发执⾏的时候，会出现数据不⼀致的\n问题，可以⽤以下⼿段来解决。\n在更新缓存前先加个分布式锁，保证同⼀时间只运⾏⼀个请求更新缓存，就会不会产⽣并发问题了。\n在更新完缓存时，给缓存加上较短的过期时间\n如何保证删除缓存操作⼀定能成功？\n重试机制\n引⼊消息队列\n如果应⽤删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。如果重试\n超过的⼀定次数，还是没有成功，就需要向业务层发送报错信息了。\n如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。\n订阅BINLog\n订阅 binlog ⽇志，拿到具体要操作的数据，然后再执⾏缓存删除。可以让删除服务模拟⾃⼰伪装成⼀个 MySQL 的\n从节点，向 MySQL 主节点发送 dump 请求，主节点收到请求后，就会开始推送 BINLog ，删除服务解析 BINLog\n字节流之后，转换为便于读取的结构化数据，再进⾏删除。\n什么是Redis, 具有哪些特点\nRedis是⼀个基于内存的数据库，读写速度⾮常快，通常被⽤作缓存、消息队列、分布式锁和键值存储数据库。它\n⽀持多种数据结构，如字符串、哈希表、列表、集合、有序集合等， Redis 还提供了分布式特性，可以将数据分布\n在多个节点上，以提⾼可扩展性和可⽤性。\nRedis为什么快\n基于内存操作：  传统的磁盘⽂件操作相⽐减少了IO，提⾼了操作的速度。\n⾼效的数据结构：Redis专⻔设计了STRING、LIST、HASH等⾼效的数据结构，依赖各种数据结构提升了读写\n的效率。\n单线程：单线程操作省去了上下⽂切换带来的开销和CPU的消耗，同时不存在资源竞争，避免了死锁现象的发\nI/O多路复⽤：采⽤I/O多路复⽤机制同时监听多个Socket，根据Socket上的事件来选择对应的事件处理器进⾏\n处理。\n为什么Redis是单线程\nRedis单线程指的是：⽹络请求模块使⽤单线程进⾏处理，其他模块仍⽤多个线程，单线程减少了上下⽂切换的开\n销，也减少了资源竞争⽽导致的锁的问题，提升了整体性能。\n官⽅答案是：因为CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存或者⽹络带宽。既然单线程容易实现，\n⽽且CPU不会成为瓶颈，那就顺理成章地采⽤单线程的⽅案了。\nRedis为什么⼜要引⼊多线程呢\n因为Redis的瓶颈不在内存，⽽是在⽹络I/O模块带来CPU的耗时，所以Redis6.0的多线程是⽤来处理⽹络I/O这部\n分，充分利⽤CPU资源，减少⽹络I/O阻塞带来的性能损耗。Redis引⼊的多线程 I/O 特性对性能提升⾄少是⼀倍以\nRedis数据类型 【常问】\nRedis 常⻅的五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）及 Zset(sorted\nset：有序集合)。",
    "question": "## Redis故障宕机",
    "answer": "针对 Redis 故障宕机⽽引发的缓存雪崩问题，常⻅的应对⽅法有下⾯这⼏种：\n服务熔断或请求限流机制：\n服务熔断：暂停业务应⽤对缓存服务的访问，直接返回错误\n请求限流：只将少部分请求发送到数据库进⾏处理，再多的请求就在⼊⼝直接拒绝服务\n构建Redis缓存⾼可靠集群：\n通过主从节点的⽅式构建 Redis 缓存⾼可靠集群，\n如果  Redis  缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于\nRedis 故障宕机⽽导致的缓存雪崩问题。\nconfig get maxmemory-policy\n什么是缓存击穿\n缓存击穿：当某个“热点数据”过期时，⼤量并发请求查询这个缓存不存在的数据时，导致请求直接访问数据库，增\n加数据库的负载。缓存击穿是缓存雪崩的⼀个⼦集，可以使⽤前⾯说到的⽅案，添加互斥锁或者后台更新缓存。\n什么是缓存穿透\n缓存穿透要访问的数据既不在缓存中，也不在数据库中，这样就⽆法构建缓存数据，后续所有的请求都会向数据库\n查找，增加数据库的负载。\n出现缓存穿透⼀般是因为以下两种原因：\n业务误操作，缓存中的数据和数据库中的数据都被误删除了\n恶意攻击，通过构造不存在的 key ⼤量访问缓存，导致对数据库的频繁查询。\n对应的解决办法\n3种：\n对⾮法请求做限制\n针对查询的数据，在缓存中设置⼀个空值或者默认值\n使⽤布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。\n如何保证数据库和缓存的⼀致性\nCache Aside策略\n细分为「读策略」和「写策略」\n写策略的步骤：\n更新数据库中的数据；\n删除缓存中的数据。\n读策略的步骤：\n如果读取的数据命中了缓存，则直接返回数据；\n如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写⼊到缓存，并且返回给⽤户。\n「先更新数据库 + 再删除缓存」的⽅案，是可以保证数据⼀致性的，但是每次更新数据的时候，缓存的数据都会被\n删除，这样会对缓存的命中率带来影响。\n如果业务对缓存命中率有很⾼的要求，我们可以采⽤「更新数据库 + 更新缓存（不是删除缓存，⽽是更新缓存）」\n的⽅案，因为更新缓存并不会出现缓存未命中的情况，但是在两个更新请求并发执⾏的时候，会出现数据不⼀致的\n问题，可以⽤以下⼿段来解决。\n在更新缓存前先加个分布式锁，保证同⼀时间只运⾏⼀个请求更新缓存，就会不会产⽣并发问题了。\n在更新完缓存时，给缓存加上较短的过期时间\n如何保证删除缓存操作⼀定能成功？\n重试机制\n引⼊消息队列\n如果应⽤删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。如果重试\n超过的⼀定次数，还是没有成功，就需要向业务层发送报错信息了。\n如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。\n订阅BINLog\n订阅 binlog ⽇志，拿到具体要操作的数据，然后再执⾏缓存删除。可以让删除服务模拟⾃⼰伪装成⼀个 MySQL 的\n从节点，向 MySQL 主节点发送 dump 请求，主节点收到请求后，就会开始推送 BINLog ，删除服务解析 BINLog\n字节流之后，转换为便于读取的结构化数据，再进⾏删除。\n什么是Redis, 具有哪些特点\nRedis是⼀个基于内存的数据库，读写速度⾮常快，通常被⽤作缓存、消息队列、分布式锁和键值存储数据库。它\n⽀持多种数据结构，如字符串、哈希表、列表、集合、有序集合等， Redis 还提供了分布式特性，可以将数据分布\n在多个节点上，以提⾼可扩展性和可⽤性。\nRedis为什么快\n基于内存操作：  传统的磁盘⽂件操作相⽐减少了IO，提⾼了操作的速度。\n⾼效的数据结构：Redis专⻔设计了STRING、LIST、HASH等⾼效的数据结构，依赖各种数据结构提升了读写\n的效率。\n单线程：单线程操作省去了上下⽂切换带来的开销和CPU的消耗，同时不存在资源竞争，避免了死锁现象的发\nI/O多路复⽤：采⽤I/O多路复⽤机制同时监听多个Socket，根据Socket上的事件来选择对应的事件处理器进⾏\n处理。\n为什么Redis是单线程\nRedis单线程指的是：⽹络请求模块使⽤单线程进⾏处理，其他模块仍⽤多个线程，单线程减少了上下⽂切换的开\n销，也减少了资源竞争⽽导致的锁的问题，提升了整体性能。\n官⽅答案是：因为CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存或者⽹络带宽。既然单线程容易实现，\n⽽且CPU不会成为瓶颈，那就顺理成章地采⽤单线程的⽅案了。\nRedis为什么⼜要引⼊多线程呢\n因为Redis的瓶颈不在内存，⽽是在⽹络I/O模块带来CPU的耗时，所以Redis6.0的多线程是⽤来处理⽹络I/O这部\n分，充分利⽤CPU资源，减少⽹络I/O阻塞带来的性能损耗。Redis引⼊的多线程 I/O 特性对性能提升⾄少是⼀倍以\nRedis数据类型 【常问】\nRedis 常⻅的五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）及 Zset(sorted\nset：有序集合)。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2111,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000145",
    "content": "问题，可以⽤以下⼿段来解决。\n\n在更新缓存前先加个分布式锁，保证同⼀时间只运⾏⼀个请求更新缓存，就会不会产⽣并发问题了。\n在更新完缓存时，给缓存加上较短的过期时间\n如何保证删除缓存操作⼀定能成功？\n重试机制\n引⼊消息队列\n如果应⽤删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。如果重试\n超过的⼀定次数，还是没有成功，就需要向业务层发送报错信息了。\n如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。\n订阅BINLog\n订阅 binlog ⽇志，拿到具体要操作的数据，然后再执⾏缓存删除。可以让删除服务模拟⾃⼰伪装成⼀个 MySQL 的\n从节点，向 MySQL 主节点发送 dump 请求，主节点收到请求后，就会开始推送 BINLog ，删除服务解析 BINLog\n字节流之后，转换为便于读取的结构化数据，再进⾏删除。",
    "question": "问题，可以⽤以下⼿段来解决。",
    "answer": "在更新缓存前先加个分布式锁，保证同⼀时间只运⾏⼀个请求更新缓存，就会不会产⽣并发问题了。\n在更新完缓存时，给缓存加上较短的过期时间\n如何保证删除缓存操作⼀定能成功？\n重试机制\n引⼊消息队列\n如果应⽤删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。如果重试\n超过的⼀定次数，还是没有成功，就需要向业务层发送报错信息了。\n如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。\n订阅BINLog\n订阅 binlog ⽇志，拿到具体要操作的数据，然后再执⾏缓存删除。可以让删除服务模拟⾃⼰伪装成⼀个 MySQL 的\n从节点，向 MySQL 主节点发送 dump 请求，主节点收到请求后，就会开始推送 BINLog ，删除服务解析 BINLog\n字节流之后，转换为便于读取的结构化数据，再进⾏删除。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 388,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000146",
    "content": "什么是Redis, 具有哪些特点\n\nRedis是⼀个基于内存的数据库，读写速度⾮常快，通常被⽤作缓存、消息队列、分布式锁和键值存储数据库。它\n⽀持多种数据结构，如字符串、哈希表、列表、集合、有序集合等， Redis 还提供了分布式特性，可以将数据分布\n在多个节点上，以提⾼可扩展性和可⽤性。\nRedis为什么快\n基于内存操作：  传统的磁盘⽂件操作相⽐减少了IO，提⾼了操作的速度。\n⾼效的数据结构：Redis专⻔设计了STRING、LIST、HASH等⾼效的数据结构，依赖各种数据结构提升了读写\n的效率。\n单线程：单线程操作省去了上下⽂切换带来的开销和CPU的消耗，同时不存在资源竞争，避免了死锁现象的发\nI/O多路复⽤：采⽤I/O多路复⽤机制同时监听多个Socket，根据Socket上的事件来选择对应的事件处理器进⾏\n处理。\n为什么Redis是单线程\nRedis单线程指的是：⽹络请求模块使⽤单线程进⾏处理，其他模块仍⽤多个线程，单线程减少了上下⽂切换的开\n销，也减少了资源竞争⽽导致的锁的问题，提升了整体性能。\n官⽅答案是：因为CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存或者⽹络带宽。既然单线程容易实现，\n⽽且CPU不会成为瓶颈，那就顺理成章地采⽤单线程的⽅案了。\nRedis为什么⼜要引⼊多线程呢\n因为Redis的瓶颈不在内存，⽽是在⽹络I/O模块带来CPU的耗时，所以Redis6.0的多线程是⽤来处理⽹络I/O这部\n分，充分利⽤CPU资源，减少⽹络I/O阻塞带来的性能损耗。Redis引⼊的多线程 I/O 特性对性能提升⾄少是⼀倍以\nRedis数据类型 【常问】\nRedis 常⻅的五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）及 Zset(sorted\nset：有序集合)。\n## 字符串STRING ：存储字符串数据，最基本的数据类型。\n## 哈希表HASH ：存储字段和值的映射，⽤于存储对象。\n## 列表LIST ：存储有序的字符串元素列表。\n## 集合SET ：存储唯⼀的字符串元素，⽆序。\n## 有序集合ZSET ：类似于集合，但每个元素都关联⼀个分数，可以按分数进⾏排序。\nRedis版本更新，⼜增加了⼏种数据类型，\nBitMap : 存储位的数据结构，可以⽤于处理⼀些位运算操作。\nHyperLogLog ：⽤于基数估算的数据结构，⽤于统计元素的唯⼀数量。\nGEO ： 存储地理位置信息的数据结构。\nStream ：专⻔为消息队列设计的数据类型。\nRedis数据类型的应⽤场景\nRedis 五种常⻅数据类型的应⽤场景：\nString  类型的应⽤场景：缓存对象、常规计数、分布式锁、共享session信息等。\nList 类型的应⽤场景：消息队列（有两个问题：1. ⽣产者需要⾃⾏实现全局唯⼀ ID；2. 不能以消费组形式消\n费数据）等。\nHash 类型：缓存对象、购物⻋等。\nSet  类型：聚合计算（并集、交集、差集）场景，⽐如点赞、共同关注、抽奖活动等。\nZset  类型：排序场景，⽐如排⾏榜、电话和姓名排序等。\nRedis  后续版本⼜⽀持四种数据类型，它们的应⽤场景如下：\nBitMap（2.2   版新增）：⼆值状态统计的场景，⽐如签到、判断⽤户登陆状态、连续签到⽤户总数等；\nHyperLogLog（2.8 版新增）：海量数据基数统计的场景，⽐如百万级⽹⻚ UV 计数等；\nGEO（3.2  版新增）：存储地理位置信息的场景，⽐如滴滴叫⻋；\nStream（5.0 版新增）：消息队列，相⽐于基于 List 类型实现的消息队列，有这两个特有的特性：⾃动⽣成\n全局唯⼀消息ID，⽀持以消费组形式消费数据。\nRedis底层使⽤了什么数据结构\n## SDS: 简单动态字符串：⽤于存储⼆进制安全的字符串数据，包含字符串的⻓度信息以及字符数组，⽀持动态\n扩展。\n## 双端链表：Redis中的List  就是⽤双端链表实现的，⽀持在两端进⾏元素的快速插⼊和删除。\n## 压缩列表：紧凑的由连续内存块组成的顺序型数据结构，可以在元素较少时减少内存占⽤。\n## 哈希表：⽤于实现 Redis 的哈希表数据类型。它使⽤两种不同的底层实现：ziplist 和哈希表，当哈希表的元素\n较少时，使⽤压缩列表（ziplist）来存储，⽽在元素较多时，切换到更为传统的哈希表结构。\n## 整数集合：整数集合是⼀种专⻔⽤于存储整数值的数据结构，通过紧凑的⼆进制表示，提⾼了整数存储的效\n率。整数集合被⽤于存储Redis中的集合数据结构的整数元素。\n## 跳表：跳跃表是⼀种在链表基础上改进过来的，实现了⼀种「多层」的有序链表，当数据量很⼤时，跳表的查\n找复杂度就是O(logN)。⽤于实现有序集合（Sorted Set）。\n## quicklist ： quicklist 就是双向链表 + 压缩列表组合，quicklist 就是⼀个链表，⽽链表中的每个元素⼜\n是⼀个压缩列表。\n## listpack ：listpack 没有压缩列表中记录前⼀个节点⻓度的字段，listpack 只记录当前节点的⻓度，当我们\n向 listpack 加⼊⼀个新元素的时候，不会影响其他节点的⻓度字段的变化，从⽽避免了压缩列表的连锁更新",
    "question": "什么是Redis, 具有哪些特点",
    "answer": "Redis是⼀个基于内存的数据库，读写速度⾮常快，通常被⽤作缓存、消息队列、分布式锁和键值存储数据库。它\n⽀持多种数据结构，如字符串、哈希表、列表、集合、有序集合等， Redis 还提供了分布式特性，可以将数据分布\n在多个节点上，以提⾼可扩展性和可⽤性。\nRedis为什么快\n基于内存操作：  传统的磁盘⽂件操作相⽐减少了IO，提⾼了操作的速度。\n⾼效的数据结构：Redis专⻔设计了STRING、LIST、HASH等⾼效的数据结构，依赖各种数据结构提升了读写\n的效率。\n单线程：单线程操作省去了上下⽂切换带来的开销和CPU的消耗，同时不存在资源竞争，避免了死锁现象的发\nI/O多路复⽤：采⽤I/O多路复⽤机制同时监听多个Socket，根据Socket上的事件来选择对应的事件处理器进⾏\n处理。\n为什么Redis是单线程\nRedis单线程指的是：⽹络请求模块使⽤单线程进⾏处理，其他模块仍⽤多个线程，单线程减少了上下⽂切换的开\n销，也减少了资源竞争⽽导致的锁的问题，提升了整体性能。\n官⽅答案是：因为CPU不是Redis的瓶颈，Redis的瓶颈最有可能是机器内存或者⽹络带宽。既然单线程容易实现，\n⽽且CPU不会成为瓶颈，那就顺理成章地采⽤单线程的⽅案了。\nRedis为什么⼜要引⼊多线程呢\n因为Redis的瓶颈不在内存，⽽是在⽹络I/O模块带来CPU的耗时，所以Redis6.0的多线程是⽤来处理⽹络I/O这部\n分，充分利⽤CPU资源，减少⽹络I/O阻塞带来的性能损耗。Redis引⼊的多线程 I/O 特性对性能提升⾄少是⼀倍以\nRedis数据类型 【常问】\nRedis 常⻅的五种数据类型：String（字符串），Hash（哈希），List（列表），Set（集合）及 Zset(sorted\nset：有序集合)。\n## 字符串STRING ：存储字符串数据，最基本的数据类型。\n## 哈希表HASH ：存储字段和值的映射，⽤于存储对象。\n## 列表LIST ：存储有序的字符串元素列表。\n## 集合SET ：存储唯⼀的字符串元素，⽆序。\n## 有序集合ZSET ：类似于集合，但每个元素都关联⼀个分数，可以按分数进⾏排序。\nRedis版本更新，⼜增加了⼏种数据类型，\nBitMap : 存储位的数据结构，可以⽤于处理⼀些位运算操作。\nHyperLogLog ：⽤于基数估算的数据结构，⽤于统计元素的唯⼀数量。\nGEO ： 存储地理位置信息的数据结构。\nStream ：专⻔为消息队列设计的数据类型。\nRedis数据类型的应⽤场景\nRedis 五种常⻅数据类型的应⽤场景：\nString  类型的应⽤场景：缓存对象、常规计数、分布式锁、共享session信息等。\nList 类型的应⽤场景：消息队列（有两个问题：1. ⽣产者需要⾃⾏实现全局唯⼀ ID；2. 不能以消费组形式消\n费数据）等。\nHash 类型：缓存对象、购物⻋等。\nSet  类型：聚合计算（并集、交集、差集）场景，⽐如点赞、共同关注、抽奖活动等。\nZset  类型：排序场景，⽐如排⾏榜、电话和姓名排序等。\nRedis  后续版本⼜⽀持四种数据类型，它们的应⽤场景如下：\nBitMap（2.2   版新增）：⼆值状态统计的场景，⽐如签到、判断⽤户登陆状态、连续签到⽤户总数等；\nHyperLogLog（2.8 版新增）：海量数据基数统计的场景，⽐如百万级⽹⻚ UV 计数等；\nGEO（3.2  版新增）：存储地理位置信息的场景，⽐如滴滴叫⻋；\nStream（5.0 版新增）：消息队列，相⽐于基于 List 类型实现的消息队列，有这两个特有的特性：⾃动⽣成\n全局唯⼀消息ID，⽀持以消费组形式消费数据。\nRedis底层使⽤了什么数据结构\n## SDS: 简单动态字符串：⽤于存储⼆进制安全的字符串数据，包含字符串的⻓度信息以及字符数组，⽀持动态\n扩展。\n## 双端链表：Redis中的List  就是⽤双端链表实现的，⽀持在两端进⾏元素的快速插⼊和删除。\n## 压缩列表：紧凑的由连续内存块组成的顺序型数据结构，可以在元素较少时减少内存占⽤。\n## 哈希表：⽤于实现 Redis 的哈希表数据类型。它使⽤两种不同的底层实现：ziplist 和哈希表，当哈希表的元素\n较少时，使⽤压缩列表（ziplist）来存储，⽽在元素较多时，切换到更为传统的哈希表结构。\n## 整数集合：整数集合是⼀种专⻔⽤于存储整数值的数据结构，通过紧凑的⼆进制表示，提⾼了整数存储的效\n率。整数集合被⽤于存储Redis中的集合数据结构的整数元素。\n## 跳表：跳跃表是⼀种在链表基础上改进过来的，实现了⼀种「多层」的有序链表，当数据量很⼤时，跳表的查\n找复杂度就是O(logN)。⽤于实现有序集合（Sorted Set）。\n## quicklist ： quicklist 就是双向链表 + 压缩列表组合，quicklist 就是⼀个链表，⽽链表中的每个元素⼜\n是⼀个压缩列表。\n## listpack ：listpack 没有压缩列表中记录前⼀个节点⻓度的字段，listpack 只记录当前节点的⻓度，当我们\n向 listpack 加⼊⼀个新元素的时候，不会影响其他节点的⻓度字段的变化，从⽽避免了压缩列表的连锁更新",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2198,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000147",
    "content": "## listpack ：listpack 没有压缩列表中记录前⼀个节点⻓度的字段，listpack 只记录当前节点的⻓度，当我们\n\n向 listpack 加⼊⼀个新元素的时候，不会影响其他节点的⻓度字段的变化，从⽽避免了压缩列表的连锁更新\n问题。\nRedis与MySQL的区别是什么\nRedis基于键值对，⽀持多种数据结构；⽽MySQL是⼀种关系型数据库，使⽤表来组织数据。\nRedis将数据存在内存中，通过持久化机制将数据写⼊磁盘，MySQL通常将数据存储在磁盘上。\nRedis不使⽤SQL，⽽是使⽤⾃⼰的命令集，MySQL使⽤SQL来进⾏数据查询和操作。\nRedis以⾼性能和低延迟为⽬标，适⽤于读多写少的应⽤场景，MySQL 适⽤于需要⽀持复杂查询、事务处\n理、拥有⼤规模数据集的场景。\nRedis 更适合处理⾼速、⾼并发的数据访问，以及需要复杂数据结构和功能的场景，在实际应⽤中，很多系统会同\n时使⽤ MySQL 和 Redis。\nRedis与Memcached有什么区别\nRedis⽀持更多的数据结构，⽽Memcached主要关注于简单的键值存储。\nRedis⽀持数据的持久性，⽽Memcached重启服务会导致数据丢失。\nRedis通常⽐Memcached更快，部分原因是由于Redis采⽤单线程模型，⽽Memcached使⽤多线程来处理并\n发请求\n总结来说Redis适⽤于需要更丰富数据结构和功能、需要数据持久性⽀持、以及对⾼可⽤性有要求的场景，⽽\nMemcached：适⽤于简单的键值对缓存。\nRedis为什么不使⽤红⿊树，⽽使⽤跳表",
    "question": "## listpack ：listpack 没有压缩列表中记录前⼀个节点⻓度的字段，listpack 只记录当前节点的⻓度，当我们",
    "answer": "向 listpack 加⼊⼀个新元素的时候，不会影响其他节点的⻓度字段的变化，从⽽避免了压缩列表的连锁更新\n问题。\nRedis与MySQL的区别是什么\nRedis基于键值对，⽀持多种数据结构；⽽MySQL是⼀种关系型数据库，使⽤表来组织数据。\nRedis将数据存在内存中，通过持久化机制将数据写⼊磁盘，MySQL通常将数据存储在磁盘上。\nRedis不使⽤SQL，⽽是使⽤⾃⼰的命令集，MySQL使⽤SQL来进⾏数据查询和操作。\nRedis以⾼性能和低延迟为⽬标，适⽤于读多写少的应⽤场景，MySQL 适⽤于需要⽀持复杂查询、事务处\n理、拥有⼤规模数据集的场景。\nRedis 更适合处理⾼速、⾼并发的数据访问，以及需要复杂数据结构和功能的场景，在实际应⽤中，很多系统会同\n时使⽤ MySQL 和 Redis。\nRedis与Memcached有什么区别\nRedis⽀持更多的数据结构，⽽Memcached主要关注于简单的键值存储。\nRedis⽀持数据的持久性，⽽Memcached重启服务会导致数据丢失。\nRedis通常⽐Memcached更快，部分原因是由于Redis采⽤单线程模型，⽽Memcached使⽤多线程来处理并\n发请求\n总结来说Redis适⽤于需要更丰富数据结构和功能、需要数据持久性⽀持、以及对⾼可⽤性有要求的场景，⽽\nMemcached：适⽤于简单的键值对缓存。\nRedis为什么不使⽤红⿊树，⽽使⽤跳表",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 676,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000148",
    "content": "Redis与MySQL的区别是什么\n\nRedis基于键值对，⽀持多种数据结构；⽽MySQL是⼀种关系型数据库，使⽤表来组织数据。\nRedis将数据存在内存中，通过持久化机制将数据写⼊磁盘，MySQL通常将数据存储在磁盘上。\nRedis不使⽤SQL，⽽是使⽤⾃⼰的命令集，MySQL使⽤SQL来进⾏数据查询和操作。\nRedis以⾼性能和低延迟为⽬标，适⽤于读多写少的应⽤场景，MySQL 适⽤于需要⽀持复杂查询、事务处\n理、拥有⼤规模数据集的场景。\nRedis 更适合处理⾼速、⾼并发的数据访问，以及需要复杂数据结构和功能的场景，在实际应⽤中，很多系统会同\n时使⽤ MySQL 和 Redis。",
    "question": "Redis与MySQL的区别是什么",
    "answer": "Redis基于键值对，⽀持多种数据结构；⽽MySQL是⼀种关系型数据库，使⽤表来组织数据。\nRedis将数据存在内存中，通过持久化机制将数据写⼊磁盘，MySQL通常将数据存储在磁盘上。\nRedis不使⽤SQL，⽽是使⽤⾃⼰的命令集，MySQL使⽤SQL来进⾏数据查询和操作。\nRedis以⾼性能和低延迟为⽬标，适⽤于读多写少的应⽤场景，MySQL 适⽤于需要⽀持复杂查询、事务处\n理、拥有⼤规模数据集的场景。\nRedis 更适合处理⾼速、⾼并发的数据访问，以及需要复杂数据结构和功能的场景，在实际应⽤中，很多系统会同\n时使⽤ MySQL 和 Redis。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 296,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000149",
    "content": "Redis与Memcached有什么区别\n\nRedis⽀持更多的数据结构，⽽Memcached主要关注于简单的键值存储。\nRedis⽀持数据的持久性，⽽Memcached重启服务会导致数据丢失。\nRedis通常⽐Memcached更快，部分原因是由于Redis采⽤单线程模型，⽽Memcached使⽤多线程来处理并\n发请求\n总结来说Redis适⽤于需要更丰富数据结构和功能、需要数据持久性⽀持、以及对⾼可⽤性有要求的场景，⽽\nMemcached：适⽤于简单的键值对缓存。\nRedis为什么不使⽤红⿊树，⽽使⽤跳表\n## 跳表相对于红⿊树来说实现更加简单\n## 跳表是⼀种相对简单的数据结构，更容易理解和调试。\n## 跳表对于范围查询的⽀持较好，这符合有序集合数据类型的特性。有序集合中的元素是有序的，⽽跳表天然⽀\n持按范围查找。\n## 跳表在插⼊和删除操作上的性能表现较好，尤其是在有序集合的场景下。\nRedis实现分布式锁\n使⽤SETNX 命令，只有插⼊的key不存在才插⼊，如果SETNX的key存在就插⼊失败，key插⼊成功代表加锁成功，\n否则加锁失败；解锁的过程就是将key删除，保证执⾏操作的客户端就是加锁的客户端，加锁时候要设\n置unique_value ，解锁的时候，要先判断锁的\n是否为加锁客户端，是才将\n键删除。\n此外要给锁设置⼀个过期时间，以免客户端拿到锁后发⽣异常，导致锁⼀直⽆法释放，可以指定\n过期时间。\n参数设置\nRedis持久化机制有哪些【常问】\nAOF  ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥；\nRDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；\n混合持久化⽅式：Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；\nAOF的三种写回策略\nAlways、Everysec 和  No，这三种策略在可靠性上是从⾼到低，⽽在性能上从低到⾼。\nAlways是每次写操作命令执⾏完后，同步将 AOF ⽇志数据写回硬盘；Everysec每次写操作命令执⾏完后，先将\n命令写⼊到 AOF ⽂件的内核缓冲区，然后每隔⼀秒将缓冲区⾥的内容写回到硬盘；No就是不控制写回硬盘的时\n机。每次写操作命令执⾏完后，先将命令写⼊到 AOF ⽂件的内核缓冲区，再由操作系统决定何时将缓冲区内容写\n回硬盘。\n什么是Redis事务\n在  Redis  中，事务是⼀组命令的有序执⾏序列，它们被⼀起执⾏，⽽在执⾏期间不会被其他客户端的命令打断。\nRedis 使⽤ MULTI 和 EXEC 命令来实现事务。\n基本流程如下：\nMULTI： 开始⼀个事务，标记事务的开始。\n在 MULTI 和 EXEC 之间，可以输⼊多个 Redis 命令。这些命令并不会⽴即执⾏，⽽是放⼊⼀个队列中，等待\n执⾏。\nEXEC： 执⾏所有在 MULTI 和 EXEC 之间输⼊的命令。这些命令作为⼀个事务⼀起执⾏，⽽且是按照顺序执\n⾏的。如果在 EXEC 之前发⽣错误，整个事务会被取消。\n如果事务执⾏成功，客户端会收到⼀个包含所有命令执⾏结果的数组。\n如果事务执⾏失败（⽐如在 MULTI 和 EXEC 之间发⽣了错误），那么事务中的所有命令都不会被执⾏，Redis\n将回滚到 MULTI 命令执⾏之前的状态。\n在事务中，还可以使⽤ WATCH 命令来监视⼀个或多个键。如果在事务执⾏期间监视的键被其他客户端修改了，事\n务就会被取消，从⽽确保事务执⾏的原⼦性。\nSET lock_key unique_value NX PX 10000\nunique_value\nlock_key\nEX/PX\nPSYNC",
    "question": "Redis与Memcached有什么区别",
    "answer": "Redis⽀持更多的数据结构，⽽Memcached主要关注于简单的键值存储。\nRedis⽀持数据的持久性，⽽Memcached重启服务会导致数据丢失。\nRedis通常⽐Memcached更快，部分原因是由于Redis采⽤单线程模型，⽽Memcached使⽤多线程来处理并\n发请求\n总结来说Redis适⽤于需要更丰富数据结构和功能、需要数据持久性⽀持、以及对⾼可⽤性有要求的场景，⽽\nMemcached：适⽤于简单的键值对缓存。\nRedis为什么不使⽤红⿊树，⽽使⽤跳表\n## 跳表相对于红⿊树来说实现更加简单\n## 跳表是⼀种相对简单的数据结构，更容易理解和调试。\n## 跳表对于范围查询的⽀持较好，这符合有序集合数据类型的特性。有序集合中的元素是有序的，⽽跳表天然⽀\n持按范围查找。\n## 跳表在插⼊和删除操作上的性能表现较好，尤其是在有序集合的场景下。\nRedis实现分布式锁\n使⽤SETNX 命令，只有插⼊的key不存在才插⼊，如果SETNX的key存在就插⼊失败，key插⼊成功代表加锁成功，\n否则加锁失败；解锁的过程就是将key删除，保证执⾏操作的客户端就是加锁的客户端，加锁时候要设\n置unique_value ，解锁的时候，要先判断锁的\n是否为加锁客户端，是才将\n键删除。\n此外要给锁设置⼀个过期时间，以免客户端拿到锁后发⽣异常，导致锁⼀直⽆法释放，可以指定\n过期时间。\n参数设置\nRedis持久化机制有哪些【常问】\nAOF  ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥；\nRDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；\n混合持久化⽅式：Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；\nAOF的三种写回策略\nAlways、Everysec 和  No，这三种策略在可靠性上是从⾼到低，⽽在性能上从低到⾼。\nAlways是每次写操作命令执⾏完后，同步将 AOF ⽇志数据写回硬盘；Everysec每次写操作命令执⾏完后，先将\n命令写⼊到 AOF ⽂件的内核缓冲区，然后每隔⼀秒将缓冲区⾥的内容写回到硬盘；No就是不控制写回硬盘的时\n机。每次写操作命令执⾏完后，先将命令写⼊到 AOF ⽂件的内核缓冲区，再由操作系统决定何时将缓冲区内容写\n回硬盘。\n什么是Redis事务\n在  Redis  中，事务是⼀组命令的有序执⾏序列，它们被⼀起执⾏，⽽在执⾏期间不会被其他客户端的命令打断。\nRedis 使⽤ MULTI 和 EXEC 命令来实现事务。\n基本流程如下：\nMULTI： 开始⼀个事务，标记事务的开始。\n在 MULTI 和 EXEC 之间，可以输⼊多个 Redis 命令。这些命令并不会⽴即执⾏，⽽是放⼊⼀个队列中，等待\n执⾏。\nEXEC： 执⾏所有在 MULTI 和 EXEC 之间输⼊的命令。这些命令作为⼀个事务⼀起执⾏，⽽且是按照顺序执\n⾏的。如果在 EXEC 之前发⽣错误，整个事务会被取消。\n如果事务执⾏成功，客户端会收到⼀个包含所有命令执⾏结果的数组。\n如果事务执⾏失败（⽐如在 MULTI 和 EXEC 之间发⽣了错误），那么事务中的所有命令都不会被执⾏，Redis\n将回滚到 MULTI 命令执⾏之前的状态。\n在事务中，还可以使⽤ WATCH 命令来监视⼀个或多个键。如果在事务执⾏期间监视的键被其他客户端修改了，事\n务就会被取消，从⽽确保事务执⾏的原⼦性。\nSET lock_key unique_value NX PX 10000\nunique_value\nlock_key\nEX/PX\nPSYNC",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1518,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000150",
    "content": "## 跳表在插⼊和删除操作上的性能表现较好，尤其是在有序集合的场景下。\n\nRedis实现分布式锁\n使⽤SETNX 命令，只有插⼊的key不存在才插⼊，如果SETNX的key存在就插⼊失败，key插⼊成功代表加锁成功，\n否则加锁失败；解锁的过程就是将key删除，保证执⾏操作的客户端就是加锁的客户端，加锁时候要设\n置unique_value ，解锁的时候，要先判断锁的\n是否为加锁客户端，是才将\n键删除。\n此外要给锁设置⼀个过期时间，以免客户端拿到锁后发⽣异常，导致锁⼀直⽆法释放，可以指定\n过期时间。\n参数设置\nRedis持久化机制有哪些【常问】\nAOF  ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥；\nRDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；\n混合持久化⽅式：Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；\nAOF的三种写回策略\nAlways、Everysec 和  No，这三种策略在可靠性上是从⾼到低，⽽在性能上从低到⾼。\nAlways是每次写操作命令执⾏完后，同步将 AOF ⽇志数据写回硬盘；Everysec每次写操作命令执⾏完后，先将\n命令写⼊到 AOF ⽂件的内核缓冲区，然后每隔⼀秒将缓冲区⾥的内容写回到硬盘；No就是不控制写回硬盘的时\n机。每次写操作命令执⾏完后，先将命令写⼊到 AOF ⽂件的内核缓冲区，再由操作系统决定何时将缓冲区内容写\n回硬盘。\n什么是Redis事务\n在  Redis  中，事务是⼀组命令的有序执⾏序列，它们被⼀起执⾏，⽽在执⾏期间不会被其他客户端的命令打断。\nRedis 使⽤ MULTI 和 EXEC 命令来实现事务。\n基本流程如下：\nMULTI： 开始⼀个事务，标记事务的开始。\n在 MULTI 和 EXEC 之间，可以输⼊多个 Redis 命令。这些命令并不会⽴即执⾏，⽽是放⼊⼀个队列中，等待\n执⾏。\nEXEC： 执⾏所有在 MULTI 和 EXEC 之间输⼊的命令。这些命令作为⼀个事务⼀起执⾏，⽽且是按照顺序执\n⾏的。如果在 EXEC 之前发⽣错误，整个事务会被取消。\n如果事务执⾏成功，客户端会收到⼀个包含所有命令执⾏结果的数组。\n如果事务执⾏失败（⽐如在 MULTI 和 EXEC 之间发⽣了错误），那么事务中的所有命令都不会被执⾏，Redis\n将回滚到 MULTI 命令执⾏之前的状态。\n在事务中，还可以使⽤ WATCH 命令来监视⼀个或多个键。如果在事务执⾏期间监视的键被其他客户端修改了，事\n务就会被取消，从⽽确保事务执⾏的原⼦性。\nSET lock_key unique_value NX PX 10000\nunique_value\nlock_key\nEX/PX\nPSYNC\n缓存中的热点数据和冷数据是什么\n热数据指的就是访问次数较多的数据\n冷数据就是访问很少或者从不访问的数据\n只有热数据，缓存才有价值。\nRedis集群模式有哪些\n主从复制：将⼀个Redis实例的数据复制到其他实例，其中⼀个是主节点，其余是从节点。主节点将写操作传\n播到所有从节点。\n哨兵：监控Redis实例的状态，发现主节点的故障并⾃动进⾏故障转移。\n切⽚集群：将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖\nRedis的哨兵是⽤来做什么的\nRedis哨兵⽤于监控Redis实例的状态，发现主节点的故障并⾃动进⾏故障转移。\n监控：监控 Redis 主服务器和从服务器的状态，包括连接状态、是否能够执⾏命令、是否有持久性问题等\n故障转移：当 Sentinel （哨兵）发现主服务器不可⽤时（⽐如宕机），它会通过⼀定的选举机制选择⼀个从\n服务器升级为新的主服务器，然后通知其他从服务器将其切换到新的主服务器。\n主从模式的同步过程\n连接协商：从服务器先发送命令给主服务器表示要进⾏数据同步，命令内容包括主服务器的runID和复制进度\n两个参数，主服务器收到命令之后会给从服务响应命令，响应包括主服务器的runID和复制进度。从服务器收\n到响应之后会记录这两个值。\n主从数据同步：主服务器执⾏\n命令，⽣成 RDB 快照⽂件。这个⽂件包含了主服务器当前时刻的数据\n状态，将⽣成的 RDB 快照⽂件发送给从服务器。从服务器接收到 RDB 快照⽂件后，通过\n载到内存中，从服务器的数据现在与主服务器的数据⼀致。\n命令将其加\n主服务器开启增量同步：主服务器将开启  TCP  连接，等待从服务器连接，并开始记录所有的写命令，将它们\n发送给从服务器，从服务器连接到主服务器，执⾏\n命令，开始接收主服务器发送的增量同步命令，从\n服务器按顺序执⾏主服务器发送的所有写命令，确保与主服务器同步。\n哨兵的⼯作原理 【常问】\n判断节点是否存活\n每个哨兵定期向 Redis 服务器发送 PING 命令，以检测服务器是否处于活跃状态。如果哨兵连续⼀定次数未收到服\n务器的响应，就认为服务器主观下线。然后哨兵会从从节点中选择⼀个作为主节点。\n选出新主节点\n在发现主服务器下线后，哨兵会协调选举⼀个新的主服务器。这个过程中，哨兵会考虑每个可⽤的从服务器，选择\n⼀个作为新的主服务器，并将其他从服务器配置为复制新的主服务器。\n具体过程：\n选择候选从服务器： 哨兵会从可⽤的从服务器中选择⼀组候选服务器，通常选择复制偏移量（replication\noffset）最⼤的从服务器。\n计算投票：   每个哨兵为每个候选从服务器投票。投票的考量因素包括从服务器的复制偏移量、连接质量、优\nBGSAVE\nLOAD\n先级等。\n达成共识：  哨兵们根据投票结果达成共识，选择⼀个从服务器作为新的主服务器。这通常需要获得多数哨兵的\n同意。\n更新配置信息\n⼀旦新的主服务器被选出，哨兵会更新 Redis 集群的配置信息，包括将新的主服务器的地址和端⼝通知给其他哨兵\n和客户端。\n通知客户端\n哨兵会向客户端发送通知，告知客户端新的主服务器的位置，以便客户端能够重新连接。\n缓存雪崩、击穿、穿透和解决办法【常问】",
    "question": "## 跳表在插⼊和删除操作上的性能表现较好，尤其是在有序集合的场景下。",
    "answer": "Redis实现分布式锁\n使⽤SETNX 命令，只有插⼊的key不存在才插⼊，如果SETNX的key存在就插⼊失败，key插⼊成功代表加锁成功，\n否则加锁失败；解锁的过程就是将key删除，保证执⾏操作的客户端就是加锁的客户端，加锁时候要设\n置unique_value ，解锁的时候，要先判断锁的\n是否为加锁客户端，是才将\n键删除。\n此外要给锁设置⼀个过期时间，以免客户端拿到锁后发⽣异常，导致锁⼀直⽆法释放，可以指定\n过期时间。\n参数设置\nRedis持久化机制有哪些【常问】\nAOF  ⽇志：每执⾏⼀条写操作命令，就把该命令以追加的⽅式写⼊到⼀个⽂件⾥；\nRDB 快照：将某⼀时刻的内存数据，以⼆进制的⽅式写⼊磁盘；\n混合持久化⽅式：Redis 4.0 新增的⽅式，集成了 AOF 和 RBD 的优点；\nAOF的三种写回策略\nAlways、Everysec 和  No，这三种策略在可靠性上是从⾼到低，⽽在性能上从低到⾼。\nAlways是每次写操作命令执⾏完后，同步将 AOF ⽇志数据写回硬盘；Everysec每次写操作命令执⾏完后，先将\n命令写⼊到 AOF ⽂件的内核缓冲区，然后每隔⼀秒将缓冲区⾥的内容写回到硬盘；No就是不控制写回硬盘的时\n机。每次写操作命令执⾏完后，先将命令写⼊到 AOF ⽂件的内核缓冲区，再由操作系统决定何时将缓冲区内容写\n回硬盘。\n什么是Redis事务\n在  Redis  中，事务是⼀组命令的有序执⾏序列，它们被⼀起执⾏，⽽在执⾏期间不会被其他客户端的命令打断。\nRedis 使⽤ MULTI 和 EXEC 命令来实现事务。\n基本流程如下：\nMULTI： 开始⼀个事务，标记事务的开始。\n在 MULTI 和 EXEC 之间，可以输⼊多个 Redis 命令。这些命令并不会⽴即执⾏，⽽是放⼊⼀个队列中，等待\n执⾏。\nEXEC： 执⾏所有在 MULTI 和 EXEC 之间输⼊的命令。这些命令作为⼀个事务⼀起执⾏，⽽且是按照顺序执\n⾏的。如果在 EXEC 之前发⽣错误，整个事务会被取消。\n如果事务执⾏成功，客户端会收到⼀个包含所有命令执⾏结果的数组。\n如果事务执⾏失败（⽐如在 MULTI 和 EXEC 之间发⽣了错误），那么事务中的所有命令都不会被执⾏，Redis\n将回滚到 MULTI 命令执⾏之前的状态。\n在事务中，还可以使⽤ WATCH 命令来监视⼀个或多个键。如果在事务执⾏期间监视的键被其他客户端修改了，事\n务就会被取消，从⽽确保事务执⾏的原⼦性。\nSET lock_key unique_value NX PX 10000\nunique_value\nlock_key\nEX/PX\nPSYNC\n缓存中的热点数据和冷数据是什么\n热数据指的就是访问次数较多的数据\n冷数据就是访问很少或者从不访问的数据\n只有热数据，缓存才有价值。\nRedis集群模式有哪些\n主从复制：将⼀个Redis实例的数据复制到其他实例，其中⼀个是主节点，其余是从节点。主节点将写操作传\n播到所有从节点。\n哨兵：监控Redis实例的状态，发现主节点的故障并⾃动进⾏故障转移。\n切⽚集群：将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖\nRedis的哨兵是⽤来做什么的\nRedis哨兵⽤于监控Redis实例的状态，发现主节点的故障并⾃动进⾏故障转移。\n监控：监控 Redis 主服务器和从服务器的状态，包括连接状态、是否能够执⾏命令、是否有持久性问题等\n故障转移：当 Sentinel （哨兵）发现主服务器不可⽤时（⽐如宕机），它会通过⼀定的选举机制选择⼀个从\n服务器升级为新的主服务器，然后通知其他从服务器将其切换到新的主服务器。\n主从模式的同步过程\n连接协商：从服务器先发送命令给主服务器表示要进⾏数据同步，命令内容包括主服务器的runID和复制进度\n两个参数，主服务器收到命令之后会给从服务响应命令，响应包括主服务器的runID和复制进度。从服务器收\n到响应之后会记录这两个值。\n主从数据同步：主服务器执⾏\n命令，⽣成 RDB 快照⽂件。这个⽂件包含了主服务器当前时刻的数据\n状态，将⽣成的 RDB 快照⽂件发送给从服务器。从服务器接收到 RDB 快照⽂件后，通过\n载到内存中，从服务器的数据现在与主服务器的数据⼀致。\n命令将其加\n主服务器开启增量同步：主服务器将开启  TCP  连接，等待从服务器连接，并开始记录所有的写命令，将它们\n发送给从服务器，从服务器连接到主服务器，执⾏\n命令，开始接收主服务器发送的增量同步命令，从\n服务器按顺序执⾏主服务器发送的所有写命令，确保与主服务器同步。\n哨兵的⼯作原理 【常问】\n判断节点是否存活\n每个哨兵定期向 Redis 服务器发送 PING 命令，以检测服务器是否处于活跃状态。如果哨兵连续⼀定次数未收到服\n务器的响应，就认为服务器主观下线。然后哨兵会从从节点中选择⼀个作为主节点。\n选出新主节点\n在发现主服务器下线后，哨兵会协调选举⼀个新的主服务器。这个过程中，哨兵会考虑每个可⽤的从服务器，选择\n⼀个作为新的主服务器，并将其他从服务器配置为复制新的主服务器。\n具体过程：\n选择候选从服务器： 哨兵会从可⽤的从服务器中选择⼀组候选服务器，通常选择复制偏移量（replication\noffset）最⼤的从服务器。\n计算投票：   每个哨兵为每个候选从服务器投票。投票的考量因素包括从服务器的复制偏移量、连接质量、优\nBGSAVE\nLOAD\n先级等。\n达成共识：  哨兵们根据投票结果达成共识，选择⼀个从服务器作为新的主服务器。这通常需要获得多数哨兵的\n同意。\n更新配置信息\n⼀旦新的主服务器被选出，哨兵会更新 Redis 集群的配置信息，包括将新的主服务器的地址和端⼝通知给其他哨兵\n和客户端。\n通知客户端\n哨兵会向客户端发送通知，告知客户端新的主服务器的位置，以便客户端能够重新连接。\n缓存雪崩、击穿、穿透和解决办法【常问】",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2485,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000151",
    "content": "缓存中的热点数据和冷数据是什么\n\n热数据指的就是访问次数较多的数据\n冷数据就是访问很少或者从不访问的数据\n只有热数据，缓存才有价值。",
    "question": "缓存中的热点数据和冷数据是什么",
    "answer": "热数据指的就是访问次数较多的数据\n冷数据就是访问很少或者从不访问的数据\n只有热数据，缓存才有价值。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 66,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000152",
    "content": "Redis集群模式有哪些\n\n主从复制：将⼀个Redis实例的数据复制到其他实例，其中⼀个是主节点，其余是从节点。主节点将写操作传\n播到所有从节点。\n哨兵：监控Redis实例的状态，发现主节点的故障并⾃动进⾏故障转移。\n切⽚集群：将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖\nRedis的哨兵是⽤来做什么的\nRedis哨兵⽤于监控Redis实例的状态，发现主节点的故障并⾃动进⾏故障转移。\n监控：监控 Redis 主服务器和从服务器的状态，包括连接状态、是否能够执⾏命令、是否有持久性问题等\n故障转移：当 Sentinel （哨兵）发现主服务器不可⽤时（⽐如宕机），它会通过⼀定的选举机制选择⼀个从\n服务器升级为新的主服务器，然后通知其他从服务器将其切换到新的主服务器。\n主从模式的同步过程\n连接协商：从服务器先发送命令给主服务器表示要进⾏数据同步，命令内容包括主服务器的runID和复制进度\n两个参数，主服务器收到命令之后会给从服务响应命令，响应包括主服务器的runID和复制进度。从服务器收\n到响应之后会记录这两个值。\n主从数据同步：主服务器执⾏\n命令，⽣成 RDB 快照⽂件。这个⽂件包含了主服务器当前时刻的数据\n状态，将⽣成的 RDB 快照⽂件发送给从服务器。从服务器接收到 RDB 快照⽂件后，通过\n载到内存中，从服务器的数据现在与主服务器的数据⼀致。\n命令将其加\n主服务器开启增量同步：主服务器将开启  TCP  连接，等待从服务器连接，并开始记录所有的写命令，将它们\n发送给从服务器，从服务器连接到主服务器，执⾏\n命令，开始接收主服务器发送的增量同步命令，从\n服务器按顺序执⾏主服务器发送的所有写命令，确保与主服务器同步。\n哨兵的⼯作原理 【常问】\n判断节点是否存活\n每个哨兵定期向 Redis 服务器发送 PING 命令，以检测服务器是否处于活跃状态。如果哨兵连续⼀定次数未收到服\n务器的响应，就认为服务器主观下线。然后哨兵会从从节点中选择⼀个作为主节点。\n选出新主节点\n在发现主服务器下线后，哨兵会协调选举⼀个新的主服务器。这个过程中，哨兵会考虑每个可⽤的从服务器，选择\n⼀个作为新的主服务器，并将其他从服务器配置为复制新的主服务器。\n具体过程：\n选择候选从服务器： 哨兵会从可⽤的从服务器中选择⼀组候选服务器，通常选择复制偏移量（replication\noffset）最⼤的从服务器。\n计算投票：   每个哨兵为每个候选从服务器投票。投票的考量因素包括从服务器的复制偏移量、连接质量、优\nBGSAVE\nLOAD\n先级等。\n达成共识：  哨兵们根据投票结果达成共识，选择⼀个从服务器作为新的主服务器。这通常需要获得多数哨兵的\n同意。\n更新配置信息\n⼀旦新的主服务器被选出，哨兵会更新 Redis 集群的配置信息，包括将新的主服务器的地址和端⼝通知给其他哨兵\n和客户端。\n通知客户端\n哨兵会向客户端发送通知，告知客户端新的主服务器的位置，以便客户端能够重新连接。\n缓存雪崩、击穿、穿透和解决办法【常问】\n## 缓存雪崩是指在某个时间点，⼤量缓存同时失效，导致请求直接访问数据库或其他后端系统，增加了系统负\n对于缓存雪崩，可以通过合理设置缓存的过期时间，分散缓存失效时间点，或者采⽤永不过期的策略，再结合\n定期更新缓存。\n## 缓存击穿是指⼀个缓存中不存在但是数据库中存在的数据，当有⼤量并发请求查询这个缓存不存在的数据时，\n导致请求直接访问数据库，增加数据库的负载。典型的场景是当⼀个缓存中的数据过期或被清理，⽽此时有⼤\n量请求访问这个缓存中不存在的数据，导致⼤量请求直接访问底层存储系统。\n对于缓存击穿，可以采⽤互斥锁（例如分布式锁）或者在查询数据库前先检查缓存是否存在，如果不存在再允\n许查询数据库，并将查询结果写⼊缓存。\n## 缓存穿透是指查询⼀个在缓存和数据库都不存在的数据，这个数据始终⽆法被缓存，导致每次请求都直接访问\n数据库，增加数据库的负载。典型的情况是攻击者可能通过构造不存在的 key ⼤量访问缓存，导致对数据库的\n频繁查询。\n对于缓存穿透，可以采⽤布隆过滤器等⼿段来过滤掉恶意请求，或者在查询数据库前先进⾏参数的合法性校\n如何保证数据库和缓存的⼀致性【常问】\nCache Aside\n原理：先从缓存中读取数据，如果没有就再去数据库⾥⾯读数据，然后把数据放回缓存中，如果缓存中可以找\n到数据就直接返回数据；更新数据的时候先把数据持久化到数据库，然后再让缓存失效。",
    "question": "Redis集群模式有哪些",
    "answer": "主从复制：将⼀个Redis实例的数据复制到其他实例，其中⼀个是主节点，其余是从节点。主节点将写操作传\n播到所有从节点。\n哨兵：监控Redis实例的状态，发现主节点的故障并⾃动进⾏故障转移。\n切⽚集群：将数据分布在不同的服务器上，以此来降低系统对单主节点的依赖\nRedis的哨兵是⽤来做什么的\nRedis哨兵⽤于监控Redis实例的状态，发现主节点的故障并⾃动进⾏故障转移。\n监控：监控 Redis 主服务器和从服务器的状态，包括连接状态、是否能够执⾏命令、是否有持久性问题等\n故障转移：当 Sentinel （哨兵）发现主服务器不可⽤时（⽐如宕机），它会通过⼀定的选举机制选择⼀个从\n服务器升级为新的主服务器，然后通知其他从服务器将其切换到新的主服务器。\n主从模式的同步过程\n连接协商：从服务器先发送命令给主服务器表示要进⾏数据同步，命令内容包括主服务器的runID和复制进度\n两个参数，主服务器收到命令之后会给从服务响应命令，响应包括主服务器的runID和复制进度。从服务器收\n到响应之后会记录这两个值。\n主从数据同步：主服务器执⾏\n命令，⽣成 RDB 快照⽂件。这个⽂件包含了主服务器当前时刻的数据\n状态，将⽣成的 RDB 快照⽂件发送给从服务器。从服务器接收到 RDB 快照⽂件后，通过\n载到内存中，从服务器的数据现在与主服务器的数据⼀致。\n命令将其加\n主服务器开启增量同步：主服务器将开启  TCP  连接，等待从服务器连接，并开始记录所有的写命令，将它们\n发送给从服务器，从服务器连接到主服务器，执⾏\n命令，开始接收主服务器发送的增量同步命令，从\n服务器按顺序执⾏主服务器发送的所有写命令，确保与主服务器同步。\n哨兵的⼯作原理 【常问】\n判断节点是否存活\n每个哨兵定期向 Redis 服务器发送 PING 命令，以检测服务器是否处于活跃状态。如果哨兵连续⼀定次数未收到服\n务器的响应，就认为服务器主观下线。然后哨兵会从从节点中选择⼀个作为主节点。\n选出新主节点\n在发现主服务器下线后，哨兵会协调选举⼀个新的主服务器。这个过程中，哨兵会考虑每个可⽤的从服务器，选择\n⼀个作为新的主服务器，并将其他从服务器配置为复制新的主服务器。\n具体过程：\n选择候选从服务器： 哨兵会从可⽤的从服务器中选择⼀组候选服务器，通常选择复制偏移量（replication\noffset）最⼤的从服务器。\n计算投票：   每个哨兵为每个候选从服务器投票。投票的考量因素包括从服务器的复制偏移量、连接质量、优\nBGSAVE\nLOAD\n先级等。\n达成共识：  哨兵们根据投票结果达成共识，选择⼀个从服务器作为新的主服务器。这通常需要获得多数哨兵的\n同意。\n更新配置信息\n⼀旦新的主服务器被选出，哨兵会更新 Redis 集群的配置信息，包括将新的主服务器的地址和端⼝通知给其他哨兵\n和客户端。\n通知客户端\n哨兵会向客户端发送通知，告知客户端新的主服务器的位置，以便客户端能够重新连接。\n缓存雪崩、击穿、穿透和解决办法【常问】\n## 缓存雪崩是指在某个时间点，⼤量缓存同时失效，导致请求直接访问数据库或其他后端系统，增加了系统负\n对于缓存雪崩，可以通过合理设置缓存的过期时间，分散缓存失效时间点，或者采⽤永不过期的策略，再结合\n定期更新缓存。\n## 缓存击穿是指⼀个缓存中不存在但是数据库中存在的数据，当有⼤量并发请求查询这个缓存不存在的数据时，\n导致请求直接访问数据库，增加数据库的负载。典型的场景是当⼀个缓存中的数据过期或被清理，⽽此时有⼤\n量请求访问这个缓存中不存在的数据，导致⼤量请求直接访问底层存储系统。\n对于缓存击穿，可以采⽤互斥锁（例如分布式锁）或者在查询数据库前先检查缓存是否存在，如果不存在再允\n许查询数据库，并将查询结果写⼊缓存。\n## 缓存穿透是指查询⼀个在缓存和数据库都不存在的数据，这个数据始终⽆法被缓存，导致每次请求都直接访问\n数据库，增加数据库的负载。典型的情况是攻击者可能通过构造不存在的 key ⼤量访问缓存，导致对数据库的\n频繁查询。\n对于缓存穿透，可以采⽤布隆过滤器等⼿段来过滤掉恶意请求，或者在查询数据库前先进⾏参数的合法性校\n如何保证数据库和缓存的⼀致性【常问】\nCache Aside\n原理：先从缓存中读取数据，如果没有就再去数据库⾥⾯读数据，然后把数据放回缓存中，如果缓存中可以找\n到数据就直接返回数据；更新数据的时候先把数据持久化到数据库，然后再让缓存失效。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1855,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000153",
    "content": "## 缓存穿透是指查询⼀个在缓存和数据库都不存在的数据，这个数据始终⽆法被缓存，导致每次请求都直接访问\n\n数据库，增加数据库的负载。典型的情况是攻击者可能通过构造不存在的 key ⼤量访问缓存，导致对数据库的\n频繁查询。\n对于缓存穿透，可以采⽤布隆过滤器等⼿段来过滤掉恶意请求，或者在查询数据库前先进⾏参数的合法性校\n如何保证数据库和缓存的⼀致性【常问】\nCache Aside\n原理：先从缓存中读取数据，如果没有就再去数据库⾥⾯读数据，然后把数据放回缓存中，如果缓存中可以找\n到数据就直接返回数据；更新数据的时候先把数据持久化到数据库，然后再让缓存失效。\n问题：假如有两个操作⼀个更新⼀个查询，第⼀个操作先更新数据库，还没来及删除数据库，查询操作可能拿\n到的就是旧的数据；更新操作⻢上让缓存失效了，所以后续的查询可以保证数据的⼀致性；还有的问题就是有\n⼀个是读操作没有命中缓存，然后就到数据库中取数据，此时来了⼀个写操作，写完数据库后，让缓存失效，\n然后，之前的那个读操作再把⽼的数据放进去，也会造成脏数据。\n可⾏性：出现上述问题的概率其实⾮常低，需要同时达成读缓存时缓存失效并且有并发写的操作。数据库读写\n要⽐缓存慢得多，所以读操作在写操作之前进⼊数据库，并且在写操作之后更新，概率⽐较低。\nRead/Write Through\n原理：Read/Write   Through原理是把更新数据库（Repository）的操作由缓存代理，应⽤认为后端是⼀个单\n⼀的存储，⽽存储⾃⼰维护⾃⼰的缓存。\nRead Through：就是在查询操作中更新缓存，也就是说，当缓存失效的时候，Cache Aside策略是由调⽤⽅\n负责把数据加载⼊缓存，⽽Read  Through则⽤缓存服务⾃⼰来加载，从⽽对调⽤⽅是透明的。\nWrite Through：当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓\n存，则更新缓存，然后再由缓存⾃⼰更新数据库（这是⼀个同步操作）。\nWrite Behind\n原理：在更新数据的时候，只更新缓存，不更新数据库，⽽缓存会异步地批量更新数据库。这个设计的好处就\n是让数据的I/O操作⾮常快，带来的问题是，数据不是强⼀致性的，⽽且可能会丢。\n第⼆步失效问题：这种可能性极⼩，缓存删除只是标记⼀下⽆效的软删除，可以看作不耗时间。如果会出问\n题，⼀般程序在写数据库那⾥就没有完成：故意在写完数据库后，休眠很⻓时间再来删除缓存。\nRedis过期删除策略有哪些\n定时删除：设置 key 的过期时间，当时间到达时，⾃动执⾏ key 的删除操作。\n惰性删除： 每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n定期删除：每隔⼀段时间「随机」从数据库中取出⼀定数量的 key 进⾏检查，并删除其中的过期key。\nRedis 选择「惰性删除+定期删除」这两种策略配和使⽤\n在应⽤中是怎么使⽤Redis的\n可以⽤作缓存层，存储频繁访问的数据，提⾼访问速度。\n⽤作消息队列，通过发布订阅模式传递消息。\n存储会话数据、计数器等。\n设计模式\n想要了解更多设计模式，可以查看卡码⽹设计模式精讲\n常⽤设计模式\n单例模式\n单例设计模式是⼀种确保⼀个类只有⼀个实例，并提供⼀个全局访问点来访问该实例的创建模式。\n有些实例，全局只需要⼀个就够了，使⽤单例模式就可以避免⼀个全局使⽤的类，频繁的创建与销毁，耗费系统资\n关键概念",
    "question": "## 缓存穿透是指查询⼀个在缓存和数据库都不存在的数据，这个数据始终⽆法被缓存，导致每次请求都直接访问",
    "answer": "数据库，增加数据库的负载。典型的情况是攻击者可能通过构造不存在的 key ⼤量访问缓存，导致对数据库的\n频繁查询。\n对于缓存穿透，可以采⽤布隆过滤器等⼿段来过滤掉恶意请求，或者在查询数据库前先进⾏参数的合法性校\n如何保证数据库和缓存的⼀致性【常问】\nCache Aside\n原理：先从缓存中读取数据，如果没有就再去数据库⾥⾯读数据，然后把数据放回缓存中，如果缓存中可以找\n到数据就直接返回数据；更新数据的时候先把数据持久化到数据库，然后再让缓存失效。\n问题：假如有两个操作⼀个更新⼀个查询，第⼀个操作先更新数据库，还没来及删除数据库，查询操作可能拿\n到的就是旧的数据；更新操作⻢上让缓存失效了，所以后续的查询可以保证数据的⼀致性；还有的问题就是有\n⼀个是读操作没有命中缓存，然后就到数据库中取数据，此时来了⼀个写操作，写完数据库后，让缓存失效，\n然后，之前的那个读操作再把⽼的数据放进去，也会造成脏数据。\n可⾏性：出现上述问题的概率其实⾮常低，需要同时达成读缓存时缓存失效并且有并发写的操作。数据库读写\n要⽐缓存慢得多，所以读操作在写操作之前进⼊数据库，并且在写操作之后更新，概率⽐较低。\nRead/Write Through\n原理：Read/Write   Through原理是把更新数据库（Repository）的操作由缓存代理，应⽤认为后端是⼀个单\n⼀的存储，⽽存储⾃⼰维护⾃⼰的缓存。\nRead Through：就是在查询操作中更新缓存，也就是说，当缓存失效的时候，Cache Aside策略是由调⽤⽅\n负责把数据加载⼊缓存，⽽Read  Through则⽤缓存服务⾃⼰来加载，从⽽对调⽤⽅是透明的。\nWrite Through：当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓\n存，则更新缓存，然后再由缓存⾃⼰更新数据库（这是⼀个同步操作）。\nWrite Behind\n原理：在更新数据的时候，只更新缓存，不更新数据库，⽽缓存会异步地批量更新数据库。这个设计的好处就\n是让数据的I/O操作⾮常快，带来的问题是，数据不是强⼀致性的，⽽且可能会丢。\n第⼆步失效问题：这种可能性极⼩，缓存删除只是标记⼀下⽆效的软删除，可以看作不耗时间。如果会出问\n题，⼀般程序在写数据库那⾥就没有完成：故意在写完数据库后，休眠很⻓时间再来删除缓存。\nRedis过期删除策略有哪些\n定时删除：设置 key 的过期时间，当时间到达时，⾃动执⾏ key 的删除操作。\n惰性删除： 每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n定期删除：每隔⼀段时间「随机」从数据库中取出⼀定数量的 key 进⾏检查，并删除其中的过期key。\nRedis 选择「惰性删除+定期删除」这两种策略配和使⽤\n在应⽤中是怎么使⽤Redis的\n可以⽤作缓存层，存储频繁访问的数据，提⾼访问速度。\n⽤作消息队列，通过发布订阅模式传递消息。\n存储会话数据、计数器等。\n设计模式\n想要了解更多设计模式，可以查看卡码⽹设计模式精讲\n常⽤设计模式\n单例模式\n单例设计模式是⼀种确保⼀个类只有⼀个实例，并提供⼀个全局访问点来访问该实例的创建模式。\n有些实例，全局只需要⼀个就够了，使⽤单例模式就可以避免⼀个全局使⽤的类，频繁的创建与销毁，耗费系统资\n关键概念",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1436,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000154",
    "content": "问题：假如有两个操作⼀个更新⼀个查询，第⼀个操作先更新数据库，还没来及删除数据库，查询操作可能拿\n\n到的就是旧的数据；更新操作⻢上让缓存失效了，所以后续的查询可以保证数据的⼀致性；还有的问题就是有\n⼀个是读操作没有命中缓存，然后就到数据库中取数据，此时来了⼀个写操作，写完数据库后，让缓存失效，\n然后，之前的那个读操作再把⽼的数据放进去，也会造成脏数据。\n可⾏性：出现上述问题的概率其实⾮常低，需要同时达成读缓存时缓存失效并且有并发写的操作。数据库读写\n要⽐缓存慢得多，所以读操作在写操作之前进⼊数据库，并且在写操作之后更新，概率⽐较低。\nRead/Write Through\n原理：Read/Write   Through原理是把更新数据库（Repository）的操作由缓存代理，应⽤认为后端是⼀个单\n⼀的存储，⽽存储⾃⼰维护⾃⼰的缓存。\nRead Through：就是在查询操作中更新缓存，也就是说，当缓存失效的时候，Cache Aside策略是由调⽤⽅\n负责把数据加载⼊缓存，⽽Read  Through则⽤缓存服务⾃⼰来加载，从⽽对调⽤⽅是透明的。\nWrite Through：当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓\n存，则更新缓存，然后再由缓存⾃⼰更新数据库（这是⼀个同步操作）。\nWrite Behind\n原理：在更新数据的时候，只更新缓存，不更新数据库，⽽缓存会异步地批量更新数据库。这个设计的好处就\n是让数据的I/O操作⾮常快，带来的问题是，数据不是强⼀致性的，⽽且可能会丢。\n第⼆步失效问题：这种可能性极⼩，缓存删除只是标记⼀下⽆效的软删除，可以看作不耗时间。如果会出问\n题，⼀般程序在写数据库那⾥就没有完成：故意在写完数据库后，休眠很⻓时间再来删除缓存。",
    "question": "问题：假如有两个操作⼀个更新⼀个查询，第⼀个操作先更新数据库，还没来及删除数据库，查询操作可能拿",
    "answer": "到的就是旧的数据；更新操作⻢上让缓存失效了，所以后续的查询可以保证数据的⼀致性；还有的问题就是有\n⼀个是读操作没有命中缓存，然后就到数据库中取数据，此时来了⼀个写操作，写完数据库后，让缓存失效，\n然后，之前的那个读操作再把⽼的数据放进去，也会造成脏数据。\n可⾏性：出现上述问题的概率其实⾮常低，需要同时达成读缓存时缓存失效并且有并发写的操作。数据库读写\n要⽐缓存慢得多，所以读操作在写操作之前进⼊数据库，并且在写操作之后更新，概率⽐较低。\nRead/Write Through\n原理：Read/Write   Through原理是把更新数据库（Repository）的操作由缓存代理，应⽤认为后端是⼀个单\n⼀的存储，⽽存储⾃⼰维护⾃⼰的缓存。\nRead Through：就是在查询操作中更新缓存，也就是说，当缓存失效的时候，Cache Aside策略是由调⽤⽅\n负责把数据加载⼊缓存，⽽Read  Through则⽤缓存服务⾃⼰来加载，从⽽对调⽤⽅是透明的。\nWrite Through：当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓\n存，则更新缓存，然后再由缓存⾃⼰更新数据库（这是⼀个同步操作）。\nWrite Behind\n原理：在更新数据的时候，只更新缓存，不更新数据库，⽽缓存会异步地批量更新数据库。这个设计的好处就\n是让数据的I/O操作⾮常快，带来的问题是，数据不是强⼀致性的，⽽且可能会丢。\n第⼆步失效问题：这种可能性极⼩，缓存删除只是标记⼀下⽆效的软删除，可以看作不耗时间。如果会出问\n题，⼀般程序在写数据库那⾥就没有完成：故意在写完数据库后，休眠很⻓时间再来删除缓存。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 757,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000155",
    "content": "Redis过期删除策略有哪些\n\n定时删除：设置 key 的过期时间，当时间到达时，⾃动执⾏ key 的删除操作。\n惰性删除： 每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n定期删除：每隔⼀段时间「随机」从数据库中取出⼀定数量的 key 进⾏检查，并删除其中的过期key。\nRedis 选择「惰性删除+定期删除」这两种策略配和使⽤\n在应⽤中是怎么使⽤Redis的\n可以⽤作缓存层，存储频繁访问的数据，提⾼访问速度。\n⽤作消息队列，通过发布订阅模式传递消息。\n存储会话数据、计数器等。\n设计模式\n想要了解更多设计模式，可以查看卡码⽹设计模式精讲\n常⽤设计模式\n单例模式\n单例设计模式是⼀种确保⼀个类只有⼀个实例，并提供⼀个全局访问点来访问该实例的创建模式。\n有些实例，全局只需要⼀个就够了，使⽤单例模式就可以避免⼀个全局使⽤的类，频繁的创建与销毁，耗费系统资",
    "question": "Redis过期删除策略有哪些",
    "answer": "定时删除：设置 key 的过期时间，当时间到达时，⾃动执⾏ key 的删除操作。\n惰性删除： 每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。\n定期删除：每隔⼀段时间「随机」从数据库中取出⼀定数量的 key 进⾏检查，并删除其中的过期key。\nRedis 选择「惰性删除+定期删除」这两种策略配和使⽤\n在应⽤中是怎么使⽤Redis的\n可以⽤作缓存层，存储频繁访问的数据，提⾼访问速度。\n⽤作消息队列，通过发布订阅模式传递消息。\n存储会话数据、计数器等。\n设计模式\n想要了解更多设计模式，可以查看卡码⽹设计模式精讲\n常⽤设计模式\n单例模式\n单例设计模式是⼀种确保⼀个类只有⼀个实例，并提供⼀个全局访问点来访问该实例的创建模式。\n有些实例，全局只需要⼀个就够了，使⽤单例模式就可以避免⼀个全局使⽤的类，频繁的创建与销毁，耗费系统资",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 396,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000156",
    "content": "关键概念\n\n## ⼀个私有构造函数（确保只能单例类⾃⼰创建实例）：\n单例类通常会将其构造函数设为私有，以防⽌外部代码直接实例化对象。\n## ⼀个私有静态变量（确保只有⼀个实例）\n单例类通常包含⼀个私有的静态变量，⽤于保存该类的唯⼀实例。\n## ⼀个公有静态函数（给使⽤者提供调⽤⽅法）\n单例类提供⼀个公共的静态⽅法，⽤于获取该类的实例。如果实例不存在，则在该⽅法内部创建实例并返回。\n简单来说就是，单例类的构造⽅法不让其他⼈修改和使⽤；并且单例类⾃⼰只创建⼀个实例，这个实例，其他⼈也\n⽆法修改和直接使⽤；然后单例类提供⼀个调⽤⽅法，想⽤这个实例，只能调⽤。这样就确保了全局只创建了⼀个\n实例。\n单例模式的6种实现",
    "question": "关键概念",
    "answer": "## ⼀个私有构造函数（确保只能单例类⾃⼰创建实例）：\n单例类通常会将其构造函数设为私有，以防⽌外部代码直接实例化对象。\n## ⼀个私有静态变量（确保只有⼀个实例）\n单例类通常包含⼀个私有的静态变量，⽤于保存该类的唯⼀实例。\n## ⼀个公有静态函数（给使⽤者提供调⽤⽅法）\n单例类提供⼀个公共的静态⽅法，⽤于获取该类的实例。如果实例不存在，则在该⽅法内部创建实例并返回。\n简单来说就是，单例类的构造⽅法不让其他⼈修改和使⽤；并且单例类⾃⼰只创建⼀个实例，这个实例，其他⼈也\n⽆法修改和直接使⽤；然后单例类提供⼀个调⽤⽅法，想⽤这个实例，只能调⽤。这样就确保了全局只创建了⼀个\n实例。\n单例模式的6种实现",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 307,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000157",
    "content": "## ⼀个公有静态函数（给使⽤者提供调⽤⽅法）\n\n单例类提供⼀个公共的静态⽅法，⽤于获取该类的实例。如果实例不存在，则在该⽅法内部创建实例并返回。\n简单来说就是，单例类的构造⽅法不让其他⼈修改和使⽤；并且单例类⾃⼰只创建⼀个实例，这个实例，其他⼈也\n⽆法修改和直接使⽤；然后单例类提供⼀个调⽤⽅法，想⽤这个实例，只能调⽤。这样就确保了全局只创建了⼀个\n实例。\n单例模式的6种实现\n单例模式6种实现及各实现的优缺点",
    "question": "## ⼀个公有静态函数（给使⽤者提供调⽤⽅法）",
    "answer": "单例类提供⼀个公共的静态⽅法，⽤于获取该类的实例。如果实例不存在，则在该⽅法内部创建实例并返回。\n简单来说就是，单例类的构造⽅法不让其他⼈修改和使⽤；并且单例类⾃⼰只创建⼀个实例，这个实例，其他⼈也\n⽆法修改和直接使⽤；然后单例类提供⼀个调⽤⽅法，想⽤这个实例，只能调⽤。这样就确保了全局只创建了⼀个\n实例。\n单例模式的6种实现\n单例模式6种实现及各实现的优缺点",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 206,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000158",
    "content": "单例模式6种实现及各实现的优缺点\n\n## 懒汉式（线程不安全）\n// 类加载时就创建实例\nprivate static final Singleton instance = new Singleton();\n// 私有构造函数\n先不创建实例，当第⼀次被调⽤时，再创建实例，所以被称为懒汉式。\n延迟了实例化，如果不需要使⽤该类，就不会被实例化，只有在需要时才创建实例，避免了资源浪费。\n线程不安全，多线程环境下，如果多个线程同时进⼊了 if ( uniqueInstance = =  null)  ，若此时还未实例化，也就是\nuniqueInstance == null，那么就会有多个线程执⾏ uniqueInstance = new Singleton(); ，就会实例化多个实例；\n## 饿汉式（线程安全）\n先不管需不需要使⽤这个实例，直接先实例化好实例（饿死⻤⼀样，所以称为饿汉式），然后当需要使⽤的时候，\n直接调⽅法就可以使⽤了\n提起实例化好了⼀个实例，避免了线程不安全问题的出现，\n// 类加载时就创建实例\nprivate static final Singleton instance = new Singleton();\n// 私有构造函数\nprivate static Singleton uniqueInstance;\nprivate static singleton() {}\nprivate static synchronized Sing leton getUinqueInstance()\n{ if (uniqueInstance == null) {\nreturn uniqueInstance;\nprivate volatile static Singleton uniqueInstance;\n使⽤双重检查锁定保证线程安全\npublic static Singleton getUniqueInstance()\n{ if (uniqueInstance == null) {\nsynchronized (Singleton.class)\n{ if (uniqueInstance == null)\nreturn uniqueInstance;\n直接实例化了实例，不再延迟实例化；若系统没有使⽤这个实例，或者系统运⾏很久之后才需要使⽤这个实例，都\n会使操作系统的资源浪费。\n## 懒汉式（线程安全）\n实现和线程不安全的懒汉式 ⼏乎⼀样，唯⼀不同的点是，在get⽅法上 加了⼀把锁。如此⼀来，多个线程访问，每\n次只有拿到锁的的线程能够进⼊该⽅法，避免了多线程不安全问题的出现。\n延迟实例化，节约了资源，并且是线程安全的。\n虽然解决了线程安全问题，但是性能降低了。因为，即使实例已经实例化了，既后续不会再出现线程安全问题了，\n但是锁还在，每次还是只能拿到锁的线程进⼊该⽅法使线程阻塞，等待时间过⻓。\n## 双重检查锁实现（线程安全）\n双重检查锁相当于是改进了线程安全的懒汉式。线程安全的懒汉式的缺点是性能降低了，造成的原因是因为即使实\n例已经实例化，依然每次都会有锁。\n⽽现在，我们将锁的位置变了，并且多加了⼀个检查。也就是，先判断实例是否已经存在，若已经存在了，则不会\n执⾏判断⽅法内的有锁⽅法了。 ⽽如果，还没有实例化的时候，多个线程进去了，也没有事，因为⾥⾯的⽅法有\n锁，只会让⼀个线程进⼊最内层⽅法并实例化实例。如此⼀来，最多最多，也就是第⼀次实例化的时候，会有线程\n阻塞的情况，后续便不会再有线程阻塞的问题。\n为什么使⽤ volatile 关键字修饰了 uniqueInstance 实例变量？\n这段代码执⾏时分为三步：\n## 为 uniqueInstance 分配内存空间\n## 初始化uniqueInstance\n## 将\n指向分配的内存地址\n正常的执⾏顺序当然是 1>2>3 ，但是由于 JVM 具有指令重排的特性，执⾏顺序有可能变成 1>3>2。\n单线程环境时，指令重排并没有什么问题；多线程环境时，会导致有些线程可能会获取到还没初始化的实例。\n例如：线程A 只执⾏了 1 和 3 ，此时线程B来调⽤ getUniqueInstance() ，发现\n不为空，便\n解决办法就是加⼀个\n实例，但是其实此时的\n关键字修饰\n还没有初始化。\n， volatile 会禁⽌ JVM 的指令重排，就可以保\n证多线程环境下的安全运⾏。\n延迟实例化，节约了资源；线程安全；并且相对于线程安全的懒汉式，性能提⾼了。\nvolatile  关键字，对性能也有⼀些影响。\n## 静态内部类实现（线程安全）\nvolatile\npublic enum Singleton\n{ INSTANCE;\n// 可以添加其他⽅法和属性\npublic void doSomething() {\n// 实现\n⾸先，当外部类 Singleton 被加载时，静态内部类 SingletonHolder 并没有被加载进内存。当调⽤\ngetUniqueInstance() ⽅法时，会运⾏ return SingletonHolder.INSTANCE;\n触发了 SingletonHolder.INSTANCE ，此时静态内部类 SingletonHolder 才会被加载进内存，并且初始化\nINSTANCE 实例，⽽且 JVM 会确保 INSTANCE 只被实例化⼀次。\n延迟实例化，节约了资源，且线程安全，性能也提⾼了。\n## 枚举类实现（线程安全）\n默认枚举实例的创建就是线程安全的，且在任何情况下都是单例。\n写法简单，线程安全，天然防⽌反射和反序列化调⽤。\n防⽌反序列化\n序列化：\n把java对象转换为字节序列的过程；\npublic class Singleton\n{ private Singleton() {}\n// 静态内部类持有实例\nprivate static class SingletonHolder {\nprivate static final Singleton instance = new Singleton();\n{ return SingletonHolder.instance;\nreadResolve();\nprivate Object readResolve();\nthrows\nObjectStreamException\n{ return singleton;\n反序列化：\n通过这些字节序列在内存中新建java对象的过程；\n反序列化将⼀个单例实例对象写到磁盘再读回来，从⽽获得了⼀个新的实例。\n我们要防⽌反序列化，避免得到多个实例，枚举类天然防⽌反序列化。\n其他单例模式 可以通过 重写 readResolve() ⽅法，从⽽防⽌反序列化，使实例唯⼀重写\n单例模式的应⽤场景\n单例设计模式适⽤于以下⼀些场景\n资源共享：当多个模块或系统需要共享某⼀资源时，可以使⽤单例模式确保该资源只被创建⼀次，避免重复创\n建和浪费资源。\n控制资源访问：单例模式可以⽤于控制对特定资源的访问，例如数据库连接池、线程池等。\n配置管理器：当整个应⽤程序需要共享⼀些配置信息时，可以使⽤单例模式将配置信息存储在单例类中，⽅便\n全局访问和管理。\n⽇志记录器：单例模式可以⽤于创建⼀个全局的⽇志记录器，⽤于记录系统中的⽇志信息。\n线程池：在多线程环境下，使⽤单例模式管理线程池，确保线程池只被创建⼀次，提⾼线程池的利⽤率。\n缓存：单例模式可以⽤于实现缓存系统，确保缓存只有⼀个实例，避免数据不⼀致性和内存浪费。\n应⽤场景举例：\n## ⽹站计数器\n## 应⽤程序的⽇志应⽤\n## Web项⽬中的配置对象的读取\n## 数据库连接池\n## 多线程池\n使⽤场景总结：\n（1） 频繁实例化然后⼜销毁的对象，使⽤单例模式可以提⾼性能\n（2） 经常使⽤的对象，但实例化时耗费时间或者资源多，如数据库连接池，使⽤单例模式，可以提⾼性能，降低\n资源损坏\n（3） 使⽤线程池之类的控制资源时，使⽤单例模式，可以⽅便资源之间的通信\n⼯⼚模式\n概述：\n⼯⼚模式是⼀种⾮常常⽤的创建型设计模式，其提供了创建对象的最佳⽅式。在创建对象时，不会对客户端暴露对\n象的创建逻辑，⽽是通过使⽤共同的接⼝来创建对象。其⽤来封装和管理类的创建，本质是对获取对象过程的抽\n⼀般情况下，⼯⼚模式分为三种更加细分的类型：简单⼯⼚、⼯⼚⽅法和抽象⼯⼚。\n不过，在 GoF 的《设计模式》⼀书中，它将简单⼯⼚模式看作是⼯⼚⽅法模式的⼀种特例，所以⼯⼚模式只被分\n成了⼯⼚⽅法和抽象⼯⼚两类\n解耦：将对象的创建和使⽤进⾏分离，客户端代码与具体产品类的实例化过程解耦，客户端只需要知道⼯⼚的\n接⼝和抽象产品的接⼝，⽽不需要关⼼具体的实现类。\n可复⽤：对于创建过程⽐较复杂且在很多地⽅都使⽤到的对象，通过⼯⼚模式可以提⾼对象创建的代码的复⽤\n易于扩展：添加新的产品类时，只需要扩展相应的具体产品和具体⼯⼚，⽽不需要修改已有的代码，符合开闭\n原则。\n更符合⾯向对象的设计原则：通过⼯⼚模式，将对象的创建封装在⼯⼚类中，使得系统更符合单⼀职责原则。\n简单⼯⼚模式\n简单⼯⼚模式也被称为静态⼯⼚⽅法模式。\n简单⼯⼚模式并不是⼀个标准的设计模式，更像是⼀种编程习惯。在简单⼯⼚模式中，⼀个⼯⼚类负责创建多个产\n品类的实例，通过传⼊不同的参数来决定创建哪种产品。\n同时在简单⼯⼚模式中会定义⼀个类负责创建其他类的实例，被创建的实例也通常具有共同的⽗类。\n虽然实现了对象的创建和使⽤的分离，但是不够灵活，⼯⼚类集合了所有产品的创建逻辑，职责过重，同时新增⼀\n个产品就需要在原⼯⼚类内部添加⼀个分⽀，违反了开闭原则。并且若是有多个判断条件共同决定创建对象，则后\n期修改会越来越复杂。\n实际应⽤\nJDK中的DateFormate、Calendar类都有使⽤，通过不同参数返回我们需要的对象。\n⼯⼚⽅法模式\n⼯⼚⽅法模式中，将简单⼯⼚中的⼯⼚类变为⼀个抽象接⼝。负责给出不同⼯⼚应该实现的⽅法，⾃身不再负责创\n建各种产品，⽽是将具体的创建操作交给实现该接⼝的⼦⼯⼚类来做。\n通过多态的形式解决了简单⼯⼚模式过多的分⽀问题。虽然在新增产品时不仅要新增⼀个产品类还要实现与之对应\n的⼦⼯⼚，但是相较于简单⼯⼚模式更符合开闭原则\n实际应⽤\nJDK中的Collection接⼝中Iterator的实现。Collection中不同的实现类⽣产适合于⾃⼰的迭代器对象\n## Factory：Collection\n## SubFactoryA：LinkedList\n## SubFactoryB：ArrayList\n## Product：Iterator\n## ProductA：ListItr\n## ProductB：Itr\n抽象⼯⼚模式\n抽象⼯⼚模式提供⼀个创建⼀系列相关或相互依赖对象的接⼝，⽽⽆需指定它们的具体类。抽象⼯⼚模式通常涉及\n多个抽象产品、多个具体产品和多个具体⼯⼚。\n⼯⼚⽅法模式通过引⼊⼯⼚等级结构，解决了简单⼯⼚模式中⼯⼚类职责太重的问题，但由于⼯⼚⽅法模式中的每\n个⼯⼚只⽣产⼀类产品，可能会导致系统中存在⼤量的⼯⼚类，势必会增加系统的开销。抽象⼯⼚模式为⼯⼚⽅法\n模式的进⼀步延伸，其将⼀些相关的产品组成⼀个“产品族”，由同⼀个⼯⼚来统⼀⽣产。虽然对于新增⼀个产品族\n很⽅⾯，并且也符合开闭原则，但是新增⼀个产品等级结构，会对整个⼯⼚结构进⾏⼤改\nSpring中的BeanFactory\n⼯⼚设计模式的应⽤场景\n当⼀个类不知道它所需要的类的时候。\n当⼀个类希望通过其⼦类来指定创建对象的时候。\n当类将创建对象的职责委托给多个帮助⼦类中的某⼀个，并且希望将哪⼀个帮助⼦类是代理者的信息局部化\n举例来说：\n在数据库操作中，通过⼯⼚模式可以根据不同的数据库类型（MySQL、Oracle等）创建对应的数据库连接对\n通过⼯⼚模式可以根据配置⽂件或其他条件选择不同类型的⽇志记录器，如⽂件⽇志记录器、数据库⽇志记录\n器等。\n在图形⽤户界⾯（GUI）库中，可以使⽤⼯⼚模式创建不同⻛格或主题的界⾯元素，如按钮、⽂本框等。\n在加密算法库中，可以使⽤⼯⼚模式根据需要选择不同的加密算法，例如对称加密、⾮对称加密等。\n在⽂件解析过程中，可以使⽤⼯⼚模式根据⽂件类型选择不同的解析器，如XML解析器、JSON解析器等。\n在⽹络通信库中，可以使⽤⼯⼚模式创建不同类型的⽹络连接对象，如TCP连接、UDP连接等。\n观察者模式\n属于⾏为型模式的⼀种，它定义了⼀种⼀对多的依赖关系，让多个观察者对象同时监听某⼀个主题对象。这个主题\n对象在状态变化时，会通知所有的观察者对象，使他们能够⾃动更新⾃⼰。\n主要构成\nSubject（主题）：\n主题是被观察的对象，它包含了⼀组观察者对象，并提供了添加、删除和通知观察者的⽅法。主题通常有⼀个状\n态，当状态改变时，通知所有观察者。\nObserver（观察者）：\n观察者是依赖于主题的对象，当主题的状态发⽣改变时，观察者得到通知并进⾏相应的更新。观察者的具体实现类\n需要实现更新的⽅法。\nConcreteSubject（具体主题）：\n具体主题是主题的具体实现类，它维护了⼀个状态，并在状态改变时通知观察者。\nConcreteObserver（具体观察者）：\n具体观察者是观察者的具体实现类，实现了更新的⽅法，以便在接收到通知时进⾏相应的处理。\n案例：\nCarl哥的微信公众号 是被观察者，微信⽤户 是观察者，有多个微信⽤户关注了Carl哥的公众号，当Carl哥的公众号\n更新订阅时就会通知这些订阅了的微信⽤户。\n解除耦合，让耦合的双⽅都依赖于抽象，从⽽使得各⾃的变换都不会影响另⼀边的变换\n调试复杂，⽽且在Java中消息的通知⼀般是顺序执⾏，那么⼀个观察者卡顿，会影响整体的执⾏效率，在这种情况\n下，⼀般会采⽤异步实现。",
    "question": "单例模式6种实现及各实现的优缺点",
    "answer": "## 懒汉式（线程不安全）\n// 类加载时就创建实例\nprivate static final Singleton instance = new Singleton();\n// 私有构造函数\n先不创建实例，当第⼀次被调⽤时，再创建实例，所以被称为懒汉式。\n延迟了实例化，如果不需要使⽤该类，就不会被实例化，只有在需要时才创建实例，避免了资源浪费。\n线程不安全，多线程环境下，如果多个线程同时进⼊了 if ( uniqueInstance = =  null)  ，若此时还未实例化，也就是\nuniqueInstance == null，那么就会有多个线程执⾏ uniqueInstance = new Singleton(); ，就会实例化多个实例；\n## 饿汉式（线程安全）\n先不管需不需要使⽤这个实例，直接先实例化好实例（饿死⻤⼀样，所以称为饿汉式），然后当需要使⽤的时候，\n直接调⽅法就可以使⽤了\n提起实例化好了⼀个实例，避免了线程不安全问题的出现，\n// 类加载时就创建实例\nprivate static final Singleton instance = new Singleton();\n// 私有构造函数\nprivate static Singleton uniqueInstance;\nprivate static singleton() {}\nprivate static synchronized Sing leton getUinqueInstance()\n{ if (uniqueInstance == null) {\nreturn uniqueInstance;\nprivate volatile static Singleton uniqueInstance;\n使⽤双重检查锁定保证线程安全\npublic static Singleton getUniqueInstance()\n{ if (uniqueInstance == null) {\nsynchronized (Singleton.class)\n{ if (uniqueInstance == null)\nreturn uniqueInstance;\n直接实例化了实例，不再延迟实例化；若系统没有使⽤这个实例，或者系统运⾏很久之后才需要使⽤这个实例，都\n会使操作系统的资源浪费。\n## 懒汉式（线程安全）\n实现和线程不安全的懒汉式 ⼏乎⼀样，唯⼀不同的点是，在get⽅法上 加了⼀把锁。如此⼀来，多个线程访问，每\n次只有拿到锁的的线程能够进⼊该⽅法，避免了多线程不安全问题的出现。\n延迟实例化，节约了资源，并且是线程安全的。\n虽然解决了线程安全问题，但是性能降低了。因为，即使实例已经实例化了，既后续不会再出现线程安全问题了，\n但是锁还在，每次还是只能拿到锁的线程进⼊该⽅法使线程阻塞，等待时间过⻓。\n## 双重检查锁实现（线程安全）\n双重检查锁相当于是改进了线程安全的懒汉式。线程安全的懒汉式的缺点是性能降低了，造成的原因是因为即使实\n例已经实例化，依然每次都会有锁。\n⽽现在，我们将锁的位置变了，并且多加了⼀个检查。也就是，先判断实例是否已经存在，若已经存在了，则不会\n执⾏判断⽅法内的有锁⽅法了。 ⽽如果，还没有实例化的时候，多个线程进去了，也没有事，因为⾥⾯的⽅法有\n锁，只会让⼀个线程进⼊最内层⽅法并实例化实例。如此⼀来，最多最多，也就是第⼀次实例化的时候，会有线程\n阻塞的情况，后续便不会再有线程阻塞的问题。\n为什么使⽤ volatile 关键字修饰了 uniqueInstance 实例变量？\n这段代码执⾏时分为三步：\n## 为 uniqueInstance 分配内存空间\n## 初始化uniqueInstance\n## 将\n指向分配的内存地址\n正常的执⾏顺序当然是 1>2>3 ，但是由于 JVM 具有指令重排的特性，执⾏顺序有可能变成 1>3>2。\n单线程环境时，指令重排并没有什么问题；多线程环境时，会导致有些线程可能会获取到还没初始化的实例。\n例如：线程A 只执⾏了 1 和 3 ，此时线程B来调⽤ getUniqueInstance() ，发现\n不为空，便\n解决办法就是加⼀个\n实例，但是其实此时的\n关键字修饰\n还没有初始化。\n， volatile 会禁⽌ JVM 的指令重排，就可以保\n证多线程环境下的安全运⾏。\n延迟实例化，节约了资源；线程安全；并且相对于线程安全的懒汉式，性能提⾼了。\nvolatile  关键字，对性能也有⼀些影响。\n## 静态内部类实现（线程安全）\nvolatile\npublic enum Singleton\n{ INSTANCE;\n// 可以添加其他⽅法和属性\npublic void doSomething() {\n// 实现\n⾸先，当外部类 Singleton 被加载时，静态内部类 SingletonHolder 并没有被加载进内存。当调⽤\ngetUniqueInstance() ⽅法时，会运⾏ return SingletonHolder.INSTANCE;\n触发了 SingletonHolder.INSTANCE ，此时静态内部类 SingletonHolder 才会被加载进内存，并且初始化\nINSTANCE 实例，⽽且 JVM 会确保 INSTANCE 只被实例化⼀次。\n延迟实例化，节约了资源，且线程安全，性能也提⾼了。\n## 枚举类实现（线程安全）\n默认枚举实例的创建就是线程安全的，且在任何情况下都是单例。\n写法简单，线程安全，天然防⽌反射和反序列化调⽤。\n防⽌反序列化\n序列化：\n把java对象转换为字节序列的过程；\npublic class Singleton\n{ private Singleton() {}\n// 静态内部类持有实例\nprivate static class SingletonHolder {\nprivate static final Singleton instance = new Singleton();\n{ return SingletonHolder.instance;\nreadResolve();\nprivate Object readResolve();\nthrows\nObjectStreamException\n{ return singleton;\n反序列化：\n通过这些字节序列在内存中新建java对象的过程；\n反序列化将⼀个单例实例对象写到磁盘再读回来，从⽽获得了⼀个新的实例。\n我们要防⽌反序列化，避免得到多个实例，枚举类天然防⽌反序列化。\n其他单例模式 可以通过 重写 readResolve() ⽅法，从⽽防⽌反序列化，使实例唯⼀重写\n单例模式的应⽤场景\n单例设计模式适⽤于以下⼀些场景\n资源共享：当多个模块或系统需要共享某⼀资源时，可以使⽤单例模式确保该资源只被创建⼀次，避免重复创\n建和浪费资源。\n控制资源访问：单例模式可以⽤于控制对特定资源的访问，例如数据库连接池、线程池等。\n配置管理器：当整个应⽤程序需要共享⼀些配置信息时，可以使⽤单例模式将配置信息存储在单例类中，⽅便\n全局访问和管理。\n⽇志记录器：单例模式可以⽤于创建⼀个全局的⽇志记录器，⽤于记录系统中的⽇志信息。\n线程池：在多线程环境下，使⽤单例模式管理线程池，确保线程池只被创建⼀次，提⾼线程池的利⽤率。\n缓存：单例模式可以⽤于实现缓存系统，确保缓存只有⼀个实例，避免数据不⼀致性和内存浪费。\n应⽤场景举例：\n## ⽹站计数器\n## 应⽤程序的⽇志应⽤\n## Web项⽬中的配置对象的读取\n## 数据库连接池\n## 多线程池\n使⽤场景总结：\n（1） 频繁实例化然后⼜销毁的对象，使⽤单例模式可以提⾼性能\n（2） 经常使⽤的对象，但实例化时耗费时间或者资源多，如数据库连接池，使⽤单例模式，可以提⾼性能，降低\n资源损坏\n（3） 使⽤线程池之类的控制资源时，使⽤单例模式，可以⽅便资源之间的通信\n⼯⼚模式\n概述：\n⼯⼚模式是⼀种⾮常常⽤的创建型设计模式，其提供了创建对象的最佳⽅式。在创建对象时，不会对客户端暴露对\n象的创建逻辑，⽽是通过使⽤共同的接⼝来创建对象。其⽤来封装和管理类的创建，本质是对获取对象过程的抽\n⼀般情况下，⼯⼚模式分为三种更加细分的类型：简单⼯⼚、⼯⼚⽅法和抽象⼯⼚。\n不过，在 GoF 的《设计模式》⼀书中，它将简单⼯⼚模式看作是⼯⼚⽅法模式的⼀种特例，所以⼯⼚模式只被分\n成了⼯⼚⽅法和抽象⼯⼚两类\n解耦：将对象的创建和使⽤进⾏分离，客户端代码与具体产品类的实例化过程解耦，客户端只需要知道⼯⼚的\n接⼝和抽象产品的接⼝，⽽不需要关⼼具体的实现类。\n可复⽤：对于创建过程⽐较复杂且在很多地⽅都使⽤到的对象，通过⼯⼚模式可以提⾼对象创建的代码的复⽤\n易于扩展：添加新的产品类时，只需要扩展相应的具体产品和具体⼯⼚，⽽不需要修改已有的代码，符合开闭\n原则。\n更符合⾯向对象的设计原则：通过⼯⼚模式，将对象的创建封装在⼯⼚类中，使得系统更符合单⼀职责原则。\n简单⼯⼚模式\n简单⼯⼚模式也被称为静态⼯⼚⽅法模式。\n简单⼯⼚模式并不是⼀个标准的设计模式，更像是⼀种编程习惯。在简单⼯⼚模式中，⼀个⼯⼚类负责创建多个产\n品类的实例，通过传⼊不同的参数来决定创建哪种产品。\n同时在简单⼯⼚模式中会定义⼀个类负责创建其他类的实例，被创建的实例也通常具有共同的⽗类。\n虽然实现了对象的创建和使⽤的分离，但是不够灵活，⼯⼚类集合了所有产品的创建逻辑，职责过重，同时新增⼀\n个产品就需要在原⼯⼚类内部添加⼀个分⽀，违反了开闭原则。并且若是有多个判断条件共同决定创建对象，则后\n期修改会越来越复杂。\n实际应⽤\nJDK中的DateFormate、Calendar类都有使⽤，通过不同参数返回我们需要的对象。\n⼯⼚⽅法模式\n⼯⼚⽅法模式中，将简单⼯⼚中的⼯⼚类变为⼀个抽象接⼝。负责给出不同⼯⼚应该实现的⽅法，⾃身不再负责创\n建各种产品，⽽是将具体的创建操作交给实现该接⼝的⼦⼯⼚类来做。\n通过多态的形式解决了简单⼯⼚模式过多的分⽀问题。虽然在新增产品时不仅要新增⼀个产品类还要实现与之对应\n的⼦⼯⼚，但是相较于简单⼯⼚模式更符合开闭原则\n实际应⽤\nJDK中的Collection接⼝中Iterator的实现。Collection中不同的实现类⽣产适合于⾃⼰的迭代器对象\n## Factory：Collection\n## SubFactoryA：LinkedList\n## SubFactoryB：ArrayList\n## Product：Iterator\n## ProductA：ListItr\n## ProductB：Itr\n抽象⼯⼚模式\n抽象⼯⼚模式提供⼀个创建⼀系列相关或相互依赖对象的接⼝，⽽⽆需指定它们的具体类。抽象⼯⼚模式通常涉及\n多个抽象产品、多个具体产品和多个具体⼯⼚。\n⼯⼚⽅法模式通过引⼊⼯⼚等级结构，解决了简单⼯⼚模式中⼯⼚类职责太重的问题，但由于⼯⼚⽅法模式中的每\n个⼯⼚只⽣产⼀类产品，可能会导致系统中存在⼤量的⼯⼚类，势必会增加系统的开销。抽象⼯⼚模式为⼯⼚⽅法\n模式的进⼀步延伸，其将⼀些相关的产品组成⼀个“产品族”，由同⼀个⼯⼚来统⼀⽣产。虽然对于新增⼀个产品族\n很⽅⾯，并且也符合开闭原则，但是新增⼀个产品等级结构，会对整个⼯⼚结构进⾏⼤改\nSpring中的BeanFactory\n⼯⼚设计模式的应⽤场景\n当⼀个类不知道它所需要的类的时候。\n当⼀个类希望通过其⼦类来指定创建对象的时候。\n当类将创建对象的职责委托给多个帮助⼦类中的某⼀个，并且希望将哪⼀个帮助⼦类是代理者的信息局部化\n举例来说：\n在数据库操作中，通过⼯⼚模式可以根据不同的数据库类型（MySQL、Oracle等）创建对应的数据库连接对\n通过⼯⼚模式可以根据配置⽂件或其他条件选择不同类型的⽇志记录器，如⽂件⽇志记录器、数据库⽇志记录\n器等。\n在图形⽤户界⾯（GUI）库中，可以使⽤⼯⼚模式创建不同⻛格或主题的界⾯元素，如按钮、⽂本框等。\n在加密算法库中，可以使⽤⼯⼚模式根据需要选择不同的加密算法，例如对称加密、⾮对称加密等。\n在⽂件解析过程中，可以使⽤⼯⼚模式根据⽂件类型选择不同的解析器，如XML解析器、JSON解析器等。\n在⽹络通信库中，可以使⽤⼯⼚模式创建不同类型的⽹络连接对象，如TCP连接、UDP连接等。\n观察者模式\n属于⾏为型模式的⼀种，它定义了⼀种⼀对多的依赖关系，让多个观察者对象同时监听某⼀个主题对象。这个主题\n对象在状态变化时，会通知所有的观察者对象，使他们能够⾃动更新⾃⼰。\n主要构成\nSubject（主题）：\n主题是被观察的对象，它包含了⼀组观察者对象，并提供了添加、删除和通知观察者的⽅法。主题通常有⼀个状\n态，当状态改变时，通知所有观察者。\nObserver（观察者）：\n观察者是依赖于主题的对象，当主题的状态发⽣改变时，观察者得到通知并进⾏相应的更新。观察者的具体实现类\n需要实现更新的⽅法。\nConcreteSubject（具体主题）：\n具体主题是主题的具体实现类，它维护了⼀个状态，并在状态改变时通知观察者。\nConcreteObserver（具体观察者）：\n具体观察者是观察者的具体实现类，实现了更新的⽅法，以便在接收到通知时进⾏相应的处理。\n案例：\nCarl哥的微信公众号 是被观察者，微信⽤户 是观察者，有多个微信⽤户关注了Carl哥的公众号，当Carl哥的公众号\n更新订阅时就会通知这些订阅了的微信⽤户。\n解除耦合，让耦合的双⽅都依赖于抽象，从⽽使得各⾃的变换都不会影响另⼀边的变换\n调试复杂，⽽且在Java中消息的通知⼀般是顺序执⾏，那么⼀个观察者卡顿，会影响整体的执⾏效率，在这种情况\n下，⼀般会采⽤异步实现。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 5690,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000159",
    "content": "## ProductB：Itr\n\n抽象⼯⼚模式\n抽象⼯⼚模式提供⼀个创建⼀系列相关或相互依赖对象的接⼝，⽽⽆需指定它们的具体类。抽象⼯⼚模式通常涉及\n多个抽象产品、多个具体产品和多个具体⼯⼚。\n⼯⼚⽅法模式通过引⼊⼯⼚等级结构，解决了简单⼯⼚模式中⼯⼚类职责太重的问题，但由于⼯⼚⽅法模式中的每\n个⼯⼚只⽣产⼀类产品，可能会导致系统中存在⼤量的⼯⼚类，势必会增加系统的开销。抽象⼯⼚模式为⼯⼚⽅法\n模式的进⼀步延伸，其将⼀些相关的产品组成⼀个“产品族”，由同⼀个⼯⼚来统⼀⽣产。虽然对于新增⼀个产品族\n很⽅⾯，并且也符合开闭原则，但是新增⼀个产品等级结构，会对整个⼯⼚结构进⾏⼤改\nSpring中的BeanFactory\n⼯⼚设计模式的应⽤场景\n当⼀个类不知道它所需要的类的时候。\n当⼀个类希望通过其⼦类来指定创建对象的时候。\n当类将创建对象的职责委托给多个帮助⼦类中的某⼀个，并且希望将哪⼀个帮助⼦类是代理者的信息局部化\n举例来说：\n在数据库操作中，通过⼯⼚模式可以根据不同的数据库类型（MySQL、Oracle等）创建对应的数据库连接对\n通过⼯⼚模式可以根据配置⽂件或其他条件选择不同类型的⽇志记录器，如⽂件⽇志记录器、数据库⽇志记录\n器等。\n在图形⽤户界⾯（GUI）库中，可以使⽤⼯⼚模式创建不同⻛格或主题的界⾯元素，如按钮、⽂本框等。\n在加密算法库中，可以使⽤⼯⼚模式根据需要选择不同的加密算法，例如对称加密、⾮对称加密等。\n在⽂件解析过程中，可以使⽤⼯⼚模式根据⽂件类型选择不同的解析器，如XML解析器、JSON解析器等。\n在⽹络通信库中，可以使⽤⼯⼚模式创建不同类型的⽹络连接对象，如TCP连接、UDP连接等。\n观察者模式\n属于⾏为型模式的⼀种，它定义了⼀种⼀对多的依赖关系，让多个观察者对象同时监听某⼀个主题对象。这个主题\n对象在状态变化时，会通知所有的观察者对象，使他们能够⾃动更新⾃⼰。\n主要构成\nSubject（主题）：\n主题是被观察的对象，它包含了⼀组观察者对象，并提供了添加、删除和通知观察者的⽅法。主题通常有⼀个状\n态，当状态改变时，通知所有观察者。\nObserver（观察者）：\n观察者是依赖于主题的对象，当主题的状态发⽣改变时，观察者得到通知并进⾏相应的更新。观察者的具体实现类\n需要实现更新的⽅法。\nConcreteSubject（具体主题）：\n具体主题是主题的具体实现类，它维护了⼀个状态，并在状态改变时通知观察者。\nConcreteObserver（具体观察者）：\n具体观察者是观察者的具体实现类，实现了更新的⽅法，以便在接收到通知时进⾏相应的处理。\n案例：\nCarl哥的微信公众号 是被观察者，微信⽤户 是观察者，有多个微信⽤户关注了Carl哥的公众号，当Carl哥的公众号\n更新订阅时就会通知这些订阅了的微信⽤户。\n解除耦合，让耦合的双⽅都依赖于抽象，从⽽使得各⾃的变换都不会影响另⼀边的变换\n调试复杂，⽽且在Java中消息的通知⼀般是顺序执⾏，那么⼀个观察者卡顿，会影响整体的执⾏效率，在这种情况\n下，⼀般会采⽤异步实现。\n实现步骤",
    "question": "## ProductB：Itr",
    "answer": "抽象⼯⼚模式\n抽象⼯⼚模式提供⼀个创建⼀系列相关或相互依赖对象的接⼝，⽽⽆需指定它们的具体类。抽象⼯⼚模式通常涉及\n多个抽象产品、多个具体产品和多个具体⼯⼚。\n⼯⼚⽅法模式通过引⼊⼯⼚等级结构，解决了简单⼯⼚模式中⼯⼚类职责太重的问题，但由于⼯⼚⽅法模式中的每\n个⼯⼚只⽣产⼀类产品，可能会导致系统中存在⼤量的⼯⼚类，势必会增加系统的开销。抽象⼯⼚模式为⼯⼚⽅法\n模式的进⼀步延伸，其将⼀些相关的产品组成⼀个“产品族”，由同⼀个⼯⼚来统⼀⽣产。虽然对于新增⼀个产品族\n很⽅⾯，并且也符合开闭原则，但是新增⼀个产品等级结构，会对整个⼯⼚结构进⾏⼤改\nSpring中的BeanFactory\n⼯⼚设计模式的应⽤场景\n当⼀个类不知道它所需要的类的时候。\n当⼀个类希望通过其⼦类来指定创建对象的时候。\n当类将创建对象的职责委托给多个帮助⼦类中的某⼀个，并且希望将哪⼀个帮助⼦类是代理者的信息局部化\n举例来说：\n在数据库操作中，通过⼯⼚模式可以根据不同的数据库类型（MySQL、Oracle等）创建对应的数据库连接对\n通过⼯⼚模式可以根据配置⽂件或其他条件选择不同类型的⽇志记录器，如⽂件⽇志记录器、数据库⽇志记录\n器等。\n在图形⽤户界⾯（GUI）库中，可以使⽤⼯⼚模式创建不同⻛格或主题的界⾯元素，如按钮、⽂本框等。\n在加密算法库中，可以使⽤⼯⼚模式根据需要选择不同的加密算法，例如对称加密、⾮对称加密等。\n在⽂件解析过程中，可以使⽤⼯⼚模式根据⽂件类型选择不同的解析器，如XML解析器、JSON解析器等。\n在⽹络通信库中，可以使⽤⼯⼚模式创建不同类型的⽹络连接对象，如TCP连接、UDP连接等。\n观察者模式\n属于⾏为型模式的⼀种，它定义了⼀种⼀对多的依赖关系，让多个观察者对象同时监听某⼀个主题对象。这个主题\n对象在状态变化时，会通知所有的观察者对象，使他们能够⾃动更新⾃⼰。\n主要构成\nSubject（主题）：\n主题是被观察的对象，它包含了⼀组观察者对象，并提供了添加、删除和通知观察者的⽅法。主题通常有⼀个状\n态，当状态改变时，通知所有观察者。\nObserver（观察者）：\n观察者是依赖于主题的对象，当主题的状态发⽣改变时，观察者得到通知并进⾏相应的更新。观察者的具体实现类\n需要实现更新的⽅法。\nConcreteSubject（具体主题）：\n具体主题是主题的具体实现类，它维护了⼀个状态，并在状态改变时通知观察者。\nConcreteObserver（具体观察者）：\n具体观察者是观察者的具体实现类，实现了更新的⽅法，以便在接收到通知时进⾏相应的处理。\n案例：\nCarl哥的微信公众号 是被观察者，微信⽤户 是观察者，有多个微信⽤户关注了Carl哥的公众号，当Carl哥的公众号\n更新订阅时就会通知这些订阅了的微信⽤户。\n解除耦合，让耦合的双⽅都依赖于抽象，从⽽使得各⾃的变换都不会影响另⼀边的变换\n调试复杂，⽽且在Java中消息的通知⼀般是顺序执⾏，那么⼀个观察者卡顿，会影响整体的执⾏效率，在这种情况\n下，⼀般会采⽤异步实现。\n实现步骤",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1287,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000160",
    "content": "实现步骤\n\n## 定义主题接⼝（Subject），包括注册、移除和通知观察者的⽅法。\n## 定义观察者接⼝（Observer），包括更新的⽅法。\n## 创建具体主题类（Concrete   Subject），维护⼀组观察者对象，并在状态改变时通知观察者。\n## 创建具体观察者类（Concrete  Observer），实现更新的⽅法。\n## 客户端代码中创建主题对象和观察者对象，注册观察者到主题中，然后通过主题改变状态，观察者得到通知并\n进⾏更新。\n使⽤场景\n## 事件处理：当⼀个对象的状态发⽣改变时，观察者模式可以⽤于通知和处理与该对象相关的事件。这在图形⽤\n户界⾯（GUI）开发中是很常⻅的，例如按钮点击事件、⿏标移动事件等。\n## 发布订阅：观察者模式可以⽤于实现发布-订阅模型，其中⼀个主题（发布者）负责发送通知，⽽多个观察者\n（订阅者）监听并响应这些通知。这种模型在消息队列系统、事件总线等场景中经常使⽤。\n## MVC架构：观察者模式常被⽤于实现MVC架构中的模型和视图之间的通信。当模型的状态发⽣改变时，所有\n相关的视图都会得到通知并更新显示。\n## 异步编程：观察者模式可以⽤于处理异步任务的完成事件。任务完成时，通知所有相关的观察者进⾏后续处\n代理模式\n结构图：\n代理模式（Proxy Pattern）是⼀种结构型设计模式，其主要⽬的是在访问某个对象时引⼊⼀种代理对象，通过代\n理对象控制对原始对象的访问。代理模式可以⽤于实现懒加载、控制访问、监控对象等场景。\n主要⻆⾊\n## 抽象主题（ Subject ): 定义了代理对象和真实对象的共同接⼝，使得代理对象能够替代真实对象。\n## 真实主题Real Subject : 是实际执⾏业务逻辑的对象，是代理模式中的被代理对象。\n## 代理Proxy : 包含⼀个指向真实主题的引⽤，提供与真实主题相同的接⼝，可以控制对真实主题的访问，并在\n需要时负责创建或删除真实主题的实例。\n代理模式结构图\n（1） Subject类\n（2） RealSubject 类，\n定义Proxy 所代表的真实实体\n（3） Proxy 类\n保存⼀个引⽤使得代理可以访问实体，并提供⼀个与Subject的接⼝相同的接⼝，这样代理就可以⽤来替代实体。\n（4） 客户端代码\n代理模式应⽤\n（1） 远程代理\n⼀个对象在不同的地址空间提供局部代表。这样可以隐藏⼀个对象存在于不同地址空间的事实。\n（2） 虚拟代理\n根据需要创建开销很⼤的对象。通过它来存放实例化需要很⻓时间的真实对象，这样就可以达到性能的最优化。⽐\n如说你打开⼀个很⼤的HTML⽹⻚时，⾥⾯可能有很多的⽂字和图⽚，但你还是可以很快打开它，此时你所看到的\n是所有的⽂字，但图⽚却是⼀张⼀张地下载后才能看到。那些未打开的图⽚框，就是通过虚拟代理来替代了真实的\n图⽚，此时代理存储了真实图⽚的路径和尺⼨。\n（3） 安全代理\n⽤来控制真实对象访问时的权限。⼀般⽤于对象应该有不同的访问权限的时候。\n（4） 智能指引\n是指当调⽤真实的对象时，代理处理另外⼀些事。如计算真实对象的引⽤次数，这样当该对象没有引⽤时，可以⾃\n动释放它；或当第⼀次引⽤⼀个持久对象时，将它装⼊内存；或在访问⼀个实际对象前，检查是否已经锁定它，以\n确保其他对象不能改变它。它们都是通过代理在访问⼀个对象时附加⼀些内务处理。\n策略模式\n策略模式（Strategy Pattern）是⼀种⾏为设计模式，它定义了⼀系列算法，，把它们单独封装起来，并且使它们\n可以互相替换，使得算法可以独⽴于使⽤它的客户端⽽变化，也是说这些算法所完成的功能类型是⼀样的，对外接\n⼝也是⼀样的，只是不同的策略为引起环境⻆⾊表现出不同的⾏为。\n相⽐于使⽤⼤量的if...else，使⽤策略模式可以降低复杂度，使得代码更容易维护。\n缺点：可能需要定义⼤量的策略类，并且这些策略类都要提供给客户端。\n主要构成\n策略接⼝（Stragety）： 策略接⼝定义了算法的抽象，具体的策略类实现了这个接⼝。\n具体策略类（ConcreteStragety）： 具体策略类实现了策略接⼝，封装了具体的算法。\n环境类（Context): ⽤来操作策略的上下⽂环境类,环境类的构造函数包含了Strategy类，通过多态传进来不同\n的具体策略（ConcreteStrategyA。ConcreteStrategyB）来调⽤不同策略的⽅法\n实现步骤：\n## 定义⼀个策略接⼝，声明算法的抽象⽅法。\n## 创建具体的策略类，实现策略接⼝，封装具体的算法。\n## 创建环境类，包含对策略接⼝的引⽤，以及⼀个⽤于设置具体策略对象的⽅法。\n## 在客户端中创建环境类的对象，并调⽤其⽅法来执⾏具体的算法。\n优缺点：\n使⽤策略模式可以避免使⽤多重条件转移语句。多重转移语句将算法或⾏为的逻辑混合在⼀起，不易维护\n客户端必须知道所有的策略类，并⾃⾏决定使⽤哪⼀个策略类，策略模式只适⽤于客户端知道所有的算法或⾏为的\n情况。\n下⾯是⼀个简单的策略模式的示例，假设有⼀个商场销售系统，根据不同的促销策略计算最终价格：\n// 策略接⼝\npublic interface PricingStrategy\n{ double calculatePrice(double\nprice);\n// 具体策略类：⽆折扣\npublic class NoDiscountStrategy implements PricingStrategy\npublic double calculatePrice(double price)\n{ return price;\n// 具体策略类：打九折\npublic class DiscountStrategy implements PricingStrategy\npublic double calculatePrice(double price)\n{ return price * 0.9;\n// 具体策略类：满减\npublic class CashbackStrategy implements PricingStrategy\npublic double calculatePrice(double price)\n{ if (price >= 200) {\nreturn price - 50;\n} else {\nreturn price;\n// 环境类\npublic class ShoppingCart {\nprivate PricingStrategy pricingStrategy;\npublic void setPricingStrategy(PricingStrategy pricingStrategy)\n{ this.pricingStrategy = pricingStrategy;\npublic double checkout(double totalPrice) {\nreturn pricingStrategy.calculatePrice(totalPrice);\n装饰模式\n结构图\n装饰模式（Decorator Pattern）是⼀种结构型设计模式，它允许在不改变原始类接⼝的情况下，动态地添加功能\n或责任。装饰模式通过创建⼀个装饰类，包裹原始类的实例，并在保持原始类接⼝不变的情况下，提供额外的功\n能。，就增加功能来说，装饰模式⽐⽣成⼦类更为灵活。\n// 客户端代码\npublic class Client {\npublic static void main(String[] args)\n{ ShoppingCart cart = new ShoppingCart();\n// 选择⽆折扣策略\ncart.setPricingStrategy(new NoDiscountStrategy());\ndouble price1 = cart.checkout(100);\nSystem.out.println(\"Total Price: \" + price1); // 输出：Total Price: 100.0\n// 选择打九折策略\ncart.setPricingStrategy(new DiscountStrategy());\ndouble price2 = cart.checkout(100);\nSystem.out.println(\"Total Price: \" + price2); // 输出：Total Price: 90.0\n// 选择满减策略\ncart.setPricingStrategy(new CashbackStrategy());\ndouble price3 = cart.checkout(200);\nSystem.out.println(\"Total Price: \" + price3); // 输出：Total Price: 150.0\n主要⻆⾊\n## 组件接⼝：定义了具体组件和装饰器共同的接⼝，确保它们可以互相替换。\n## 具体组件：实现了组件接⼝，是被装饰的具体对象。\n## 装饰器：持有⼀个组件对象的引⽤，并实现了组件接⼝。装饰器通常是⼀个抽象类，它的具体⼦类实现具体的\n装饰逻辑。\n## 具体装饰器：继承⾃装饰器，实现了具体的装饰逻辑，并调⽤⽗类的⽅法以保持接⼝⼀致。\n结构图\n基本代码实现\n（1） Component类\n（2） ConcreteComponent类\n（3） Decorator类\n（4） ConcreteDecoratorA类 和 ConcreteDecoratorB类\n（5） 客户端代码\n## 装饰模式在什么情况下使⽤\n装饰模式把每个要装饰的功能放在单独的类中，并让这个类包装它所要装饰的对象。因此，当需要执⾏特殊⾏为\n时，客户代码就可以在运⾏时根据需要有选择地、按顺序地使⽤装饰功能包装对象了。",
    "question": "实现步骤",
    "answer": "## 定义主题接⼝（Subject），包括注册、移除和通知观察者的⽅法。\n## 定义观察者接⼝（Observer），包括更新的⽅法。\n## 创建具体主题类（Concrete   Subject），维护⼀组观察者对象，并在状态改变时通知观察者。\n## 创建具体观察者类（Concrete  Observer），实现更新的⽅法。\n## 客户端代码中创建主题对象和观察者对象，注册观察者到主题中，然后通过主题改变状态，观察者得到通知并\n进⾏更新。\n使⽤场景\n## 事件处理：当⼀个对象的状态发⽣改变时，观察者模式可以⽤于通知和处理与该对象相关的事件。这在图形⽤\n户界⾯（GUI）开发中是很常⻅的，例如按钮点击事件、⿏标移动事件等。\n## 发布订阅：观察者模式可以⽤于实现发布-订阅模型，其中⼀个主题（发布者）负责发送通知，⽽多个观察者\n（订阅者）监听并响应这些通知。这种模型在消息队列系统、事件总线等场景中经常使⽤。\n## MVC架构：观察者模式常被⽤于实现MVC架构中的模型和视图之间的通信。当模型的状态发⽣改变时，所有\n相关的视图都会得到通知并更新显示。\n## 异步编程：观察者模式可以⽤于处理异步任务的完成事件。任务完成时，通知所有相关的观察者进⾏后续处\n代理模式\n结构图：\n代理模式（Proxy Pattern）是⼀种结构型设计模式，其主要⽬的是在访问某个对象时引⼊⼀种代理对象，通过代\n理对象控制对原始对象的访问。代理模式可以⽤于实现懒加载、控制访问、监控对象等场景。\n主要⻆⾊\n## 抽象主题（ Subject ): 定义了代理对象和真实对象的共同接⼝，使得代理对象能够替代真实对象。\n## 真实主题Real Subject : 是实际执⾏业务逻辑的对象，是代理模式中的被代理对象。\n## 代理Proxy : 包含⼀个指向真实主题的引⽤，提供与真实主题相同的接⼝，可以控制对真实主题的访问，并在\n需要时负责创建或删除真实主题的实例。\n代理模式结构图\n（1） Subject类\n（2） RealSubject 类，\n定义Proxy 所代表的真实实体\n（3） Proxy 类\n保存⼀个引⽤使得代理可以访问实体，并提供⼀个与Subject的接⼝相同的接⼝，这样代理就可以⽤来替代实体。\n（4） 客户端代码\n代理模式应⽤\n（1） 远程代理\n⼀个对象在不同的地址空间提供局部代表。这样可以隐藏⼀个对象存在于不同地址空间的事实。\n（2） 虚拟代理\n根据需要创建开销很⼤的对象。通过它来存放实例化需要很⻓时间的真实对象，这样就可以达到性能的最优化。⽐\n如说你打开⼀个很⼤的HTML⽹⻚时，⾥⾯可能有很多的⽂字和图⽚，但你还是可以很快打开它，此时你所看到的\n是所有的⽂字，但图⽚却是⼀张⼀张地下载后才能看到。那些未打开的图⽚框，就是通过虚拟代理来替代了真实的\n图⽚，此时代理存储了真实图⽚的路径和尺⼨。\n（3） 安全代理\n⽤来控制真实对象访问时的权限。⼀般⽤于对象应该有不同的访问权限的时候。\n（4） 智能指引\n是指当调⽤真实的对象时，代理处理另外⼀些事。如计算真实对象的引⽤次数，这样当该对象没有引⽤时，可以⾃\n动释放它；或当第⼀次引⽤⼀个持久对象时，将它装⼊内存；或在访问⼀个实际对象前，检查是否已经锁定它，以\n确保其他对象不能改变它。它们都是通过代理在访问⼀个对象时附加⼀些内务处理。\n策略模式\n策略模式（Strategy Pattern）是⼀种⾏为设计模式，它定义了⼀系列算法，，把它们单独封装起来，并且使它们\n可以互相替换，使得算法可以独⽴于使⽤它的客户端⽽变化，也是说这些算法所完成的功能类型是⼀样的，对外接\n⼝也是⼀样的，只是不同的策略为引起环境⻆⾊表现出不同的⾏为。\n相⽐于使⽤⼤量的if...else，使⽤策略模式可以降低复杂度，使得代码更容易维护。\n缺点：可能需要定义⼤量的策略类，并且这些策略类都要提供给客户端。\n主要构成\n策略接⼝（Stragety）： 策略接⼝定义了算法的抽象，具体的策略类实现了这个接⼝。\n具体策略类（ConcreteStragety）： 具体策略类实现了策略接⼝，封装了具体的算法。\n环境类（Context): ⽤来操作策略的上下⽂环境类,环境类的构造函数包含了Strategy类，通过多态传进来不同\n的具体策略（ConcreteStrategyA。ConcreteStrategyB）来调⽤不同策略的⽅法\n实现步骤：\n## 定义⼀个策略接⼝，声明算法的抽象⽅法。\n## 创建具体的策略类，实现策略接⼝，封装具体的算法。\n## 创建环境类，包含对策略接⼝的引⽤，以及⼀个⽤于设置具体策略对象的⽅法。\n## 在客户端中创建环境类的对象，并调⽤其⽅法来执⾏具体的算法。\n优缺点：\n使⽤策略模式可以避免使⽤多重条件转移语句。多重转移语句将算法或⾏为的逻辑混合在⼀起，不易维护\n客户端必须知道所有的策略类，并⾃⾏决定使⽤哪⼀个策略类，策略模式只适⽤于客户端知道所有的算法或⾏为的\n情况。\n下⾯是⼀个简单的策略模式的示例，假设有⼀个商场销售系统，根据不同的促销策略计算最终价格：\n// 策略接⼝\npublic interface PricingStrategy\n{ double calculatePrice(double\nprice);\n// 具体策略类：⽆折扣\npublic class NoDiscountStrategy implements PricingStrategy\npublic double calculatePrice(double price)\n{ return price;\n// 具体策略类：打九折\npublic class DiscountStrategy implements PricingStrategy\npublic double calculatePrice(double price)\n{ return price * 0.9;\n// 具体策略类：满减\npublic class CashbackStrategy implements PricingStrategy\npublic double calculatePrice(double price)\n{ if (price >= 200) {\nreturn price - 50;\n} else {\nreturn price;\n// 环境类\npublic class ShoppingCart {\nprivate PricingStrategy pricingStrategy;\npublic void setPricingStrategy(PricingStrategy pricingStrategy)\n{ this.pricingStrategy = pricingStrategy;\npublic double checkout(double totalPrice) {\nreturn pricingStrategy.calculatePrice(totalPrice);\n装饰模式\n结构图\n装饰模式（Decorator Pattern）是⼀种结构型设计模式，它允许在不改变原始类接⼝的情况下，动态地添加功能\n或责任。装饰模式通过创建⼀个装饰类，包裹原始类的实例，并在保持原始类接⼝不变的情况下，提供额外的功\n能。，就增加功能来说，装饰模式⽐⽣成⼦类更为灵活。\n// 客户端代码\npublic class Client {\npublic static void main(String[] args)\n{ ShoppingCart cart = new ShoppingCart();\n// 选择⽆折扣策略\ncart.setPricingStrategy(new NoDiscountStrategy());\ndouble price1 = cart.checkout(100);\nSystem.out.println(\"Total Price: \" + price1); // 输出：Total Price: 100.0\n// 选择打九折策略\ncart.setPricingStrategy(new DiscountStrategy());\ndouble price2 = cart.checkout(100);\nSystem.out.println(\"Total Price: \" + price2); // 输出：Total Price: 90.0\n// 选择满减策略\ncart.setPricingStrategy(new CashbackStrategy());\ndouble price3 = cart.checkout(200);\nSystem.out.println(\"Total Price: \" + price3); // 输出：Total Price: 150.0\n主要⻆⾊\n## 组件接⼝：定义了具体组件和装饰器共同的接⼝，确保它们可以互相替换。\n## 具体组件：实现了组件接⼝，是被装饰的具体对象。\n## 装饰器：持有⼀个组件对象的引⽤，并实现了组件接⼝。装饰器通常是⼀个抽象类，它的具体⼦类实现具体的\n装饰逻辑。\n## 具体装饰器：继承⾃装饰器，实现了具体的装饰逻辑，并调⽤⽗类的⽅法以保持接⼝⼀致。\n结构图\n基本代码实现\n（1） Component类\n（2） ConcreteComponent类\n（3） Decorator类\n（4） ConcreteDecoratorA类 和 ConcreteDecoratorB类\n（5） 客户端代码\n## 装饰模式在什么情况下使⽤\n装饰模式把每个要装饰的功能放在单独的类中，并让这个类包装它所要装饰的对象。因此，当需要执⾏特殊⾏为\n时，客户代码就可以在运⾏时根据需要有选择地、按顺序地使⽤装饰功能包装对象了。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 4060,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000161",
    "content": "## 装饰模式在什么情况下使⽤\n\n装饰模式把每个要装饰的功能放在单独的类中，并让这个类包装它所要装饰的对象。因此，当需要执⾏特殊⾏为\n时，客户代码就可以在运⾏时根据需要有选择地、按顺序地使⽤装饰功能包装对象了。\n23种设计模式的概念\n创建型模式",
    "question": "## 装饰模式在什么情况下使⽤",
    "answer": "装饰模式把每个要装饰的功能放在单独的类中，并让这个类包装它所要装饰的对象。因此，当需要执⾏特殊⾏为\n时，客户代码就可以在运⾏时根据需要有选择地、按顺序地使⽤装饰功能包装对象了。\n23种设计模式的概念\n创建型模式",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 122,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000162",
    "content": "23种设计模式的概念\n\n创建型模式\n## ⼯⼚⽅法(factory method)模式：\n定义⼀个创建对象的接⼝，但由⼦类决定需要实例化哪⼀个类。⼯⼚⽅法使得⼦类实例化的过程推迟\n## 抽象⼯⼚(abstract factory)模式：\n提供⼀个接⼝，可以创建⼀系列相关或相互依赖的对象，⽽⽆需指定他们具体的类\n## 原型(prototype)模式：\n⽤原型实例指定创建对象的类型，并且通过拷⻉这个原型来创建新的对象\n## 单例(singleton)模式：\n保证⼀个类只有⼀个实例，并提供⼀个访问它的全局访问点\n## 构建器(builder)模式：\n将⼀个复杂类的表示与其构造相分离，使得相同的构建过程能够得出不同的表示\n结构型模式\n## 适配器(adapter)模式：\n将⼀个类的接⼝转换成⽤户希望得到的另⼀个接⼝。它使原本不相容的接⼝得以协同⼯作——速记关键字:转换接⼝\n## 桥接(bridge)模式：\n将类的抽象部分和它的实现部分分离开来，使它们可以独⽴地变化——速记关键字：继承树拆分\n## 组合(composite)模式：\n将对象组合成树型结构以表示“整体-部分”的层次结构，使得⽤户对单个对象和组合对象的使⽤具有⼀致性——速记\n关键字：树形⽬录结构\n## 装饰(decorator)模式：\n动态地给⼀个对象添加⼀些额外的职责。它提供了⽤⼦类扩展功能的⼀个灵活的替代，⽐派⽣⼀个⼦类更加灵活\n——速记关键字：附加职责\n## 外观(facade)模式：\n定义⼀个⾼层接⼝，为⼦系统中的⼀组接⼝提供⼀个⼀致的外观，从⽽简化了该⼦系统的使⽤——速记关键字：对\n外统⼀接⼝\n## 享元(flyweight)模式：\n提供⽀持⼤量细粒度对象共享的有效⽅法\n## 代理(proxy)模式：\n为其他对象提供⼀种代理以控制这个对象的访问\n⾏为型模式\n## 职责链(chain of responsibility)模式：\n通过给多个对象处理请求的机会，减少请求的发送者与接收者之间的耦合。将接收对象链接起来，在链中传递请\n求，直到有⼀个对象处理这个请求——速记关键字：传递职责\n## 命令(command)模式：\n将⼀个请求封装为⼀个对象，从⽽可⽤不同的请求对客户进⾏参数化，将请求排队或记录请求⽇志，⽀持可撤销的\n操作——速记关键字：⽇志记录，可撤销\n## 解释器(interpreter)模式：\n给定⼀种语⾔，定义它的⽂法表示，并定义⼀个解释器，该解释器⽤来根据⽂法表示来解释语⾔中的句⼦\n## 迭代器(iterator)模式：\n提供⼀种⽅法来顺序访问⼀个聚合对象中的各个元素⽽不需要暴露该对象的内部表示\n## 中介者(mediator)模式：\n⽤⼀个中介对象来封装⼀系列的对象交互。它使各对象不需要显式地相互调⽤，从⽽达到低耦合，还可以独⽴地改\n变对象间的交互——速记关键字：不直接引⽤\n## 备忘录(memento)模式：\n在不破坏封装性的前提下，捕获⼀个对象的内部状态，并在该对象之外保存这个状态，从⽽可⽤在以后将该对象恢\n复到原先保存的状态\n## 观察者(observer)模式：\n定义对象间的⼀种⼀对多的依赖关系，当⼀个对象的状态发⽣改变时，所有依赖于它的对象都得到通知并⾃动更新\n## 状态(state)模式：\n允许⼀个对象在其内部状态改变时改变它的⾏为——速记关键字：状态变成类\n## 策略(strategy)模式：\n定义⼀系列算法，把它们⼀个个封装起来，并且使它们之间可互相替换，从⽽让算法可以独⽴于使⽤它的⽤户⽽变\n## 模板⽅法(template method)模式：\n定义⼀个操作中的算法⻣架，⽽将⼀些步骤延迟到⼦类中，使得⼦类可以不改变⼀个算法的结构即可重新定义算法",
    "question": "23种设计模式的概念",
    "answer": "创建型模式\n## ⼯⼚⽅法(factory method)模式：\n定义⼀个创建对象的接⼝，但由⼦类决定需要实例化哪⼀个类。⼯⼚⽅法使得⼦类实例化的过程推迟\n## 抽象⼯⼚(abstract factory)模式：\n提供⼀个接⼝，可以创建⼀系列相关或相互依赖的对象，⽽⽆需指定他们具体的类\n## 原型(prototype)模式：\n⽤原型实例指定创建对象的类型，并且通过拷⻉这个原型来创建新的对象\n## 单例(singleton)模式：\n保证⼀个类只有⼀个实例，并提供⼀个访问它的全局访问点\n## 构建器(builder)模式：\n将⼀个复杂类的表示与其构造相分离，使得相同的构建过程能够得出不同的表示\n结构型模式\n## 适配器(adapter)模式：\n将⼀个类的接⼝转换成⽤户希望得到的另⼀个接⼝。它使原本不相容的接⼝得以协同⼯作——速记关键字:转换接⼝\n## 桥接(bridge)模式：\n将类的抽象部分和它的实现部分分离开来，使它们可以独⽴地变化——速记关键字：继承树拆分\n## 组合(composite)模式：\n将对象组合成树型结构以表示“整体-部分”的层次结构，使得⽤户对单个对象和组合对象的使⽤具有⼀致性——速记\n关键字：树形⽬录结构\n## 装饰(decorator)模式：\n动态地给⼀个对象添加⼀些额外的职责。它提供了⽤⼦类扩展功能的⼀个灵活的替代，⽐派⽣⼀个⼦类更加灵活\n——速记关键字：附加职责\n## 外观(facade)模式：\n定义⼀个⾼层接⼝，为⼦系统中的⼀组接⼝提供⼀个⼀致的外观，从⽽简化了该⼦系统的使⽤——速记关键字：对\n外统⼀接⼝\n## 享元(flyweight)模式：\n提供⽀持⼤量细粒度对象共享的有效⽅法\n## 代理(proxy)模式：\n为其他对象提供⼀种代理以控制这个对象的访问\n⾏为型模式\n## 职责链(chain of responsibility)模式：\n通过给多个对象处理请求的机会，减少请求的发送者与接收者之间的耦合。将接收对象链接起来，在链中传递请\n求，直到有⼀个对象处理这个请求——速记关键字：传递职责\n## 命令(command)模式：\n将⼀个请求封装为⼀个对象，从⽽可⽤不同的请求对客户进⾏参数化，将请求排队或记录请求⽇志，⽀持可撤销的\n操作——速记关键字：⽇志记录，可撤销\n## 解释器(interpreter)模式：\n给定⼀种语⾔，定义它的⽂法表示，并定义⼀个解释器，该解释器⽤来根据⽂法表示来解释语⾔中的句⼦\n## 迭代器(iterator)模式：\n提供⼀种⽅法来顺序访问⼀个聚合对象中的各个元素⽽不需要暴露该对象的内部表示\n## 中介者(mediator)模式：\n⽤⼀个中介对象来封装⼀系列的对象交互。它使各对象不需要显式地相互调⽤，从⽽达到低耦合，还可以独⽴地改\n变对象间的交互——速记关键字：不直接引⽤\n## 备忘录(memento)模式：\n在不破坏封装性的前提下，捕获⼀个对象的内部状态，并在该对象之外保存这个状态，从⽽可⽤在以后将该对象恢\n复到原先保存的状态\n## 观察者(observer)模式：\n定义对象间的⼀种⼀对多的依赖关系，当⼀个对象的状态发⽣改变时，所有依赖于它的对象都得到通知并⾃动更新\n## 状态(state)模式：\n允许⼀个对象在其内部状态改变时改变它的⾏为——速记关键字：状态变成类\n## 策略(strategy)模式：\n定义⼀系列算法，把它们⼀个个封装起来，并且使它们之间可互相替换，从⽽让算法可以独⽴于使⽤它的⽤户⽽变\n## 模板⽅法(template method)模式：\n定义⼀个操作中的算法⻣架，⽽将⼀些步骤延迟到⼦类中，使得⼦类可以不改变⼀个算法的结构即可重新定义算法",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1543,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000163",
    "content": "## 模板⽅法(template method)模式：\n\n定义⼀个操作中的算法⻣架，⽽将⼀些步骤延迟到⼦类中，使得⼦类可以不改变⼀个算法的结构即可重新定义算法\n的某些特定步骤",
    "question": "## 模板⽅法(template method)模式：",
    "answer": "定义⼀个操作中的算法⻣架，⽽将⼀些步骤延迟到⼦类中，使得⼦类可以不改变⼀个算法的结构即可重新定义算法\n的某些特定步骤",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 87,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000164",
    "content": "的某些特定步骤\n\n## 访问者(visitor)模式：\n表示⼀个作⽤于某对象结构中的各元素的操作，使得在不改变各元素的类的前提下定义作⽤于这些元素的新操作\n设计原则\n单⼀职责\n在设计类的时候要尽量缩⼩粒度，使功能明确、单⼀，不要做多余的事情（⾼内聚，低耦合）\n开闭原则\n软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。这意味着可以通过扩展来添加新功能，⽽不必修改\n现有代码。\n⾥⽒替换\n⼦类型必须能够替换掉它们的基类型。在程序中，如果有⼀个基类和⼀个⼦类，那么可以⽤⼦类对象替换基类对\n象，⽽程序的⾏为仍然是正确的。\n接⼝隔离\n不应该强迫⼀个类实现它不需要的接⼝。⼀个类不应该对它⽤不到的⽅法负责。\n依赖倒置\n⾼层模块不应该依赖于低层模块，⽽是应该依赖于抽象。抽象不应该依赖于具体实现，具体实现应该依赖于抽象。\n⽐如Java的操作数据库，Java定义了⼀组接⼝，由各个数据库去实现它，Java不依赖于他们，数据库依赖于Java\n组合优于继承\n继承耦合度⾼，组合耦合度低\n继承基类是固定好的，但是组合通过组合类的指针，可以传⼊不同的类，避免⾼耦合\n组合复⽤原则\n## 概念：\n优先使⽤组合 contains a（聚合 has a），⽽不是继承 is a 来达到⽬的\n## 原因：\n继承会将实现细节暴露给⼦类，继承复⽤破坏了封装性，是⽩箱复⽤\n使⽤继承时需要考虑⾥⽒替换原则\n## 优点：\n新类对象存取成员对象只通过成员对象的接⼝，是⿊箱复⽤，系统更灵活，降低耦合度，可以在运⾏时动态进⾏，\n新对象可动态引⽤与成员对象类型相同的对象\n## 缺点：\n需要管理较多对象\npublic class EagerSingleton {\n// 类加载时就创建唯⼀实例\nprivate static final EagerSingleton instance = new EagerSingleton();\n// 私有构造⽅法\nprivate EagerSingleton() {\n// 公有静态⽅法，获取唯⼀实例\npublic static EagerSingleton getInstance()\n迪⽶特法则\n概念：\n⼀个对象应当对其他对象有尽可能少的了解，即不和陌⽣⼈说话\n“朋友圈”概念（以下情况是该对象朋友）：\n## this：\n## 该对象⽅法中的参数\n## 实例变量直接引⽤的对象\n## 实例变量如果是⼀个聚集（聚合对象），聚集中的元素\n## 该对象⽅法中创建的变量\n## 要求：\n## 优先考虑将⼀个类设计成不变类\n## 尽量降低⼀个类的访问权限\n## 谨慎使⽤  Serializable（持久化，通过序列化⼀个对象，将其写⼊磁4.   盘，以后程序调⽤时重新恢复该对象）\n## 尽量降低成员的访问权限\n## 优点： 降低类之间的耦合\n## 缺点：  过多使⽤迪⽶特法则，会产⽣⼤量中介类，设计变复杂\n⼿写单例设计模式\n## 饿汉式\n## 懒汉式\npublic class InnerStaticSingleton {\n// 私有静态内部类\nprivate static class SingletonHolder {\nprivate static final InnerStaticSingleton instance = new\nInnerStaticSingleton();\n// 私有构造⽅法\nprivate InnerStaticSingleton() {\n// 公有静态⽅法，获取唯⼀实例\npublic static InnerStaticSingleton getInstance()\n{ return SingletonHolder.instance;\n## 静态内部类单例模式\n## 枚举单例模式\n// 私有静态成员变量，⽤于保存唯⼀的实例\nprivate static Singleton instance;\n// 私有构造⽅法，防⽌外部通过 new 创建实例\nprivate Singleton() {\n// 公有静态⽅法，获取唯⼀的实例\npublic static Singleton getInstance() {\n// 使⽤双重检查锁定，确保在多线程环境下也能正常⼯作，并且提⾼了性能\nif (instance == null) {\nsynchronized (Singleton.class)\n{ if (instance == null) {\ninstance = new Singleton();\nreturn instance;\n你在实际开发中⽤过哪些设计模式\n## 单例模式：  ⽤于确保系统中某个类只有⼀个实例。在数据库连接、⽇志管理等场景中使⽤过。\n## ⼯⼚模式： ⽤于创建对象，将对象的创建过程封装在⼀个⼯⼚类中。在创建复杂对象、实现类的选择时使⽤\n## 观察者模式： ⽤于实现对象之间的⼀对多依赖关系，当⼀个对象的状态发⽣变化时，其所有依赖对象都会得\n到通知。在实现⽤户界⾯和数据模型之间的通信、事件处理等场景中使⽤过。\n设计模式了解吗？有哪些设计原则需要遵守？\n单⼀职责\n在设计类的时候要尽量缩⼩粒度，使功能明确、单⼀，不要做多余的事情（⾼内聚，低耦合）\n单⼀职责下的类会⽐较⼩⽽精悍，需要使⽤结构性模式组合复⽤他们\n开闭原则\n⼀个类应该对扩展开发，对修改关闭\n关键是要做好封装，隐藏内部的实现细节，开发⾜够的接⼝，这样⼦外部的代码就只能通过接⼝去扩展功能，不需\n要侵⼊到类的内部\nfinal关键字\n不能说要实现某个功能必要要修改类内部的代码才能实现，需要能够通过扩展实现新的功能（低耦合）\n⾥⽒替换\n⼦类能够完全替换⽗类，不会改变⽗类定义的⾏为\n⽐如⼀个基类⻦类中有⼀个⽅法，能够⻜⾏，所有的⻦类都必须继承它，但是企鹅、鸵⻦这些没办法⻜⾏（使⽤接\n⼝代替继承）\n接⼝隔离\n不应该强迫客户依赖于它们不需要的接⼝\n建⽴单⼀接⼝，不要建⽴庞⼤的接⼝，尽量细化，接⼝中的⽅法要建⽴少\npublic enum EnumSingleton {\n// 定义⼀个枚举元素，它就是 Singleton 的唯⼀实例\nINSTANCE;\n// 其他业务⽅法\npublic void doSomething() {\nimport java.util.ArrayList;\nimport java.util.List;\n// 主题接⼝\ninterface Subject {\nvoid addObserver(Observer observer);\nvoid removeObserver(Observer observer);\nvoid notifyObservers();\n// 具体主题类\nclass WeatherStation implements Subject {\nprivate List<Observer> observers = new ArrayList<>();\nprivate float temperature;\npublic void setTemperature(float temperature) {\nthis.temperature = temperature;\nnotifyObservers();\npublic void addObserver(Observer observer)\n{ observers.add(observer);\n类“⽝科”依赖接⼝I中的⽅法：捕⻝（），⾏⾛（），奔跑（）， 宠物狗类是对类“⽝科”的实现。 对于具体的类：宠\n物狗来说，虽然存在着⽤不到的⽅法，但由于继承了接⼝，所以也必须要实现这些⽤不到的⽅法\n依赖倒置\n上层要避免依赖下层的实现细节，两者都应该依赖于抽象\n⽐如Java的操作数据库，Java定义了⼀组接⼝，由各个数据库去实现它，Java不依赖于他们，数据库依赖于Java\n组合优于继承\n继承耦合度⾼，组合耦合度低\n继承基类是固定好的，但是组合通过组合类的指针，可以传⼊不同的类，避免⾼耦合\n说⼀说你了解的⼯⼚模式\n⼯⼚模式提供了⼀种创建对象的接⼝，但由⼦类决定实例化的类是哪⼀个。⼯⼚模式可以将复杂的对象创建过程封\n装在具体⼯⼚类中，客户端只需关⼼使⽤⼯⼚接⼝创建产品即可，适⽤于需要将对象创建过程进⾏解耦，或者在⼀\n个系统中有多个产品族、产品等级结构，需要统⼀管理的情况。\n说⼀说你了解的观察者模式\n定义了⼀种⼀对多的依赖关系，让多个观察者对象同时监听某⼀个主题对象，当主题对象状态发⽣变化时，会通知\n所有的观察者对象，使得它们能够⾃动更新。\n考虑⼀个简单的⽓象站示例，⽓象站可以测量温度、湿度和⽓压，并在这些数据发⽣变化时通知观察者更新。\npublic void removeObserver(Observer observer)\n{ observers.remove(observer);\npublic void notifyObservers() {\nfor (Observer observer : observers)\n{ observer.update(temperature);\n// 观察者接⼝\ninterface Observer {\nvoid update(float temperature);\n// 具体观察者类\nclass Display implements Observer\npublic void update(float temperature)\n{ System.out.println(\"Display: Temperature is \" +\ntemperature);\nclass Logger implements Observer\npublic void update(float temperature) {\nSystem.out.println(\"Logger: Logging temperature data - \" + temperature);\n// 客户端代码\npublic class Client {\npublic static void main(String[] args) {\nWeatherStation weatherStation = new WeatherStation();\nObserver display = new Display();\nObserver logger = new Logger();\nweatherStation.addObserver(display);\nweatherStation.addObserver(logger);\n// 模拟温度变化\nweatherStation.setTemperature(25.5f);\n// 输出：",
    "question": "的某些特定步骤",
    "answer": "## 访问者(visitor)模式：\n表示⼀个作⽤于某对象结构中的各元素的操作，使得在不改变各元素的类的前提下定义作⽤于这些元素的新操作\n设计原则\n单⼀职责\n在设计类的时候要尽量缩⼩粒度，使功能明确、单⼀，不要做多余的事情（⾼内聚，低耦合）\n开闭原则\n软件实体（类、模块、函数等）应该对扩展开放，对修改关闭。这意味着可以通过扩展来添加新功能，⽽不必修改\n现有代码。\n⾥⽒替换\n⼦类型必须能够替换掉它们的基类型。在程序中，如果有⼀个基类和⼀个⼦类，那么可以⽤⼦类对象替换基类对\n象，⽽程序的⾏为仍然是正确的。\n接⼝隔离\n不应该强迫⼀个类实现它不需要的接⼝。⼀个类不应该对它⽤不到的⽅法负责。\n依赖倒置\n⾼层模块不应该依赖于低层模块，⽽是应该依赖于抽象。抽象不应该依赖于具体实现，具体实现应该依赖于抽象。\n⽐如Java的操作数据库，Java定义了⼀组接⼝，由各个数据库去实现它，Java不依赖于他们，数据库依赖于Java\n组合优于继承\n继承耦合度⾼，组合耦合度低\n继承基类是固定好的，但是组合通过组合类的指针，可以传⼊不同的类，避免⾼耦合\n组合复⽤原则\n## 概念：\n优先使⽤组合 contains a（聚合 has a），⽽不是继承 is a 来达到⽬的\n## 原因：\n继承会将实现细节暴露给⼦类，继承复⽤破坏了封装性，是⽩箱复⽤\n使⽤继承时需要考虑⾥⽒替换原则\n## 优点：\n新类对象存取成员对象只通过成员对象的接⼝，是⿊箱复⽤，系统更灵活，降低耦合度，可以在运⾏时动态进⾏，\n新对象可动态引⽤与成员对象类型相同的对象\n## 缺点：\n需要管理较多对象\npublic class EagerSingleton {\n// 类加载时就创建唯⼀实例\nprivate static final EagerSingleton instance = new EagerSingleton();\n// 私有构造⽅法\nprivate EagerSingleton() {\n// 公有静态⽅法，获取唯⼀实例\npublic static EagerSingleton getInstance()\n迪⽶特法则\n概念：\n⼀个对象应当对其他对象有尽可能少的了解，即不和陌⽣⼈说话\n“朋友圈”概念（以下情况是该对象朋友）：\n## this：\n## 该对象⽅法中的参数\n## 实例变量直接引⽤的对象\n## 实例变量如果是⼀个聚集（聚合对象），聚集中的元素\n## 该对象⽅法中创建的变量\n## 要求：\n## 优先考虑将⼀个类设计成不变类\n## 尽量降低⼀个类的访问权限\n## 谨慎使⽤  Serializable（持久化，通过序列化⼀个对象，将其写⼊磁4.   盘，以后程序调⽤时重新恢复该对象）\n## 尽量降低成员的访问权限\n## 优点： 降低类之间的耦合\n## 缺点：  过多使⽤迪⽶特法则，会产⽣⼤量中介类，设计变复杂\n⼿写单例设计模式\n## 饿汉式\n## 懒汉式\npublic class InnerStaticSingleton {\n// 私有静态内部类\nprivate static class SingletonHolder {\nprivate static final InnerStaticSingleton instance = new\nInnerStaticSingleton();\n// 私有构造⽅法\nprivate InnerStaticSingleton() {\n// 公有静态⽅法，获取唯⼀实例\npublic static InnerStaticSingleton getInstance()\n{ return SingletonHolder.instance;\n## 静态内部类单例模式\n## 枚举单例模式\n// 私有静态成员变量，⽤于保存唯⼀的实例\nprivate static Singleton instance;\n// 私有构造⽅法，防⽌外部通过 new 创建实例\nprivate Singleton() {\n// 公有静态⽅法，获取唯⼀的实例\npublic static Singleton getInstance() {\n// 使⽤双重检查锁定，确保在多线程环境下也能正常⼯作，并且提⾼了性能\nif (instance == null) {\nsynchronized (Singleton.class)\n{ if (instance == null) {\ninstance = new Singleton();\nreturn instance;\n你在实际开发中⽤过哪些设计模式\n## 单例模式：  ⽤于确保系统中某个类只有⼀个实例。在数据库连接、⽇志管理等场景中使⽤过。\n## ⼯⼚模式： ⽤于创建对象，将对象的创建过程封装在⼀个⼯⼚类中。在创建复杂对象、实现类的选择时使⽤\n## 观察者模式： ⽤于实现对象之间的⼀对多依赖关系，当⼀个对象的状态发⽣变化时，其所有依赖对象都会得\n到通知。在实现⽤户界⾯和数据模型之间的通信、事件处理等场景中使⽤过。\n设计模式了解吗？有哪些设计原则需要遵守？\n单⼀职责\n在设计类的时候要尽量缩⼩粒度，使功能明确、单⼀，不要做多余的事情（⾼内聚，低耦合）\n单⼀职责下的类会⽐较⼩⽽精悍，需要使⽤结构性模式组合复⽤他们\n开闭原则\n⼀个类应该对扩展开发，对修改关闭\n关键是要做好封装，隐藏内部的实现细节，开发⾜够的接⼝，这样⼦外部的代码就只能通过接⼝去扩展功能，不需\n要侵⼊到类的内部\nfinal关键字\n不能说要实现某个功能必要要修改类内部的代码才能实现，需要能够通过扩展实现新的功能（低耦合）\n⾥⽒替换\n⼦类能够完全替换⽗类，不会改变⽗类定义的⾏为\n⽐如⼀个基类⻦类中有⼀个⽅法，能够⻜⾏，所有的⻦类都必须继承它，但是企鹅、鸵⻦这些没办法⻜⾏（使⽤接\n⼝代替继承）\n接⼝隔离\n不应该强迫客户依赖于它们不需要的接⼝\n建⽴单⼀接⼝，不要建⽴庞⼤的接⼝，尽量细化，接⼝中的⽅法要建⽴少\npublic enum EnumSingleton {\n// 定义⼀个枚举元素，它就是 Singleton 的唯⼀实例\nINSTANCE;\n// 其他业务⽅法\npublic void doSomething() {\nimport java.util.ArrayList;\nimport java.util.List;\n// 主题接⼝\ninterface Subject {\nvoid addObserver(Observer observer);\nvoid removeObserver(Observer observer);\nvoid notifyObservers();\n// 具体主题类\nclass WeatherStation implements Subject {\nprivate List<Observer> observers = new ArrayList<>();\nprivate float temperature;\npublic void setTemperature(float temperature) {\nthis.temperature = temperature;\nnotifyObservers();\npublic void addObserver(Observer observer)\n{ observers.add(observer);\n类“⽝科”依赖接⼝I中的⽅法：捕⻝（），⾏⾛（），奔跑（）， 宠物狗类是对类“⽝科”的实现。 对于具体的类：宠\n物狗来说，虽然存在着⽤不到的⽅法，但由于继承了接⼝，所以也必须要实现这些⽤不到的⽅法\n依赖倒置\n上层要避免依赖下层的实现细节，两者都应该依赖于抽象\n⽐如Java的操作数据库，Java定义了⼀组接⼝，由各个数据库去实现它，Java不依赖于他们，数据库依赖于Java\n组合优于继承\n继承耦合度⾼，组合耦合度低\n继承基类是固定好的，但是组合通过组合类的指针，可以传⼊不同的类，避免⾼耦合\n说⼀说你了解的⼯⼚模式\n⼯⼚模式提供了⼀种创建对象的接⼝，但由⼦类决定实例化的类是哪⼀个。⼯⼚模式可以将复杂的对象创建过程封\n装在具体⼯⼚类中，客户端只需关⼼使⽤⼯⼚接⼝创建产品即可，适⽤于需要将对象创建过程进⾏解耦，或者在⼀\n个系统中有多个产品族、产品等级结构，需要统⼀管理的情况。\n说⼀说你了解的观察者模式\n定义了⼀种⼀对多的依赖关系，让多个观察者对象同时监听某⼀个主题对象，当主题对象状态发⽣变化时，会通知\n所有的观察者对象，使得它们能够⾃动更新。\n考虑⼀个简单的⽓象站示例，⽓象站可以测量温度、湿度和⽓压，并在这些数据发⽣变化时通知观察者更新。\npublic void removeObserver(Observer observer)\n{ observers.remove(observer);\npublic void notifyObservers() {\nfor (Observer observer : observers)\n{ observer.update(temperature);\n// 观察者接⼝\ninterface Observer {\nvoid update(float temperature);\n// 具体观察者类\nclass Display implements Observer\npublic void update(float temperature)\n{ System.out.println(\"Display: Temperature is \" +\ntemperature);\nclass Logger implements Observer\npublic void update(float temperature) {\nSystem.out.println(\"Logger: Logging temperature data - \" + temperature);\n// 客户端代码\npublic class Client {\npublic static void main(String[] args) {\nWeatherStation weatherStation = new WeatherStation();\nObserver display = new Display();\nObserver logger = new Logger();\nweatherStation.addObserver(display);\nweatherStation.addObserver(logger);\n// 模拟温度变化\nweatherStation.setTemperature(25.5f);\n// 输出：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 4430,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000165",
    "content": "## 观察者模式： ⽤于实现对象之间的⼀对多依赖关系，当⼀个对象的状态发⽣变化时，其所有依赖对象都会得\n\n到通知。在实现⽤户界⾯和数据模型之间的通信、事件处理等场景中使⽤过。\n设计模式了解吗？有哪些设计原则需要遵守？\n单⼀职责\n在设计类的时候要尽量缩⼩粒度，使功能明确、单⼀，不要做多余的事情（⾼内聚，低耦合）\n单⼀职责下的类会⽐较⼩⽽精悍，需要使⽤结构性模式组合复⽤他们\n开闭原则\n⼀个类应该对扩展开发，对修改关闭\n关键是要做好封装，隐藏内部的实现细节，开发⾜够的接⼝，这样⼦外部的代码就只能通过接⼝去扩展功能，不需\n要侵⼊到类的内部\nfinal关键字\n不能说要实现某个功能必要要修改类内部的代码才能实现，需要能够通过扩展实现新的功能（低耦合）\n⾥⽒替换\n⼦类能够完全替换⽗类，不会改变⽗类定义的⾏为\n⽐如⼀个基类⻦类中有⼀个⽅法，能够⻜⾏，所有的⻦类都必须继承它，但是企鹅、鸵⻦这些没办法⻜⾏（使⽤接\n⼝代替继承）\n接⼝隔离\n不应该强迫客户依赖于它们不需要的接⼝\n建⽴单⼀接⼝，不要建⽴庞⼤的接⼝，尽量细化，接⼝中的⽅法要建⽴少\npublic enum EnumSingleton {\n// 定义⼀个枚举元素，它就是 Singleton 的唯⼀实例\nINSTANCE;\n// 其他业务⽅法\npublic void doSomething() {\nimport java.util.ArrayList;\nimport java.util.List;\n// 主题接⼝\ninterface Subject {\nvoid addObserver(Observer observer);\nvoid removeObserver(Observer observer);\nvoid notifyObservers();\n// 具体主题类\nclass WeatherStation implements Subject {\nprivate List<Observer> observers = new ArrayList<>();\nprivate float temperature;\npublic void setTemperature(float temperature) {\nthis.temperature = temperature;\nnotifyObservers();\npublic void addObserver(Observer observer)\n{ observers.add(observer);\n类“⽝科”依赖接⼝I中的⽅法：捕⻝（），⾏⾛（），奔跑（）， 宠物狗类是对类“⽝科”的实现。 对于具体的类：宠\n物狗来说，虽然存在着⽤不到的⽅法，但由于继承了接⼝，所以也必须要实现这些⽤不到的⽅法\n依赖倒置\n上层要避免依赖下层的实现细节，两者都应该依赖于抽象\n⽐如Java的操作数据库，Java定义了⼀组接⼝，由各个数据库去实现它，Java不依赖于他们，数据库依赖于Java\n组合优于继承\n继承耦合度⾼，组合耦合度低\n继承基类是固定好的，但是组合通过组合类的指针，可以传⼊不同的类，避免⾼耦合\n说⼀说你了解的⼯⼚模式\n⼯⼚模式提供了⼀种创建对象的接⼝，但由⼦类决定实例化的类是哪⼀个。⼯⼚模式可以将复杂的对象创建过程封\n装在具体⼯⼚类中，客户端只需关⼼使⽤⼯⼚接⼝创建产品即可，适⽤于需要将对象创建过程进⾏解耦，或者在⼀\n个系统中有多个产品族、产品等级结构，需要统⼀管理的情况。\n说⼀说你了解的观察者模式\n定义了⼀种⼀对多的依赖关系，让多个观察者对象同时监听某⼀个主题对象，当主题对象状态发⽣变化时，会通知\n所有的观察者对象，使得它们能够⾃动更新。\n考虑⼀个简单的⽓象站示例，⽓象站可以测量温度、湿度和⽓压，并在这些数据发⽣变化时通知观察者更新。\npublic void removeObserver(Observer observer)\n{ observers.remove(observer);\npublic void notifyObservers() {\nfor (Observer observer : observers)\n{ observer.update(temperature);\n// 观察者接⼝\ninterface Observer {\nvoid update(float temperature);\n// 具体观察者类\nclass Display implements Observer\npublic void update(float temperature)\n{ System.out.println(\"Display: Temperature is \" +\ntemperature);\nclass Logger implements Observer\npublic void update(float temperature) {\nSystem.out.println(\"Logger: Logging temperature data - \" + temperature);\n// 客户端代码\npublic class Client {\npublic static void main(String[] args) {\nWeatherStation weatherStation = new WeatherStation();\nObserver display = new Display();\nObserver logger = new Logger();\nweatherStation.addObserver(display);\nweatherStation.addObserver(logger);\n// 模拟温度变化\nweatherStation.setTemperature(25.5f);\n// 输出：\n代理模式和适配器模式有什么区别\n代理模式（Proxy  Pattern）和适配器模式（Adapter  Pattern）都属于结构型设计模式",
    "question": "## 观察者模式： ⽤于实现对象之间的⼀对多依赖关系，当⼀个对象的状态发⽣变化时，其所有依赖对象都会得",
    "answer": "到通知。在实现⽤户界⾯和数据模型之间的通信、事件处理等场景中使⽤过。\n设计模式了解吗？有哪些设计原则需要遵守？\n单⼀职责\n在设计类的时候要尽量缩⼩粒度，使功能明确、单⼀，不要做多余的事情（⾼内聚，低耦合）\n单⼀职责下的类会⽐较⼩⽽精悍，需要使⽤结构性模式组合复⽤他们\n开闭原则\n⼀个类应该对扩展开发，对修改关闭\n关键是要做好封装，隐藏内部的实现细节，开发⾜够的接⼝，这样⼦外部的代码就只能通过接⼝去扩展功能，不需\n要侵⼊到类的内部\nfinal关键字\n不能说要实现某个功能必要要修改类内部的代码才能实现，需要能够通过扩展实现新的功能（低耦合）\n⾥⽒替换\n⼦类能够完全替换⽗类，不会改变⽗类定义的⾏为\n⽐如⼀个基类⻦类中有⼀个⽅法，能够⻜⾏，所有的⻦类都必须继承它，但是企鹅、鸵⻦这些没办法⻜⾏（使⽤接\n⼝代替继承）\n接⼝隔离\n不应该强迫客户依赖于它们不需要的接⼝\n建⽴单⼀接⼝，不要建⽴庞⼤的接⼝，尽量细化，接⼝中的⽅法要建⽴少\npublic enum EnumSingleton {\n// 定义⼀个枚举元素，它就是 Singleton 的唯⼀实例\nINSTANCE;\n// 其他业务⽅法\npublic void doSomething() {\nimport java.util.ArrayList;\nimport java.util.List;\n// 主题接⼝\ninterface Subject {\nvoid addObserver(Observer observer);\nvoid removeObserver(Observer observer);\nvoid notifyObservers();\n// 具体主题类\nclass WeatherStation implements Subject {\nprivate List<Observer> observers = new ArrayList<>();\nprivate float temperature;\npublic void setTemperature(float temperature) {\nthis.temperature = temperature;\nnotifyObservers();\npublic void addObserver(Observer observer)\n{ observers.add(observer);\n类“⽝科”依赖接⼝I中的⽅法：捕⻝（），⾏⾛（），奔跑（）， 宠物狗类是对类“⽝科”的实现。 对于具体的类：宠\n物狗来说，虽然存在着⽤不到的⽅法，但由于继承了接⼝，所以也必须要实现这些⽤不到的⽅法\n依赖倒置\n上层要避免依赖下层的实现细节，两者都应该依赖于抽象\n⽐如Java的操作数据库，Java定义了⼀组接⼝，由各个数据库去实现它，Java不依赖于他们，数据库依赖于Java\n组合优于继承\n继承耦合度⾼，组合耦合度低\n继承基类是固定好的，但是组合通过组合类的指针，可以传⼊不同的类，避免⾼耦合\n说⼀说你了解的⼯⼚模式\n⼯⼚模式提供了⼀种创建对象的接⼝，但由⼦类决定实例化的类是哪⼀个。⼯⼚模式可以将复杂的对象创建过程封\n装在具体⼯⼚类中，客户端只需关⼼使⽤⼯⼚接⼝创建产品即可，适⽤于需要将对象创建过程进⾏解耦，或者在⼀\n个系统中有多个产品族、产品等级结构，需要统⼀管理的情况。\n说⼀说你了解的观察者模式\n定义了⼀种⼀对多的依赖关系，让多个观察者对象同时监听某⼀个主题对象，当主题对象状态发⽣变化时，会通知\n所有的观察者对象，使得它们能够⾃动更新。\n考虑⼀个简单的⽓象站示例，⽓象站可以测量温度、湿度和⽓压，并在这些数据发⽣变化时通知观察者更新。\npublic void removeObserver(Observer observer)\n{ observers.remove(observer);\npublic void notifyObservers() {\nfor (Observer observer : observers)\n{ observer.update(temperature);\n// 观察者接⼝\ninterface Observer {\nvoid update(float temperature);\n// 具体观察者类\nclass Display implements Observer\npublic void update(float temperature)\n{ System.out.println(\"Display: Temperature is \" +\ntemperature);\nclass Logger implements Observer\npublic void update(float temperature) {\nSystem.out.println(\"Logger: Logging temperature data - \" + temperature);\n// 客户端代码\npublic class Client {\npublic static void main(String[] args) {\nWeatherStation weatherStation = new WeatherStation();\nObserver display = new Display();\nObserver logger = new Logger();\nweatherStation.addObserver(display);\nweatherStation.addObserver(logger);\n// 模拟温度变化\nweatherStation.setTemperature(25.5f);\n// 输出：\n代理模式和适配器模式有什么区别\n代理模式（Proxy  Pattern）和适配器模式（Adapter  Pattern）都属于结构型设计模式",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 2500,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000166",
    "content": "代理模式和适配器模式有什么区别\n\n代理模式（Proxy  Pattern）和适配器模式（Adapter  Pattern）都属于结构型设计模式\n## ⽬的不同\n代理模式的主要⽬的是控制对对象的访问，可以添加额外的操作，⽽不改变原始对象的结构。\n适配器模式的主要⽬的是使得原本由于接⼝不兼容⽽不能⼀起⼯作的类可以⼀起⼯作。\n## ⻆⾊不同\n代理模式包含抽象主题、真实主题和代理。\n适配器模式包含⽬标接⼝、适配器和被适配者\n## 应⽤场景不同\n代理模式适⽤于控制对对象的访问、延迟加载、实现权限控制等场景。\n适配器模式适⽤于解决两个已有接⼝不兼容的情况，使它们能够⼀起⼯作。\n计算机系统&Linux\n计算机体系结构内容较难，考察也较少，可以仅做了解，重点关注  Linux  相关的⼀些⾯试题\n字符编码\n我们知道⼀个字节有8位，8位在不考虑正负的情况下，能够表示256个数字。同理2个字节就能表示出65536个数\n字。那么对于字符该如何表示？\n通过计算机领域的⾄理名⾔：计算机科学领域的任何问题都可以通过增加⼀个间接的中间层来解决。\n我们通过在字符和⼆进制编码之间嵌套⼀个数字编号，通过数字编号，就能实现字符、⼆进制编码之间的关系绑\n// Display: Temperature is 25.5\n// Logger: Logging temperature data - 25.5\n像这样收录了很多的字符并⾏⼀⼀编号得到的⼀个对照表，我们称之为字符集。从⼆进制 -> 字符 称为解码，从字符\n-> ⼆进制 称为编码\n从ASCII字符集表示英⽂、控制符号这些，再到GB2312能表示出中⽂，⽬前存在着很多的字符集，这也就出现了⼀\n个问题，同⼀个⼆进制，在不同的字符集可能对应的字符不同，这也就导致了同⼀个⽂件，通过不同的字符集进⾏\n解码，呈现的结果不同（也就是我们所说的乱码）。如果有⼀种统⼀的编码形式（很全的字符集），对所有的字符\n都能提供唯⼀的⼆进制编码，那么就能解决上述的问题。Unicode就是这个很全的字符集。\n虽然通过Unicode我们实现了对字符的唯⼀表示，但是随之⽽来的还有另⼀个问题，这些⼆进制编码该如何存储？\n以代码world为例，将⼆进制直接照搬成⼀⾏，按照不同的步⻓进⾏解析，则会得出不同的结果，如何解决？\n固定⻓度编码\n最直接思路，就是固定⻓度，不管编号多⼤多⼩，统⼀根据最⻓位数来，位数不够，⾼位补零。\n优点：⾼效、快速进⾏编码、解码\n缺点：固定⻓度的形式，会导致内存的浪费，并且随着编码越来越⼤，编码之间的跨度也就越⼤，这样定⻓编码造\n成的浪费就更加显著\n可变⻓度编码\n根据固定⻓度编码的缺点，可以采⽤变⻓的形式进⾏解决，⼩编号少占⽤字节，⼤编号多占字节。不过如何划分边\n界是⼀个问题\n⼀种解决⽅案：\n可以采⽤类似IPV4中的分类编制的形式，在⼆进制中占⽤⼏位作为标识。\n上述的解决⽅案，其实就是我们所熟知的UTF-8编码，同时也是Go默认的编码⽅式\n冯诺依曼模型\n冯诺依曼模型分为 5 ⼤部件：内存、CPU、总线、输⼊设备、输出设备\nPC 实质上是⼀个⼤⼩为⼀个字的存储区域。对于32位的机器，⼀个字是4个字节；对于64位的机器，⼀I/O设备个\n字就是8个字节。说⽩了，PC就是⼀个4字节或是8字节的存储空间，⾥⾯存放的是某⼀条指令的地址。\n从系统上电的那⼀瞬间，直到系统断电，处理器就不断地在执⾏ PC 指向的指令，然后更新 PC，使其指向下⼀条要\n执⾏的指令（注意：这个下⼀条指令与刚刚执⾏的指令不⼀定是相邻的）\n从 0 开始编号，最先存储单位是字节（byte）\n处理器在执⾏程序时，内存主要存放程序指令以及数据\n内存和处理器之间通过总线来进⾏数据传递。实际上，总线贯穿了整个计算机系统，它负责将信息从⼀个部件传递\n到另外⼀个部件。\nCPU\nCPU 位宽： CPU ⼀次能处理多少字节的数据\n32位CPU⼀次可以计算4个字节;\n64位CPU⼀次可以计算8个字节;\n为了能⼀次计算⼤数的运算，CPU需要⽀持多个byte⼀起计算，所以CPU位宽越⼤，可以计算的数值就越⼤。\n⽐如说32位CPU能计算的最⼤整数是4294967295。\nCPU内部还有⼀些组件，常⻅的有寄存器、控制单元和逻辑运算单元等\n控制单元： 控制CPU⼯作；\n逻辑运算单元： 负责计算；\n寄存器： 在 CPU 中，计算速度快\n通俗的讲，寄存器可以理解为⼀个临时存放数据的空间。\n例如我们计算两个变量 a+b 的和，处理器从内存中读取 a 的值暂存在寄存器 X 中，读取 B 的值暂存在寄存器 Y\n中，这个操作会覆盖寄存器中原来的数值，处理器完成加载的操作后，ALU（Arithmatic/logic Unit）会从复制寄\n存器 X 和 Y 中保存的数值，然后进⾏算术运算，得到的结果会保存到寄存器 X 或者寄存器 Y 中，此时寄存器中原\n来的数值会被新的数值覆盖\n常⻅寄存器类型：\n通⽤寄存器：放运算数据\n程序记数器（PC）：⽤来存放 CPU 下⼀条要执⾏指令的 内存地址；\n指令寄存器：⽤来存放 PC 执⾏的指令，即 指令本身（取值后放⼊到 指令寄存器中）\n⽤于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种:\n地址总线：\n⽤于指定CPU将要操作的内存地址;\n数据总线：\n⽤于读写内存的数据;\n控制总线：\n⽤于发送和接收信号，⽐如中断、设备复位等信号，CPU收到信号后⾃然进⾏响应，这时也需要控制总线;\n当CPU要读写内存数据的时候．⼀般需要通过两个总线:\n⾸先要通过「地址总线」来指定内存的地址;\n再通过「数据总线」来传输数据;\n程序的执⾏过程\n现代⼤多数 CPU 都使⽤来流⽔线的⽅式来执⾏指令，\n所谓的流⽔线就是把⼀个任务拆分成多个⼩任务，于是⼀条指令通常分为 4 个阶段，称为 4 级流⽔线\n## 取指令\n## CPU 的 控制单元向 地址总线 发送 PC 中的地址，从内存中找到 待执⾏指令；\n## 并将 待执⾏指令 通过 数据总线 传⼊到 CPU 中的 指令寄存器 中\n## ⾃动更新 PC，指向下⼀条待执⾏指令的地址\n## 译指（分析指令）\n## CPU分析「指令寄存器」中的指令，确定指令的类型和参数：\n## 如果是计算类型的指令，就把指令交给「逻辑运算单元」运算;\n## 如果是存储类型的指令，则交由「控制单元」执⾏\n## 执⾏指令\n## 根据 译指的结果，把指令交给 CPU 中响应的控件（逻辑运算单元/控制单元）执⾏\n## 数据回写\n## CPU 将计算结果存回寄存器或者将寄存器的值存⼊内存\n不同的阶段其实是由计算机中的不同组件完成的：\n取指令、译指令：由 控制器 进⾏；\n指令执⾏：\n## 算术操作、逻辑操作、数据传输、条件分⽀都是由  逻辑运算单元（运算器)完成\n## 跳转语句：由 控制器（控制单元）完成\n输⼊/输出设备\n除了处理器，内存以及总线，计算机系统还包含各种输⼊输出设备，如键盘、⿏标、显示器以及磁盘等等。\n控制器与适配器主要区别是在于它们的封装⽅式，⽆论是控制器还是适配器，它们的功能都是在 IO 设备与 IO 总线之\n间传递数据\n编译系统如何⼯作\n## 理解编译系统可以优化程序的性能。\n例如：⼀个switch语句是不是要⽐⼀连串的if-else要⾼效得多？函数调⽤的开销有多⼤？while循环⽐for循环更⾼\n效么？\n## 理解编译系统可以帮助我们理解链接过程中出现的错误\n例如：静态变量和全局变量的区别是什么？静态库和动态库的区别是什么？\nlinux> ./hello\n## 避免安全漏洞\n例如：缓冲区溢出（buffer   overflow）是导致互联⽹安全漏洞的主要原因，如何避免写出的代码存在安全漏洞，第\n⼀步就是要理解数据和控制信息在程序栈上是如何存储的，了解不严谨不规范的书写⽅式会引起什么样的后果\n处理器解释指令\n处理器读并解释储存在内存中的指令\n运⾏hello程序\nhello.c 经过编译系统得到可执⾏⽬标⽂件 hello，此时可执⾏⽬标⽂件 hello 已经存放在系统的磁盘上，那么，如\n何运⾏这个可执⾏⽂件呢？\n在 linux 系统上运⾏可执⾏程序：打开⼀个 shell 程序，然后在 shell 中输⼊相应可执⾏程序的⽂件名。\nshell 是⼀个命令解释程序，它输出⼀个提示符 > 来等待⼀个命令⾏的输⼊，然后执⾏这个命令，如果该命令⾏的\n第⼀个单词不是内置的 shell 命令，那么 shell 就会假设这是⼀个可执⾏⽂件的名字，对这个⽂件进⾏加载并运\n在这个例⼦中，shell 加载并且运⾏ hello 程序，屏幕上显示 hello,world 内容，hello 程序运⾏结束并退出，shell\n继续等待下⼀个命令的输⼊。",
    "question": "代理模式和适配器模式有什么区别",
    "answer": "代理模式（Proxy  Pattern）和适配器模式（Adapter  Pattern）都属于结构型设计模式\n## ⽬的不同\n代理模式的主要⽬的是控制对对象的访问，可以添加额外的操作，⽽不改变原始对象的结构。\n适配器模式的主要⽬的是使得原本由于接⼝不兼容⽽不能⼀起⼯作的类可以⼀起⼯作。\n## ⻆⾊不同\n代理模式包含抽象主题、真实主题和代理。\n适配器模式包含⽬标接⼝、适配器和被适配者\n## 应⽤场景不同\n代理模式适⽤于控制对对象的访问、延迟加载、实现权限控制等场景。\n适配器模式适⽤于解决两个已有接⼝不兼容的情况，使它们能够⼀起⼯作。\n计算机系统&Linux\n计算机体系结构内容较难，考察也较少，可以仅做了解，重点关注  Linux  相关的⼀些⾯试题\n字符编码\n我们知道⼀个字节有8位，8位在不考虑正负的情况下，能够表示256个数字。同理2个字节就能表示出65536个数\n字。那么对于字符该如何表示？\n通过计算机领域的⾄理名⾔：计算机科学领域的任何问题都可以通过增加⼀个间接的中间层来解决。\n我们通过在字符和⼆进制编码之间嵌套⼀个数字编号，通过数字编号，就能实现字符、⼆进制编码之间的关系绑\n// Display: Temperature is 25.5\n// Logger: Logging temperature data - 25.5\n像这样收录了很多的字符并⾏⼀⼀编号得到的⼀个对照表，我们称之为字符集。从⼆进制 -> 字符 称为解码，从字符\n-> ⼆进制 称为编码\n从ASCII字符集表示英⽂、控制符号这些，再到GB2312能表示出中⽂，⽬前存在着很多的字符集，这也就出现了⼀\n个问题，同⼀个⼆进制，在不同的字符集可能对应的字符不同，这也就导致了同⼀个⽂件，通过不同的字符集进⾏\n解码，呈现的结果不同（也就是我们所说的乱码）。如果有⼀种统⼀的编码形式（很全的字符集），对所有的字符\n都能提供唯⼀的⼆进制编码，那么就能解决上述的问题。Unicode就是这个很全的字符集。\n虽然通过Unicode我们实现了对字符的唯⼀表示，但是随之⽽来的还有另⼀个问题，这些⼆进制编码该如何存储？\n以代码world为例，将⼆进制直接照搬成⼀⾏，按照不同的步⻓进⾏解析，则会得出不同的结果，如何解决？\n固定⻓度编码\n最直接思路，就是固定⻓度，不管编号多⼤多⼩，统⼀根据最⻓位数来，位数不够，⾼位补零。\n优点：⾼效、快速进⾏编码、解码\n缺点：固定⻓度的形式，会导致内存的浪费，并且随着编码越来越⼤，编码之间的跨度也就越⼤，这样定⻓编码造\n成的浪费就更加显著\n可变⻓度编码\n根据固定⻓度编码的缺点，可以采⽤变⻓的形式进⾏解决，⼩编号少占⽤字节，⼤编号多占字节。不过如何划分边\n界是⼀个问题\n⼀种解决⽅案：\n可以采⽤类似IPV4中的分类编制的形式，在⼆进制中占⽤⼏位作为标识。\n上述的解决⽅案，其实就是我们所熟知的UTF-8编码，同时也是Go默认的编码⽅式\n冯诺依曼模型\n冯诺依曼模型分为 5 ⼤部件：内存、CPU、总线、输⼊设备、输出设备\nPC 实质上是⼀个⼤⼩为⼀个字的存储区域。对于32位的机器，⼀个字是4个字节；对于64位的机器，⼀I/O设备个\n字就是8个字节。说⽩了，PC就是⼀个4字节或是8字节的存储空间，⾥⾯存放的是某⼀条指令的地址。\n从系统上电的那⼀瞬间，直到系统断电，处理器就不断地在执⾏ PC 指向的指令，然后更新 PC，使其指向下⼀条要\n执⾏的指令（注意：这个下⼀条指令与刚刚执⾏的指令不⼀定是相邻的）\n从 0 开始编号，最先存储单位是字节（byte）\n处理器在执⾏程序时，内存主要存放程序指令以及数据\n内存和处理器之间通过总线来进⾏数据传递。实际上，总线贯穿了整个计算机系统，它负责将信息从⼀个部件传递\n到另外⼀个部件。\nCPU\nCPU 位宽： CPU ⼀次能处理多少字节的数据\n32位CPU⼀次可以计算4个字节;\n64位CPU⼀次可以计算8个字节;\n为了能⼀次计算⼤数的运算，CPU需要⽀持多个byte⼀起计算，所以CPU位宽越⼤，可以计算的数值就越⼤。\n⽐如说32位CPU能计算的最⼤整数是4294967295。\nCPU内部还有⼀些组件，常⻅的有寄存器、控制单元和逻辑运算单元等\n控制单元： 控制CPU⼯作；\n逻辑运算单元： 负责计算；\n寄存器： 在 CPU 中，计算速度快\n通俗的讲，寄存器可以理解为⼀个临时存放数据的空间。\n例如我们计算两个变量 a+b 的和，处理器从内存中读取 a 的值暂存在寄存器 X 中，读取 B 的值暂存在寄存器 Y\n中，这个操作会覆盖寄存器中原来的数值，处理器完成加载的操作后，ALU（Arithmatic/logic Unit）会从复制寄\n存器 X 和 Y 中保存的数值，然后进⾏算术运算，得到的结果会保存到寄存器 X 或者寄存器 Y 中，此时寄存器中原\n来的数值会被新的数值覆盖\n常⻅寄存器类型：\n通⽤寄存器：放运算数据\n程序记数器（PC）：⽤来存放 CPU 下⼀条要执⾏指令的 内存地址；\n指令寄存器：⽤来存放 PC 执⾏的指令，即 指令本身（取值后放⼊到 指令寄存器中）\n⽤于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种:\n地址总线：\n⽤于指定CPU将要操作的内存地址;\n数据总线：\n⽤于读写内存的数据;\n控制总线：\n⽤于发送和接收信号，⽐如中断、设备复位等信号，CPU收到信号后⾃然进⾏响应，这时也需要控制总线;\n当CPU要读写内存数据的时候．⼀般需要通过两个总线:\n⾸先要通过「地址总线」来指定内存的地址;\n再通过「数据总线」来传输数据;\n程序的执⾏过程\n现代⼤多数 CPU 都使⽤来流⽔线的⽅式来执⾏指令，\n所谓的流⽔线就是把⼀个任务拆分成多个⼩任务，于是⼀条指令通常分为 4 个阶段，称为 4 级流⽔线\n## 取指令\n## CPU 的 控制单元向 地址总线 发送 PC 中的地址，从内存中找到 待执⾏指令；\n## 并将 待执⾏指令 通过 数据总线 传⼊到 CPU 中的 指令寄存器 中\n## ⾃动更新 PC，指向下⼀条待执⾏指令的地址\n## 译指（分析指令）\n## CPU分析「指令寄存器」中的指令，确定指令的类型和参数：\n## 如果是计算类型的指令，就把指令交给「逻辑运算单元」运算;\n## 如果是存储类型的指令，则交由「控制单元」执⾏\n## 执⾏指令\n## 根据 译指的结果，把指令交给 CPU 中响应的控件（逻辑运算单元/控制单元）执⾏\n## 数据回写\n## CPU 将计算结果存回寄存器或者将寄存器的值存⼊内存\n不同的阶段其实是由计算机中的不同组件完成的：\n取指令、译指令：由 控制器 进⾏；\n指令执⾏：\n## 算术操作、逻辑操作、数据传输、条件分⽀都是由  逻辑运算单元（运算器)完成\n## 跳转语句：由 控制器（控制单元）完成\n输⼊/输出设备\n除了处理器，内存以及总线，计算机系统还包含各种输⼊输出设备，如键盘、⿏标、显示器以及磁盘等等。\n控制器与适配器主要区别是在于它们的封装⽅式，⽆论是控制器还是适配器，它们的功能都是在 IO 设备与 IO 总线之\n间传递数据\n编译系统如何⼯作\n## 理解编译系统可以优化程序的性能。\n例如：⼀个switch语句是不是要⽐⼀连串的if-else要⾼效得多？函数调⽤的开销有多⼤？while循环⽐for循环更⾼\n效么？\n## 理解编译系统可以帮助我们理解链接过程中出现的错误\n例如：静态变量和全局变量的区别是什么？静态库和动态库的区别是什么？\nlinux> ./hello\n## 避免安全漏洞\n例如：缓冲区溢出（buffer   overflow）是导致互联⽹安全漏洞的主要原因，如何避免写出的代码存在安全漏洞，第\n⼀步就是要理解数据和控制信息在程序栈上是如何存储的，了解不严谨不规范的书写⽅式会引起什么样的后果\n处理器解释指令\n处理器读并解释储存在内存中的指令\n运⾏hello程序\nhello.c 经过编译系统得到可执⾏⽬标⽂件 hello，此时可执⾏⽬标⽂件 hello 已经存放在系统的磁盘上，那么，如\n何运⾏这个可执⾏⽂件呢？\n在 linux 系统上运⾏可执⾏程序：打开⼀个 shell 程序，然后在 shell 中输⼊相应可执⾏程序的⽂件名。\nshell 是⼀个命令解释程序，它输出⼀个提示符 > 来等待⼀个命令⾏的输⼊，然后执⾏这个命令，如果该命令⾏的\n第⼀个单词不是内置的 shell 命令，那么 shell 就会假设这是⼀个可执⾏⽂件的名字，对这个⽂件进⾏加载并运\n在这个例⼦中，shell 加载并且运⾏ hello 程序，屏幕上显示 hello,world 内容，hello 程序运⾏结束并退出，shell\n继续等待下⼀个命令的输⼊。",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 3604,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000167",
    "content": "## 避免安全漏洞\n\n例如：缓冲区溢出（buffer   overflow）是导致互联⽹安全漏洞的主要原因，如何避免写出的代码存在安全漏洞，第\n⼀步就是要理解数据和控制信息在程序栈上是如何存储的，了解不严谨不规范的书写⽅式会引起什么样的后果\n处理器解释指令\n处理器读并解释储存在内存中的指令\n运⾏hello程序\nhello.c 经过编译系统得到可执⾏⽬标⽂件 hello，此时可执⾏⽬标⽂件 hello 已经存放在系统的磁盘上，那么，如\n何运⾏这个可执⾏⽂件呢？\n在 linux 系统上运⾏可执⾏程序：打开⼀个 shell 程序，然后在 shell 中输⼊相应可执⾏程序的⽂件名。\nshell 是⼀个命令解释程序，它输出⼀个提示符 > 来等待⼀个命令⾏的输⼊，然后执⾏这个命令，如果该命令⾏的\n第⼀个单词不是内置的 shell 命令，那么 shell 就会假设这是⼀个可执⾏⽂件的名字，对这个⽂件进⾏加载并运\n在这个例⼦中，shell 加载并且运⾏ hello 程序，屏幕上显示 hello,world 内容，hello 程序运⾏结束并退出，shell\n继续等待下⼀个命令的输⼊。\n程序执⾏流程\n⾸先我们通过键盘输⼊\"./hello\" 的字符串，shell 程序会将输⼊的字符逐⼀读⼊寄存器，处理器会把 hello 这个字符\n串放⼊内存中。\n当我们完成输⼊，按下回⻋键时，shell 程序就知道我们已经完成了命令的输⼊，然后执⾏⼀系列的指令来来加载\n可执⾏⽂件 hello ，这些指令将 hello 中的数据和代码从磁盘复制到内存。\n数据就是我们要显示输出的 \"hello , world\\n\" ，这个复制的过程将利⽤DMA（Direct Memory Access）技术，数\n据可以不经过处理器，从磁盘直接到达内存。当可执⾏⽂件 hello 中的代码和数据被加载到内存中，处理器就开始\n执⾏ main 函数中的代码，main 函数⾮常简单，只有⼀个打印功能。\nCPU会将 \"hello , world\\n\" 这个字符串从内存复制到寄存器⽂件。然后再从寄存器⽂件复制到显示设备，最终hello\n, world显示在屏幕上。\n从 hello 程序执⾏的过程来看，系统即使执⾏如此简单的程序，数据信息仍旧需要在磁盘、内存、处理器以及 IO\n设备之间进⾏搬运。\n数据从⼀个地⽅搬运到另外⼀个地⽅需要花费时间，系统设计⼈员的⼀个主要任务就是缩短信息搬运所花费的时\n场景题 & 系统设计\n系统设计\n如何设计⼀个⾼性能的系统\n后台服务架构⾼性能设计之道\n如何设计⼀个秒杀系统\n秒杀系统相关问题",
    "question": "## 避免安全漏洞",
    "answer": "例如：缓冲区溢出（buffer   overflow）是导致互联⽹安全漏洞的主要原因，如何避免写出的代码存在安全漏洞，第\n⼀步就是要理解数据和控制信息在程序栈上是如何存储的，了解不严谨不规范的书写⽅式会引起什么样的后果\n处理器解释指令\n处理器读并解释储存在内存中的指令\n运⾏hello程序\nhello.c 经过编译系统得到可执⾏⽬标⽂件 hello，此时可执⾏⽬标⽂件 hello 已经存放在系统的磁盘上，那么，如\n何运⾏这个可执⾏⽂件呢？\n在 linux 系统上运⾏可执⾏程序：打开⼀个 shell 程序，然后在 shell 中输⼊相应可执⾏程序的⽂件名。\nshell 是⼀个命令解释程序，它输出⼀个提示符 > 来等待⼀个命令⾏的输⼊，然后执⾏这个命令，如果该命令⾏的\n第⼀个单词不是内置的 shell 命令，那么 shell 就会假设这是⼀个可执⾏⽂件的名字，对这个⽂件进⾏加载并运\n在这个例⼦中，shell 加载并且运⾏ hello 程序，屏幕上显示 hello,world 内容，hello 程序运⾏结束并退出，shell\n继续等待下⼀个命令的输⼊。\n程序执⾏流程\n⾸先我们通过键盘输⼊\"./hello\" 的字符串，shell 程序会将输⼊的字符逐⼀读⼊寄存器，处理器会把 hello 这个字符\n串放⼊内存中。\n当我们完成输⼊，按下回⻋键时，shell 程序就知道我们已经完成了命令的输⼊，然后执⾏⼀系列的指令来来加载\n可执⾏⽂件 hello ，这些指令将 hello 中的数据和代码从磁盘复制到内存。\n数据就是我们要显示输出的 \"hello , world\\n\" ，这个复制的过程将利⽤DMA（Direct Memory Access）技术，数\n据可以不经过处理器，从磁盘直接到达内存。当可执⾏⽂件 hello 中的代码和数据被加载到内存中，处理器就开始\n执⾏ main 函数中的代码，main 函数⾮常简单，只有⼀个打印功能。\nCPU会将 \"hello , world\\n\" 这个字符串从内存复制到寄存器⽂件。然后再从寄存器⽂件复制到显示设备，最终hello\n, world显示在屏幕上。\n从 hello 程序执⾏的过程来看，系统即使执⾏如此简单的程序，数据信息仍旧需要在磁盘、内存、处理器以及 IO\n设备之间进⾏搬运。\n数据从⼀个地⽅搬运到另外⼀个地⽅需要花费时间，系统设计⼈员的⼀个主要任务就是缩短信息搬运所花费的时\n场景题 & 系统设计\n系统设计\n如何设计⼀个⾼性能的系统\n后台服务架构⾼性能设计之道\n如何设计⼀个秒杀系统\n秒杀系统相关问题",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1090,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000168",
    "content": "程序执⾏流程\n\n⾸先我们通过键盘输⼊\"./hello\" 的字符串，shell 程序会将输⼊的字符逐⼀读⼊寄存器，处理器会把 hello 这个字符\n串放⼊内存中。\n当我们完成输⼊，按下回⻋键时，shell 程序就知道我们已经完成了命令的输⼊，然后执⾏⼀系列的指令来来加载\n可执⾏⽂件 hello ，这些指令将 hello 中的数据和代码从磁盘复制到内存。\n数据就是我们要显示输出的 \"hello , world\\n\" ，这个复制的过程将利⽤DMA（Direct Memory Access）技术，数\n据可以不经过处理器，从磁盘直接到达内存。当可执⾏⽂件 hello 中的代码和数据被加载到内存中，处理器就开始\n执⾏ main 函数中的代码，main 函数⾮常简单，只有⼀个打印功能。\nCPU会将 \"hello , world\\n\" 这个字符串从内存复制到寄存器⽂件。然后再从寄存器⽂件复制到显示设备，最终hello\n, world显示在屏幕上。\n从 hello 程序执⾏的过程来看，系统即使执⾏如此简单的程序，数据信息仍旧需要在磁盘、内存、处理器以及 IO\n设备之间进⾏搬运。\n数据从⼀个地⽅搬运到另外⼀个地⽅需要花费时间，系统设计⼈员的⼀个主要任务就是缩短信息搬运所花费的时\n场景题 & 系统设计\n系统设计\n如何设计⼀个⾼性能的系统\n后台服务架构⾼性能设计之道\n如何设计⼀个秒杀系统\n秒杀系统相关问题",
    "question": "程序执⾏流程",
    "answer": "⾸先我们通过键盘输⼊\"./hello\" 的字符串，shell 程序会将输⼊的字符逐⼀读⼊寄存器，处理器会把 hello 这个字符\n串放⼊内存中。\n当我们完成输⼊，按下回⻋键时，shell 程序就知道我们已经完成了命令的输⼊，然后执⾏⼀系列的指令来来加载\n可执⾏⽂件 hello ，这些指令将 hello 中的数据和代码从磁盘复制到内存。\n数据就是我们要显示输出的 \"hello , world\\n\" ，这个复制的过程将利⽤DMA（Direct Memory Access）技术，数\n据可以不经过处理器，从磁盘直接到达内存。当可执⾏⽂件 hello 中的代码和数据被加载到内存中，处理器就开始\n执⾏ main 函数中的代码，main 函数⾮常简单，只有⼀个打印功能。\nCPU会将 \"hello , world\\n\" 这个字符串从内存复制到寄存器⽂件。然后再从寄存器⽂件复制到显示设备，最终hello\n, world显示在屏幕上。\n从 hello 程序执⾏的过程来看，系统即使执⾏如此简单的程序，数据信息仍旧需要在磁盘、内存、处理器以及 IO\n设备之间进⾏搬运。\n数据从⼀个地⽅搬运到另外⼀个地⽅需要花费时间，系统设计⼈员的⼀个主要任务就是缩短信息搬运所花费的时\n场景题 & 系统设计\n系统设计\n如何设计⼀个⾼性能的系统\n后台服务架构⾼性能设计之道\n如何设计⼀个秒杀系统\n秒杀系统相关问题",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 600,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000169",
    "content": "## 秒杀系统场景特点\n\n秒杀⼀般是访问请求数量远远⼤于库存数量，只有少部分⽤户能够秒杀成功\n秒杀时⼤量⽤户会在同⼀时间同时进⾏抢购，⽹站瞬时访问流量激增\n秒杀业务流程⽐较简单，⼀般就是下订单减库存\n## 秒杀架构设计理念\n限流：  鉴于只有少部分⽤户能够秒杀成功，所以要限制⼤部分流量，只允许少部分流量进⼊服务后端秒杀程序。\n削峰：对于秒杀系统瞬时会有⼤量⽤户涌⼊，所以在抢购⼀开始会有很⾼的瞬间峰值。⾼峰值流量是压垮系统\n很重要的原因，所以如何把瞬间的⾼流量变成⼀段时间平稳的流量也是设计秒杀系统很重要的思路。实现削峰\n的常⽤的⽅法有前端添加⼀定难度的验证码后端利⽤缓存和消息中间件等技术。\n异步处理：秒杀系统是⼀个⾼并发系统，采⽤异步处理模式可以极⼤地提⾼系统并发量，其实异步处理就是削\n峰的⼀种实现⽅式。\n内存缓存：秒杀系统最⼤的瓶颈⼀般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把\n部分数据或业务逻辑转移到内存缓存，效率会有极⼤地提升。\n可拓展：当然如果我们想⽀持更多⽤户，更⼤的并发，最好就将系统设计成弹性可拓展的，如果流量来了，拓\n展机器就好了。像淘宝、京东等双⼗⼀活动时会增加⼤量机器应对交易⾼峰。\n## 架构⽅案\n⼀般的秒杀系统架构\n设计思路\n## 设计思路\n将请求拦截在系统上游，降低下游压⼒：秒杀系统特点是并发量极⼤，但实际秒杀成功的请求数量却很少，所\n以如果不在前端拦截很可能造成数据库读写锁冲突，甚⾄导致死锁，最终请求超时\n充分利⽤缓存：利⽤缓存预减库存，拦截掉⼤部分请求\n消息队列：这是⼀个异步处理过程，后台业务根据⾃⼰的处理能⼒，从消息队列中主动的拉取请求消息进⾏业\n务处理\n## 前端⽅案\n⻚⾯静态化：将活动⻚⾯上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。\n禁⽌重复提交：⽤户提交之后按钮置灰，禁⽌重复提交\n⽤户限流：在某⼀时间段内只允许⽤户提交⼀次请求，⽐如可以采取IP限流\n## 后端⽅案\n服务端控制器层(⽹关层)\n限制uid（UserID）访问频率：我们上⾯拦截了浏览器访问的请求，但针对某些恶意攻击或其它插件，在服务端控\n制层需要针对同⼀个访问uid，限制访问频率。\n## 服务层\n上⾯只拦截了⼀部分访问请求，当秒杀的⽤户量很⼤时，即使每个⽤户只有⼀个请求，到服务层的请求数量还是很\n⼤。⽐如我们有100W⽤户同时抢100台⼿机，服务层并发请求压⼒⾄少为100W。\n把需要秒杀的商品的主要信息以及库存初始化到redis缓存中\n做请求合法性的校验（⽐如是否登录），如果请求⾮法，直接给前端返回错误码，进⾏相应的提示\n进⾏内存标识的判断(true 已经秒杀结束，false 未秒杀结束，下⾯第4步会写⼊)，如果内存标识为true，直接\n返回秒杀结束\nredis中使⽤decr 进⾏预减库存操作，判断：如果decr后库存量⼩于0，则把内存标记置为true(已经秒杀结\n束，第3步会⽤到)，且返回秒杀结束\n⽤redis的布隆过滤器来判断是否已经秒杀到了（下⾯第7步会写⼊），防⽌重复秒杀，如果重复秒杀，直接返\n回重复秒杀的错误码。具体做法是：先⽤redis的布隆过滤器来判断是否秒杀过，如果布隆过滤器判断已经秒\n杀过了， 则再次查库确认是否秒杀过了，之所以再次查库确认是因为布隆过滤器对可能存在的数据是有误判\n率的；但是它对不存在的数据的判断是百分百准确的，所以如果redis的布隆过滤器判断没秒杀过，就直接放\n过去进⾏秒杀\n发送成功秒杀到的MQ消息给相应的业务端进⾏处理，并给⽤户端返回排队中，如果客户端收到排队中的消\n息，则⾃动进⾏轮询查询，直到返回秒杀成功或者秒杀失败为⽌\n相应的业务端进⾏处理：真正处理秒杀的业务端，再次进⾏校验（⽐如秒杀是否结束，库存是否充⾜等）、将\n⽤户和商品id作为key存⼊redis的布隆过滤器来标识该⽤户秒杀该商品成功（第5步会⽤到）、减库存（这⾥\n的是真正的减库存，操作数据库的库存）、⽣成秒杀订单、返回秒杀成功\n注意：就算请求⾛到了真正处理业务的这⼀端，也有可能秒杀失败，⽐如秒杀结束，库存不⾜，真正减库存失败，\n秒杀单⽣成失败等等，⼀旦失败，则返回秒杀结束\n优化：将秒杀接⼝隐藏：⽤户点击秒杀按钮的时候，根据⽤户id⽣成唯⼀的加密串存⼊缓存并返回给客户端，然后\n客户端再次请求的时候带着加密串过来，后端进⾏校验是否合法，若不合法，直接返回请求⾮法；\n限制某个接⼝的访问频率：可以⽤拦截器配合⾃定义注解来实现，这么做可以和具体的业务分离减少⼊侵，使⽤起\n来也⾮常⽅便\n## 数据库层\n数据库层是最脆弱的⼀层，⼀般在应⽤设计时在上游就需要把请求拦截掉，数据库层只承担“能⼒范围内”的访",
    "question": "## 秒杀系统场景特点",
    "answer": "秒杀⼀般是访问请求数量远远⼤于库存数量，只有少部分⽤户能够秒杀成功\n秒杀时⼤量⽤户会在同⼀时间同时进⾏抢购，⽹站瞬时访问流量激增\n秒杀业务流程⽐较简单，⼀般就是下订单减库存\n## 秒杀架构设计理念\n限流：  鉴于只有少部分⽤户能够秒杀成功，所以要限制⼤部分流量，只允许少部分流量进⼊服务后端秒杀程序。\n削峰：对于秒杀系统瞬时会有⼤量⽤户涌⼊，所以在抢购⼀开始会有很⾼的瞬间峰值。⾼峰值流量是压垮系统\n很重要的原因，所以如何把瞬间的⾼流量变成⼀段时间平稳的流量也是设计秒杀系统很重要的思路。实现削峰\n的常⽤的⽅法有前端添加⼀定难度的验证码后端利⽤缓存和消息中间件等技术。\n异步处理：秒杀系统是⼀个⾼并发系统，采⽤异步处理模式可以极⼤地提⾼系统并发量，其实异步处理就是削\n峰的⼀种实现⽅式。\n内存缓存：秒杀系统最⼤的瓶颈⼀般都是数据库读写，由于数据库读写属于磁盘IO，性能很低，如果能够把\n部分数据或业务逻辑转移到内存缓存，效率会有极⼤地提升。\n可拓展：当然如果我们想⽀持更多⽤户，更⼤的并发，最好就将系统设计成弹性可拓展的，如果流量来了，拓\n展机器就好了。像淘宝、京东等双⼗⼀活动时会增加⼤量机器应对交易⾼峰。\n## 架构⽅案\n⼀般的秒杀系统架构\n设计思路\n## 设计思路\n将请求拦截在系统上游，降低下游压⼒：秒杀系统特点是并发量极⼤，但实际秒杀成功的请求数量却很少，所\n以如果不在前端拦截很可能造成数据库读写锁冲突，甚⾄导致死锁，最终请求超时\n充分利⽤缓存：利⽤缓存预减库存，拦截掉⼤部分请求\n消息队列：这是⼀个异步处理过程，后台业务根据⾃⼰的处理能⼒，从消息队列中主动的拉取请求消息进⾏业\n务处理\n## 前端⽅案\n⻚⾯静态化：将活动⻚⾯上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。\n禁⽌重复提交：⽤户提交之后按钮置灰，禁⽌重复提交\n⽤户限流：在某⼀时间段内只允许⽤户提交⼀次请求，⽐如可以采取IP限流\n## 后端⽅案\n服务端控制器层(⽹关层)\n限制uid（UserID）访问频率：我们上⾯拦截了浏览器访问的请求，但针对某些恶意攻击或其它插件，在服务端控\n制层需要针对同⼀个访问uid，限制访问频率。\n## 服务层\n上⾯只拦截了⼀部分访问请求，当秒杀的⽤户量很⼤时，即使每个⽤户只有⼀个请求，到服务层的请求数量还是很\n⼤。⽐如我们有100W⽤户同时抢100台⼿机，服务层并发请求压⼒⾄少为100W。\n把需要秒杀的商品的主要信息以及库存初始化到redis缓存中\n做请求合法性的校验（⽐如是否登录），如果请求⾮法，直接给前端返回错误码，进⾏相应的提示\n进⾏内存标识的判断(true 已经秒杀结束，false 未秒杀结束，下⾯第4步会写⼊)，如果内存标识为true，直接\n返回秒杀结束\nredis中使⽤decr 进⾏预减库存操作，判断：如果decr后库存量⼩于0，则把内存标记置为true(已经秒杀结\n束，第3步会⽤到)，且返回秒杀结束\n⽤redis的布隆过滤器来判断是否已经秒杀到了（下⾯第7步会写⼊），防⽌重复秒杀，如果重复秒杀，直接返\n回重复秒杀的错误码。具体做法是：先⽤redis的布隆过滤器来判断是否秒杀过，如果布隆过滤器判断已经秒\n杀过了， 则再次查库确认是否秒杀过了，之所以再次查库确认是因为布隆过滤器对可能存在的数据是有误判\n率的；但是它对不存在的数据的判断是百分百准确的，所以如果redis的布隆过滤器判断没秒杀过，就直接放\n过去进⾏秒杀\n发送成功秒杀到的MQ消息给相应的业务端进⾏处理，并给⽤户端返回排队中，如果客户端收到排队中的消\n息，则⾃动进⾏轮询查询，直到返回秒杀成功或者秒杀失败为⽌\n相应的业务端进⾏处理：真正处理秒杀的业务端，再次进⾏校验（⽐如秒杀是否结束，库存是否充⾜等）、将\n⽤户和商品id作为key存⼊redis的布隆过滤器来标识该⽤户秒杀该商品成功（第5步会⽤到）、减库存（这⾥\n的是真正的减库存，操作数据库的库存）、⽣成秒杀订单、返回秒杀成功\n注意：就算请求⾛到了真正处理业务的这⼀端，也有可能秒杀失败，⽐如秒杀结束，库存不⾜，真正减库存失败，\n秒杀单⽣成失败等等，⼀旦失败，则返回秒杀结束\n优化：将秒杀接⼝隐藏：⽤户点击秒杀按钮的时候，根据⽤户id⽣成唯⼀的加密串存⼊缓存并返回给客户端，然后\n客户端再次请求的时候带着加密串过来，后端进⾏校验是否合法，若不合法，直接返回请求⾮法；\n限制某个接⼝的访问频率：可以⽤拦截器配合⾃定义注解来实现，这么做可以和具体的业务分离减少⼊侵，使⽤起\n来也⾮常⽅便\n## 数据库层\n数据库层是最脆弱的⼀层，⼀般在应⽤设计时在上游就需要把请求拦截掉，数据库层只承担“能⼒范围内”的访",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1952,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000170",
    "content": "## 数据库层\n\n数据库层是最脆弱的⼀层，⼀般在应⽤设计时在上游就需要把请求拦截掉，数据库层只承担“能⼒范围内”的访\n问请求。所以，上⾯通过在服务层引⼊队列和缓存，让最底层的数据库⾼枕⽆忧\n为防⽌秒杀出现负数订单数⼤于真正的库存数，所以在真正减库存，update库存的时候应该加上where   库存\n>0，⽽且需要给秒杀订单表加上⽤户id和商品id联合的唯⼀索引\n如何设计⼀个本地缓存\n想要设计⼀个本地缓存，考虑点主要在数据⽤何种⽅式存储，能存储多少数据，多余的数据如何处理等⼏个点，下\n⾯我们来详细的介绍每个考虑点：",
    "question": "## 数据库层",
    "answer": "数据库层是最脆弱的⼀层，⼀般在应⽤设计时在上游就需要把请求拦截掉，数据库层只承担“能⼒范围内”的访\n问请求。所以，上⾯通过在服务层引⼊队列和缓存，让最底层的数据库⾼枕⽆忧\n为防⽌秒杀出现负数订单数⼤于真正的库存数，所以在真正减库存，update库存的时候应该加上where   库存\n>0，⽽且需要给秒杀订单表加上⽤户id和商品id联合的唯⼀索引\n如何设计⼀个本地缓存\n想要设计⼀个本地缓存，考虑点主要在数据⽤何种⽅式存储，能存储多少数据，多余的数据如何处理等⼏个点，下\n⾯我们来详细的介绍每个考虑点：",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 260,
    "metadata": {
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000171",
    "content": "问请求。所以，上⾯通过在服务层引⼊队列和缓存，让最底层的数据库⾼枕⽆忧\n\n为防⽌秒杀出现负数订单数⼤于真正的库存数，所以在真正减库存，update库存的时候应该加上where   库存\n>0，⽽且需要给秒杀订单表加上⽤户id和商品id联合的唯⼀索引\n如何设计⼀个本地缓存\n想要设计⼀个本地缓存，考虑点主要在数据⽤何种⽅式存储，能存储多少数据，多余的数据如何处理等⼏个点，下\n⾯我们来详细的介绍每个考虑点：\n## 数据结构\n⾸要考虑的就是数据该如何存储，⽤什么数据结构存储。最简单的就直接⽤Map来存储数据，或者复杂的如\nredis⼀样提供了多种数据类型哈希，列表，集合，有序集合等，底层使⽤了双端链表，压缩列表，集合，跳\n跃表等数据结构。\n## 对象上限\n因为是本地缓存，内存有上限，所以⼀般都会指定缓存对象的数量⽐如1024，当达到某个上限后需要有某种\n策略去删除多余的数据。\n## 清除策略\n上⾯说到当达到对象上限之后需要有清除策略，常⻅的⽐如有LRU(最近最少使⽤)、FIFO(先进先出)、LFU(最\n近最不常⽤)、SOFT(软引⽤)、WEAK(弱引⽤)等策略。\n## 过期时间\n除了使⽤清除策略，⼀般本地缓存也会有⼀个过期时间设置，⽐如redis可以给每个key设置⼀个过期时间，这\n样当达到过期时间之后直接删除，采⽤清除策略+过期时间双重保证。\n## 线程安全\n像redis是直接使⽤单线程处理，所以就不存在线程安全问题。⽽我们现在提供的本地缓存往往是可以多个线\n程同时访问的，所以线程安全是不容忽视的问题，并且线程安全问题是不应该抛给使⽤者去保证。\n## 简明的接⼝\n提供⼀个傻⽠式的对外接⼝是很有必要的，对使⽤者来说使⽤此缓存不是⼀种负担⽽是⼀种享受，提供常⽤的\nget，put，remove，clear，getSize等⽅法即可。\n## 是否持久化\n这个其实不是必须的，是否需要将缓存数据持久化看需求。本地缓存如ehcache是⽀持持久化的，⽽guava是\n没有持久化功能的。分布式缓存如redis是有持久化功能的，memcached是没有持久化功能的。\n## 阻塞机制\n我们使⽤缓存的⽬的就是因为被缓存的数据⽣成⽐较费时，⽐如调⽤对外的接⼝，查询数据库，计算量很⼤的\n结果等等。这时候如果多个线程同时调⽤get⽅法获取的结果都为null，每个线程都去执⾏⼀遍费时的计算，其\n实也是对资源的浪费。最好的办法是只有⼀个线程去执⾏，其他线程等待，计算⼀次就够了。但是此功能基本\n上都交给使⽤者来处理，很少有本地缓存有这种功能。\n如何设计⼀个RPC框架\n## 定义RPC接⼝：  定义服务接⼝及其⽅法。这是RPC的核⼼，决定了客户端可以调⽤哪些⽅法。\n## 选择通信协议： 选择合适的通信协议，如HTTP/REST、TCP、UDP等。不同的协议有不同的优劣势，取决于\n你的应⽤需求。\n## 选择序列化协议：   选择序列化协议，将数据转换为字节流以在⽹络上传输。常⻅的有JSON、Protobuf、\nThrift等。考虑效率、可读性和平台兼容性。\n## 实现远程调⽤： 实现将RPC请求发送到远程服务并接收响应的机制。这可能涉及到⽹络通信、数据解析和错\n误处理。\n## 服务注册与发现：   提供服务注册中⼼，使服务能够动态注册和发现。Zookeeper、Consul、etcd等⼯具可以\n⽤于服务注册与发现。\n## 负载均衡：  实现负载均衡机制，确保请求在多个服务节点之间分布均匀。常⻅的负载均衡算法有轮询、随机、\n最⼩连接数等。\n## 安全性：  考虑数据在传输中的安全性，可以使⽤加密协议（如TLS/SSL）来保护通信。\n## 错误处理： 设计良好的错误处理机制，包括定义错误码、异常传播和⽇志记录。确保客户端能够得知发⽣了\n什么问题。\n## 性能优化：  考虑并发性、延迟和吞吐量等性能⽅⾯的问题。使⽤连接池、异步IO等技术进⾏优化。\n## 监控和⽇志：   实现监控和⽇志记录，以便及时发现问题并进⾏故障排除。集成⽇志系统和监控⼯具，如\nPrometheus、Grafana等。\n微信红包怎么设计？\n微信红包架构设计\n扫码登录怎么设计？",
    "question": "问请求。所以，上⾯通过在服务层引⼊队列和缓存，让最底层的数据库⾼枕⽆忧",
    "answer": "为防⽌秒杀出现负数订单数⼤于真正的库存数，所以在真正减库存，update库存的时候应该加上where   库存\n>0，⽽且需要给秒杀订单表加上⽤户id和商品id联合的唯⼀索引\n如何设计⼀个本地缓存\n想要设计⼀个本地缓存，考虑点主要在数据⽤何种⽅式存储，能存储多少数据，多余的数据如何处理等⼏个点，下\n⾯我们来详细的介绍每个考虑点：\n## 数据结构\n⾸要考虑的就是数据该如何存储，⽤什么数据结构存储。最简单的就直接⽤Map来存储数据，或者复杂的如\nredis⼀样提供了多种数据类型哈希，列表，集合，有序集合等，底层使⽤了双端链表，压缩列表，集合，跳\n跃表等数据结构。\n## 对象上限\n因为是本地缓存，内存有上限，所以⼀般都会指定缓存对象的数量⽐如1024，当达到某个上限后需要有某种\n策略去删除多余的数据。\n## 清除策略\n上⾯说到当达到对象上限之后需要有清除策略，常⻅的⽐如有LRU(最近最少使⽤)、FIFO(先进先出)、LFU(最\n近最不常⽤)、SOFT(软引⽤)、WEAK(弱引⽤)等策略。\n## 过期时间\n除了使⽤清除策略，⼀般本地缓存也会有⼀个过期时间设置，⽐如redis可以给每个key设置⼀个过期时间，这\n样当达到过期时间之后直接删除，采⽤清除策略+过期时间双重保证。\n## 线程安全\n像redis是直接使⽤单线程处理，所以就不存在线程安全问题。⽽我们现在提供的本地缓存往往是可以多个线\n程同时访问的，所以线程安全是不容忽视的问题，并且线程安全问题是不应该抛给使⽤者去保证。\n## 简明的接⼝\n提供⼀个傻⽠式的对外接⼝是很有必要的，对使⽤者来说使⽤此缓存不是⼀种负担⽽是⼀种享受，提供常⽤的\nget，put，remove，clear，getSize等⽅法即可。\n## 是否持久化\n这个其实不是必须的，是否需要将缓存数据持久化看需求。本地缓存如ehcache是⽀持持久化的，⽽guava是\n没有持久化功能的。分布式缓存如redis是有持久化功能的，memcached是没有持久化功能的。\n## 阻塞机制\n我们使⽤缓存的⽬的就是因为被缓存的数据⽣成⽐较费时，⽐如调⽤对外的接⼝，查询数据库，计算量很⼤的\n结果等等。这时候如果多个线程同时调⽤get⽅法获取的结果都为null，每个线程都去执⾏⼀遍费时的计算，其\n实也是对资源的浪费。最好的办法是只有⼀个线程去执⾏，其他线程等待，计算⼀次就够了。但是此功能基本\n上都交给使⽤者来处理，很少有本地缓存有这种功能。\n如何设计⼀个RPC框架\n## 定义RPC接⼝：  定义服务接⼝及其⽅法。这是RPC的核⼼，决定了客户端可以调⽤哪些⽅法。\n## 选择通信协议： 选择合适的通信协议，如HTTP/REST、TCP、UDP等。不同的协议有不同的优劣势，取决于\n你的应⽤需求。\n## 选择序列化协议：   选择序列化协议，将数据转换为字节流以在⽹络上传输。常⻅的有JSON、Protobuf、\nThrift等。考虑效率、可读性和平台兼容性。\n## 实现远程调⽤： 实现将RPC请求发送到远程服务并接收响应的机制。这可能涉及到⽹络通信、数据解析和错\n误处理。\n## 服务注册与发现：   提供服务注册中⼼，使服务能够动态注册和发现。Zookeeper、Consul、etcd等⼯具可以\n⽤于服务注册与发现。\n## 负载均衡：  实现负载均衡机制，确保请求在多个服务节点之间分布均匀。常⻅的负载均衡算法有轮询、随机、\n最⼩连接数等。\n## 安全性：  考虑数据在传输中的安全性，可以使⽤加密协议（如TLS/SSL）来保护通信。\n## 错误处理： 设计良好的错误处理机制，包括定义错误码、异常传播和⽇志记录。确保客户端能够得知发⽣了\n什么问题。\n## 性能优化：  考虑并发性、延迟和吞吐量等性能⽅⾯的问题。使⽤连接池、异步IO等技术进⾏优化。\n## 监控和⽇志：   实现监控和⽇志记录，以便及时发现问题并进⾏故障排除。集成⽇志系统和监控⼯具，如\nPrometheus、Grafana等。\n微信红包怎么设计？\n微信红包架构设计\n扫码登录怎么设计？",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 1729,
    "metadata": {
      "is_split": false,
      "part": null,
      "category": "未分类"
    }
  },
  {
    "chunk_id": "qa_000172",
    "content": "## 监控和⽇志：   实现监控和⽇志记录，以便及时发现问题并进⾏故障排除。集成⽇志系统和监控⼯具，如\n\nPrometheus、Grafana等。\n微信红包怎么设计？\n微信红包架构设计\n扫码登录怎么设计？\n扫码登录流程",
    "question": "## 监控和⽇志：   实现监控和⽇志记录，以便及时发现问题并进⾏故障排除。集成⽇志系统和监控⼯具，如",
    "answer": "Prometheus、Grafana等。\n微信红包怎么设计？\n微信红包架构设计\n扫码登录怎么设计？\n扫码登录流程",
    "chunk_type": "qa",
    "source_file": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\清洗后数据\\题库\\题库\\八股文\\计算机基础篇（最强八股文）第五版 .pdf",
    "page_num": null,
    "question_num": null,
    "char_count": 109,
    "metadata": {
      "category": "未分类"
    }
  }
]