{
  "version": "llm_dedup_v1",
  "generated_at": "2026-01-27T09:21:45.638375Z",
  "total_questions": 7298,
  "categories": {
    "LLM": {
      "count": 2039,
      "questions": [
        "如何用模型投票发现潜在错误标注？",
        "如何设计 20 条 LF（Labeling Function）并估计准确率？",
        "当 LF 冲突时，如何采用多数投票加权重？",
        "如何评估弱监督标签对微调效果影响？",
        "如何采用熵+多样性混合策略选择样本？",
        "当预算仅允许标注 1000 条时，如何采用批量选择？",
        "如何可视化选择结果并解释？",
        "如何基于 RL 动态调整标注单价并激励质量？",
        "当标注错误导致重标时，如何采用惩罚机制？",
        "如何计算单条标注的 ROI 并优化？",
        "如何构建 GitHub 监控机器人并自动汇总 release note？",
        "当权重格式从 FP16 转为 BF16 时，如何评估对精度的影响？",
        "如何基于 Docker 多版本镜像快速切换对比？",
        "如何用 arxiv-sanity 筛选每日相关论文并打标签？",
        "当复现 LLaMA 3 时，如何估算 8B 模型在 2k GPU 小时内的成本？",
        "如何开源复现代码并吸引社区贡献？",
        "如何编写 CONTRIBUTING.md 并设置 CI 检查？",
        "当 PR 冲突时，如何采用 rebase 保持线性历史？",
        "如何用 allcontributors 机器人自动识别贡献者？",
        "如何基于 Google Trends 和论文投稿量预测 MoE 热度？",
        "当规划 2025 技术路线时，如何采用德尔菲法收集专家意见？",
        "如何将路线图可视化并定期 review？",
        "如何构建专利检索关键词并监控竞争对手？",
        "当发现潜在侵权时，如何采用专利规避设计？",
        "如何撰写中国 AI 专利并加快审查？",
        "如何在客服场景选择“问题解决率”而非“点击率”作为北极星？",
        "当指标滞后 7 天时，如何采用代理指标实时指导？",
        "如何用 North-Star Framework 对齐团队目标？",
        "如何量化模型替代人工客服节省的 FTE 并折算年费？",
        "当 GPU 成本上升 20% 时，如何计算 ROI 盈亏平衡点？",
        "如何用 Monte Carlo 模拟 ROI 分布并给出 95% 置信区间？",
        "如何设计双盲实验避免诱导性问卷？",
        "当 NPS 提升 10 分时，如何验证与模型优化的因果关系？",
        "如何细分人群（年龄、地域）分析 NPS 差异？",
        "如何针对模型输出违规设计 15 分钟响应流程？",
        "当服务宕机时，如何自动降级到规则客服并保证 SLA？",
        "如何每季度演练并更新预案？",
        "如何用 OKR 设置季度模型优化目标？",
        "当竞品上线新功能时，如何采用 Sprint 快速跟进？",
        "如何基于用户反馈优先级排序并 roadmap 可视化？",
        "Qwen-72B 的推理延迟与首 token 时间是多少？",
        "量化到 INT4 后的性能损失是多少？",
        "混合云架构能否降低合规溢价？",
        "如何计算合规溢价？",
        "如何避免权重冲突？",
        "如何明确“独立且可分离”以避免传染？",
        "什么是小信息集？",
        "给定指令 A、B，让同一位标注者同时阅读并强制二选一：哪条指令更难？",
        "如何完成近似去重？",
        "为什么不用 SimHash+Hamming LSH？",
        "量更新策略是什么？",
        "如何做敏感实体识别？",
        "请解释可落地的工业级方案，而不是只背论文。",
        "在多模态对话里，图片 token 的熵如何定义？",
        "如何保证对下游任务影响 <2%？",
        "如何保证信息不丢失？",
        "如何设置质量与多样性阈值？",
        "如果院方只给 10 条私有种子，如何快速扩增？",
        "多样性阈值能否动态调整？",
        "如何与推理加速联动？",
        "如何制作 95% 置信区间？",
        "如何回滚到任意版本？",
        "如何对齐流与批的事件时间窗口？",
        "如何用 Continued Learning + Experience Replay，把“必须重训”降级为“增量合并”？",
        "如何用广播与优先级队列避免 GPU 资源死锁？",
        "增量参数量是多少？",
        "如何实现最小显存占用？",
        "什么是批次累积？",
        "如何设置系数防止过拟合？",
        "Prometheus+Grafana 看板如何设计？",
        "什么是 Early Stopping？",
        "任务间共享底层 Transformer 时，如何防止某任务 loss 爆炸拖垮整体？",
        "千亿模型 ckpt 200GB，网络拷贝耗时 10 分钟，如何做到秒级回滚？",
        "PT 与 SFT 的 epoch 比例如何设置？",
        "PT 与 SFT 的幻觉率差异是什么？",
        "如何更换 tokenizer 并保证嵌入层初始化？",
        "如何修改权重矩阵并加入损失？",
        "如何设置 buffer 大小？",
        "如何量化遗忘并触发回放？",
        "如何构建轻量级 rehearsal buffer？",
        "如何在线动态调整 buffer 大小，兼顾成本与效果？",
        "如何绘制边际收益曲线？",
        "如何进行稳定性筛选？",
        "如何设计拒绝模板？",
        "如何动态升级风控？",
        "如何避免截断？",
        "如何确保请求费用 ≤ 用户套餐剩余额度，否则降级到流式摘要方案？",
        "多模态场景下，文本塔用 LoRA、ID 塔用 HashTable 查表，如何实现分钟级热插拔？",
        "为什么不用交叉熵而用 Margin？",
        "margin 值怎么调？",
        "如何防止模型把正例 score 打爆到 1 之后梯度消失？",
        "如何提升 batch 吞吐？",
        "如何保证 NDCG@10 下降 <1%？",
        "如何保证召回？",
        "如何根据业务召回指标反向推导 efConstruction？",
        "如何在百亿级向量、天级更新的 LLMOps 管线里落地？",
        "如何优化 pp×tp×dp 组合？",
        "如何映射加载 7B 模型？",
        "与 REST 互通：使用 google.api.HttpRule 把 FieldMask 映射成什么？",
        "强化学习微调（RLHF）能否替代重试？",
        "多租户场景下，如何做到租户级告警隔离？",
        "如何降低 RTO？",
        "重训后模型效果“虚假回升”（指标好看但人工评测下降）怎么发现？",
        "如果知识库本身过期或矛盾，如何给知识置信度再打分？",
        "遇到多跳事实（A的B的C是多少）怎么办？",
        "若要支持实时流式生成（直播字幕），如何做到逐句验证不阻塞？",
        "如何让请求落同一 Pod，避免 CPU 缓存失效导致长尾延迟？",
        "LSH 与向量数据库如何协同？",
        "如何满足《生成式 AI 服务管理暂行办法》对可追溯、可撤销、可红？",
        "谐音错误也纳入对抗样本吗？",
        "如果白名单膨胀到 10 万条以上，配置中心性能瓶颈如何解决？",
        "未来监管要求“豁免需可解释”，如何自动化生成解释报告？",
        "如何将模型库版本 + Chunk-ID 也纳入同一 Request-ID 证据链？",
        "如何做多级日志快照，既能还原完整语境，又避免 N² 膨胀？",
        "在千亿参数模型上如何秒级抽取并脱敏展示？",
        "如何将Attention输入张量钉住，防止EPC换页？",
        "如果业务方要求ε=0.1但延迟只能增加2ms，该如何权衡？",
        "如何设计可追溯、可验证、可解释的LLMOps流水线？",
        "如何把模型概率输出转化为符合《电子数据若干规定》《个人信息保护》的结果？",
        "如何在80%置信度下补足剩余20%不确定性，使报告达到“高度盖然”？",
        "大模型输出内容哈希上链后，如何防止“先上链后篡改”的链下文件掉包？",
        "梯度噪声过大怎么办？",
        "如何在不牺牲精度的前提下实现流式增量渲染？",
        "如果业务要求准确率93%但模型必须<800M，如何再压缩？",
        "若未来芯片进一步受限（仅48GB显存），如何单卡完成7B→1B蒸馏？",
        "动态阈值：如何让规则随监管政策自动刷新？",
        "多模态参数：图片里嵌了非法二维码，如何校验？",
        "如何用插件而非微调实现“可验证引用”？",
        "如何助力B租户模型提升，满足《数据跨境传输安全评估办法》？",
        "如何在安全与性能之间做Trade-off？",
        "插件热更新时，如何做到“零中断+零信任”？",
        "国密算法性能在GPU推理节点上可能成为瓶颈，怎么办？",
        "插件想要访问外部HTTPS服务，如何既放行又审计？",
        "如果社区提交的是多模态任务（图文混合），如何复用现有YAML描述？",
        "遇到恶意刷榜（偷偷在测试集里加训练语料）怎么办？",
        "多模态边界：当输入出现图片+文字时，如何定义单元？",
        "请求实时翻译为英/日/西语，调用对应模型，若业务决策差异率>1%，怎么办？",
        "数据合成比例继续提高，会不会导致模型崩溃？",
        "政务客户担心开源后数据泄露机密，如何平衡？",
        "可微几何约束能否直接写进 Transformer loss？",
        "多源坐标系混用（WGS-84、GCJ-02、BD-09）时，如何统一约束？",
        "极端大场景（千亿级参数+城市级路网）如何横向扩展？",
        "当生成解释引入多模态（图文混排）后，满意度评估指标需要如何升级？",
        "多模态长链如何校验？",
        "如何对抗“隐蔽矛盾”？",
        "如何设计增量召回 + 滑动窗口标注？",
        "如何保证标注一致性？",
        "如何用合成数据纠偏并保证增量微调不偏航？",
        "能否设计一套双缓冲流水线保证计算不空等吗？",
        "如何在“文化偏见”与“本地化合规”冲突时取舍？",
        "如何在交叉编译后的 ARM 环境部署？",
        "如何做降维可视化？",
        "如何将推理延迟从 420ms 降到 180ms，并保持矩阵统计特性不变？",
        "如何实时捕获熵崩溃信号（毫秒级延迟）？",
        "如何无人工干预触发 checkpoint 回滚与训练重启？",
        "如何与 LLMOps 平台打通做持续监控？",
        "如何在线插入已有前沿而不重新跑全量实验？",
        "head 数不一致怎么办？",
        "大模型时代，BERT 向量是否还够用？",
        "聚类结果如何反哺大模型微调？",
        "国产化算力瓶颈怎么破？",
        "“差异>10%”是否一定需要重采样？",
        "如何在 30 分钟内热修复？",
        "Stable Diffusion API 如何同时满足图片审核和版权过滤？",
        "如何导出完整证据链？",
        "模型如何自适应？",
        "怎么让英文大语言模型支持中文？",
        "目前主流的开源模型体系有哪些？",
        "Prefix Decoder、Causal Decoder 和 Encoder-Decoder 的区别是什么？",
        "大模型（LLM）的训练目标是什么？",
        "涌现能力出现的原因是什么？",
        "为何现在的大模型大部分是 Decoder-only 结构？",
        "简单介绍一下大模型（LLMs）。",
        "大模型（LLMs）后面跟的 175B、60B、540B 等指什么？",
        "大模型（LLMs）具有什么优点？",
        "大模型（LLMs）具有什么缺点？",
        "Prefix LM 和 Causal LM 的区别是什么？",
        "大模型（LLM）的架构如何？",
        "什么是 LLMs 复读机问题？",
        "为什么会出现 LLMs 复读机问题？",
        "如何缓解 LLMs 复读机问题？",
        "LLaMA 输入句子长度理论上可以无限长吗？",
        "什么情况用 BERT 模型，什么情况用 LLaMA、ChatGLM 类大模型，如何选择？",
        "各个专业领域是否需要各自的领域大模型来服务？",
        "如何让大模型处理更长的文本？",
        "如果想在某个模型基础上做全参数微调，需要多少显存？",
        "为什么 SFT 之后感觉 LLM 变傻了？",
        "SFT 指令微调数据如何构建？",
        "领域模型 Continue Pretrain 的数据如何选取？",
        "领域数据训练后通用能力下降，如何缓解遗忘通用能力？",
        "领域模型 Continue Pretrain 时，如何让模型在预训练过程中学习到更多知识？",
        "进行 SFT 时，基座模型选用 Chat 还是 Base？",
        "领域模型微调时，指令和数据输入格式有什么要求？",
        "领域模型微调的领域评测集如何构建？",
        "领域模型是否有必要进行词表扩增？",
        "如何训练自己的大模型？",
        "指令微调的好处是什么？",
        "预训练和微调哪个阶段注入知识？",
        "想让模型学习某个领域或行业的知识，应该做预训练还是微调？",
        "多轮对话任务如何微调模型？",
        "微调后的模型出现能力劣化，灾难性遗忘是怎么回事？",
        "微调模型需要多大显存？",
        "大模型（LLM）进行 SFT 时在学习什么？",
        "大模型（LLM）进行 SFT 时如何对样本进行优化？",
        "分布式训练框架如何选择？",
        "LLMs 训练时有哪些有用的建议？",
        "模型大小如何选择？",
        "加速卡如何选择？",
        "什么是 LangChain？",
        "LangChain 包含哪些核心概念？",
        "LangChain 中 Components and Chains 是什么？",
        "LangChain 中 Prompt Templates and Values 是什么？",
        "LangChain 中 Example Selectors 是什么？",
        "LangChain 中 Output Parsers 是什么？",
        "LangChain 中 Indexes and Retrievers 是什么？",
        "LangChain 中 Chat Message History 是什么？",
        "LangChain 中 Agents and Toolkits 是什么？",
        "什么是 LangChain Agent？",
        "如何使用 LangChain？",
        "LangChain 支持哪些功能？",
        "什么是 LangChain model？",
        "LangChain 包含哪些特点？",
        "LangChain 如何调用 LLMs 生成回复？",
        "LangChain 如何修改提示模板？",
        "LangChain 如何链接多个组件处理一个特定的下游任务？",
        "LangChain 如何 Embedding & vector store？",
        "LangChain 存在哪些问题及方法方案？",
        "LangChain 替代方案有哪些？",
        "为什么大模型需要外挂（向量）知识库？",
        "基于 LLM + 向量库的文档对话思路是怎么样？",
        "基于 LLM + 向量库的文档对话核心技术是什么？",
        "基于 LLM + 向量库的文档对话 prompt 模板如何构建？",
        "基于 LLM + 向量库的文档对话存在哪些痛点？",
        "LLMs 存在模型幻觉问题，请问如何处理？",
        "如何从长文档（书籍）中提取关键信息？",
        "为什么要提取标题甚至是多级标题？",
        "如何提取文章标题？",
        "如何区分单栏还是双栏 PDF？",
        "如何重新排序？",
        "如何提取表格和图片中的数据？",
        "微调方法的批处理大小对 GPU 显存和速度有什么影响？",
        "适配器微调（Adapter-tuning）思路是什么？",
        "提示学习（Prompting）有哪些方法，能不能稍微介绍一下它们间？",
        "为什么需要前缀微调（Prefix-tuning）？",
        "前缀微调（Prefix-tuning）思路是什么？",
        "前缀微调（Prefix-tuning）的优点是什么？",
        "前缀微调（Prefix-tuning）的缺点是什么？",
        "P-tuning 的思路是什么？",
        "P-tuning 的优点是什么？",
        "P-tuning 的缺点是什么？",
        "P-tuning v2 的思路是什么？",
        "P-tuning v2 的优点是什么？",
        "P-tuning v2 的缺点是什么？",
        "LoRA 微调方法为什么能加速训练？",
        "什么是 low-rank adaptation of large language models？",
        "为什么大模型推理时显存涨得那么多还一直占着？",
        "大模型在 GPU 和 CPU 上推理速度如何？",
        "推理速度上，int8 和 fp16 比起来怎么样？",
        "大模型有推理能力吗？",
        "大模型生成时的参数怎么设置？",
        "有哪些省内存的大语言模型训练/微调/推理方法？",
        "如何估算模型所需的 RAM？",
        "如何让大模型输出合规化？",
        "为什么要增量预训练？",
        "进行增量预训练需要做哪些准备工作？",
        "增量预训练所用训练框架是什么？",
        "增量预训练训练流程是怎么样？",
        "大模型怎么评测？",
        "大模型的 honest 原则是如何实现的？",
        "如何衡量大模型水平？",
        "大模型评估方法有哪些？",
        "大模型评估工具有哪些？",
        "模型如何判断回答的知识是训练过的已知的知识，怎么训练这种能力？",
        "简单介绍强化学习？",
        "简单介绍一下 RLHF？",
        "奖励模型需要和基础模型一致吗？",
        "RLHF 在实践过程中存在哪些不足？",
        "如何解决人工产生的偏好数据集成本较高、很难量产的问题？",
        "如何解决三个阶段的训练（SFT->RM->PPO）过程较长、更新迭代较慢的问题？",
        "如何解决 PPO 的训练过程同时存在 4 个模型（2 训练，2 推理），对计算资源的要求较高的问题？",
        "SFT（有监督微调）的数据集格式是什么？",
        "RM（奖励模型）的数据格式是什么？",
        "PPO（强化学习）的数据格式是什么？",
        "微调需要多少条数据？",
        "有哪些大模型的训练集？",
        "进行领域大模型预训练应用哪些数据集比较好？",
        "大模型大概有多大，模型文件有多大？",
        "能否用 4 * V100 32G 训练 Vicuna 65B？",
        "如果就是想要试试65b模型，但是显存不多怎么办？",
        "nB模型推理需要多少显存？",
        "nB模型训练需要多少显存？",
        "如何评估你的显卡利用率？",
        "如何查看多机训练时的网速？",
        "如何查看服务器上的多卡之间的NVLINK topo？",
        "如何查看服务器上显卡的具体型号？",
        "如何查看训练时的flops？",
        "如何查看对deepspeed的环境配置是否正确？",
        "tf32格式有多长？",
        "哪里看各类显卡算力比较？",
        "（torch profiler）如何查看自己的训练中通信开销？",
        "训练大语言模型存在问题？",
        "什么是点对点通信？",
        "什么是集体通信？",
        "什么是数据并行？",
        "数据并行如何提升效率？",
        "什么是流水线并行？",
        "什么是张量并行 (intra-layer)？",
        "数据并行 vs 张量并行 vs 流水线并行？",
        "什么是3D并行？",
        "想要训练1个LLM，如果只想用1张显卡，那么对显卡的要求是什么？",
        "如果有N张显存足够大的显卡，怎么加速训练？",
        "如果显卡的显存不够装下一个完整的模型呢？",
        "PP推理时是一个串行的过程，1个GPU计算、其他空闲，有没有其他方式？",
        "Colossal-AI 有1D/2D/2.5D/3D，是什么情况？",
        "除了3D并行有没有其他方式大规模训练？",
        "有了ZeRO系列，为什么还需要3D并行？",
        "平民适不适合玩3D并行？",
        "平民适不适合直接上多机多卡的ZeRO3（万兆网）？",
        "分布式并行及显存优化技术有哪一些，都有什么特点？",
        "显存优化技术有哪一些，都有什么特点？",
        "常见的分布式训练框架哪一些，都有什么特点？",
        "假如有超多的8卡A100节点（DGX A100），如何应用3D并行策略？",
        "如果想构这样一个大规模并行训练系统，训练框架如何选？",
        "如何选择一款分布式训练框架？",
        "为什么多机训练效率不如单机？",
        "为什么需要流水线并行（Pipeline Parallelism）？",
        "流水线并行（Pipeline Parallelism）优化目标是什么？",
        "流水线并行（Pipeline Parallelism）优缺点？",
        "为什么需要nn.DataParallel？",
        "pytorch中的GPU操作默认是什么样？",
        "介绍一下nn.DataParallel函数？",
        "nn.DataParallel函数处理逻辑介绍一下？",
        "nn.DataParallel 常见问题及解答有哪些？",
        "多 GPU 计算能减少程序运行时间吗？",
        "如何保存和加载多 GPU 训练的模型？",
        "为什么使用 nn.DataParallel 时第一块 GPU 的显存占用会更多？",
        "直接使用 nn.DataParallel 进行多卡训练时出现 warning 的原因是什么？",
        "nn.DataParallel 的参数更新方式是什么？",
        "nn.DataParallel 的优点有哪些？",
        "nn.DataParallel 的缺点有哪些？",
        "为什么需要 nn.parallel.DistributedDataParallel？",
        "什么是 DistributedDataParallel 的核心机制 Ring-AllReduce？",
        "nn.parallel.DistributedDataParallel 是什么？",
        "nn.parallel.DistributedDataParallel 如何实现多卡加速训练？",
        "nn.parallel.DistributedDataParallel 的实现流程是什么？",
        "nn.parallel.DistributedDataParallel 的参数更新机制是什么？",
        "nn.DataParallel（DP）与 DistributedDataParallel（DDP）有什么区别？",
        "DistributedDataParallel（DDP）的优点有哪些？",
        "DistributedDataParallel（DDP）的缺点有哪些？",
        "torch.multiprocessing 是什么？",
        "torch.multiprocessing 如何使用？",
        "什么是共享 CUDA 张量？",
        "什么是共享策略？",
        "为什么需要 AMP 混合精度训练？",
        "为什么需要自动混合精度？",
        "混合精度训练的优点是什么？",
        "混合精度训练的缺点是什么？",
        "混合精度训练的关键技术是什么？",
        "什么是混合精度训练的动态损失缩放？",
        "如何在 PyTorch 中使用自动混合精度？",
        "为什么需要 DeepSpeed？",
        "DeepSpeed 的基本概念是什么？",
        "DeepSpeed 的通信策略是什么？",
        "DeepSpeed 如何使用？",
        "DeepSpeed 如何进行代码实现？",
        "什么是训练精度？",
        "如何获取模型参数？",
        "为什么需要 accelerate 分布式训练？",
        "accelerate 分布式训练是什么？",
        "accelerate 分布式训练的原理是什么？",
        "accelerate 分布式训练如何实践？",
        "D 并行策略有哪些？",
        "为什么需要 ZeRO？",
        "ZeRO 的核心思想是什么？",
        "ZeRO 的显存如何分配？",
        "ZeRO 的优化策略是什么？",
        "ZeRO Offload 后的计算流程是什么？",
        "如何给 LLM 注入领域知识？",
        "如果想要快速体验各种模型，该怎么办？",
        "预训练数据 Token 重复是否影响模型性能？",
        "SFT 需要训练多少 Token？",
        "什么是位置编码？",
        "什么是绝对位置编码？",
        "什么是相对位置编码？",
        "旋转位置编码 RoPE 的思路是什么？",
        "推导一下旋转位置编码 RoPE？",
        "旋转位置编码 RoPE 有什么优点？",
        "旋转位置编码 RoPE 被哪些 LLMs 应用？",
        "什么是长度外推问题？",
        "长度外推问题的解决方法有哪些？",
        "ALiBi (Attention with Linear Biases) 的思路是什么？",
        "ALiBi (Attention with Linear Biases) 的偏置矩阵是什么，有什么作用？",
        "ALiBi (Attention with Linear Biases) 有什么优点？",
        "ALiBi (Attention with Linear Biases) 被哪些 LLMs 应用？",
        "Byte-Pair Encoding (BPE) 如何构建词典？",
        "WordPiece 与 BPE 异同点是什么？",
        "简单介绍一下 SentencePiece 的思路？",
        "举例介绍一下不同大模型 LLMs 的分词方式？",
        "介绍一下不同大模型 LLMs 的分词方式的区别？",
        "为什么需要构建中文 tokenization？",
        "如何对原始数据预处理？",
        "如何构建中文的词库？",
        "如何使用 transformers 库加载 sentencepiece 模型？",
        "如何合并英文词表和中文词表？",
        "怎么使用修改后的词表？",
        "总结一下构建中文 tokenization？",
        "为什么需要进行继续预训练？",
        "如何对继续预训练数据预处理？",
        "如何构建模型？",
        "如何使用模型？",
        "为什么需要对预训练模型进行指令微调？",
        "对预训练模型进行指令微调的数据如何处理？",
        "对预训练模型进行指令微调的 tokenization 如何构建？",
        "对预训练模型进行指令微调的模型如何构建？",
        "Layer Norm 的计算公式写一下？",
        "RMS Norm 的计算公式写一下？",
        "RMS Norm 相比于 Layer Norm 有什么特点？",
        "Deep Norm 的思路是什么？",
        "写一下 Deep Norm 代码实现？",
        "Deep Norm 有什么优点？",
        "LN 在 LLMs 中的不同位置有什么区别？",
        "LLMs 各模型分别用了哪种 Layer Normalization？",
        "介绍一下 FFN 块计算公式？",
        "介绍一下 GeLU 计算公式？",
        "介绍一下 Swish 计算公式？",
        "介绍一下使用 GLU 线性门控单元的 FFN 块计算公式？",
        "介绍一下使用 GeLU 的 GLU 块计算公式？",
        "介绍一下使用 Swish 的 GLU 块计算公式？",
        "各 LLMs 都使用哪种激活函数？",
        "当前优化模型最主要技术手段有哪些？",
        "推理加速框架有哪些？都有什么特点？",
        "vLLM 的功能有哪些？",
        "vLLM 的优点有哪些？",
        "vLLM 的缺点有哪些？",
        "vLLM 如何进行离线批量推理？",
        "vLLM 的 API Server 是什么？如何使用？",
        "介绍一下 Text generation inference？",
        "Text generation inference 的功能有哪些？",
        "Text generation inference 的优点有哪些？",
        "Text generation inference 的缺点有哪些？",
        "Text generation inference 如何使用 docker 运行 web server？",
        "vLLM 用于大模型并行推理加速存在什么问题？",
        "vLLM 如何优化大模型并行推理加速？",
        "什么是 PagedAttention？",
        "为什么需要 vLLM？",
        "vLLM 具有哪些特点？",
        "vLLM 支持哪些 Huggingface 模型？",
        "vLLM 性能如何？",
        "vLLM 如何安装？",
        "vLLM 如何使用？",
        "为什么需要 FasterTransformer？",
        "介绍一下 FasterTransformer？",
        "FasterTransformer 核心是什么？",
        "FasterTransformer 做了哪些优化？",
        "为什么需要 LightLLM？",
        "目前 LLM 推理框架有哪些？",
        "LightLLM 介绍一下？",
        "什么是 LightLLM？",
        "Token Attention 是什么？",
        "Efficient Router 是什么？",
        "LightLLM 性能表现如何？",
        "LightLLM 依赖包有哪些？",
        "LightLLM 如何安装？",
        "LightLLM 如何使用？",
        "LightLLM 支持哪些 LLMs 模型？",
        "传统 Attention 存在哪些问题？",
        "Attention 变体有哪些？",
        "Multi-head Attention 存在什么问题？",
        "介绍一下 Multi-Query Attention？",
        "对比一下 Multi-head Attention 和 Multi-Query Attention？",
        "Multi-Query Attention 这样做的好处是什么？",
        "有哪些模型使用 Multi-Query Attention？",
        "什么是 Grouped-query Attention？",
        "有哪些大模型使用 Grouped-query Attention？",
        "并行 transformer block 介绍一下？",
        "什么是大模型幻觉？",
        "为什么LLM会产生幻觉？",
        "为什么需要解决LLM的幻觉问题？",
        "幻觉一定是有害的吗？",
        "幻觉有哪些不同类型？",
        "如何度量幻觉？",
        "如何缓解LLM幻觉？",
        "LLMs什么时候最容易产生幻觉？",
        "LLMs训练数据和数据量对比如何？",
        "你了解baichuan-7B解构么？",
        "baichuan-7B如何收集原始数据并构建训练数据？",
        "baichuan-7B如何提高训练稳定性和吞吐？",
        "相比于baichuan-7B，baichuan-13B的特点体现在哪？",
        "如何对baichuan-13B进行推理和部署？",
        "如何对baichuan-13B进行微调？",
        "baichuan-53B相比于baichuan-7B和baichuan-13B有哪些优势？",
        "baichuan-53B如何对预训练数据做处理？",
        "baichuan-53B如何进行搜索增强？",
        "baichuan进行微调时，领域数据与通用数据配比如何？",
        "什么是思维链提示？",
        "思维链提示本质是什么？",
        "思维链提示与标准的提示学习方法有什么不同？",
        "思维链提示为什么可以提高语言模型的复杂推理能力？",
        "思维链提示的优势在哪？",
        "思维链提示适用场景有哪些？",
        "思维链提示目前还存在哪些不足点？",
        "思维链提示对推动语言模型复杂推理能力研究有哪些启发和影响？",
        "思维链提示对实现真正的通用人工智能仍面临哪些挑战？",
        "如何通过增加模型规模来获得语言模型强大的思维链推理能力？",
        "你认为可以在哪些其他方面应用“思维链提示”这一思路来提升语言模型的能力？",
        "如果需要你对思维链提示进行改进，你觉得你会改进哪些地方？",
        "思维链提示未来研究方向是什么？",
        "什么是思维链Chain-of-Thought（COT）？",
        "思维链Chain-of-Thought（COT）的思路是什么？",
        "思维链Chain-of-Thought（COT）存在哪些问题？",
        "为什么需要思维树Tree of Thoughts（TOT）？",
        "什么是思维树Tree of Thoughts（TOT）？",
        "思维树Tree of Thoughts（TOT）涉及哪些问题？",
        "为什么需要思维图Graph of Thoughts（GOT）？",
        "什么是思维图Graph of Thoughts（GOT）？",
        "思维图Graph of Thoughts（GOT）的核心思想是什么？",
        "为什么需要思维算法Algorithm of Thoughts（AOT）？",
        "思维算法Algorithm of Thoughts（AOT）的思路是什么？",
        "思维算法Algorithm of Thoughts（AOT）与其他COT的区别是什么？",
        "思维链 Chain-of-Thought（COT）有哪些应用场景？",
        "思维链 Chain-of-Thought（COT）有哪些局限性？",
        "为什么需要 Graph RAG？",
        "什么是 Graph RAG？",
        "Graph RAG 思路介绍？",
        "用代码介绍 Graph RAG？",
        "用示例介绍 Graph RAG？",
        "Graph RAG 排序优化方式？",
        "什么情况用 Bert 模型，什么情况用 LLaMA、ChatGLM 类大模？",
        "各个专业领域是否需要各自的大模型来服务？",
        "为什么 SFT 之后感觉 LLM 傻了？",
        "领域模型 Continue PreTrain 数据选取？",
        "进行 SFT 操作的时候，基座模型选用 Chat 还是 Base？",
        "领域模型微调指令&数据输入格式要求？",
        "领域模型微调领域评测集构建？",
        "预训练和微调哪个阶段注入知识的？",
        "想让模型学习某领域或行业知识，是应该预训练还是应该微调？",
        "大模型 LLM 进行 SFT 操作的时候在学习什么？",
        "预训练和 SFT 操作有什么不同？",
        "样本量规模增大，训练出现 OOM 报错，怎么解决？",
        "大模型 LLM 进行 SFT 如何对样本进行优化？",
        "模型参数迭代实验步骤？",
        "为什么需要进行参数微调？",
        "参数微调的原因有哪些？",
        "模型参数微调的方式有哪些？",
        "prompt tuning 和 prefix tuning 在微调上的区别是什么？",
        "LLaMA-adapter 如何实现稳定训练？",
        "LoRA 原理与使用技巧有哪些？",
        "LoRA 权重合入 chatglm 模型的方法？",
        "P-tuning 讲一下？",
        "P-tuning 与 P-tuning v2 区别在哪里？",
        "P-tuning 的优点与缺点？",
        "训练一个通用大模型的流程有哪些？",
        "DDO 与 DPO 的区别是什么？",
        "是否接触过 embeding 模型的微调方法？",
        "大模型 (LLMs) 评测有哪些方法？",
        "如何衡量大模型的效果？",
        "如何解决三个阶段的训练（SFT->RM->PPO）过程较长、迭代较慢的问题？",
        "模型训练的数据集问题：一般数据集哪里找？",
        "为什么需要进行模型量化及原理？",
        "大模型词表扩充的方法及工具？",
        "大模型应用框架及其功能？",
        "搭建大模型应用遇到过哪些问题，如何解决的？",
        "如何提升大模型的检索效果？",
        "是否了解上下文压缩方法？",
        "如何实现窗口上下文检索？",
        "开源的 RAG 框架有哪些，你比较了解？",
        "向量库有哪些？各自优点与区别？",
        "向量数据库有哪些？",
        "文档块的大小如何确定？",
        "RAG(检索增强生成)对于大模型来说，有什么好处？",
        "Self-attention 的公式及参数量？",
        "为什么用多头 (Multi-Head) 注意力？",
        "LangChain 替代方案？",
        "大模型进行训练用的是什么框架？",
        "业内常用的分布式 AI 框架有哪些？",
        "数据并行、张量并行、流水线并行的原理及区别？",
        "推理优化技术 Flash Attention 的作用是什么？",
        "推理优化技术 Paged Attention 的作用是什么？",
        "ZeRO（零冗余优化器）的三个阶段是什么？",
        "混合精度训练的优点是什么，可能带来什么问题？",
        "Megatron-DeepSpeed 方法是什么？",
        "Megatron-LM 方法是什么？",
        "DeepSpeed 方法是什么？",
        "涌现能力产生的原因是什么？",
        "self-attention 的计算方式是什么？",
        "请介绍一下 Transformer 的模型架构和细节。",
        "BART、LLaMA、GPT、T5、PaLM 等主流模型的异同点是什么？",
        "请介绍你个人项目中模型的优化点和技术细节。",
        "你个人项目中如何选择最佳的指令策略，以及其对模型效果的影响？",
        "你个人项目中模型如何评测（数据集、评测指标等）？",
        "LLaMA2 中使用的注意力机制是什么？",
        "RLHF 的具体工程流程是什么，包含哪几个模型？",
        "显存不够一般怎么解决？",
        "几种主流大模型的 loss 你了解哪些，它们有哪些异同？",
        "self-attention 的公式及参数量是什么，为什么用多头，为什么要除以根号 d？",
        "请介绍一下 BERT 和 GPT 的训练方式（预训练任务与训练细节）的区别。",
        "大模型的模型架构有哪些？",
        "ChatGPT 对比 GPT-3 的性能提升主要来源于哪些方面？",
        "大模型中常见的位置编码有哪些？",
        "大模型高效参数微调方法有哪些？",
        "样本构建的流程是怎样的？",
        "节点特征指的是什么？",
        "查询流程是什么？",
        "使用什么向量数据库？",
        "请介绍一下 RAG 原理。",
        "RAG 如何解决多实体提问问题？",
        "Prompt 是如何生成的，优化目标是什么，任务是什么？",
        "OCR 抽取效果不好，需要怎么排查问题？",
        "RNN 与 GNN 之间有哪些区别，以及它们各自适用于哪些场景？",
        "GPT 和 BERT 在文本表征方面有哪些结构和工作原理上的差异？",
        "为什么说 BERT 更好训练？",
        "分布式训练框架都了解哪些，能不能简单介绍一下？",
        "你了解 DeepSpeed 吗？介绍 ZeRO-1/2/3 分别是什么，并分析训练时的显存占用。",
        "说一下 Transformer 的架构和其内部细节？",
        "介绍大模型推理过程中，可以通过调节哪些参数提高性能？",
        "大模型训练的三种并行是什么？",
        "分布式训练的通信开销如何分析与对比？",
        "使用不超过 mm 复杂度的代码求解其两两之间的欧式距离？",
        "聊一下 RAG 项目总体思路？",
        "使用外挂知识库主要是为了解决什么问题？",
        "如何评价 RAG 项目的效果好坏，即指标是什么？",
        "在做 RAG 项目过程中遇到哪些问题，怎么解决的？",
        "RAG 项目里面有哪一些亮点？",
        "数据集怎么构建的，什么规模，评估指标是什么，这些指标存在哪些问题？",
        "模型底座是什么，这些不同底座什么区别，什么规模？",
        "同方法的差别是什么？",
        "模型推理是怎么做的，有没有 CoT、ToT 等，还是单轮？",
        "大模型可控性如何实现，怎么保证可控性？",
        "模型部署的平台是什么，推理效率怎么样，如何提升推理效率？",
        "项目最后上线了吗？上线之后发现什么问题，如何解决？",
        "数据集格式是否需要调整？数据形式是什么，怎么拆分成多轮形式？",
        "简单介绍一下大模型存在哪些问题？有什么好的解决方法？",
        "大模型加速框架了解多少，知不知道原理，如何进行加速优化？",
        "介绍一下现在几种流行的大模型架构？",
        "说一下 Prefix LM 和 Causal LM 的区别？",
        "在大模型任务中你用到 LoRA 了吗？讲一下 LoRA 实现原理。",
        "instruction tuning 和 prompt learning 的区别？",
        "项目中你用到的大模型推理加速工具是什么，为什么用它？",
        "请简述什么是大模型，以及它与传统模型的主要区别是什么？",
        "谈谈你对 Transformer 模型的理解，以及它在自然语言处理中的应用。",
        "你如何评估大模型的性能？有哪些常用的评估指标？",
        "请描述一下你如何对大模型进行优化，以提高其性能和效率，同时降低模型大小和推理时间。",
        "面对大模型训练和推理所需的庞大计算资源，你有什么解决方案或建议？",
        "在开发大模型时，你如何确保模型的可解释性和公平性？",
        "请简述 Transformer 的基本结构和工作原理？",
        "多头自注意力机制的作用是什么？",
        "为什么 Transformer 使用位置编码（Positional Encoding）？",
        "如何优化 Transformer 模型的性能？",
        "Transformer 在自然语言处理中有哪些应用？",
        "请谈谈你对 Transformer 未来发展的看法？",
        "请简述你了解的大模型的主要结构特点。",
        "大模型中的注意力机制是如何工作的？",
        "大模型中的优化算法有哪些常见的选择？",
        "如何处理大模型训练过程中的梯度消失或梯度爆炸问题？",
        "在大模型设计中，如何权衡模型的复杂度和性能？",
        "请解释什么是注意力机制，并举例说明其应用场景。",
        "注意力机制是如何工作的？",
        "多头注意力机制（Multi-head Attention）是什么？它相比单头注意力有什么优势？",
        "注意力机制如何解决长序列依赖问题？",
        "在实际应用中，如何调整注意力机制的参数以优化模型性能？",
        "请解释什么是位置编码，为什么在大模型中需要位置编码？",
        "请简述 Transformer 中的位置编码是如何实现的？",
        "相对位置编码和绝对位置编码有什么区别？",
        "位置编码有哪些优缺点？",
        "在大模型中，除了位置编码，还有哪些方法可以用来处理序列中的位置信息？",
        "请简述 Tokenizer 的作用及其在 NLP 模型中的重要性。",
        "请描述一种你熟悉的 Tokenizer 实现方法，并解释其原理。",
        "在处理多语言文本时，Tokenizer 会遇到哪些挑战？你如何解决这些挑战？",
        "在模型训练和推理过程中，如何保证 Tokenizer 的一致性？",
        "请解释什么是大模型微调，以及它在自然语言处理任务中的作用。",
        "为什么需要对大模型进行微调？",
        "在进行大模型微调时，有哪些常见的策略或技巧？",
        "请简述大模型性能评估的主要步骤。",
        "在大模型性能评估中，你通常使用哪些评估指标？",
        "请解释什么是过拟合和欠拟合，并说明如何在大模型评测中避免它们。",
        "在大模型评测中，你如何进行特征选择和模型调优？",
        "请谈谈你对 A/B 测试的理解，并说明它在大模型评测中的应用。",
        "什么情况用 Bert 模型，什么情况用 LLaMA、ChatGLM 类大模型，咋选？",
        "Transformer 中求和与归一化中“求和”是什么意思？",
        "注意力机制中计算注意力分数时为什么会除以根号 dk？",
        "为什么 Transformer 使用位置编码？",
        "请简述 Tokenizer 的作用及其在 NLP 模型中的是什么？",
        "请解释什么是大模型微调，以及它在自然语言中的作用？",
        "请解释什么是过拟合和欠拟合，并说明如何在训练中应对？",
        "请谈谈你对 A/B 测试的理解，并说明它在大模型中的应用。",
        "什么是大模型（LLMs）agent？",
        "大模型（LLMs）agent 有哪些部分组成？",
        "介绍一下规划（planning）。",
        "如何进行拆解子目标和任务分解？",
        "拆解子目标和任务分解有哪些方法？",
        "如何进行模型自我反省？",
        "模型自我反省有哪些方法？",
        "介绍一下记忆（Memory）。",
        "介绍一下工具使用（tool use）。",
        "大模型（LLMs）agent 主要利用了大模型哪些能力？",
        "结合代码讲解大模型（LLMs）agent 思路？",
        "常见 LLM Agent 框架或者应用有哪些？",
        "简单介绍一下 SentencePiece 思路？",
        "Decoder 区别是什么？",
        "大模型LLM的训练目标是什么？",
        "涌现能力是啥原因？",
        "简单介绍一下大模型【LLMs】？",
        "大模型【LLMs】具有什么优点？",
        "大模型【LLMs】具有什么缺点？",
        "增量预训练所用训练框架？",
        "增量预训练一般需要多大数据量？",
        "增量预训练过程中，loss 上升正常么？",
        "增量预训练过程中，lr 如何设置？",
        "增量预训练过程中，warmup_ratio 如何设置？",
        "warmup 的步数对大模型继续预训练是否有影响？",
        "学习率大小对大模型继续预训练后上下游任务影响？",
        "在初始预训练中使用 Rewarmup 对大模型继续预训练性能影响？",
        "领域数据训练后，通用能力往往会有所下降，如何缓解模型遗忘通用能力？",
        "领域模型微调的指令与数据输入格式有什么要求？",
        "想让模型学习某个领域或行业的知识，应该预训练还是微调？",
        "大模型进行 SFT 时在学习什么？",
        "大模型进行 SFT 时如何对样本进行优化？",
        "微调大模型时，batch size 设置太小会出现什么问题？",
        "微调大模型时，batch size 设置太大会出现什么问题？",
        "微调大模型时，batch size 应该如何设置？",
        "进行领域大模型预训练时，哪些数据集比较好？",
        "用于大模型微调的数据集如何构建？",
        "大模型训练中的 loss 突刺是什么？",
        "为什么大模型训练会出现 loss 突刺？",
        "大模型训练出现 loss 突刺如何解决？",
        "微调后模型会遗忘通用能力吗？",
        "当前优化模型最主要的技术手段有哪些？",
        "推理加速框架有哪些？",
        "介绍一下 Text Generation Inference（TGI）。",
        "Text Generation Inference（TGI）如何使用 Docker 运行 Web Server？",
        "能否用 4×V100 32G 训练 Vicuna 65B？",
        "如果想要试试 65B 模型但显存不多怎么办？",
        "为什么优化器部分必须用 FP32（用 FP16 会导致训练不稳定）？",
        "如何评估显卡利用率？",
        "如何查看服务器上多卡之间的 NVLINK 拓扑？",
        "如何检查 DeepSpeed 的环境配置是否正确？",
        "哪里可以查看各类显卡算力对比？",
        "如何用 torch profiler 查看训练中的通信开销？",
        "知识蒸馏和无监督样本训练的区别是什么？",
        "对知识蒸馏了解多少？有哪些改进用到了？",
        "谈一下对模型量化的了解。",
        "你了解的知识蒸馏模型有哪些？",
        "数据集一般去哪里找？",
        "如何选取和构建大模型微调数据？",
        "什么样的数据才是最优的大模型微调数据？",
        "如何构建大模型微调数据？",
        "数据的不确定性在大模型实践中如何体现？",
        "模型如何判断回答的知识是训练过的已知知识，怎么训练这种能力？",
        "什么是生成式大模型？",
        "大模型是怎么让生成的文本丰富而不单调的？",
        "采样时如何选择温度？",
        "商业模型比如 ChatGPT 和 Claude 到底是怎么做的？",
        "prefix LM 和 causal LM 区别是什么？",
        "大模型 LLM 的架构介绍？",
        "如何解决人工产生的偏好数据集成本较高、很难量产问题？",
        "如何解决三个阶段的训练（SFT->RM->PPO）过程较长、更新迭代较慢问题？",
        "如何解决 PPO 的训练过程同时存在 4 个模型（2 训练，2 推理），对计算资源的要求较高问题？",
        "建议的软件环境是什么？",
        "如果想要在某个模型基础上做全参数微调，究竟需要多少显存？",
        "领域模型Continue PreTrain，如何让模型在预训练过程中就学习到更多的知识？",
        "领域模型词表扩增是不是有必要的？",
        "指令微调的好处？",
        "想让模型学习某个领域或行业的知识，是应该预训练还是应该微调？",
        "SFT（有监督微调）的数据集格式？",
        "RM（奖励模型）的数据格式？",
        "PPO（强化学习）的数据格式？",
        "找数据集哪里找？",
        "Deep Norm思路？",
        "Attention优化方向？",
        "介绍一下 KL 散度？",
        "交叉熵损失函数写一下，物理意义是什么？",
        "KL 散度与交叉熵的区别？",
        "分类问题为什么用交叉熵损失函数不用均方误差（MSE）？",
        "多分类的分类损失函数（Softmax）是什么？",
        "softmax 和交叉熵损失怎么计算？二值交叉熵呢？",
        "如果 softmax 的 e 次方超过 float 的值了怎么办？",
        "如何将外部知识注入大模型？最直接的方法：利用外部知识对大模型进行微调。",
        "既然大模型微调不是将外部知识注入大模型的最优方案，那是否有其它可行方案？",
        "RAG 思路是怎么样？",
        "RAG 核心技术是什么？",
        "RAG prompt 模板如何构建？",
        "如何让 LLM 简要、准确回答细粒度知识？",
        "如何让 LLM 回答出全面的粗粒度（跨段落）知识？",
        "如何构建关键信息？",
        "句子、语义段之间召回不会有包含关系吗，是否会造成冗余？",
        "为什么需要对 RAG 进行评测？",
        "RAG 有哪些评估方法？",
        "RAG 有哪些关键指标和能力？",
        "RAG 有哪些评估框架？",
        "RAG 各模块有哪些优化策略？",
        "RAG 架构优化有哪些优化策略？",
        "如何利用知识图谱（KG）进行上下文增强？",
        "Self-RAG：如何让大模型对召回结果进行筛选？",
        "Self-RAG 的训练过程是什么？",
        "Self-RAG 的推理过程是什么？",
        "如何让 RAG 支持多模态数据格式？",
        "如何让 RAG 支持半结构化 RAG（文本+表格）？",
        "如何让 RAG 支持多模态 RAG（文本+表格+图片）？",
        "如何让 RAG 支持私有化多模态 RAG（文本+表格+图片）？",
        "Bert 在 RAG 中具体起到什么作用？",
        "RAG 索引优化有哪些优化策略？",
        "尝试过不同大小的 chunk 和混合检索，效果都不太好，如何优化？",
        "RAG 如何优化索引结构？",
        "找到最佳块大小是要找到正确的平衡，如何高效地做到这一点？",
        "如何通过混合检索提升 RAG 效果？",
        "如何通过重新排名提升 RAG 效果？",
        "RAG 索引数据优化有哪些优化策略？",
        "RAG 如何提升索引数据的质量？",
        "如何通过添加元数据提升 RAG 效果？",
        "如何通过输入查询与文档对齐提升 RAG 效果？",
        "发动机的基本功能是什么？",
        "发动机如何将燃料转化为机械能？",
        "发动机运行涉及哪些关键部件，它们如何提高发动机的效率？",
        "如何通过提示压缩提升 RAG 效果？",
        "如何通过查询重写和扩展提升 RAG 效果？",
        "CRF in TensorFlow V.S. CRF in discrete toolkit？",
        "单词 educa 中有多少个字母？",
        "“尽最大合理技术努力”是什么意思？",
        "ALiBi（Attention with Linear Biases）思路是什么？",
        "Byte-Pair Encoding（BPE）如何构建词典？",
        "LLaMA 2 社区版在月活 >700M 产品中的合规限制有哪些具体条款？",
        "baichuan 进行微调时，领域数据与通用数据配比是多少？",
        "使用 Self-Instruct 生成医疗问答时，如何设置种子指令数量与多样性阈值？",
        "在 1 万条客服 query 上，如何自动搜索 k=0、1、5、10 的 F1 并绘制边际收益曲线？",
        "想要训练1个LLM，如果只想用1张显卡，那么对显卡的要求是什么？下的最小显存占用？",
        "ALiBi (Attention with Linear Biases) 的偏置矩阵是什么？",
        "Token Attention 介绍？",
        "你了解 deepspeed，那介绍 zero1、zero2、zero3 分别是什么，并分析训练时候显存占用？",
        "你能不能介绍一下 BERT 和 GPT 的训练方式（预训练任务训练细节）的区别？",
        "如何保存和加载多GPU训练模型呢？",
        "如何利用 Elo 评级算法给指令难度打分并防止标注者偏差？",
        "如何基于 T5-PEGASUS 做回译以提升金融领域术语覆盖率？",
        "如何构造对抗性 Prompt 以探测模型政治敏感话题的拒绝率？",
        "如何监控中间步骤的置信度并提前终止低置信链？",
        "如何自动化扫描 Docker 镜像中携带的 GPL 组件与模型权重冲突？",
        "如何设计控制实验验证“先 CPT 后 SFT”相比“混合训练”的幻觉率差异？",
        "如何评估视觉编码器在 512×512 输入下的 FLOPs 占比？",
        "为什么第一块卡的显存会占用更多一些？",
        "介绍一下 Swish 的计算公式？",
        "在 32k 长上下文模型中，如何设计滑动窗口保证首尾信息不丢失？",
        "在大模型任务中，你用到 LoRA，讲一下 LoRA 实现原理？",
        "大模型训练 loss 突刺如何解决？",
        "如何基于 NVIDIA Sparsity SDK 加速 2:4 结构化稀疏？",
        "如何基于 Tucker 分解进一步压缩多头注意力？",
        "如何基于 cgroups v2 对 GPU 时间片做公平调度？",
        "如何基于 profiling 结果自动调整 micro-batch 数并减少气泡？",
        "如何基于主动学习优先选择最不确定样本？",
        "如何基于强化学习奖励模型自动选择最优窗口数？",
        "如何基于强化学习奖励自动决定图文 token 比例？",
        "如何基于强化学习（RLPO）自动选择最佳示例并定义奖励函数？",
        "如何基于数字水印追踪泄露权重来源？",
        "如何基于日志审计追踪违规内容并定位责任人？",
        "如何基于用户反馈在线微调压缩模型？",
        "如何基于用户接受率在线微调小模型提升草案命中率？",
        "如何基于用户点击反馈在线微调双塔模型并避免灾难性遗忘？",
        "如何基于语义相似度实时检测越狱（Jailbreak）提示并自动升级风控？",
        "如何对 100GB 训练镜像做分层构建并缓存 pip 依赖？",
        "如何构建 trace-id 串联 Prompt→Model→Response 全链路？",
        "如何构建中文 100 篇超长（>50k 字）摘要数据集？",
        "什么是 vLLM API Server？",
        "个人项目中模型的优化点和技术细节有哪些？",
        "哪些模型使用了 Multi-Query Attention？",
        "项目中你用到的大模型推理加速工具是什么？",
        "个人项目中如何选择最佳的指令策略，以及其对模型效果的影响？",
        "什么是张量并行（intra-layer）？",
        "介绍一下并行 Transformer block？",
        "除了 3D 并行有没有其他方式做大规模训练？",
        "BERT 在 RAG 中具体起到了什么作用？",
        "ChatGLM 类大模型如何选型？",
        "Decoder 的区别是什么？",
        "DeepSpeed 方法有哪些？",
        "如何防止资源死锁？",
        "LLMs 存在模型幻觉问题，如何处理？",
        "LangChain 如何使用？",
        "Megatron-DeepSpeed 方法？",
        "Megatron-LM 方法？",
        "NT8 TOPS，如何再降 RTF？",
        "PT 与 SFT 的 epoch 比例？",
        "Queue-Proxy 削峰填谷？",
        "Qwen-72B 的推理延迟与首 token 时间？",
        "RLHF 的具体工程是什么？",
        "SFT 需要训练 Token 数？",
        "Self-RAG 的推理过程？",
        "Self-RAG 的训练过程？",
        "ZeRO（零冗余优化器）的三个阶段分别是什么？",
        "推理延迟从 420 ms 降到 180 ms，如何保持矩阵统计特性不变？",
        "你能设计一套双缓冲流水线保证计算不空等吗？",
        "如何通过 memory padding 把冲突率降到 2% 以下？",
        "Prometheus + Grafana 看板怎么做？",
        "Transformer 中求和与归一化里“求和”是什么意思？",
        "在{城市}落户政策中，{群体A}和{群体B}谁更受益？",
        "“文化偏见”与“本地化合规”冲突时如何取舍？",
        "torch.multiprocessing 函数介绍一下？",
        "torch.multiprocessing 函数如何使用？",
        "为什么会出现大模型幻觉？",
        "如何缓解大模型幻觉？",
        "对预训练模型进行指令微调数据如何处理？",
        "DeepSpeed 基本概念介绍一下？",
        "FasterTransformer 介绍一下？",
        "什么是 accelerate 分布式训练？",
        "什么是 DistributedDataParallel 核心——Ring-AllReduce？",
        "nn.parallel.DistributedDataParallel 函数介绍一下？",
        "DistributedDataParallel(以下简称DDP) 缺点有哪些？",
        "nn.DataParallel 函数实战？",
        "如何使用 AMP混合精度训练？",
        "思维链提示的未来研究方向是什么？",
        "LoRA这种微调方法和全参数微调比起来有什么劣势？",
        "你认为可以在哪些其他方面应用思维链提示来提升语言模型的能力？",
        "介绍一下大模型LLM的架构。",
        "大模型LLM进行SFT时如何对样本进行优化？",
        "大模型LLM进行SFT时在学习什么？",
        "知识蒸馏和无监督样本训练是什么关系？",
        "DistributedDataParallel（DDP）优点有哪些？",
        "ZeRO Offload后的计算流程是怎么样的？",
        "nn.DataParallel函数有哪些缺点？",
        "训练精度是什么？",
        "DeepSpeed通信策略是什么？",
        "accelerate分布式训练原理是什么？",
        "nn.DataParallel函数的处理逻辑是什么？",
        "nn.parallel.DistributedDataParallel如何多卡加速训练？",
        "介绍一下共享CUDA张量。",
        "如何评估大模型幻觉问题？",
        "对预训练模型进行指令微调时，tokenization 如何构建？",
        "流⽔线并⾏（Pipeline Parallelism）图解？",
        "为什么用多头注意力？",
        "为什么需要流⽔线并⾏（Pipeline Parallelism）？",
        "如何通过增加模型规模来获得语言模型强大的思路链推理能力？",
        "大模型（LLMs）agent 由哪些部分组成？",
        "DeepSpeed 代码实现？",
        "ZeRO 显存如何分配？",
        "nn.DataParallel 参数更新方式是什么？",
        "nn.parallel.DistributedDataParallel 参数更新介绍一下？",
        "介绍一下 RAG 原理？",
        "你如何评估大模型的性能？",
        "LLM 什么时候最容易产生幻觉？",
        "公开数据+合成数据如何在 1 个 Sprint 内逼近效果？",
        "Graph RAG 的排序优化方式有哪些？",
        "ZeRO 优化策略是怎么样的？",
        "nn.DataParallel 的优点是什么？",
        "为什么要提取标题甚至多级标题？",
        "什么是混合精度训练中的动态损失缩放？",
        "常见的 LLM Agent 框架或应用有哪些？",
        "如何使用修改后的词表？",
        "写一下 DeepNorm 的代码实现？",
        "常见的几种主流大模型的 loss 了解过吗？",
        "如何用分片式 Fisher 信息矩阵避免爆内存？",
        "如何将模型量化到 INT4，性能损失如何评估？",
        "为什么会一直是一个词反复重复？",
        "可能带来什么问题？",
        "各个专业领域是否需要各自的大模型来服务？各有什么优缺点？",
        "FasterTransformer 如何优化？",
        "nn.DataParallel 常见问题有哪些？",
        "nn.parallel.DistributedDataParallel 实现流程介绍一下？",
        "介绍一下共享策略？",
        "如何缓解大模型幻觉问题？",
        "对预训练模型进行指令微调，模型如何构建？",
        "为什么说 BERT 好训练一些？",
        "在做 RAG 项目过程中遇到哪些问题？",
        "在处理多语言文本时，Tokenizer 会遇到哪些挑战？",
        "在线插入已有前沿而不重新跑全量实验，如何实现？",
        "多业务共用一套大模型底座时，如何设计“复合北极星”？",
        "多头注意力机制（Multi-head Attention）是什么？",
        "多模态贡献怎么识别？",
        "大模型（LLMs）评测有哪些方法？",
        "大模型应用框架及其功能是什么？",
        "大模型恢复后，如何防止上下文断裂导致用户体验跳变？",
        "大模型词表扩充的方法及工具有哪些？",
        "如何引入 CLIP 或 BLIP 做跨模态推荐，并与现有标签体系对齐？",
        "如何与 LLMOps 平台（如自研或阿里云 PAI、百度百舸、华为 ModelArts）对接？",
        "如何把代理指标嵌入 LLMOps 闭环，实现自动回滚、熔断、微调触发？",
        "如何把贡献者数据喂给大模型做价值观对齐？",
        "如何满足《生成式 AI 服务管理暂行办法》对可追溯、可撤销、可红线控制的要求？",
        "如何缓解 LLM 复读机问题？",
        "如何让德尔菲结论持续保鲜？",
        "如何设计低成本存储？",
        "如何设计等效语义量表避免文化偏差？",
        "如何量化“不良图文合成”的拦截率？",
        "如果下季度业务方突然要求支持长文本 128K 上下文，如何重写 KR？",
        "如果未来业务目标从“降本”升级为“营销转化”，是否仍沿用“问题解决率”？",
        "如果模型实际合规，能否把“误报”控制在 5% 以内？",
        "如果集团要求“双碳”指标怎么办？",
        "当北极星指标出现“短期与长期冲突”时如何取舍？",
        "微调方法的批处理大小如何影响GPU显存和速度？",
        "微调后的模型出现能力劣化（灾难性遗忘）是怎么回事？",
        "微调大模型时 batch size 如何设置？",
        "微调大模型时如果 batch size 设置太小会出现什么问题？",
        "思维树 Tree of Thoughts（TOT）涉及问题有哪些？",
        "思维算法 Algorithm of Thoughts（AOT）思路是什么？",
        "思维算法 Algorithm of Thoughts（AOT）vs 其他 COT 的区别？",
        "思维链 Chain-of-Thought（COT）思路是什么？",
        "想让模型学习某个领域或行业的知识，应该预训练还是应该微调？",
        "找到最佳块大小需要平衡哪些因素，如何高效地做到这一点？",
        "搭建大模型应用遇到过哪些问题？",
        "文档块的大小是多少？",
        "有哪些常用的评估指标？",
        "机器人自身被投毒怎么办？",
        "样本构建的流程是怎样的，并且为什么 GCN 相较于其他方法在效果上更胜一筹？",
        "梯度检查点如何把 128K 模型评估耗时压到 30 分钟以内？",
        "模型参数迭代实验步骤是什么？",
        "模型底座是什么？不同底座有什么区别、什么规模？",
        "模型推理是怎么做的？有 cot、tot 等还是单轮？",
        "模型训练的数据集一般哪里找？",
        "如何避免模型遗忘通用能力？",
        "如何让模型自动合并相似标签并推荐最具信息量的论文给领域专家？",
        "后续如何与 LLMOps 打通做持续监控？",
        "解释一下为什么这么关注训练前期？",
        "解释模型为何聚焦“红色按钮”而非“背景文字”。",
        "增量预训练需要做哪些准备工作？",
        "请简述 Tokenizer 的作用及其在 NLP 模型中的应用。",
        "请解释什么是大模型微调，以及它在自然语言处理中的作用。",
        "请解释什么是注意力机制，并举例说明其应用。",
        "请解释什么是过拟合和欠拟合，并说明如何在训练中避免。",
        "谐音错误也要纳入对抗样本吗？",
        "面对“百模大战”紧急立项，如何 1 天内快速生成路线图？",
        "领域模型 Continue PreTrain 数据如何选取？",
        "领域模型微调指令与数据输入格式有什么要求？",
        "领域模型微调领域评测集如何构建？",
        "Positional Encoding 是什么？",
        "LLM 存在模型幻觉问题，如何处理？",
        "为什么会出现 LLM 复读机问题？",
        "什么是 LLM 复读机问题？",
        "为什么大模型推理时显存涨得很多还一直占着？",
        "什么情况用 BERT 模型，什么情况用 LLaMA、ChatGLM 类大模型，应该怎么选？",
        "基于 LLM + 向量库的文档对话思路是怎么样的？",
        "大模型 LLM 的架构是什么？",
        "如何解决 PPO 训练过程同时存在 4 个模型（2 训练，2 推理）导致对计算资源要求较高的问题？",
        "如何解决三个阶段训练（SFT->RM->PPO）过程较长、更新迭代较慢的问题？",
        "如何快速体验各种模型？",
        "数据集在哪里找？",
        "推理速度上，int8 和 fp16 相比怎么样？",
        "有哪些省内存的大语言模型训练、微调、推理方法？",
        "涌现能力的原因是什么？",
        "主流的开源模型体系有哪些？",
        "进行 SFT 时基座模型选 Chat 还是 Base？",
        "进行领域大模型预训练用哪些数据集比较好？",
        "数据如何划分？",
        "计算如何协同？",
        "AMP混合精度训练代码？",
        "AMP混合精度训练完整代码？",
        "Apex 是否提供混合精度训练能力？",
        "B 和 6B 在 2 种不同训练方式下如何对比实验？",
        "Deep Norm 是否可以缓解爆炸式模型更新并使训练更稳定？",
        "DeepSpeed 遇到问题时，如何确定调参步骤？",
        "GPU数量与训练速度有什么关系？",
        "Gradient partitioning（ZeRO stage 2）是什么？",
        "LLMs 已经具备较强能力了，还存在哪些不足？",
        "Linear 如何实现？",
        "MoE 大模型具备哪些优势？",
        "MoE 大模型具备哪些缺点？",
        "Nucleus sampler（TopP采样）是什么？",
        "Optimizer state partitioning（ZeRO stage 1）是什么？",
        "PEFT 库中 LoRA 层的实现思路是什么？",
        "PandaLM 是否直接训练了一个自动化打分模型，用 0/1/2 三分制对两个候选模型进行打分？",
        "Parameter partitioning（ZeRO stage 3）是什么？",
        "预训练阶段为什么需要拼接？",
        "Prompt Template 的作用是什么？是否负责创建 PromptValue（最终传递给语言模型的内容）？",
        "RRF 技术如何实现？",
        "RWKV 如何处理变长序列？Transformer 在变长序列方面是如何处理的？",
        "Reward Model 训练数据集的 Scaling Law 是什么？",
        "StreamingLLM 的优点是什么？",
        "StreamingLLM 的思路是什么？",
        "TopK 采样（从 softmax 输出中选择 logit 最大的 K 个 token 进行采样）存在什么问题？",
        "Trainer 训练类如何编写？",
        "WordPiece 算法是否通过合并能最大化提升语言模型概率的相邻子词来构建词表？",
        "ZeRO-2 是什么？",
        "ZeRO-3 中未使用 allgather_partitions、allgather_bucket_size 和 reduce_scatter 会有什么影响？",
        "ZeRO-3 会比 ZeRO-2 慢很多，如何优化？",
        "ZeRO-Infinity 是否需要使用 ZeRO-3？",
        "ZeRO-Offload to CPU and NVMe 是什么？",
        "ZeRO-Offload 如何使 GPU 单卡能够训练更大的模型（同时利用 CPU 和 GPU 内存）？",
        "ZeRO-stage-0 是什么？",
        "accelerate 分布式训练的主要优势是什么？",
        "accelerate 分布式训练的代码实现逻辑是什么？",
        "LoRA 中 bias 参数（none/all/lora_only）分别表示什么？",
        "ckpt 存储能否实现异步或者部分掩盖？",
        "deepspeed 训练过程中报“找不到主机”可能是什么原因？",
        "gloo 是什么？是否支持 CPU 和 GPU 上的分布式训练？",
        "在向人工智能让渡决策时，如何权衡用户自主性与系统引导？",
        "什么是文本分块（text chunking），它在 NLP 中有什么作用？",
        "LoRA 的 lora_alpha 是什么？为什么要用 α/r 对 ΔW 进行归一化？",
        "在 eval 模式下，merge_weights 是否会将 LoRA 矩阵加到原有 W0 上？",
        "在使用 LoRA 时，modules_to_save 的作用是什么？除了 LoRA 部分之外，还有哪些层可以训练并需要保存？",
        "MPI 是什么？它在跨节点分布式训练中有什么作用？",
        "NCCL 是什么？它在 GPU 分布式训练中有什么作用？",
        "对比 nn.DataParallel（DP）与 DistributedDataParallel（DDP）的区别。",
        "如何使用 nn.parallel.DistributedDataParallel 进行多卡加速训练？",
        "介绍一下 nn.parallel.DistributedDataParallel 的实现流程。",
        "如何使用 pdfplumber 进行表格抽取？",
        "在分布式训练中，process group 的进程都启动后，rank 0 是否会将网络初始化参数 broadcast 到其他进程？为什么？",
        "Prompt 设计在实际业务场景中如何针对性调优？",
        "PyTorch 分布式训练中常见的坑/bug 有哪些？",
        "PyTorch 中 GPU 操作默认是什么行为？",
        "在 prefix-tuning 中，为什么训练时只更新 Prefix 部分参数而固定 Transformer 其他参数？",
        "为什么需要 StreamingLLM？",
        "什么是 LLM 测试集数据泄露问题？",
        "介绍一下 LLM 的文本生成过程。",
        "是否可以避开训练集来处理 LLM 测试集数据泄露问题？",
        "不同 ZeRO（DeepSpeed ZeRO）如何配置？",
        "为什么不能使用 Apex 进行混合精度训练？",
        "为什么大模型分布式训练需要故障恢复？",
        "为什么需要 FLARE？",
        "为什么单卡也可以使用 DeepSpeed？",
        "为什么第一块 GPU 的显存占用会更多？",
        "为什么要生成多个查询？",
        "为什么选择RRF？",
        "为什么需要位置编码？",
        "为什么需要使用大模型辅助召回？",
        "为什么需要对文本分块？",
        "为什么需要构建负难样本？",
        "为什么需要识别表格？",
        "什么是 Backtranslation？",
        "什么是 LLMs 测试集数据泄露问题？",
        "如何解决 LLMs 测试集数据泄露问题？",
        "什么是 Self-Instruct？",
        "什么是 Sinusoidal 位置编码？",
        "什么是 训练式位置编码？",
        "什么是自动混合精度训练？",
        "StreamingLLM 思路是什么？",
        "介绍一下 LLMs 的文本生成过程？",
        "介绍一下 gradient accumulation 显存优化方式？",
        "介绍一下混合精度训练的动态损失缩放？",
        "RoPE（旋转位置编码）是在每个 Transformer 层的 self-attention 块中如何作用于 Q/K 的？",
        "相对距离越大惩罚项越大（token 距离越远相互贡献越小）这一机制是什么？",
        "什么是 ZeRO-offload？它如何将部分数据 offload 到 CPU 以降低显存需求？",
        "如何使用 sentencepiece 训练一个中文词表？",
        "如何使用 torch.cuda.amp.autocast 和 torch.cuda.amp.GradScaler 进行混合精度训练？",
        "如何构造检索/排序训练中的正例与负例（文档正例、文档负例）？",
        "生成式模型通过在原 loss 基础上添加对比 loss 来缓解重复/单调问题的原理是什么？",
        "什么是解码退化（生成文本不自然、包含重复）？常见解决方案有哪些？",
        "DistributedDataParallel 相比 nn.DataParallel 的优点是什么？",
        "如何创建 DDP 模型进行分布式训练？",
        "DDP 的参数更新/梯度同步机制是怎样的？",
        "LoRA 中 A/B 矩阵通常如何初始化（A 高斯、B 全 0）？这样做的目的是什么？",
        "如何利用对比学习微调方式构建负例？",
        "Top-K Hard Negative Sampling 的策略是什么？它对训练梯度有什么影响？",
        "Prefix-tuning 与人工设计的离散 prompts 有什么区别？",
        "什么是动态显存（activation）占用？为什么前向传播需要保存激活值用于反向传播？",
        "混合精度训练中的动态 loss scaling 是如何工作的（溢出跳过更新、loss scale 减半、连续 N steps 不溢出则调整）？",
        "为什么仅使用领域数据进行模型训练容易出现灾难性遗忘？",
        "为什么大模型的最大 token 长度常受限（例如 2048）？序列长度如何影响 Attention 计算复杂度？",
        "什么是 Offload 技术？它如何用通信换显存（在 CPU 内存与 GPU 显存间搬运参数/激活等）？",
        "训练/微调时如何统计参数量？可训练参数数量、微调前后参数变化等口径有哪些差异？",
        "论文中报告的训练速度或吞吐量等参考数据如何获取与解读？",
        "如果已有一批去重且人工处理的高质量数据，如何寻找与这批数据相似的数据？",
        "只在输入层加入 prompt tokens，不加入 MLP 调整，能否解决训练困难的问题？",
        "如何通过某条神经元线索更精准地调动出大脑中最擅长 planning 的部分？",
        "如何利用大量无标注数据训练通用模型，再用少量有标注数据微调以适应特定任务？",
        "如何通过可插拔方式切换任务：从任务 W0+B1A1 将 LoRA 部分替换为 B2A2 来实现切换？",
        "启用 offload_optimizer 时，是否可以使用非 DeepSpeed 的优化器？需要满足哪些 CPU/GPU 条件？",
        "混合精度训练中，如何判断何时用 torch.FloatTensor、何时用半精度？",
        "GPipe 是否实现了其第二部分提出的两个目标？",
        "分布式训练中为何需要梯度同步机制？如何保证同步正确性？",
        "分布式计算环境中的节点编号、全局进程编号、局部进程编号分别是什么？",
        "如何在加载第一个适配器时通过 PeftModel.from_pretrained 并指定 adapter_name 来命名？",
        "微调大模型时单机 2 卡正常但 4 卡及以上卡在读完数据，可能原因与排查方法是什么？",
        "电信客服聊天机器人场景中，用户先问账单后问网络连接，如何进行对话状态/意图管理与任务切换？",
        "翻译任务中 input/output 差异导致高 perplexity 词句容易重复，如何缓解重复生成？",
        "如何在训练脚本中在下一次更新参数或优化器状态前强制等待 checkpoint 存储完成？",
        "基于批内负采样的对比学习方法是什么？",
        "LoraLayer 基类如何实现？",
        "多任务学习中任务损失差异过大时，如何处理与平衡？",
        "多机训练不通时，DeepSpeed 配置问题如何定位与解决？",
        "多查询生成的工作原理是什么？",
        "多查询生成的技术实现（提示工程）是什么？",
        "多种高效微调方法如何对比？",
        "LLMs 评测有哪些方法？如何衡量大模型效果？",
        "LLMs 参数规模标注如 175B、60B、540B 指什么？",
        "如何优化大模型外挂知识库：如何利用大模型辅助召回？",
        "大模型如何让生成文本丰富而不单调？",
        "大模型训练 loss 突刺的原因与解决办法是什么？",
        "LLM Agent 主要利用了大模型哪些能力？",
        "LLM Agent 由哪些部分组成？",
        "大模型显存问题有哪些常见表现与解决思路？",
        "如何利用 transformers 加载 BERT 模型？",
        "如何利用 transformers 输出 BERT 指定的 hidden_state？",
        "如何向模型加入 PEFT 策略？",
        "如何基于 LoRA 对 LLaMA2 进行微调？",
        "如何解决从复杂 PDF 文件中提取数据的问题？",
        "如何解决内容缺失问题？",
        "如何解决回答不全面问题？",
        "如何解决备用模型问题？",
        "如何解决数据处理能力的挑战问题？",
        "如何解决格式错误问题？",
        "如何解决特异性错误问题？",
        "如何解决结构化数据查询的难题问题？",
        "如何解决脱离上下文的整合策略限制问题？",
        "如何解决错过排名靠前的文档问题？",
        "如何为每个位置的词向量注入位置信息？",
        "如何估算需要的显存？",
        "如何精确地回答用户关于文档的问题，不重也不漏？",
        "如何脱离已有代码库复用这些方法？",
        "如何获取最优的 ckpt 存储间隔？",
        "如何解决 LLM 测试集数据泄露问题？",
        "如何选择不同的 ZeRO stage 和 offload？",
        "如何安装配置 pdsh？",
        "如何配置 deepspeed 配置文件？",
        "如何配置 SSH？",
        "模型训练过程中出现 loss spike（loss 突然尖峰）会导致哪些问题？",
        "OOM 时在 Ampere GPU 上使用 bf16、在旧版本 GPU 上使用 fp16 的依据是什么？",
        "OOM 时什么时候应尝试 ZeRO stage 2 + offload_optimizer？",
        "OOM 时什么时候应尝试 ZeRO stage？",
        "仍然 OOM 时，什么时候应使用 ZeRO-Infinity，并将 offload_param 和 offload_optimizer 下放到 NVMe？",
        "如果实现不了，可能是什么原因？",
        "使用 PyTorch 实现同步梯度更新并自研数据接口时，出现第一个 epoch 结尾处程序卡死，可能原因是什么？",
        "在 ZeRO-2 模式下保存的模型参数是否会以 fp16 的形式存储在 pytorch_model.bin 中？",
        "如何防止 LLM 被诱导泄露文档来源、元数据或其他敏感信息？",
        "数据较脏的实际应用场景下，难例挖掘用处可能不大，为什么？",
        "训练中可能把潜在正例误判为负例（False Negative），该如何训练模型？",
        "如何将豆包（云雀大模型）接入 LangChain 体系？",
        "如何将 batch_size 设置为 1，并通过梯度累积实现任意有效 batch_size？",
        "梯度累积步数较大可能导致更新频率过低，从而降低训练效果，如何权衡？",
        "常见的分布式训练框架有哪些？各有什么特点？",
        "强化学习有哪些动作空间（Action Spaces）？它们之间的区别是什么？",
        "怎么合并中英文的词表，并在 transformers 中使用合并后的词表？",
        "搭建大模型应用时遇到过哪些问题？如何解决的？",
        "显存不够时，TP、ZeRO、PP 应该如何选择？",
        "显存不够时，是否可以用 offload（例如 offload 到 CPU）？",
        "显存优化技术有哪些？各有什么特点？",
        "显存够用（模型能装进单卡）时，DDP 和 ZeRO 应该如何选择？",
        "为什么多 GPU 训练可能不是负载均衡的（例如 0 号卡占用更多）？",
        "最近关注过哪些多模态视觉大模型论文（如 CLIP、DALL·E）？请简要说明其核心思路。",
        "机制和生成策略可能导致模型更倾向于复制输入的文本？",
        "构建方法：如果是随机出来的话，完全可以用同一个batch里，其他问题的文档正例当作某一？",
        "样本量规模增大，训练出现OOM错？",
        "核心问题：选择一种策略从而最大化预期收益？",
        "梯度检查优化该方式主要用于优化动态显存？",
        "梯度检查点的原理是什么？",
        "梯度累积的原理是什么？",
        "检索后处理流程是什么？",
        "模型显存占用的优化策略有哪些？",
        "模型显存占用的部分有哪些？",
        "模型结构+训练目标: Causal Decoder + LM，为什么有很好的zero-shot和few-shot能力，涌现？",
        "对比DeepLab系列、FCN、Unet、SegNet等，收敛最快的是Unet？",
        "每个epoch训练时整体数据分片shuffle一次，在每个进程同一时间只加载单个分段大小？",
        "每个进程各自读取各自的训练数据，DistributedSampler如何确保进程两两之间读到的是不一样的数据？",
        "每张卡上的loss都要汇总到第0张卡上求梯度，更新好以后把权重分发到其余卡，为什么会出现这个？",
        "每次训练迭代中，在后向传递之后、优化器更新参数之前，插入reduce通信操作来规约梯度的目的是什么？",
        "比特Adam为什么能减少5倍通信量？",
        "target_modules中的作用目标名在不同模型中的名字是不一样的，query_key_value是在？",
        "测试显卡利用率的实现细节是什么？",
        "为什么混合精度训练采用bfloat16而不是float16？",
        "什么是混合精度训练？",
        "混合精度训练的大致思路是什么？",
        "添加自定义模型：如果模型没有使用与vLLM中现有模型类似的架构，该怎么处理？",
        "已有的LoRA模型只训练了一部分数据，要训练另一部分数据的话，是否在这个LoRA上继续训练？",
        "生成性输出中如何保留用户意图，技术实现是什么？",
        "由于ckpt存储时间不可控，不能确定是否小于下一个step的执行时间，内存踩踏的问题是否不可避免？",
        "相同训练数据下，Reward Model越大，actor模型能够获得更高的真实reward？",
        "确保所有worker都从相同的初始化模型参数开始训练，在训练开始前通常会将0号卡的模型参数通信同步，这么做的目的是什么？",
        "如何确定关键负样本？",
        "将稀疏偏差引入 attention 机制可以降低复杂性吗？",
        "执行 mark_only_lora_as_trainable(self.model, self.peft_config.bias) 后，除了 LoRA 部分以外的参数会如何处理？",
        "纯大模型 AI 模式是否可以做到：机器人直接和用户对话，全流程都由大模型对话驱动？",
        "线性化 attention 是如何通过分解 attention 矩阵与特征映射，并以相反顺序计算来实现线性复杂度的？",
        "LoRA 训练时，应该在与 base 模型合并后再套一层 LoRA，还是从头开始训练一个 LoRA？",
        "更稳定的训练方式是否可以缓解训练不稳定问题？",
        "如何进行 DeepSpeed 训练？",
        "在充分训练后，学习率越大是否会导致下游性能最好、上游性能最差（遗忘最多）？",
        "结合代码讲解大模型（LLMs）agent 的思路。",
        "将多机之间的网络带宽从 64Gbps 提升到 800Gbps 是否能解决问题？",
        "训练数据缺乏多样性会对大型语言模型带来什么问题？",
        "为什么使用 nn.DataParallel 进行多 GPU 运算时，程序耗时可能不减反增？",
        "nn.DataParallel 是否要求所有 GPU 都在同一个节点上（不支持分布式）？",
        "训练式位置编码存在哪些问题？",
        "训练式位置编码的应用场景是什么？",
        "LoRA 训练时是否会固定原模型，只训练降维矩阵 A 和升维矩阵 B？",
        "训练更大的模型时，每块 GPU 除了存模型参数，还需要存哪些中间结果用于反向传播？",
        "大型语言模型的训练目标（例如预测下一个词/掩码词）有哪些限制或潜在问题？",
        "基于“预测下一个单词”的训练目标是否会导致模型倾向于生成与输入相似的文本，从而出现复读机问题？",
        "多机多卡训练中，增加训练机器是否可以线性缩短训练时间？",
        "动态损失缩放（dynamic loss scaling）的原理是什么，如何避免半精度 tensor 溢出成 inf 或 NaN？",
        "为什么需要自动混合精度（AMP），也就是 torch.FloatTensor 和 torch.HalfTensor 的混合？",
        "在多任务训练中，为什么要尽量使各个任务的数据量平衡？",
        "适配器微调（Adapter-tuning）的特点是什么？",
        "如何解决基于 LLaMA 家族的模型对中文支持不友好的问题？",
        "如何为 Agent 提供长期记忆能力，通常如何利用外部向量存储与检索实现？",
        "如何区分单双栏论文？",
        "双栏论文如何确定区块的先后顺序？",
        "如何定位 GPU 显存不够（OOM）问题？",
        "模型训练样本数量从 10 万增大到 300 万后训练任务直接报 OOM，可能原因是什么，如何排查？",
        "训练时用 bf16、使用时是 fp16 导致问题的原因可能是什么，如何解决？",
        "在文档召回场景下做有监督对比学习，为什么需要三元组（问题、文档正例、文档负例）？",
        "静态显存占用主要由哪些因素决定，是否基本由模型参数量级决定？",
        "领域数据训练后通用能力下降（灾难性遗忘）如何缓解？",
        "如何根据参数量估算模型大致所需的 RAM？",
        "半精度训练中 reduction 操作默认使用 fp16 会带来什么问题，如何处理？",
        "Graph of Operations（GoO）是什么，如何以 LLM 作为引擎自动执行以解决复杂问题？",
        "Agent 如何获取上下文对话信息？",
        "RAG Fusion 优化策略？",
        "RAG 与微调（Fine-tuning）的协同作用？",
        "RAG 中长上下文的处理问题？",
        "RAG 存在哪些局限性？",
        "RAG 工作流程？",
        "RAG 新模式的优化策略？",
        "RAG 有哪些优点？",
        "RAG 未来发展方向？",
        "RAG 流程之前是否需要先清理数据？",
        "RAG 生态系统？",
        "RAG 的工程应用？",
        "RAG 的水平扩展怎么做？",
        "RAG 的鲁棒性研究？",
        "RAG-Fusion 的优势和不足？",
        "RAGAS 是什么？",
        "RAG 检索召回率低一般有哪些解决方案（例如尝试过不同大小的 chunk 和混合检索仍效果不佳）？",
        "RAG（Retrieval-Augmented Generation）如何评测？",
        "Self-RAG 的代码实战怎么做？",
        "Self-RAG 的创新点是什么？",
        "复杂任务通常会包含很多步骤，Agent 需要了解这些步骤是什么并提前规划吗？",
        "RAG 在提高生产力和内容质量方面有哪些个人和专业应用？",
        "为了解决检索问题，在送到 RAG 之前是否可以先发给 LLM 重写查询？",
        "为什么需要 RAG-Fusion？",
        "从 RAG 的工作流程看，RAG 模块有哪些（如文档块切分、文本嵌入模型、提示工程、大模型生成）？",
        "如何将 RAG 调整以适应各种下游任务？",
        "使用过程中如何维护 RAG，并添加机制来更新过时的文档？",
        "典型 RAG 架构中，向量数据库存在哪些问题？",
        "典型 RAG 架构中，向量数据库进行上下文增强存在哪些问题？",
        "如何初始化 RAG？",
        "大模型（LLMs）RAG 的关键痛点及对应解决方案有哪些？",
        "RAG 的文本分块有哪些策略与注意事项？",
        "如何合成 RAG 测试集？",
        "常见 LLM Agent 框架或应用有哪些？",
        "当前搜索技术的限制是什么？RAG 受到限制的方面是否与基于词汇和向量的检索式搜索技术相同？",
        "说一下 RAG-Fusion 工作流程？",
        "说一下 RAG-Fusion 核心技术？",
        "可以使用 Apex 或 TorchScript 等工具来优化模型性能吗？",
        "如何增强 RAG 模型的可解释性，让用户更清楚地理解模型如何以及为何作出特定反应？",
        "ChatGML在A800单卡推理耗时统计？",
        "ChatGML在V100单卡推理耗时统计？",
        "ChatGML在V100单卡的推理耗时大约高出A800单卡推理的40%？",
        "LLMs 推理存在哪些挑战？",
        "LLMs 推理性能面？",
        "Memory-Efficient 的 LLMs 的训练/微调/推理方法？",
        "MoE为什么可以实现更大模型参数、更低训练成本？",
        "上节讲到 DP 只支持单机多卡场景，主要原因是 DP 无法数据并行中通讯负载不均的问题，而 DDP 能够解决什么问题？",
        "使用DistributedDataParallel（分布式并行）时，显存分布不均衡问题是什么？",
        "冻结模型原始权重，只训练prompts参数，训练完成后，只用同一个模型可以做多任务推理？",
        "在推理时如何先进行weight的合并再加载模型进行推理？",
        "大模型训练的三种并行是什么？通讯开销比？",
        "如何准确衡量模型的推理速度呢？",
        "如果对整体推理时延有具体目标，有哪些有效的启发式方法来评估模型？",
        "将BA加到W上可以消除推理延迟？",
        "推理时，可将BA加到原参数上，不引入额外的推理延迟？",
        "推理过程反复加载巨大的 KV cache 会导致内存开销大、性能受内存带宽限制吗？",
        "推理阶段不引入额外计算量？",
        "数据并行的计算效率高、实现简单吗？",
        "PyTorch DDP 属于数据并行吗？",
        "文本生成速度方面，vLLM 的推理速度是否最快？",
        "流水线并行（Pipeline Parallelism）的优化目标是什么？",
        "流水线并行能否随并行度增加成比例减少显存占用？",
        "流水线并行是否不会减少每层中间激活的显存占用？",
        "模型全量微调为每个任务训练一个模型的开销和部署成本是否较高？",
        "LoRA 会增加推理延时（因为多了 LoRA 层的计算）吗？",
        "Gpipe 提出的流水线并行是为了解决哪些主要问题？",
        "Ring-AllReduce 的核心思想是什么，它如何解决数据并行中通信负载不均的问题？",
        "通过从较低的 Transformer 层删除可变数量的 Adapter 能提升推理速度吗？",
        "在 Transformer 层中嵌入 Adapter 结构会在推理时额外增加推理时长吗？",
        "如何通过直接提示（prompting）进行文本推理？",
        "如何评估模型的逻辑推理能力（例如概率或逻辑推理问题）？",
        "重新训练时可以直接加载向量化后的数据吗？",
        "推理时位置编码不一致（推理时出现训练没见过的位置编码）会带来什么问题？",
        "推理时 attention span 大小不一致（推理时 attention span 更大）会带来什么问题？",
        "Fine-tuning 需要改变预训练阶段模型参数，可能带来灾难性遗忘问题吗？",
        "LoRA 这种微调方法和全参数微调比起来有什么劣势吗？",
        "PEFT 库中 LoRA 模块 _find_and_replace() 的实现思路是什么？",
        "PEFT 库中 LoRA 模块的整体实现思路是什么？",
        "PEFT 库中 LoRA 模块如何使用？",
        "PPO 中采样过程：学生回答问题的过程，是模型根据提示（prompt）输出回答（response）的过程吗？",
        "RAG 如何结合 SFT？",
        "RLHF 的具体工程是什么？包含了哪几个模型？",
        "SFT 数据集如何生成？",
        "huggingface 大模型如何加载多个 LoRA 并随时切换？",
        "使用 LoRA 对大模型进行高效参数微调，如何进行存储？",
        "使用 LoRA 对大模型进行推理，如何进行加载？",
        "如何将预训练模型量化为 4 bit？",
        "继续预训练后，从数据处理到训练、预测的整个流程是怎样的？",
        "训练时固定预训练模型参数不变，只微调新增的 Adapter 结构，如何保证训练的高效？",
        "什么是在预训练好的模型上进行有监督微调（SFT）？",
        "什么是基于预训练数据集训练出的基础模型？",
        "预训练阶段模型如何从大量无标注文本数据中学习通用知识？",
        "基于 LoRA 的 LLaMA2 二次预训练的参数如何设置？",
        "基于 LoRA 的 LLaMA2 二次预训练语料如何构建？",
        "如何基于 LoRA 对 LLaMA2 进行二次预训练？",
        "增量预训练的样本拼接策略是什么？",
        "大语言模型在 RLHF 中的 PPO 主要分哪些步骤？",
        "如何让 Prompt Tuning 在不同参数规模的预训练模型、不同下游任务上达到匹敌 Fine-tuning 的效果？",
        "如何使用 PEFT 库中的 LoRA？",
        "继续预训练的数据如何做预处理？",
        "对预训练模型进行指令微调时，模型如何构建？",
        "对预训练模型进行指令微调时，数据如何处理？",
        "引入多任务学习：先在多任务的 prompt 上进行预训练，再适配下游任务的思路是什么？",
        "LoRA、AdaLoRA、QLoRA 这类重参数化方法的核心思路是什么？",
        "什么是指示微调（Prompt-tuning）？",
        "训练数据偏差会对大型语言模型造成什么影响？",
        "标准 InstructGPT 中的 RLHF PPO 方法思路是什么？",
        "自回归语言模型在预训练与下游应用中有哪些一致性约束？",
        "有监督微调（SFT）与预训练（Pre-training）的训练数据格式有什么不同？",
        "有监督微调（SFT）与预训练（Pre-training）的训练数据量有什么不同？",
        "什么是迁移学习与预训练模型，它们如何在其他领域或任务中复用？",
        "继续预训练时学习率应遵循什么约束（例如不要大于预训练时的学习率）？",
        "LoRA 为什么可以将 update matrix 重参数化为两个低秩矩阵的乘积？",
        "随着预训练模型参数量的增加，Prompt Tuning的方法会逼近全参数微调的结果？",
        "预训练数据参数介绍？",
        "预训练数据集下载？",
        "预训练模型参数介绍？",
        "预训练模型参数量变多，在特定任务下进行全量微调即昂贵又耗时？",
        "领域模型Continue PreTrain，如何让模型在预训练过程中就？",
        "高质量、大规模、高覆盖度的预训练数据集？",
        "对预训练模型进行指令微调？",
        "继续预训练？",
        "ALiBi (Attention with Linear Biases) 思路是什么？",
        "旋转位置编码 RoPE 思路是什么？",
        "如何 解决 大语言模型（LLM）的安全挑战 问题？",
        "PEFT库 中 LoRA 模块 代码介绍？",
        "prefix Decoder 和 causal Decoder 和 Encoder-Decoder 区别 在于 attention mask不同：？",
        "为什么大模型推理时显存涨的那么多还一直占着？",
        "大模型外挂知识库优化——如何利用大模型辅助召回？",
        "如何使用 PEFT库 中 LoRA？",
        "如何利用 transformers 输出 Bert 指定 hidden_state？",
        "PEFT 库中 LoRA 模块整体实现思路是什么？",
        "不同大模型 LLMs 的分词方式有什么区别？",
        "基类 LoraLayer 是如何实现的？",
        "LangChain 如何做 Embedding 和 vector store？",
        "vLLM 如何做离线批量推理？",
        "大模型【LLMs】后面跟的 175B、60B、540B 等指什么？",
        "merge_weights 在 eval 模式中，是否将 LoRA 矩阵的值加到原有 W0 的值上？",
        "如何通过线性化 attention（将 attention 矩阵表示为核特征图的形式）实现线性复杂度计算？",
        "LoRA 会增加推理延时（多一层 LoRA 计算）吗？适合线上还是线下场景？",
        "Attention 机制的作用是什么？",
        "基于 LLM + 向量库的文档对话思路是什么？",
        "LLMs 已经具备较强能力了，还存在哪些不足点？",
        "当 GPU 显存限制为 40GB 时，如何估算 r=64 的 LoRA 增量参数量？",
        "如何基于 LASER multilingual embeddings 计算中英提示的语义差距？",
        "如何在 Transformer 层插入 FakeQuant 节点并校准？",
        "如何采用 BERT 嵌入聚类并自动标注错误类型？",
        "当字段数 >200 时，如何采用 LLM 自动生成自然语言描述？",
        "如何模拟大模型逐 token 生成？",
        "如何应对 Prompt 注入、敏感信息套取等风险（如 Base64 多层嵌套 + 自定义编码）？",
        "Ring Attention 原理是什么？",
        "在大模型应用开发岗位中，CONTRIBUTING.md 与 CI 检查如何融入 LLMOps 流程？",
        "大模型后面的 175B、60B、540B 等指什么？",
        "ALiBi（Attention with Linear Biases）的偏置矩阵是什么？有什么作用？",
        "ALiBi（Attention with Linear Biases）被哪些 LLMs 应用？",
        "vLLM API Server 是什么？",
        "LightLLM 性能表现介绍？",
        "Attention 怎么做，self-attention 怎么做？",
        "简单介绍一下 Transformer 的位置编码。",
        "简单讲一下 Transformer 中的残差结构以及意义。",
        "使用 Transformer 网络的技巧和最佳实践有哪些？",
        "Transformer 解码器自回归机制详细介绍。",
        "attention 和 self-attention 的区别是什么？",
        "在计算 attention score 的时候如何对 padding 做 mask？",
        "Transformer 高效的原因是什么？",
        "Transformer 不适宜的任务有哪些？",
        "Transformer 的应用有哪些？",
        "BERT 的 mask 为何不学习 Transformer 在 attention 处？",
        "SENet 的原理是什么？和 Attention 机制有什么区别？",
        "请介绍一下 Attention 机制，并简单介绍 Self-Attention？",
        "Seq2Seq 和 Transformer 的区别是什么？",
        "Attention 有哪些类型？它们的区别是什么？",
        "在 Transformer 模型中，位置编码（Position Encoding）的作用是什么？",
        "Transformer 的 Encoder 和 Decoder 有什么区别？",
        "Transformer 为什么要用 LayerNorm？作用是什么？",
        "请讲讲 Word2Vec 和 Word Embedding 的区别。",
        "Attention 机制中 Q、K、V 三个矩阵的作用是什么？",
        "BERT 的输入有哪些 Embedding？",
        "请讲一下 Transformer 的原理。",
        "Transformer 的输入和输出分别是什么？",
        "Transformer 的输出和 BERT 有什么区别？",
        "请讲一下 LoRA 的原理。",
        "请讲一下 FlashAttention 的原理。",
        "说一下 Transformer 的模型架构和细节。",
        "几种主流大模型的 loss 了解过吗？有哪些异同？",
        "大模型推理过程中，可以通过调节哪些参数提高性能？",
        "你做过 RAG 的话，能不能介绍一下 RAG？大模型在里面主要起到什么作用？",
        "Transformer 中求和与归一化里，“求和”指的是什么？",
        "请介绍一下 LLM 的架构。",
        "为什么会出现 LLM 的“复读机问题”？",
        "如何缓解 LLM 的“复读机问题”？",
        "大模型进行 SFT 的时候在学习什么？",
        "介绍一下 LightLLM？",
        "StreamingLLM 优点是什么？",
        "如何让 LLM 基于 query 和 context 得到高质量的 response？",
        "大模型（LLMs）评测有哪些方法？如何衡量大模型的效果？",
        "大模型应用框架有哪些及其功能是什么？",
        "RAG（检索增强生成）对于大模型来说有什么好处？",
        "LangChain 如何进行 Embedding 和 vector store？",
        "ALiBi（Attention with Linear Biases）的偏置矩阵是什么？",
        "大模型训练 loss 突刺是什么？",
        "prefix Decoder、causal Decoder 和 Encoder-Decoder 区别是什么？",
        "如何查看服务器上的多卡之间的 NVLINK 拓扑？",
        "如何从复杂 PDF 文件中提取数据？",
        "如何解决结构化数据查询的难题？",
        "如何解决脱离上下文（整合策略的限制）问题？",
        "有监督微调（Supervised Finetuning）的训练数据格式是什么样的？",
        "ALiBi（Attention with Linear Biases）有什么优点？",
        "PPO 中采样策略里，如何评估“收益”？",
        "预训练（Pre-training）与有监督微调（Supervised Finetuning）的区别是什么？",
        "（torch profiler）如何查看训练中的通信开销？",
        "LoRA 的 alpha 参数如何选取？",
        "LoRA 的缺点是什么？",
        "Prefix Decoder、Causal Decoder 和 Encoder-Decoder 的区别是什么？是否在 attention mask 不同？",
        "Pretrain 阶段为什么需要拼接？",
        "什么情况用 Bert 模型，什么情况用 LLaMA、ChatGLM 类大模型，怎么选？",
        "使用 DistributedDataParallel（分布式并行）时，显存分布不均衡问题是什么，怎么排查/解决？",
        "使用 LoRA 对大模型进行推理，如何加载？",
        "使用 LoRA 对大模型进行高效参数微调，如何存储？",
        "在初始预训练中使用 Rewarmup 对大模型继续预训练，性能有什么影响？",
        "多GPU并行训练的原理是什么？",
        "大模型LLM进行SFT操作时在学习什么？",
        "大模型在GPU和CPU上的推理速度如何对比？",
        "如何利用大模型辅助召回以优化外挂知识库？",
        "大模型训练中loss突刺的原因和解决办法是什么？",
        "如何基于LoRA的Llama2进行二次预训练？",
        "如何基于LoRA的Llama2进行微调？",
        "如何配置并安装pdsh？",
        "如何配置deepspeed文件？",
        "如果用PyTorch实现同步梯度更新并自研数据接口，出现第一个epoch结尾处程序卡死问题，如何排查？",
        "对比学习中的负样本是否重要？",
        "样本量规模增大时训练出现OOM错误的原因和解决办法是什么？",
        "训练效率低的缺点是什么？",
        "文本分割怎么做？",
        "PP 推理时是串行过程，1 个 GPU 计算其他空闲，有没有其他方式？",
        "Colossal-AI 有 1D/2D/2.5D/3D 并行，分别是什么情况？",
        "除了 3D 并行还有哪些方式做大规模训练？",
        "LangChain 中 Components 和 Chains 是什么？",
        "RAG-Fusion 的优势是什么？",
        "RAG 工作流程是什么？",
        "WordPiece 与 BPE 的异同点是什么？",
        "什么是 ZeRO-3 和 ZeRO-Infinity？",
        "基于 LoRA 的 Llama2 二次预训练参数有哪些？",
        "训练大语言模型存在哪些问题？",
        "训练数据如何介绍？",
        "分布式并行及显存优化技术有哪些，各有什么特点？",
        "RAG-Fusion 的挑战有哪些？",
        "如何实现 DeepNorm（代码实现思路）？",
        "如果要构建大规模并行训练系统，训练框架如何选？",
        "PEFT 库中基类 LoraLayer 如何实现？",
        "Linear 层如何实现？",
        "为什么第一块 GPU 的显存会占用更多？",
        "对比 Multi-head Attention 和 Multi-Query Attention？",
        "训练框架如何选？",
        "生成式输出中如何实现用户意图保留？",
        "RAG-Fusion 的优化策略有哪些？",
        "如何利用对比学习微调来构建负例？",
        "直接使用 nn.DataParallel 做多卡训练时出现 warning 的原因是什么？",
        "模块化 RAG 的优化策略有哪些？",
        "RAG 新模式的优化策略有哪些？",
        "RAG 结合 SFT？",
        "BPE 是否是选择频次最大的相邻子词进行合并？",
        "DDP 支持 all-reduce、broadcast、send 和 receive 等通信操作吗？",
        "DDP 通过多进程实现：操作系统会为每个 GPU 创建一个进程，从而避免 Python 解释器 GIL 的影响吗？",
        "DistributedDataParallel(DDP) 优点有哪些？",
        "DistributedDataParallel(DDP) 缺点有哪些？",
        "DP 只支持单机多卡场景吗？在多机多卡场景下，DP 的通讯问题会被放大吗？",
        "GPU 数量与训练速度之间有什么关系？",
        "Deep Norm 可以缓解爆炸式模型更新问题、把模型更新限制在常数使训练更稳定吗？",
        "DeepSpeed 的主要优化器包括 Adam、AdamW、OneBitAdam 和 Lamb 吗？这些是否已通过 ZeRO 进行优化？",
        "DeepSpeed 提供 mpi、gloo、nccl 等通信策略吗？如何根据具体情况选择和配置？",
        "deepspeed 训练过程报“找不到主机”如何排查？",
        "Gradient partitioning (ZeRO stage 2) 是什么？",
        "gloo 支持 CPU 和 GPU 上的分布式训练吗？",
        "mpi 是什么？常用于 CPU 集群上的跨节点通信吗？",
        "nccl 是什么？为什么被广泛应用于 GPU 上的分布式训练？",
        "device_ids 在多卡训练中是什么含义？例如 device_ids=[0,1,2] 表示什么？",
        "Fine-tuning 会改变预训练阶段模型参数，可能导致灾难性遗忘吗？",
        "instructGPT 的核心原理是否涉及 RLHF？RLHF 是什么？",
        "LLaMA 2 的 RLHF 是什么？",
        "LLMs 推理性能方面关注哪些点？",
        "lora_alpha 是什么？为什么用 α/r 对 ΔWx 归一化？",
        "LoRA 几乎不添加任何推理延迟，因为适配器权重可以与基本模型合并吗？",
        "LoRA 微调中可训练参数比例如何确定？",
        "LoRA 模块中 q_proj、k_proj、v_proj 在多头注意力中分别起什么作用？",
        "Memory-Efficient 的 LLMs 训练/微调/推理方法有哪些？",
        "merge_weights 在 eval 模式中是否将 LoRA 矩阵加到原有 W0 上？",
        "modules_to_save：除了 LoRA 部分之外，还有哪些层可以被训练并需要保存？",
        "什么是 Nucleus sampler（Top-p 采样），它与 Top-k 采样有什么区别？",
        "什么是 OpenAI evals，它的核心思路是什么？",
        "什么是 Optimizer state partitioning（ZeRO Stage 1）？",
        "DeepSpeed 的 overlap_comm 参数有什么作用？",
        "什么是 PandaLM，它是如何对候选模型进行打分的？",
        "什么是 Parameter partitioning（ZeRO Stage 3）？",
        "什么是 pdsh，它的优势是什么？",
        "PEFT 和全量微调的区别是什么？",
        "在 PEFT 库中如何使用 LoRA 模块？",
        "PPO 中的采样过程是什么？",
        "在分布式训练的 process group 中，rank 0 广播初始化参数到其他进程的机制是什么？",
        "Prompt Template 的作用是什么？",
        "PyTorch 中 GPU 操作默认是什么样的？",
        "PyTorch 分布式计算有哪些常见坑或 bug？",
        "当 query 相关性较弱且模型缺少相关知识时容易产生幻觉，有哪些解决思路？",
        "RAG-Fusion 的优势和不足是什么？",
        "RAG 中长上下文的处理有哪些问题与解决思路？",
        "RAG 的未来发展方向是什么？",
        "RAG 检索召回率低时一般有哪些解决方案？",
        "为什么在 RAG 流程之前需要清理数据？",
        "RAG 的工程应用有哪些关键点？",
        "RAG 如何做水平扩展？",
        "如何提高 RAG 的鲁棒性？",
        "什么是 Reflexion 框架，它如何通过动态记忆与自我反思提升推理能力？",
        "什么是 RLHF（Reinforcement Learning with Human Feedback）？",
        "什么是 reward shaping，它如何调整奖励信号来引导训练？",
        "Prefix Tuning 中训练时只更新 Prefix 参数、固定 Transformer 其他部分参数的机制是什么？",
        "文本分块（chunking）的作用是什么？",
        "tokenizer 中“保存的模型的名称前缀”指的是什么？",
        "o_proj 在多头注意力机制中起什么作用？",
        "TopK 采样通过对 Softmax 的输出结果中最大的 K 个 token 进行采样来选择输出 token，这种方法存在什么问题？",
        "Tree of Thoughts 如何将问题分解为多个步骤并在每一步探索多种推理可能性？",
        "WordPiece 算法如何通过合并相邻子词来构建词表？",
        "为什么 ZeRO-3 会比 ZeRO-2 慢很多，如何通过策略使 ZeRO-3 的速度更接近 ZeRO-2？",
        "ZeRO-Offload 到 CPU 和 NVMe 是什么？",
        "Softmax 交叉熵损失函数如何表示？",
        "为什么 DDP 能够解决 DP 在数据并行中通讯负载不均的问题？",
        "为了解决信息“丢失在中间”的问题，LongContextReorder 如何重新排序检索到的节点？",
        "torch.multiprocessing 如何通过 torch_shm_manager 解决共享内存文件泄漏问题？",
        "为了解决负样本构造成本过高的问题，可以考虑哪些方法？",
        "为什么在送到 RAG 之前需要先将查询交给 LLM 重写？",
        "为什么需要为模型引入位置编码？",
        "为什么需要 accelerate 做分布式训练？",
        "为什么需要进行pdf解析？",
        "介绍一下混合精度训练中的动态损失缩放？",
        "交叉熵损失函数为什么常用于二分类，并且可以泛化到多分类？",
        "为什么大模型输出会出现某个词反复重复？",
        "如果我们已经有了一批已去重的人工处理过的高质量数据，如何寻找与这批数据相似的数据？",
        "在探索和优化 RAG（检索增强生成器）的过程中，如何有效评估其性能？",
        "在推理时如何先进行权重合并再加载模型进行推理？",
        "什么是「有监督微调」（SFT）？",
        "在预训练阶段，模型会从大量无标注文本数据集中学习通用知识吗？",
        "如何基于 RM（奖励模型）使用 PPO 算法微调 SFT 模型？",
        "多任务学习中，如果各任务的损失差异过大，如何处理？",
        "多机训练不通时，如何排查 DeepSpeed 配置问题？",
        "如何提出一个问题，让模型给出多个不同的答案或解决方案，以测试模型的创造力和多样性？",
        "如何对比多种不同的高效微调方法？",
        "大模型 RAG 的关键痛点及对应解决方案有哪些？",
        "大模型 RAG 的优化策略有哪些（RAG-Fusion）？",
        "如何对大模型 RAG 进行版面分析（文本分块）？",
        "如何对大模型 RAG 进行版面分析（表格识别方法）？",
        "什么是大模型的增量预训练？",
        "大模型强化学习中，PPO 的核心流程是什么？",
        "什么是 RLHF 及其变种？",
        "大模型推理的关键优化点有哪些？",
        "大模型常见显存问题有哪些，如何解决？",
        "RLHF 采样策略有哪些？",
        "如何区分单栏和双栏 PDF？",
        "如何对原始数据进行预处理？",
        "如何构建中文词库？",
        "如何精确地回答用户关于文档的问题，做到不重不漏？",
        "如何让 Prompt Tuning 在不同参数规模的预训练模型、针对不同下游任务的结果上都达到匹敌 Fine-tuning 的效果？",
        "模型训练过程中出现 loss spike（loss 突然尖峰上涨）是什么原因，会导致哪些问题？",
        "出现 OOM 时，如何通过混合精度训练进行缓解（Ampere GPU 用 bf16，旧 GPU 用 fp16）？",
        "出现 OOM 时，如何通过 ZeRO stage 缓解？",
        "出现 OOM 时，如何通过 ZeRO stage 2 + offload_optimizer 缓解？",
        "如果仍然OOM，是否可以使用ZeRO-Infinity，将offload_param和offload_optimizer offload到NVMe？如果实现不了，原因是什么？",
        "如果想要在某个模型基础上做全参数微调，需要多少显存？",
        "如果使用自定义tokenizer，是否需要重新设置模型的嵌入层和lm_head层的词表大小？",
        "如果模型是在ZeRO-2模式下保存的，模型参数会以fp16形式存储在pytorch_model.bin中吗？",
        "如果模型是在ZeRO-3模式下保存，需要如何设置参数，否则pytorch_model.bin会有什么问题？",
        "在实际应用中如果数据较脏，难例挖掘可能用处不大，如何处理？",
        "训练时可能把潜在正例误判为负例（假负例/False Negative），应如何处理？",
        "对于长文档（如书籍），如何获取其中关键信息并构建索引？",
        "如何进行并行化训练加速？",
        "当使用梯度累积时，如何通过将batch_size设置为1来实现任意有效batch_size？",
        "当开启offload后开始优化参数，是否可以通过关闭offload、降低ZeRO stage并调整batch_size来继续训练？",
        "引入重参数化方法（如LoRA、AdaLoRA、QLoRA）的动机是什么，适用场景分别是什么？",
        "张量并行的实现难点是什么，为什么会因模型结构而异？",
        "张量并行只有在 NVLink 环境下才会起正向作用，但提升也不会太明显？",
        "当你从单卡穷人变成多卡富翁时，你做分布式训练的总体目标是什么？",
        "当前搜索技术的限制是什么，RAG 受到哪些限制？",
        "很多实际应用场景，我们并没法拿到 LLM 回答的标准答案，同时对每个问题的候选文档也拿不到，怎么处理？",
        "怎么合并中英文的词表，并使用 transformers 使用合并后的词表？",
        "找到最佳块大小要找到正确的平衡，如何高效地做到这一点？",
        "推理过程反复加载巨大的 KV cache，导致内存开销大、性能内存受限，如何优化？",
        "数据加载优化：可以使用 DataLoader 和 DataLoaderTransforms 来优化数据加载速度，从而减少训练时间，具体怎么做？",
        "数据并行有哪些特点（如计算效率、实现复杂度）？",
        "数据并行（如 PyTorch DDP）是如何工作的？",
        "无论我们如何准确地估计真实梯度，总存在一个最大步长，这个现象如何理解？",
        "为什么多 GPU 训练并不是负载均衡的，一般 0 卡会占用更多？",
        "显存不够时应该选 TP、ZeRO 还是 PP？",
        "显存不够时是否应该使用 offload，把部分数据放到 CPU？",
        "显存够用（模型能装进单卡）时应该用 DDP 还是 ZeRO？",
        "流水线并行不会减少每层中间激活的显存占用吗？",
        "每张卡上都保存了完整的模型、梯度、优化器状态会导致显存效率不高吗？",
        "随着并行度增加，显存占用会成比例减少吗？减少单层网络中间激活显存占用的唯一方法是什么？",
        "未经过预训练的模型在上游任务和下游任务上都不如预训练过的模型吗？",
        "与 BPE 最大的区别在于：如何选择两个子词进行合并？",
        "哪些机制和生成策略可能导致模型更倾向于复制输入文本？",
        "标准 InstructGPT 的 RLHF（PPO）方法中，是否会对同一个提示下的 4-9 个模型输出进行排序？",
        "强化学习中的核心问题是否是选择一种策略从而最大化预期收益？",
        "梯度累积（gradient accumulation）的原理是什么？",
        "什么是梯度爆炸，它会如何影响模型的收敛性和训练效果？",
        "RAG 的检索后处理流程是什么？",
        "RAG 的优化策略有哪些？",
        "为什么模型全量微调会导致对每个任务训练一个模型，从而使开销和部署成本更高？",
        "模型如何判断回答的知识是训练过的已知知识，如何训练这种能力？",
        "大型语言模型采用 Causal Decoder + LM 训练目标为什么会有较好的 zero-shot 和 few-shot 能力，是否存在“涌现”？",
        "每个 epoch 整体数据分片 shuffle 一次、每个进程同一时间只加载单个分段大小的目的是什么？",
        "每个进程各自读取各自训练数据，DistributedSampler 如何确保不同进程读到的数据不重复？",
        "为什么要在每次训练迭代中，在后向传递之后、优化器更新参数之前插入 reduce 通信来规约梯度？",
        "LoRA/PEFT 中 target_modules 的作用目标名在不同模型中为什么不一样？",
        "混合精度训练：采用 bfloat16 而不是 float16 来训练的原因是什么？",
        "混合精度训练是指在训练过程中同时使用 FP16（半精度浮点数）和 FP32（单精度浮点数）吗？",
        "混合精度训练的大致思路是什么（例如在 forward 和梯度计算时用 fp16，加速与更新参数如何处理）？",
        "如何确保所有 worker 都从相同的初始化模型参数开始训练（例如训练开始前将 0 号卡的模型参数通信同步）？",
        "什么是稀疏 attention？它如何降低复杂度？",
        "什么是线性化（Linear）attention？它如何将 Attention 的复杂度从 O(N^2) 降低为 O(N)？",
        "经过充分训练后，学习率越大，下游性能最好、上游性能最差（忘得最多）吗？",
        "为什么使用 nn.DataParallel 函数进行多 GPU 运算时，程序耗时不减反增？",
        "为什么第一块 GPU 的显存占用会比其他 GPU 更多？",
        "为什么更大的模型训练时，每块 GPU 不仅要存模型参数，还要存中间结果（用于 backward）？",
        "数据并行的优点和缺点分别是什么？",
        "训练类型需要支持哪些并行方式（如数据并行、张量并行、流水线并行、多维混合并行、自动并行等）？",
        "训练时是否可以固定原模型，只训练 LoRA 的降维矩阵 A 和升维矩阵 B？",
        "LoRA 的缺点有哪些（如推理延时增加、效果可能比全量微调差）？",
        "为什么说大型语言模型的训练目标（如预测下一个词）可能导致复读机问题出现？",
        "如何评估一个大型语言模型的水平，可以从哪些维度提出代表性问题？",
        "什么是流水线并行，GPipe 提出的流水线并行主要解决了哪些问题？",
        "当需要加载和保持多个模型时，应该如何管理这些模型？",
        "LangChain 为什么提供提示（prompt）和链（chain）来帮助开发者自行评估 LLM？",
        "动态损失缩放（dynamic loss scaling）的原理是什么，如何避免半精度 tensor 出现 overflow 变成 inf/NaN？",
        "如何通过解码策略避免生成句子出现连续重复（repetition）问题？",
        "Ring-AllReduce 是什么，如何解决数据并行训练中的通信负载不均问题？",
        "为什么需要自动混合精度（AMP），torch.FloatTensor 与 torch.HalfTensor 混用的动机是什么？",
        "多任务训练时，如何平衡各任务的数据量？",
        "断点重训时，如何选择一个好的断点？",
        "通过从较低的 Transformer 层删除可变数量的 Adapter 来提升推理速度的原理是什么？",
        "在 Transformer 层中嵌入 Adapter 结构为什么会增加推理时长？",
        "多机训练时网络带宽打满成为瓶颈的原因是什么？",
        "如何通过直接提示进行文本推理？",
        "如何通过程序合成进行符号推理（例如 Python、SQL）？",
        "如何测试并评估模型的逻辑推理能力？",
        "训练/推理长度不一致导致的长度外推问题有哪些表现？",
        "如何为 Agent 提供长期记忆能力（保留与召回长期信息），通常如何用外部向量存储与检索实现？",
        "如何定位 GPU 显存不够（OOM）的问题？",
        "训练时使用 bf16、推理时使用 fp16 可能带来哪些问题？常见于在 TPU 上训练的模型吗？",
        "模型训练样本数量从 10 万增加到 300 万后训练任务直接报 OOM，可能原因是什么，如何排查？",
        "学习率设置为什么通常不应大于预训练时的学习率？",
        "如何解决多次输入相同 prompt 时输出单调性的问题？",
        "健康饮食的主要特点是什么？",
        "居里夫人的主要成就是什么？",
        "文档召回场景下，有监督对比学习为什么需要三元组（问题、文档正例、文档负例）？",
        "随着预训练模型参数量增加，Prompt Tuning 的效果会逼近全参数微调吗？为什么？",
        "静态显存主要由什么决定？是否基本由模型参数量级决定？",
        "如何防止恶意输入操控、处理潜在不安全输出并避免敏感信息泄露？",
        "如何通过将数据预处理模块从项目中拆出，用小数据集单独运行来验证其输出是否正确？",
        "预训练数据参数有哪些？",
        "如何下载预训练数据集？",
        "预训练模型参数有哪些？",
        "预训练模型参数量变多时，在特定任务下做全量微调为什么昂贵且耗时？",
        "领域数据训练后通用能力下降，如何缓解模型遗忘通用能力？",
        "Continue PreTrain 时如何让模型在预训练过程中学习到更多领域知识？",
        "领域词表扩增主要解决什么问题？对模型效果提升是否有限？为什么？",
        "如何根据参数量估计模型大致所需的 RAM？",
        "半精度训练中，为什么默认使用 fp16 作为 reduction 操作的默认值？",
        "如何进行子目标拆解和任务分解？",
        "多查询生成技术实现（提示工程）是什么？",
        "预训练（Pre-training）与有监督微调（Supervised Finetuning）有什么区别？",
        "InstructGPT 的原理是什么？请讲讲 RLHF 和 reward model。",
        "ChatGLM-6B 做 LoRA 微调后的权重多大？",
        "为什么 LoRA 微调方法能加速训练？",
        "LoRA 权重是否可以合并？",
        "nB 参数量的模型推理需要多少显存？",
        "nB 参数量的模型训练需要多少显存？",
        "PEFT 库中 LoRA 模块的代码结构是什么？",
        "Prefix Decoder、Causal Decoder、Encoder-Decoder 的区别是什么？（是否主要体现在 attention mask）",
        "RAG 架构优化有哪些策略？",
        "RAG 索引优化有哪些策略？",
        "RAG 索引数据优化有哪些策略？",
        "RAG 的 rank 如何选取？",
        "warmup 步数对大模型继续预训练是否有影响？",
        "使用 DistributedDataParallel（分布式并行）时，显存分布不均衡问题怎么解决？",
        "在初始预训练中使用 Rewarmup 对大模型继续预训练有什么性能影响？",
        "如何利用大模型辅助召回？",
        "大模型训练loss突刺原因和解决办法是什么？",
        "如何解决PPO训练过程同时存在4个模型（2训练，2推理）对计算资源要求较高的问题？",
        "如果想要试试65B模型但是显存不多怎么办？",
        "如果用PyTorch实现同步梯度更新、自研数据接口，出现第一个epoch结尾处程序卡死问题，如何排查？",
        "学习率大小对大模型继续预训练后上下游任务有什么影响？",
        "样本量规模增大时训练出现OOM错误，如何处理？",
        "训练效率低有哪些缺点？",
        "自回归语言模型的预训练和下游应用是否完全一致，是否严格遵守只有后面的 token 才能看到前面的？",
        "说一下 RAG-Fusion 的工作流程？",
        "说一下 RAG-Fusion 的核心技术？",
        "想要训练 1 个 LLM，如果只想用 1 张显卡，对显卡的要求是什么？",
        "如果显卡的显存不够装下一个完整的模型怎么办？",
        "Colossal-AI 的 1D/2D/2.5D/3D 是什么？",
        "除了 3D 并行还有哪些方式进行大规模训练？",
        "RAG 的工作流程是什么？",
        "ZeRO-3 和 Infinity 的细节有哪些？",
        "RMSNorm 相比 LayerNorm 有什么特点？",
        "ZeRO-3 是什么？",
        "ZeRO-stage-1 是什么？",
        "介绍一下不同大模型（LLMs）的分词方式有哪些区别？",
        "基类 LoraLayer 如何实现？",
        "直接使用 nn.DataParallel 进行多卡训练时出现 warning，可能原因是什么，如何处理？",
        "利用对比学习微调时，构建负例有哪些方法？",
        "生成性输出中如何实现用户意图保留？",
        "RAG 新模式有哪些优化策略？",
        "accelerate 分布式训练如何进行依赖安装？",
        "如何用 AMP 进行混合精度训练（代码层面）？",
        "DDP 支持 all-reduce、broadcast、send 和 receive 等通信原语吗？",
        "DDP 通过多进程实现，每个 GPU 一个进程，从而避免了 Python 解释器 GIL 带来的什么问题？",
        "Deep Norm 可以缓解爆炸式模型更新问题，把模型更新限制在常数，使训练过程更稳定吗？",
        "DeepSpeed 的主要优化器（Adam、AdamW、OneBitAdam、Lamb）是如何通过 ZeRO 进行优化的？",
        "DeepSpeed 训练过程中报“找不到主机”可能是什么原因，如何排查？",
        "为什么 DP 只适合单机多卡，在多机多卡场景下 DP 的通信问题会被放大？",
        "Fine-tuning 会改变预训练阶段的模型参数，可能导致灾难性遗忘吗？",
        "GPU 数量与训练速度之间是什么关系？",
        "什么是 Gradient partitioning（ZeRO stage 2）？",
        "InstructGPT 的核心原理（RLHF）是什么？",
        "LangChain 存在哪些问题及对应方法方案？",
        "LLaMA 2 的 RLHF 流程是什么？",
        "LLMs 推理性能方面有哪些关键指标或瓶颈？",
        "LoRA 的 lora_alpha 是什么，为什么需要用 α/r 进行归一化？",
        "为什么 LoRA 几乎不添加任何推理延迟，且适配器权重可以与基础模型合并？",
        "LoRA 微调时可训练参数比例如何确定？",
        "LoRA 模块中 q_proj、k_proj、v_proj 分别是什么，它们在多头注意力中起什么作用？",
        "有哪些 Memory-Efficient 的 LLM 训练/微调/推理方法？",
        "merge_weights 在 eval 模式下是否会把 LoRA 矩阵加到原有权重 W0 上？",
        "modules_to_save 表示什么：除 LoRA 外还有哪些层可以训练并需要保存？",
        "MPI 在分布式训练中是什么，常用于哪些场景？",
        "NCCL 是什么，为什么被广泛用于 GPU 分布式训练？",
        "nn.DataParallel 的常见问题有哪些？",
        "什么是 Nucleus sampler（Top-p 采样）？它与 Top-k 采样相比有什么区别？",
        "什么是 pdsh？它能解决什么问题？",
        "如何缓解 RAG 中因 query 相关性弱或模型缺少知识导致的幻觉问题？",
        "RAG 中长上下文处理有哪些问题与常见方案？",
        "如何提升 RAG 的检索召回率？",
        "RAG 流程开始前为什么需要清理数据？",
        "RAG 模块可替换/可重配置的工程意义是什么？",
        "如何研究与提升 RAG 的鲁棒性？",
        "什么是 Reward shaping？为什么要做 reward shaping？",
        "Prefix tuning 中为什么训练时只更新 Prefix 部分参数而固定 Transformer 其他参数？",
        "文本分块（chunking）有什么作用？",
        "token映射到一个高维向量空间中，以便于模型对输入进行处理；o_proj则是多头注意力机制的？",
        "TopK通过对Softmax的输出结果logit中最大的K个token采样来选择输出的token，该方法存在的问题是当概率分？",
        "TopK采样是一种行之有效，能简单暴力的解决1.1节中提出所有重复单调问题的方案之一，当然它存在的最大问？",
        "Trainer 训练类？",
        "Trainer 训练类 编写？",
        "Tree of Thoughts：进一步扩展CoT，在每一步都探索多种推理的可能性。它首先将问题分解为？",
        "WordPiece算法选择 能够提升语言模型概率最大的相邻子词进行合并，来加入词表？",
        "ZeRO-Offload 使 GPU 单卡能够训练 10 倍大的模型： 为了同时利用 CPU 和 GPU 内存来训练？",
        "Softmax交叉熵损失函数可以写成：？",
        "项复杂任务通常会包含很多步骤，Agent需要了解这些步骤是什么并提前规划？",
        "不能使用Apex进行混合精度训练？",
        "为了解决信息 “丢失在中间” 的问题，LongContextReorder 被设计用来重新排序检索到的节点，在？",
        "为了解决共享内存文件泄漏的问题，torch.multiprocessing将产生一个守护程序torch_shm_manager，它将自己？",
        "为了解决这个问题，在送到 RAG 之前，我们先发生给 LLM 重写此查询？",
        "为了解决这个问题，我们需要为模型引入位置编码，让每个词向量都能够感知到它在输入序列中所？",
        "什么是 DistributedDataParallel（DDP）的核心机制 Ring-AllReduce？",
        "交叉熵损失函数为什么常用于二分类，并如何泛化到多分类？",
        "RAG 的工作流程包含哪些模块？",
        "作用在每个 transformer 层的 self-attention 块，在计算完 Q/K 之后，旋转位置编码作用在 Q/K？",
        "Example Selectors 的作用是什么？它们接受用户输入并返回什么？",
        "梯度检查点技术的作用是什么？",
        "梯度累积的主要作用是什么？",
        "相对距离越大惩罚项越大是否意味着两个 token 距离越远、相互贡献越小？",
        "Flash Attention（含 v2）和 Paged Attention 是否所有模型都内置支持？如果没有，如何用于优化 Transformer 推理代码？",
        "如何使用 sentencepiece 训练中文词表？",
        "torch.cuda.amp.autocast 和 torch.cuda.amp.GradScaler 在训练中的作用是什么？",
        "ZeRO-offload 将哪些数据 offload 到 CPU，从而如何降低显存需求？",
        "RAG 的维护是否需要添加机制来更新过时文档？",
        "文档正例与文档负例分别是什么？文档负例可以是什么？",
        "如何使用 Huggingface PEFT 进行 int8 训练 opt-6.5B？",
        "使用 tokenizer() 得到输入时，文本前后可能添加哪些特殊标记（如 bos_token_id 等）？",
        "对比 loss 通过添加 token 间相似度约束，是否可以解决生成式模型重复单调问题？",
        "ALiBi 方法的核心思路是什么？",
        "结合 PEFT 模块源码，LoRA 是如何实现的？",
        "冻结模型原始权重、只训练 prompts 参数后，是否可以用同一个模型做多任务推理？",
        "训练词表需要准备哪些要素（如训练语料与词表大小）？",
        "为什么参数更新量变少会减少通信时间（尤其多卡训练）？",
        "为什么 RAG 可以显著降低 LLM 幻觉？",
        "为解决解码退化（生成文本不自然且重复）提出的方案是什么？",
        "为什么 DistributedDataParallel 在内存占用和通信方面优于 nn.DataParallel？",
        "分布式训练如何在多个 GPU 或多台机器上并行训练以缩短训练时间？",
        "sentencepiece 中将用户定义特殊符号作为整体加入词表的参数是什么？其作用是什么？",
        "分析 Top-K Hard Negative Sampling 挖掘负例训练时对梯度的影响。",
        "分析 Random Sampling 挖掘负例训练时对梯度的影响。",
        "为什么分类问题常用交叉熵损失？交叉熵如何度量两个概率分布？",
        "为什么有的初始化策略会将 A 设为高斯分布、B 设为全 0，以保证训练开始时旁路为 0 矩阵？",
        "前缀微调（Prefix-tuning）与人工设计的离散 prompts 相比，核心区别是什么？",
        "训练时“剩余状态”显存占用包括哪些部分（除模型状态外）？",
        "动态显存中激活值在前向传播阶段为何需要存储？",
        "动态选择损失标度（loss scaling）的机制是什么（溢出时如何处理、连续 N 步无溢出时如何处理）？",
        "为什么仅用领域数据微调大模型容易出现灾难性遗忘？",
        "微调大模型时如何选择和构建微调数据？",
        "推理服务器的吞吐量是什么？",
        "在探索和优化 RAG（检索增强生成器）的过程中，如何有效评估其性能已经成为关键问题？",
        "在推理时如何先进行weight的合并在加载模型进行推理？",
        "什么是有监督微调（SFT）？",
        "多种不同的高效微调方法如何对比？",
        "大模型迭代中，如何基于正反馈微调模型、进行量化感知训练、提供大context window的推理模型？",
        "RAG 的关键痛点及对应解决方案有哪些？",
        "RAG 的优化策略有哪些（如 RAG-Fusion）？",
        "RAG 版面分析中，文本分块怎么做？",
        "RAG 版面分析中，表格识别方法有哪些？",
        "什么是大模型增量预训练？",
        "大模型强化学习中，PPO 的核心思路是什么？",
        "大模型推理有哪些关键问题与优化点？",
        "大模型显存问题如何定位与解决？",
        "大语言模型RLHF中，采样策略有哪些？",
        "如何对原始数据做预处理？",
        "如何对继续预训练数据做预处理？",
        "如何让Prompt Tuning在不同参数规模的预训练模型、针对不同下游任务的结果上达到匹敌Fine-tuning的效果？",
        "模型训练过程中出现loss spike（loss尖峰）是什么原因，会导致哪些问题？",
        "发生OOM时，如何选择混合精度（Ampere GPU用bf16，旧GPU用fp16）？",
        "发生OOM时，如何使用ZeRO stage解决？",
        "发生OOM时，如何使用ZeRO stage 2 + offload_optimizer解决？",
        "如果仍然 OOM，是否可以使用 ZeRO-Infinity，并将 offload_param 和 offload_optimizer offload 到 NVMe？如果实现不了，原因可能是什么？",
        "如果是我们自己定义的 tokenizer，是否需要重新设置模型的 embedding 层和 lm_head 层的词表大小？",
        "如果模型是在 ZeRO-2 模式下保存的，模型参数会以 fp16 的形式存储在 pytorch_model.bin 中吗？",
        "如果模型是在 ZeRO-3 模式下保存的，需要如何设置参数，否则 pytorch_model.bin 会出现什么问题？",
        "在实际应用中数据较脏时，难例挖掘可能用处不大；你如何评估其收益并决定是否使用？",
        "训练中可能将潜在正例误判为负例（False Negative）；这种情况下应如何训练或处理？",
        "如何对预训练模型进行指令微调：tokenization 如何构建？",
        "如何对预训练模型进行指令微调：数据如何处理？",
        "如何对预训练模型进行指令微调：模型如何构建？",
        "如何通过将 batch_size 设置为 1 并使用梯度累积，实现任意有效 batch_size？",
        "梯度累积的潜在问题是什么（例如累积步数过大导致更新频率过低）？",
        "如果训练出现 OOM，是否可以通过关闭 offload、降低 ZeRO stage、调整 batch_size 后继续训练？",
        "如何实现并行化训练加速？",
        "为什么 pipeline 并行会有缺点（例如每台机器只处理部分数据导致结果不一致或效率问题）？",
        "如何在长文档（如书籍）中获取关键信息并构建索引？",
        "如何引入人工干预与控制机制，对生成文本进行审查与筛选以确保准确性？",
        "在训练中引入多任务学习：先在多任务 prompt 上预训练再适配下游任务的思路是什么？",
        "什么是重参数化微调方法（如 LoRA、AdaLoRA、QLoRA），它们的主要区别与适用场景是什么？",
        "当M=1的时候，GPU的空置率太高，因此两个模型都没有实现训练速度和GPU个数间的线性关系？",
        "当M=32时，表现最佳，且Transformer基本实现了训练速度和GPU个数的线性关系？",
        "当前搜索技术的限制是什么？",
        "很多实际应用场景，我们并没法拿到LLM回答的标准答案，同时对每个问题的候选文档，该怎么办？",
        "推理过程：反复加载巨大的KV cache导致内存开销大、性能是内存受限，如何优化？",
        "效率：将普通模型训练代码变为分布式训练所需编写代码的行数，我们希望越少越好，如何做到？",
        "数据加载优化：如何使用DataLoader和DataLoaderTransforms来优化数据加载速度，从而减少训练耗时？",
        "数据并行的特点是什么？",
        "什么是数据并行（如PyTorch DDP）？",
        "无论我们如何准确地估计真实梯度，总存在一个最大步长，这是为什么？",
        "为什么多 GPU 训练并不是负载均衡的，一般 0 卡会占用得更多？",
        "显存不够时，TP、ZeRO、PP 应该怎么选？",
        "显存不够时是否应该使用 offload 到 CPU？",
        "在多卡训练中，每张卡都保存完整的模型、梯度、优化器状态会导致显存效率不高吗？",
        "随着并行度增加，显存占用会成比例减少吗？减少单层网络中间激活的显存占用有哪些方法？",
        "与 BPE 相比，如何选择两个子词进行合并的策略有什么不同？",
        "哪些机制和生成策略可能导致模型更倾向于复制输入文本（复读机）？",
        "InstructGPT 的 RLHF（PPO）方法中，如何对同一个提示下的多个模型输出进行排序？",
        "在强化学习中，如何选择策略以最大化预期收益？",
        "梯度爆炸会如何影响模型训练收敛和训练效果？",
        "RAG（检索增强生成）有哪些优化策略？",
        "使用 Apex 或 TorchScript 等工具可以如何优化模型性能？",
        "为什么全量微调会带来较高的训练开销和部署成本？",
        "为什么 Causal Decoder + LM 的结构与训练目标会带来 zero-shot 和 few-shot 能力（涌现）？",
        "模型结构和参数设置（如注意力机制）会如何影响复读机问题？",
        "训练和推理长句子会面临哪些挑战（如梯度消失/爆炸）？",
        "在多进程训练中，DistributedSampler 如何确保各进程读到的数据不重复？",
        "为什么每张卡上的 loss 需要汇总到第 0 张卡上求梯度并更新权重？",
        "在反向传播后、优化器更新参数前插入 reduce 通信操作规约梯度的目的是什么？",
        "混合精度训练中为什么采用 bfloat16 而不是 float16？",
        "如果要在 vLLM 中添加自定义模型，但模型架构与 vLLM 现有模型不类似，会遇到哪些问题？",
        "已有的 LoRA 模型只训练了一部分数据，要训练另一部分数据时，是在这个 LoRA 上继续训练，还是与 base 模型合并后再套一层 LoRA，或者从头开始训练一个 LoRA？",
        "在相同训练数据下，Reward Model 越大，actor 模型能够获得更高的真实 reward 吗？",
        "如何确保所有 worker 都从相同的初始化模型参数开始训练？",
        "经过充分训练后，学习率越大，下游性能最好、上游性能最差（遗忘最多）吗？",
        "nn.DataParallel 可以进行多 GPU 运算，但会导致程序花费的时间不减反增，这是为什么？",
        "训练更大的模型时，每块 GPU 不仅要存模型参数，还要存用于反向传播的中间结果；为什么会这样，带来什么影响？",
        "训练时固定原模型参数，只训练降维矩阵 A 和升维矩阵 B（如 LoRA）的原理是什么？",
        "增加并行度时，如何理解单卡计算量近似恒定、可以接近线性扩展，但梯度规约会带来开销？",
        "多机多卡训练中，增加训练机器能线性缩短训练时间吗？在什么条件下成立、什么因素会破坏线性加速？",
        "数据并行、张量并行、流水线并行等并行方式分别适用于哪些场景？",
        "流水线并行（如 GPipe）主要解决什么问题？",
        "大型语言模型以“预测下一个词”为目标训练时，为什么可能导致复读机（倾向生成与输入相似文本）问题？",
        "有监督微调与预训练在训练数据格式和数据量上有什么区别？",
        "为什么很难用传统指标评估生成模型，LangChain 为什么提供提示和链来帮助开发者使用 LLM？",
        "动态损失缩放（dynamic loss scaling）的原理是什么，如何在半精度训练中避免 tensor overflow（inf/NaN）？",
        "进行多任务训练时，为什么要尽量平衡各个任务的数据量？",
        "选择断点重训时，选择一个好的断点的标准是什么？",
        "在 Transformer 层中嵌入 Adapter 结构会在推理时增加推理时长，原因是什么？",
        "多机训练中如果网络带宽打满而其他监控正常，可能的原因是什么？",
        "什么是通过直接提示进行文本推理？",
        "什么是通过程序合成进行符号推理（例如 Python、SQL 等）？",
        "如何测试模型的逻辑推理能力？",
        "如何测试模型在道德和伦理问题上的表现（例如“在什么情况下撒谎是可以接受的？”）？",
        "基于 Llama 家族的模型中文支持不友好，有哪些办法可以解决？",
        "训练时用的是 bf16，使用时是 fp16，可能会导致哪些问题？这种情况常见于在 TPU 上训练的模型吗？",
        "当模型训练样本数量从 10 万增大到 300 万后训练任务直接报 OOM，可能原因是什么，如何排查？",
        "学习率设置为什么不应大于预训练时的学习率？",
        "如何解决同一 prompt 多次输入导致输出单调的问题？",
        "文档召回场景下，做有监督对比学习为什么需要三元组（问题、文档正例、文档负例）？",
        "LoRA 为什么可以将 update matrix 重新参数化为两个低秩矩阵的乘积？",
        "随着预训练模型参数量增加，Prompt Tuning 的效果是否会逼近全参数微调？为什么？",
        "训练一个 GPT-3 级别模型大约需要多少计算与存储资源？",
        "设计和部署大模型时，如何应对可解释性、可靠性、可持续性等挑战？",
        "静态显存占用主要由什么决定？",
        "如何防止恶意输入操控模型、处理潜在不安全输出、避免敏感信息泄露？",
        "如何单独抽取项目中的数据预处理部分，用一份小数据集运行并验证输出是否正确？",
        "预训练数据集如何下载？",
        "预训练模型的参数有哪些？",
        "预训练模型参数量变多时，在特定任务上做全量微调为什么昂贵且耗时？有哪些替代方案？",
        "领域数据训练后通用能力往往会下降，如何缓解模型遗忘通用能力？",
        "Continue PreTrain 如何让模型在预训练过程中学习到更多知识？",
        "领域词表扩增主要解决什么问题？对模型效果提升通常有多大？",
        "半精度训练中，为什么默认用 fp16 作为 reduction 操作的默认值？"
      ]
    },
    "Oracle": {
      "count": 29,
      "questions": [
        "将USERS表空间置于备份模式后，将触发哪种类型的检查点？",
        "实例恢复包含哪两个动作？",
        "当发出COMMIT命令的时候，DBWR做了什么操作？",
        "ASM自动存储管理中磁盘划分的单元（AU）默认大小为多大？",
        "参数文件和密码文件的物理路径在什么地方？",
        "基于用户管理的备份，说法正确的是？",
        "关于参数文件及参数说法正确的是？",
        "关于闪回DROP说法正确的是？",
        "在 Oracle 中，数据块、Redo 日志块及控制文件数据块的大小分别是多少？如何查？",
        "Oracle 系统进程主要有哪些？各自作用是什么？",
        "Undo 的作用是什么？",
        "如果 $GRID_HOME 下的权限被人为修改过，那么如何修复该权限问题？",
        "归档和非归档模式之间的不同点是什么？它们各自的优缺点是什么？",
        "什么是 Oracle Undo？",
        "如何理解 UNDO Retention？",
        "Hash Join 是否有排序？Hash Join 会在什么时候慢？",
        "等待事件如何分类？常见等待事件有哪些？",
        "release 的区别是什么？",
        "Oracle 中 Manager 进程是 OGG 的控制进程，运行在源端和目标端上，它的主要作用是什么？",
        "Oracle 中 Data Pump 进程（简称 Pump 进程）运行在数据库源端，它的作用是什么？",
        "如何对特定模式对象上的 DML 语句进行审计？",
        "请解释 Oracle数据库中的 SQL优化器的作用。",
        "请解释 Oracle数据库中的统计信息（statistics）的作用。",
        "自动健康检查的作用？",
        "据库自动决定何时以及如何进行重定位。在某些情况下，可能需要手动触发重定位？"
      ]
    },
    "SLAM": {
      "count": 96,
      "questions": [
        "简单的 SLAM 定位一般只考虑传感器数据前后帧的什么信息？",
        "机器人学中地图的表示方法有哪些？（特征地图、拓扑地图、栅格地图、直接表征法）",
        "回环检测的原理是什么？主要在什么阶段使用？",
        "请说明某个 SLAM 框架的工作原理、优缺点以及可改进之处。",
        "如何解决难以定义深度的问题？（如检测待定位图像中的 AR 标记、棋盘等）",
        "PnP 问题有哪些常见求解方法？（DLT、P3P、EPnP、UPnP、非线性优化）",
        "视觉、激光雷达与测量单元（如 IMU）的融合如何解决视觉里程计的漂移和尺度丢失问题？",
        "线性三角化（齐次方法）如何用于求解深度？",
        "如何用高斯-牛顿方法解决 scan-matching 问题以获得激光点集映射到已有地图的刚体变换？",
        "栅格地图是什么？它的提出者是谁？",
        "如何用 Hessian 的迹与行列式的比值判断关键点是否在边缘并剔除不稳定的边缘响应点？",
        "SLAM 要解决的两个基本问题是什么？",
        "深度可以用哪些方法确定？请以双目视觉视差为例说明。",
        "回环检测（Loop Closing）的作用是什么？它如何判断机器人是否到达过先前的位置？",
        "相机坐标系、归一化坐标系、像平面坐标系和像素坐标系有什么区别？它们之间如何相互转换？",
        "小孔成像模型的原理是什么？CCD 和 CMOS 的成像机制是什么？",
        "什么是绑架问题（重定位）？机器人在缺少之前位置信息的情况下如何确定当前位姿？",
        "SLAM 系统通常包含哪些模块？（相对姿势估计、地图表示、闭环检测、后端优化等）",
        "解决 SLAM 问题通常需要哪些传感器？不同传感器各有什么用途？",
        "在 Levenberg–Marquardt 方法中，如何理解 H 占主导与 λI 占主导的区别？它们如何避免非奇异和病态问题并提高稳定性？",
        "当两束光束坐标系存在相对变换 T0i 时，如何消除其影响？（如使用编码器或 IMU 等高频信息）",
        "Hector SLAM 的特点是什么？它在什么场景下适用？",
        "卡尔曼滤波的预测步骤是什么？如何根据输入信息从上一时刻状态推断当前时刻状态分布并计算协方差？",
        "关键帧选取的条件有哪些？（与最近关键帧的空间/运动距离、与上一关键帧的时间间隔等）",
        "纯视觉 SLAM 的尺度不确定性问题是什么？如何解决？",
        "什么是 SLAM？",
        "基本 SLAM方法？",
        "带优化的 SLAM计算方法？",
        "添加回环检测的 SLAM处理方法？",
        "全局 SLAM和局部 SLAM分开方法？",
        "某个 SLAM框架工作原理、优缺点、如何改进？",
        "SLAM中的绑架问题？",
        "为什么 SLAM中常用 L-M？",
        "为什么是 NeRF-Based SLAM？",
        "为什么是 Gaussian-Based SLAM？",
        "D激光雷达原理？",
        "IMU原理介绍及误差分析？",
        "视觉 SLAM整体流程大致可以概括为哪些步骤？",
        "解决 SLAM问题通常需要安装一个或者是多个传感器，不同的传感器有什么用途？",
        "如何处理关键帧（可以参考 ORBSLAM2）？",
        "单目视觉 SLAM中尺寸漂移是怎么产生的？",
        "Flash 激光雷达的原理是什么？",
        "D 激光雷达原理是什么？",
        "两束光束坐标系相差 T0i，如何消除其影响？可以使用编码器或 IMU 这样高频吗？",
        "光探测与测距（激光雷达）方法主要使用激光传感器（或距离传感器），对比相机、ToF 和？",
        "视觉 SLAM 整体流程大致可以概括？",
        "GPU 显存不够如何定位与解决？",
        "如何进行重定位？在某些情况下，是否需要手动触发重定位？",
        "请介绍某个 SLAM 框架的工作原理、优缺点及改进方向。",
        "g2o 的流程是什么？",
        "ORB-SLAM 的初始化流程是什么？",
        "如何对匹配好的点做进一步处理以更好保证匹配效果？",
        "请描述 GN、LM 方法。",
        "什么是 SLAM 中的绑架问题？",
        "特征匹配（稀疏）和稠密匹配有什么区别？",
        "梯度下降、G-N 和 L-M 三种方法的关系是什么？",
        "激光雷达原理是什么？",
        "IMU 原理是什么？",
        "视觉 SLAM 整体流程是什么？",
        "基本 SLAM 方法有哪些？",
        "带优化的 SLAM 计算方法是什么？",
        "添加回环检测的 SLAM 处理方法是什么？",
        "归一化坐标系、像平面坐标系和像素坐标系的区别是什么？它们之间如何相互转换？",
        "确定深度的方法有哪些？双目视觉如何通过视差估计深度？",
        "单目相机原理？",
        "镜头成像的原理是什么？CCD和CMOS的成像原理是什么？",
        "ToF相机原理？",
        "相似变换、仿射变换、射影变换的区别？",
        "单应矩阵和基础矩阵的区别？",
        "SVO中深度滤波器原理？",
        "某个SLAM框架的工作原理、优缺点和改进方向？",
        "SURF跟SIFT的区别？",
        "Kd树建立索引的原理是什么？建立Kd树时要注意什么？",
        "PnP问题有哪些常见求解方法（如DLT、P3P、EPnP、UPnP、非线性优化）？",
        "P3P方法原理是什么？为什么会有多解？",
        "Ceres的基本使用流程是什么？（如何构建优化问题、配置求解器并调用Solve）",
        "LM算法中阻尼因子μ的作用是什么？μ大/μ小时分别近似什么方法？",
        "Dog-Leg方法的原理是什么？它与trust region是什么关系？",
        "ORB-SLAM初始化流程？",
        "如何处理关键帧？（可参考ORB-SLAM2）",
        "关键帧插入策略有哪些常见判据（空间距离、时间间隔、运动等）？",
        "为什么要引入李群李代数？它如何把位姿估计变成无约束优化问题？",
        "SLAM中的绑架问题是什么？如何进行重定位？",
        "边缘检测一般分为三步：滤波、增强、检测。基本原理是什么？",
        "梯度下降、Gauss-Newton（G-N）和 Levenberg-Marquardt（L-M）三种方法的区别是什么？",
        "小误匹配对整个方法的影响是什么？",
        "如何从上一时刻的状态根据输入信息推断当前时刻的状态分布（先验）并计算协方差？",
        "Gmapping 的基本原理是什么？",
        "Hector SLAM 的基本原理是什么？",
        "KartoSLAM 的基本原理是什么？",
        "LagoSLAM 的基本原理是什么？",
        "回环检测的作用是什么？如何判断是否到达过先前的位置？",
        "IMU 原理是什么？如何做误差分析？",
        "为什么使用占据栅格地图？",
        "视觉 SLAM 算法可以大致分为两类：稀疏方法：匹配图像的特征点并使用 PTAM 和 ORB-SLAM 等算法；稠密方法：使用图像的总体亮度以及 DTAM、LSD-SLAM、DSO 和 SVO？",
        "什么是回环检测（Loop Closing），回环检测判断机器人是否到达过先前的位置？"
      ]
    },
    "Web3": {
      "count": 145,
      "questions": [
        "DAO将如何在web环境中工作？",
        "Monero是如何工作的？",
        "NFT是如何出现在web3中的？",
        "PoW(工作量证明)和PoS(权益证明)有什么区别？",
        "OpenSea和LooksRare的区别是什么？",
        "web3将如何彻底改变在线用户体验？",
        "DeFi（去中心化金融）是什么，它如何运作？",
        "“去中心化”的基本性质是什么？",
        "什么是web3？web2和web3的区别是什么？",
        "什么是ERC-20标准，它为什么重要？",
        "什么是代币化，它在区块链上如何工作？",
        "什么是侧链，它如何帮助区块链扩容？",
        "什么是共识算法？",
        "什么是加密货币的原子交换，它是如何工作的？",
        "什么是加密货币的去中心化交易所（DEX），与传统交易所有何不同？",
        "什么是区块链智能合约？",
        "什么是区块链的Layer 2解决方案？",
        "什么是区块链的Oracles，它们如何与智能合约交互？",
        "什么是去中心化？",
        "什么是智能合约？智能合约的安全隐患有哪些？",
        "何为Delegated Proof of Stake（DPoS），与PoS有何不同？",
        "你什么时候会使用私有区块链而不是公共区块链？",
        "你对密码学的理解程度如何？",
        "你用一句话讲一下AMM机制？",
        "你认为区块链技术的未来是什么？",
        "公共区块链和私有区块链有什么区别？",
        "区块链上的隐私层（如Zcash和Monero）是如何工作的？",
        "区块链如何促进版权保护和知识产权管理？",
        "区块链技术如何促进供应链管理的透明度？",
        "区块链技术如何解决数字身份认证问题？",
        "区块链技术有了新的发展，可以改进你当前的代码。您将如何决定是否值得花费时间和精力进行升级？",
        "区块链有哪些不同类型？",
        "去中心化是什么，它如何在 Web3 中帮助创建用户数据存储和管理的分布式模型？",
        "合约中的安全风险有哪些？",
        "描述您在用于区块链开发的编程语言和软件方面的经验？",
        "在区块链中，什么是孤块，它们如何产生？",
        "在区块链中，如何处理交易的隐私保护？",
        "在智能合约中产生随机数有哪些困难？",
        "在面试之前，列出你是这份工作的最佳人选的原因：你有哪些其他候选人可能没有的技能？",
        "如何在区块链上实现匿名交易？",
        "如何在区块链项目中处理交易拥堵和高手续费？",
        "如何在区块链项目中实现跨链通信？",
        "如何在区块链项目中管理和减少智能合约中的安全风险？",
        "如何通过区块链技术提高供应链的效率和透明度？",
        "如果您在区块链代码中发现安全漏洞，您会怎么做？",
        "如果要您从头开始创建区块链，您会做的第一件事是什么？",
        "怎样理解 Web3？",
        "您多久更新一次对区块链技术的了解？",
        "您如何描述区块链网络？",
        "我们想使用我们的区块链来收集数据，您将允许用户提交哪些类型的数据？为什么允许该类型的数据，以及您会采取哪些安全措施？",
        "您是如何应对 Web3 的安全性、可扩展性等挑战的？对此您有哪些看法或解决方案？",
        "您认为区块链开发人员最需要了解哪些编程语言？",
        "描述一种用于提高区块链交易隐私的技术？",
        "描述什么是区块链的“气体费用”，以及它的作用？",
        "描述加密货币钱包的工作原理及其安全性措施？",
        "描述区块链上的 DAO（去中心化自治组织）及其工作原理？",
        "描述区块链上的交易如何被验证？",
        "描述区块链上的智能合约安全最佳实践？",
        "描述区块链中的 Merkle 树及其重要性？",
        "描述区块链中的“永久性”是如何实现的？",
        "描述区块链的分片技术及其如何解决扩展性问题？",
        "描述如何使用区块链技术进行身份验证和授权？",
        "描述您在用于区块链开发的编程语言？",
        "权益证明（PoS）机制的工作原理是什么？",
        "比特币和以太坊有什么区别？",
        "流行的共识算法之间有什么不同？",
        "解释什么是“链上治理”和“链下治理”，以及它们的重要性？",
        "解释什么是区块链的分叉，以及它为什么会发生？",
        "解释什么是工作证明（PoW）以及如何实现？",
        "解释什么是闪电网络，以及它如何实现即时交易？",
        "解释什么是非同质化代币（NFT）及其在区块链上的应用？",
        "解释区块链中的交易池是如何工作的？",
        "解释区块链技术如何实现跨境支付，并阐述其优势？",
        "解释区块链的共识机制和它为什么重要？",
        "解释区块链的共识算法有哪些，它们各自的优缺点是什么？",
        "解释区块链的可扩展性问题及其当前解决方案？",
        "解释在区块链中如何实现数据的去中心化存储？",
        "解释硬分叉和软分叉的区别及其对网络的影响？",
        "（DEX）与传统交易所有何不同？",
        "什么是 Web3？Web2 和 Web3 的区别？",
        "什么是智能合约？",
        "您是如何应对 Web3 的安全性、可扩展性等挑战，对此您有哪些看法或解决方案？",
        "我们想使用我们的区块链来收集数据，您将允许用户提交哪些类型的数据？",
        "描述一种用于提高区块链交易隐私的技术（如零知识证明）？",
        "什么是DeFi（去中心化金融），它如何运作？",
        "区块链技术有了新的发展，可以改进你当前的代码。您将如何决定是否值得花费时间？",
        "您是如何应对 Web3 的安全性、可扩展性问题的？",
        "你为什么认为区块链技术将继续发展？",
        "如果一方收钱后毁约且不承认，智能合约如何处理？",
        "为什么智能合约与区块链产生了紧密关联？区块链能提供哪些保障？",
        "智能合约本质是一份代码，容易被篡改，如何为其提供强力的存储介质？",
        "什么是智能合约？智能合约有哪些安全隐患？",
        "描述一种区块链的扩容技术（如侧链）。",
        "解释在区块链中如何实现数据的去中心化。",
        "描述区块链的分片技术及其如何解决扩容问题。",
        "描述如何使用区块链技术进行身份验证。",
        "解释什么是区块链的分叉？它为什么会发生？",
        "解释如何通过区块链实现投票系统。",
        "什么是区块链的 Layer 2 解决方案？举例说明。",
        "描述区块链上的 DAO（去中心化自治组织）。",
        "区块链如何促进版权保护和知识产权保护？",
        "解释区块链的可扩展性问题及其当前解决思路。",
        "如何在区块链项目中处理交易拥堵？",
        "解释区块链技术如何实现跨境支付。",
        "描述什么是智能合约的自我执行特性。",
        "如何在区块链项目中管理和减少智能合约风险？",
        "如何通过区块链技术提高供应链的效率？",
        "回顾传统 Java 程序的运行方式是什么？",
        "为什么智能合约与区块链产生了紧密关联？区块链如何保证智能合约内容及调用记录不可篡改？",
        "智能合约本体是代码，容易被篡改；区块链如何在分布式环境下提供不可篡改的存储？",
        "解释区块链的共识机制以及它为什么重要。",
        "比特币和以太坊的区别在哪里？",
        "解释什么是工作证明（PoW）和如何实现它。",
        "您是如何应对 Web3 的安全性、可扩展性等挑战的？",
        "您将允许用户提交哪些类型的数据？",
        "当前的代码，您将如何决定是否值得花费时间和精力进行升级？",
        "解释什么是工作证明（PoW）？",
        "什么是智能合约？智能合约的安全隐患？",
        "解释在区块链中如何实现数据的去中心？",
        "解释硬分叉和软分叉的区别及其对网络？",
        "解释什么是闪电网络，以及它如何实现？",
        "区块链技术如何促进供应链管理的透明？",
        "什么是区块链的 Oracles，它们如何与？",
        "解释什么是区块链的分叉，以及它为什？",
        "区块链技术如何解决数字身份认证问？",
        "什么是 DeFi（去中心化金融），它如何？",
        "解释如何通过区块链实现投票系统，并？",
        "什么是区块链的 Layer 2解决方案，举？",
        "区块链如何促进版权保护和知识产权？",
        "解释区块链的可扩展性问题及其当前？",
        "如何在区块链项目中处理交易拥堵和？",
        "解释区块链技术如何实现跨境支付，并？",
        "解释什么是“链上治理”和“链下治理”，？",
        "如何通过区块链技术提高供应链的效？",
        "描述什么是区块链的“气体费用”，以及？"
      ]
    },
    "其他": {
      "count": 4101,
      "questions": [
        "什么是深度学习，它与传统机器学习有什么不同？",
        "权重初始化如何影响深度学习模型的性能？",
        "你能解释感知器和 S 形神经元的区别吗？",
        "你能解释反向传播在神经网络中是如何工作的吗？",
        "神经网络中常用的激活函数有哪些？",
        "如何防止神经网络的过拟合？",
        "如何决定神经网络的层数和神经元数？",
        "如何处理神经网络中缺失的数据？",
        "你能解释一下深度学习中迁移学习的概念吗？",
        "你如何评估一个深度学习模型的性能？",
        "你能解释卷积神经网络和循环神经网络的区别吗？",
        "过拟合和欠拟合的区别是什么？",
        "神经网络中 Dropout 的目的是什么？",
        "批归一化是如何工作的？",
        "激活函数在神经网络中的作用是什么？",
        "深度神经网络和浅层神经网络的区别是什么？",
        "梯度下降法和随机梯度下降法有什么区别？",
        "什么是递归神经网络？",
        "深度学习中验证集和测试集的区别是什么？",
        "前馈神经网络和循环神经网络的区别是什么？",
        "你能解释一下深度学习中权重初始化的概念吗？",
        "softmax 函数和 sigmoid 函数的区别是什么？",
        "你能解释一下深度学习中集成学习的概念吗？",
        "你能解释一下深度学习中权重衰减的概念吗？",
        "深度学习中 L1 和 L2 正则化的区别是什么？",
        "学习率在深度学习中的作用是什么？",
        "你能解释一下深度学习中早停法的概念吗？",
        "你能解释一下深度学习中数据增强的概念吗？",
        "批归一化和层归一化有什么区别？",
        "你能解释一下长短期记忆(LSTM)网络的概念吗？",
        "深度学习中生成模型和判别模型的区别是什么？",
        "你能解释一下生成对抗网络(GANs)的概念吗？",
        "深度信念网络和深度神经网络的区别是什么？",
        "你能解释一下深度学习中强化学习的概念吗？",
        "你能解释一下深度学习中注意机制的概念吗？",
        "为什么需要做特征归一化、标准化？",
        "常用的归一化和标准化的方法有哪些？",
        "神经网络的深度和宽度分别指的是什么？",
        "下采样的作用是什么？通常有哪些方式？",
        "模型的参数量指的是什么？怎么计算？",
        "模型的 FLOPs（计算量）指的是什么？",
        "有哪些经典的卷积类型？",
        "激活函数是什么？",
        "神经网络中 1×1 卷积有什么作用？",
        "随机梯度下降相比全局梯度下降好处是什么？",
        "增大感受野的方法有哪些？",
        "神经网络的正则化方法有哪些？",
        "过拟合的解决方法有哪些？",
        "梯度消失和梯度爆炸的原因是什么？",
        "深度学习为什么在计算机视觉领域这么好？",
        "为什么神经网络中常用 ReLU 作为激活函数？",
        "卷积层和全连接层的区别是什么？",
        "什么是正则化？",
        "L1 正则与 L2 正则的特点是什么，各有什么优势？",
        "常见的损失函数有哪些？",
        "Dropout 为什么能解决过拟合？",
        "深度学习中 batch 的大小对学习效果有何影响？",
        "PyTorch 和 TensorFlow 的特点分别是什么？",
        "ReLU 函数在 0 处不可导，为什么还能用？",
        "为什么 max pooling 更常用？",
        "average pooling 比 max pooling 更合适的情况是什么？",
        "为什么要反向传播？",
        "神经网络的优缺点是什么？",
        "Softmax + Cross Entropy 如何反向求导？",
        "有哪些数据增强的方式？",
        "为什么在模型训练开始会有 warmup？",
        "warmup 为什么有效，有什么理论解释？",
        "VGG 使用 3×3 卷积核的优势是什么？",
        "导致模型不收敛的原因有哪些？",
        "ReLU 比 Sigmoid 的效果好在哪里？",
        "DNN 的梯度是如何更新的？",
        "各个激活函数的优缺点是什么？",
        "梯度消失和梯度爆炸的解决方案有哪些？",
        "梯度爆炸会引发什么问题？",
        "如何确定是否出现梯度爆炸？",
        "批量归一化（BN）如何实现？",
        "神经网络中权值共享怎么理解？",
        "对 fine-tuning（微调模型）的理解是什么？",
        "为什么要修改最后几层神经网络权值？",
        "什么是 Dropout？它为什么有用、如何工作的？",
        "如何选择 dropout 的概率？",
        "什么是 Adam？",
        "Adam 和 SGD 之间的主要区别是什么？",
        "为什么 Momentum 可以加速训练？",
        "什么时候使用 Adam 和 SGD？",
        "SGD 每步做什么，为什么能进行 online learning？",
        "学习率太大(太小)时会发生什么？",
        "如何设置学习率？",
        "神经网络为什么不用拟牛顿法而是用梯度下降？",
        "BN 和 Dropout 在训练和测试时的差别？",
        "若网络初始化为 0 的话有什么问题？",
        "sigmoid 和 softmax 的区别？",
        "softmax 的公式？",
        "改进的 softmax 损失函数有哪些？",
        "深度学习调参有哪些技巧？",
        "神经网络调参，要往哪些方向想？",
        "深度学习训练中是否有必要使用 L1 获得稀疏解？",
        "神经网络数据预处理方法有哪些？",
        "如何初始化神经网络的权重？",
        "为什么构建深度学习模型需要使用 GPU？",
        "前馈神经网络(FNN)、递归神经网络(RNN)和 CNN 区别？",
        "神经网络可以解决哪些问题？",
        "如何提高小型网络的精度？",
        "什么是鞍点问题？",
        "网络设计中，为什么卷积核设计尺寸都是奇数？",
        "卷积层有哪些基本参数？",
        "如何计算卷积层的输出大小？",
        "如何计算卷积层参数数量？",
        "有哪些池化方法？",
        "*1 卷积的作用？",
        "卷积层和池化层有什么区别？",
        "卷积核是否一定越大越好？",
        "卷积在图像中有什么直观作用？",
        "CNN 中空洞卷积的作用是什么？",
        "怎样才能减少卷积层参数量？",
        "在进行卷积操作时，必须同时考虑通道和区域吗？",
        "采用宽卷积、窄卷积的好处有什么？",
        "如何提高卷积神经网络的泛化能力？",
        "卷积神经网络在 NLP 与 CV 领域应用的区别？",
        "全连接、局部连接、全卷积与局部卷积的区别？",
        "卷积层和全连接层的区别？",
        "Max pooling 如何工作？",
        "卷积神经网络的优点？",
        "为什么用小卷积核？",
        "CNN 拆成 3x1、1x3 的优点？",
        "BN、LN、IN、GN 和 SN 的区别？",
        "RNNs 训练和传统 ANN 训练异同点？",
        "为什么 RNN 训练的时候 Loss 波动很大？",
        "RNN 中为什么会出现梯度消失？",
        "如何解决 RNN 中的梯度消失问题？",
        "LSTM 结构推导，为什么比 RNN 好？",
        "为什么 LSTM 模型中既存在 sigmoid 又存在 tanh 两种激活函数，而不是选择统一一种 sigmoid 或者 tanh？",
        "LSTM 中为什么经常是两层双向 LSTM？",
        "LSTM、RNN、GRU 区别？",
        "LSTM 是如何实现长短期记忆功能的？",
        "什么是反向传播？",
        "反向传播是如何工作的？",
        "为什么需要反向传播？",
        "神经网络中包含哪些超参数？",
        "为什么要进行超参数调优？",
        "极端批样本数量下，如何训练网络？",
        "微调有哪些不同方法？",
        "微调先冻结底层，训练顶层的原因是什么？",
        "不同的数据集特性下如何微调？",
        "目标检测中使用预训练模型的优劣是什么？",
        "目标检测中如何从零开始训练（train from scratch）？",
        "自动化超参数搜索方法有哪些？",
        "为什么需要激活函数？",
        "为什么 dropout 可以解决过拟合？",
        "Dropout 在训练和测试阶段有什么区别？",
        "阶优化和二阶优化的方法有哪些？",
        "为什么不使用二阶优化？",
        "AlexNet 对比 LeNet 的优势是什么？",
        "VGG 使用 2 个 3×3 卷积的优势在哪里？",
        "每层卷积是否只能用一种尺寸的卷积核？",
        "Inception 结构能不能缓解梯度消失？",
        "ResNet 为什么不用 Dropout？",
        "ResNet 网络越来越深，准确率会不会提升？",
        "ResNet v1 与 ResNet v2 的区别是什么？",
        "DenseNet 比 ResNet 好吗？",
        "为什么需要卷积？不能使用全连接层吗？",
        "为什么检测任务常用 max pooling，而分类任务常用 average pooling？",
        "CNN 是否抗旋转？",
        "如果旋转图像，CNN 的预测会怎样？",
        "什么是数据增强？为什么需要它？",
        "你知道哪些数据增强方法？",
        "如何选择要使用的数据增强？",
        "什么是迁移学习？",
        "什么是目标检测？",
        "你知道有哪些目标检测框架吗？",
        "什么是对象分割？",
        "为什么 ReLU 常用于神经网络的激活函数？",
        "神经网络中有哪些正则化技术？",
        "神经网络中权值共享如何理解？",
        "什么是 Dropout？",
        "SGD每步做什么，为什么能online learning？",
        "前馈神经网络(FNN)、递归神经网络(RNN)和CNN的区别？",
        "CNN拆成3x1和1x3的优点？",
        "目标检测中使用预训练模型的优劣？",
        "目标检测中如何从零开始训练(train from scratch)？",
        "AlexNet 对比 LeNet 的优势？",
        "VGG使用2个3*3卷积的优势在哪里？",
        "ResNet v1 与 ResNet v2的区别？",
        "为什么 DenseNet 比 ResNet 更耗显存？",
        "为什么检测采用使用max pooling，而分类使用average pooling？",
        "one-hot 存在什么问题？",
        "word2vec 存在什么问题？",
        "fastText 存在什么问题？",
        "ELMo 存在什么问题？",
        "BERT 是什么？",
        "BERT 的三个关键点是什么？",
        "BERT 的输入输出表征是什么样的？",
        "BERT 为什么需要预训练任务 Masked LM（MLM）？",
        "BERT 的预训练任务 Masked LM（MLM）怎么做？",
        "BERT 的预训练任务 Masked LM（MLM）存在哪些问题？",
        "预训练与微调期间从未看到 [MASK] 词块有什么影响？",
        "如何解决预训练和微调之间的不匹配？",
        "BERT 为什么需要预训练任务 Next Sentence Prediction（NSP）？",
        "BERT 的预训练任务 Next Sentence Prediction（NSP）怎么做？",
        "为什么 BERT 需要 fine-tuning？",
        "BERT 如何进行 fine-tuning？",
        "BERT 的两个预训练任务对应的损失函数是什么（用公式形式展示）？",
        "多义词问题是什么？",
        "什么是多义词？",
        "为什么 word2vec 解决不了多义词问题？",
        "GPT 和 BERT 有什么不同？",
        "GPT 是单向的，这一点如何体现？",
        "为什么 ELMo、GPT、BERT 能够解决多义词问题？",
        "BERT 的预训练任务有哪些？",
        "具体的三种类型的无监督训练任务是哪三种？",
        "每种类型里面又包括什么任务？",
        "GPT 处理的有监督任务有哪些？",
        "如何实现 attention 中“不能看到的信息”和“需要 attention 的信息”的控制？",
        "什么是低秩因式分解？",
        "什么是跨层参数共享？",
        "ALBERT 使用了哪些方法？",
        "什么是蒸馏？",
        "什么是量化？",
        "什么是剪枝？",
        "模型压缩存在哪些问题？",
        "作为算法工程师，在项目初期标注数据不足时，如何解决标注数据不足问题？",
        "我们是否可以采取一个轻量级的模型，比如TextCNN，去逼近BERT的效果呢？",
        "为什么不直接蒸馏为一个浅层BERT呢？",
        "什么是概率图模型？",
        "什么是随机场？",
        "什么是马尔可夫过程？",
        "马尔可夫过程的核心思想是什么？",
        "隐马尔可夫算法是什么？",
        "隐马尔可夫算法中两个序列是什么？",
        "隐马尔可夫算法中三个矩阵是什么？",
        "隐马尔可夫算法中两个假设是什么？",
        "隐马尔可夫算法中工作流程是什么？",
        "隐马尔可夫算法序列概率计算过程是什么样的？",
        "如何对一条序列计算其整体的概率，即计算 $P(O | \\lambda)$？",
        "隐马尔可夫算法学习训练过程是什么样的？",
        "隐马尔可夫算法序列标注（解码）过程是什么样的？",
        "HMM模型三个基本问题的联系是什么？",
        "HMM存在什么问题？",
        "最大熵马尔可夫模型（MEMM）是什么？",
        "MEMM如何解决HMM问题？",
        "HMM和MEMM存在什么问题？",
        "什么是CRF？",
        "CRF的主要思想是什么？",
        "CRF的定义是什么？",
        "CRF的三个基本问题是什么？",
        "CRF的流程是什么？",
        "CRF的优点在哪里？",
        "CRF的缺点在哪里？",
        "CRF模型和HMM和MEMM模型有什么区别？",
        "为什么CRF模型会比HMM被普遍使用？",
        "命名实体识别评价指标是什么？",
        "基于规则的命名实体识别方法是什么？",
        "基于无监督学习的命名实体识别方法是什么？",
        "基于特征的监督学习的命名实体识别方法是什么？",
        "基于深度学习的命名实体识别方法的结构是怎么样的？",
        "分布式输入层是什么，有哪些方法？",
        "什么是BiLSTM-CRF？",
        "为什么要用BiLSTM？",
        "什么是Dilated CNN？",
        "为什么会有Dilated CNN？",
        "Dilated CNN的优点是什么？",
        "标签解码器是什么？",
        "MLP+softmax层是什么？",
        "条件随机场CRF层是什么？",
        "循环神经网络RNN层是什么？",
        "指针网络层是什么？",
        "CNN-CRF、BiLSTM-CRF、IDCNN-CRF有什么区别？",
        "为什么DNN后面要加CRF？",
        "CRF in TensorFlow和CRF in discrete toolkit有什么区别？",
        "为什么会有Elmo？",
        "Elmo的特点是什么？",
        "Elmo的思想是什么？",
        "Elmo存在的问题是什么？",
        "传统的相似度算法存在什么问题？",
        "什么是Faiss？",
        "Faiss如何使用？",
        "Faiss如何安装？",
        "Faiss的索引Index有哪些？",
        "为什么要创建索引？",
        "Faiss的索引Index都怎么用？",
        "Faiss如何使用GPU？",
        "问答系统的动机是什么？",
        "假设你有一个标准的问题库，此时有一个新query进来，你会做什么操作？",
        "问答系统是什么？",
        "FAQ检索式问答系统是什么？",
        "query匹配标准QA的核心是什么？",
        "常用方案有哪些？",
        "为什么QQ匹配比较常用？",
        "QQ匹配的优点有哪些？",
        "QQ匹配的语义空间是什么？",
        "QQ匹配的语料的稳定性是什么？",
        "QQ匹配的业务回答与算法模型的解耦是什么？",
        "QQ匹配的新问题发现与去重是什么？",
        "QQ匹配的上线运行速度是什么？",
        "QQ匹配一般处理流程是怎么样的？",
        "如何发现FAQ中的标准问题？",
        "FAQ如何做拆分？",
        "FAQ如何做合并？",
        "FAQ标准库如何实时更新？",
        "word-level Model是什么？",
        "word-level Model存在什么问题？",
        "Character-Level Model是什么？",
        "Character-Level Model的优点是什么？",
        "Character-Level Model存在什么问题？",
        "Character-Level Model问题的解决方法是什么？",
        "能否采取类似于subword的思路来产生更好的word embedding？",
        "fastText 是什么？",
        "fastText 的结构是什么样？",
        "fastText 词内的 n-gram 信息的训练过程是什么？",
        "fastText 词内的 n-gram 信息存在什么问题？",
        "为什么要用层次化 Softmax 回归（Hierarchical Softmax）？",
        "层次化 Softmax 回归（Hierarchical Softmax）的思想是什么？",
        "层次化 Softmax 回归（Hierarchical Softmax）的步骤是什么？",
        "如何构造每个逻辑回归单元的输入？",
        "如何建立这棵用于判断的树形结构？",
        "什么是 LoRA？",
        "LoRA 的思路是什么？",
        "LoRA 的特点是什么？",
        "简单描述一下 LoRA？",
        "QLoRA 的思路是怎么样的？",
        "QLoRA 的特点是什么？",
        "AdaLoRA 的思路是怎么样的？",
        "LoRA 权重是否可以合入原模型？",
        "ChatGLM-6B LoRA 后的权重多大？",
        "LoRA 微调优点是什么？",
        "LoRA 微调方法为啥能加速训练？",
        "如何在已有 LoRA 模型上继续训练？",
        "LoRA 缺点是什么？",
        "LoRA 这种微调方法和全参数比起来有什么劣势吗？",
        "LoRA 应该作用于 Transformer 的哪个参数矩阵？",
        "LoRA 微调参数量怎么确定？",
        "Rank 如何选取？",
        "alpha 参数如何选取？",
        "LoRA 高效微调如何避免过拟合？",
        "微调大模型时，优化器如何选择？",
        "哪些因素会影响内存使用？",
        "是否可以逐层调整 LoRA 的最优 rank？",
        "LoRA 的矩阵怎么初始化？",
        "为什么要初始化为全",
        "LoRA 微调计算可训练参数的比例如何确定？",
        "LoRA 微调结果如何保存？",
        "在已有 LoRA 模型上继续训练，还是跟 base 模型合并后再套一层 LoRA，或者从头开始训练一个 LoRA？",
        "Neo4J 怎么下载？",
        "Neo4J 怎么安装？",
        "Cypher 查询语言是什么？",
        "Neo4j 怎么创建节点？",
        "Neo4j 怎么创建关系？",
        "Neo4j 怎么创建出生地关系？",
        "Neo4j 怎么查询？",
        "Neo4j 怎么删除和修改？",
        "如何利用 Python 操作 Neo4j 图数据库？",
        "neo4j 模块：执行 CQL（Cypher）语句是什么？",
        "py2neo 模块是什么？",
        "检索的方法的训练阶段如何做？",
        "检索的方法的预测阶段如何做？",
        "那有什么方法可以解决该问题么？",
        "分类任务有哪些类别？",
        "文本分类任务相较于其他领域的分类任务有何不同之处？",
        "文本分类任务和文本领域的其他任务相比有何不同之处？",
        "文本分类的过程是什么？",
        "文本分类任务的数据预处理方法有哪些？",
        "你使用过哪些分词方法和工具？",
        "中文文本分词的方法有哪些？",
        "基于字符串匹配的分词方法的原理是什么？",
        "统计语言模型如何应用于分词？",
        "什么是N-gram最大概率分词？",
        "基于序列标注的分词方法是什么？",
        "基于(Bi-)LSTM的词性标注是什么？",
        "词干提取和词形还原有什么区别？",
        "文本分类任务可以使用哪些特征？",
        "能不能简单介绍下词袋模型？",
        "什么是n元语法？",
        "为什么要用n-gram？",
        "n-gram算法的局限性是什么？",
        "介绍一下主题建模任务？",
        "TF-IDF算法是做什么的？",
        "tf-idf高意味着什么？",
        "如何计算两段文本之间的距离？",
        "什么是jaccard距离？",
        "Dice系数和Jaccard系数的区别是什么？",
        "同样是编辑距离，莱文斯坦距离和汉明距离的区别在哪里？",
        "写一下计算编辑距离（莱温斯坦距离）的编程题吧？",
        "fastText的分类过程是什么？",
        "fastText的优点是什么？",
        "TextCNN进行文本分类的过程是什么？",
        "TextCNN可以调整哪些参数？",
        "使用CNN作为文本分类器时，不同通道channels对应着文本的什么信息？",
        "TextCNN中卷积核的长与宽代表了什么？",
        "在TextCNN中的pooling操作与一般CNN的pooling操作有何不同？",
        "TextCNN的局限性是什么？",
        "如何解决长文本分类任务？",
        "简单介绍DPCNN模型相较于TextCNN的改进？",
        "简要介绍TextRCNN相较于TextCNN的改进？",
        "注意力机制如何应用于文本分类领域？",
        "GNN图神经网络如何应用于文本分类领域？",
        "基于Transformer的预训练模型如何应用于文本分类领域？",
        "你了解哪些预训练模型？",
        "分类问题使用的激活函数sigmoid是什么？",
        "Sigmod的缺点是什么？",
        "softmax函数是什么？",
        "softmax函数怎么求导？",
        "分类问题常用的损失函数有哪些？",
        "文本分类任务常用的评估算法和指标有哪些？",
        "简单介绍混淆矩阵和 Kappa 系数。",
        "为什么要使用 one-hot 编码？",
        "什么是 one-hot 编码？",
        "one-hot 编码有什么特点？",
        "one-hot 编码存在哪些问题？",
        "什么是 TF-IDF？",
        "TF-IDF 如何评估词的重要程度？",
        "TF-IDF 的思想是什么？",
        "TF-IDF 的计算公式是什么？",
        "TF-IDF 的优点是什么？",
        "TF-IDF 的缺点是什么？",
        "TF-IDF 的应用有哪些？",
        "Word2vec 指什么？",
        "Word2vec 中 CBOW 指什么？",
        "Word2vec 中 Skip-gram 指什么？",
        "CBOW 和 Skip-gram 哪个更好？",
        "Word2vec 中霍夫曼树是什么？",
        "Word2vec 中为什么要使用霍夫曼树？",
        "Word2vec 中使用霍夫曼树的好处是什么？",
        "为什么 Word2vec 中会用到负采样？",
        "Word2vec 中的负采样是什么？",
        "Word2vec 中负采样的采样方式是什么？",
        "Word2vec 和 NNLM 对比有什么区别？",
        "Word2vec 和 TF-IDF 在相似度计算时的区别是什么？",
        "Word2vec 训练的 trick 有哪些？window 一般设置多大？",
        "中文命名实体识别与英文命名实体识别的区别是什么？",
        "什么是词汇增强？",
        "为什么说词汇增强方法对于中文 NER 任务有效？",
        "词汇增强方法有哪些？",
        "什么是 Dynamic Architecture？",
        "Dynamic Architecture 的常用方法有哪些？",
        "什么是 Lattice LSTM，存在什么问题？",
        "什么是 FLAT，存在什么问题？",
        "什么是 Adaptive Embedding 范式？",
        "Adaptive Embedding 的常用方法有哪些？",
        "什么是 WC-LSTM，存在什么问题？",
        "什么是词汇/实体类型信息增强？",
        "词汇/实体类型信息增强的方法有哪些？",
        "什么是 LEX-BERT？",
        "超参数 α、β 对训练的影响是什么？",
        "用大的数据集训练一个general的model，还是根据垂直领域训练一个specific的model呢？",
        "为什么LDA的最大似然难求？",
        "什么是事件？",
        "什么是事件抽取？",
        "ACE测评中事件抽取涉及的几个基本术语及任务是什么？",
        "事件抽取怎么发展的？",
        "事件抽取存在什么问题？",
        "什么是触发词检测？触发词检测有哪些方法？",
        "什么是类型识别？类型识别有哪些方法？",
        "什么是角色识别？角色识别有哪些方法？",
        "什么是论元检测？论元检测有哪些方法？",
        "模式匹配方法怎么用在事件抽取中？",
        "统计机器学习方法怎么用在事件抽取中？",
        "深度学习方法怎么用在事件抽取中？",
        "事件抽取中常见的英文数据集有哪些？",
        "事件抽取中常见的中文数据集有哪些？",
        "事件抽取的评价指标是什么？怎么计算的？",
        "事件抽取和命名实体识别（即实体抽取）有什么异同？",
        "事件抽取和关系抽取有什么异同？",
        "什么是事理图谱？",
        "有哪些事件关系类型？",
        "事理图谱怎么构建？",
        "技术领域及当前发展热点是什么？",
        "能简单介绍一些事件抽取的应用背景吗？",
        "事件抽取针对的是一段话还是一篇文章呢？",
        "有哪些常用的评测数据集和评测标准？",
        "事件抽取有哪些应用场景和实际的产品？",
        "为什么通过新闻可以预测网络故障呢？",
        "事件抽取的一般过程是什么？有标注数据开展研究如何扩展，没有数据怎么做？",
        "事件抽取一般有什么方法呢？",
        "深度学习在事件抽取上有哪些应用，与传统方法比有什么优势/劣势？",
        "事件抽取与其他信息抽取任务（关系抽取、NER等）有什么联系，难点在哪？",
        "触发词一般是预定义好的，还是需要做检测任务？",
        "事件之间的关系如何表示？如何做事件之间的关系抽取？目前有哪些研究？",
        "有哪些值得阅读的论文？",
        "有哪些开源了代码的工作？",
        "最新的前沿进展有哪些？",
        "微调方法是啥？",
        "如何微调？",
        "为什么需要 PEFT？",
        "介绍一下 PEFT。",
        "PEFT 有什么优点？",
        "微调方法中，批处理大小、GPU 显存与速度有什么关系？",
        "PEFT 和全量微调有什么区别？",
        "PEFT 存在什么问题？",
        "能不能总结一下各种参数高效微调方法？",
        "词向量选取：词向量还是字向量？",
        "特征提取器如何选择？",
        "专有名称怎么处理？",
        "标注数据不足怎么处理？",
        "什么是实体嵌套？",
        "如何构造 Span 矩阵？",
        "如何解决 0-1 标签稀疏问题？",
        "NER 实体 span 过长怎么办？",
        "NER 标注数据噪声问题怎么处理？",
        "NER 标注数据不均衡问题怎么处理？",
        "工业界如何解决 NER 问题？",
        "在 C++ 程序中调用被 C 编译器编译后的函数，为什么要加 extern \"C\"？",
        "什么是多线程？多线程与多任务有什么区别？",
        "可以用 for 循环直接删除 ArrayList 的特定元素吗？可能会出现什么问题？怎样解决？",
        "如何看当前 Linux 系统有几颗物理 CPU 和每颗 CPU 的核数？",
        "使用 top 查看系统资源占用情况时，哪一列表示内存占用？",
        "如何查看当前系统都有哪些进程？",
        "网卡或者硬盘有问题时，可以使用哪个命令查看相关信息？",
        "什么是 lambda 函数？它有什么好处？",
        "Python 里面如何拷贝一个对象？",
        "在一个严格单调递增的整数数组中找到 a[x] == x 的位置？",
        "树形结构为什么不需要归一化？",
        "为什么 xgboost 要用泰勒展开，优势在哪里？",
        "谈谈判别式模型和生成式模型。",
        "如何进行特征选择？",
        "机器学习和统计里面的 AUC 的物理意义是什么？",
        "常见的分类算法有哪些？它们各自的优缺点是什么？",
        "RF 与 GBDT 之间的区别与联系？",
        "简述 KNN 最近邻分类算法的过程。",
        "如何降低数据集的维度以减少模型计算时间？",
        "如何提升已经达到 96% 精度的分类模型性能？",
        "如何在一个数据集上选择重要的变量？",
        "Gradient Boosting 算法（GBM）和随机森林都是基于树的算法，它们有什么区别？",
        "如何理解模型的过拟合与欠拟合，以及如何解决？",
        "机器学习中的正则化是什么意思？",
        "请简单阐述下决策树、回归、SVM、神经网络等算法各自的优缺点？",
        "如何通俗理解贝叶斯方法和贝叶斯网络？",
        "什么是归一化，它与标准化的区别是什么？",
        "人工神经网络中为什么ReLU要好过于tanh和Sigmoid function？",
        "什么样的数据集不适合用深度学习？",
        "RNN是怎么从单层网络一步一步构造的？",
        "CNN究竟是怎样一步一步工作的？",
        "什么是非极大值抑制（NMS）？",
        "什么是深度学习中的anchor？",
        "当神经网络的调参效果不好时，从哪些角度思考？",
        "为什么用角点作为特征点？",
        "为什么说神经网络是端到端的网络？",
        "什么是感受野？",
        "工业界中遇到上亿的图像检索任务，如何提高图像对比效率？",
        "one-stage和two-stage目标检测方法的区别和优缺点？",
        "什么是TF-IDF算法？",
        "怎么解决推荐系统中的冷启动问题？",
        "什么是wide&deep模型？",
        "怎样将知识图谱引入推荐系统？",
        "如何离线评价召回阶段各种模型算法的好坏？",
        "芝麻信用分的主要计算维度？",
        "为什么我们做评分卡的时候要用woe编码？",
        "extern \"C\"是什么？",
        "margin = y(w^T x + b) = y f(x) 中的 y 是只取 1 和 -1 吗？",
        "我们把 functional margin 定为 1 了吗？",
        "什么是拉格朗日对偶性？",
        "为什么非支持向量对应的α等于零？",
        "SVM如何处理非线性数据？",
        "线性不可分时如何把两类数据分开？",
        "核函数到底是什么？",
        "如何选择乘子α和b？",
        "在每次迭代中如何更新乘子？",
        "选取哪些乘子进行更新？",
        "SVM为什么这么popular？",
        "工业界如何选取核函数（经验方法）？",
        "SVM的训练过程如何优化？",
        "KNN、KMeans之类算法是否需要归一化？",
        "什么是标准化和归一化？",
        "什么是梯度下降法？",
        "什么是梯度？",
        "如果来了一个新的房子/面积，在房屋销售价格的记录中没有该样本，我们怎么办？",
        "什么是EM算法？",
        "什么是最大似然估计？",
        "假定需要统计七月在线10万学员中男生女生的身高分布，怎么统计？",
        "怎样的θ能让L(θ)最大？",
        "用极大似然估计求解时，怎么把Z变成已知的？",
        "什么是极大化算法？",
        "现在我们的目标没变，还是估计PA和PB，需要怎么做？",
        "如果新估计出来的PA和PB和我们初始化的值差别很大，怎么办？",
        "Jensen不等式是什么来历？",
        "什么时候下界J(z,Q)与L(θ)在θ处相等？",
        "为什么EM一定会收敛？",
        "如何确保EM收敛？",
        "解释EM算法第（4）步：得到某式时，只是最大化了什么？",
        "M步中到底如何求θ的极值？",
        "M步是最大化那一步，E步如何理解？",
        "文档已经产生，如何根据已产生好的文档反推其主题？",
        "如何通俗易懂地解释EM算法并举个例子？",
        "如何感性地理解EM算法？",
        "为什么要归一化？",
        "归一化为什么能提高梯度下降法求解最优解的速度？",
        "如何根据AUC值来计算真正的类别（AUC的反向工程）？",
        "什么是AUC？",
        "为什么AUC和logloss比accuracy更常用？",
        "什么是真阳性率和假阳性率？",
        "可以直接优化AUC来训练分类器吗？",
        "为了降低数据集维度以减少模型计算时间、且机器内存有限，你会怎么做？",
        "你可以做些什么来提升模型性能？",
        "信息增益是什么？",
        "回归树是什么？",
        "回归树的输出是数值（预测值），如何确定？",
        "boosting集成学习由多个相关联的决策树联合决策，什么叫相关联？",
        "GBDT如何处理该问题？",
        "为什么GBDT可以用负梯度近似残差？",
        "损失函数不是二次函数怎么办？",
        "泰勒二次展开从哪里来？",
        "理解该推导的关键是什么？",
        "只要知道树的结构就能得到该结构下的最好分数，如何确定树的结构？",
        "特征进⾏分割后，我们选择所谓的增益Gain最⾼的那个特征，⽽Gain如何计算呢？",
        "损失函数不是二次函数时，怎么做最优化？",
        "如何确定分裂用的 feature？",
        "如何确定节点的 w 以及最小的 loss function？",
        "树是不是贪心策略？",
        "循环迭代的方式什么时候停止？",
        "为什么在实际的 kaggle 比赛中 gbdt 和 random forest 效果非常好？",
        "怎样通俗地理解泰勒级数？",
        "回归树是如何工作的？",
        "Boosting 通过迭代多棵树来共同决策，这怎么实现？",
        "GBDT 里哪里体现了 Gradient？",
        "最终分类器的误差界是多少？",
        "什么是前向分步算法？",
        "什么是过拟合（Overfitting）？",
        "如何解决过拟合问题？",
        "添加 L1 和 L2 正则化有什么用？",
        "为什么 L2 正则化可以获得值很小的参数？",
        "机器学习中使用正则化来防止过拟合是什么原理？",
        "条件独立是什么意思？",
        "因子图到底是干嘛的？",
        "到底什么是 sum-product 算法？",
        "Normalization 为什么效果好？",
        "输入不是序列而输出为序列的情况怎么处理？",
        "LSTM结构推导，为什么⽐RNN好？",
        "GRU是什么？",
        "GRU对LSTM做了哪些改动？",
        "LSTM神经⽹络输⼊输出究竟是怎样的？",
        "如何修复梯度爆炸问题？",
        "如何解决RNN梯度爆炸和弥散的问题？",
        "RNN是怎么从单层⽹络⼀步⼀步构造的？",
        "CNN究竟是怎样⼀步⼀步⼯作的？",
        "啥叫输⼊层、输出层、隐藏层呢？",
        "当我们给定⼀个\"X\"的图案，计算机怎么识别这个图案就是“X”呢？",
        "为什么要输⼊输出都⼀样呢？",
        "为什么输⼊数据需要归⼀化（Normalized Data）？",
        "归⼀化后有什么好处呢？",
        "在CNN中卷积层上要怎么做BN？",
        "定位的问题的解决思路有哪些？",
        "Regression的部分加在哪？",
        "当图像有很多物体怎么办的？",
        "选择性搜索到底怎么选出这些候选框的呢？",
        "如何加⼊某种结构，使得后⾯全连接层得到的输⼊变成固定的？",
        "R-CNN与Fast R-CNN的区别有哪些？",
        "能不能找出一个更加高效的方法来求出这些候选框？",
        "能否结合 region proposal 的思想实现更精准的定位？",
        "如何建立某个位置和其特征的对应关系？",
        "one-stage 和 two-stage 目标检测方法的区别和优缺点是什么？",
        "为什么目标检测问题更难？",
        "输入句子中各单词的注意力分配概率分布值是什么？",
        "(Tom,0.6)(Chase,0.2)(Jerry,0.2) 这样的注意力权重是如何得到的？",
        "如何理解 Attention 模型的物理含义？",
        "通过 Self Attention 到底学到了哪些规律或者抽取出了哪些特征？",
        "Self Attention 有什么增益或者好处？",
        "什么是查询向量、键向量和值向量？",
        "如何把多个矩阵压缩成一个矩阵？",
        "解码组件最后会输出一个实数向量，如何把浮点数变成一个单词？",
        "如何比较两个概率分布？",
        "这是否意味着作为关键词，它们的重要性是一样的？",
        "如何用 0 到 100 的范围来表示你有多么内向/外向？",
        "BERT 值得这么高的评价吗？",
        "BERT 的高评价是因为它有重大的理论或者模型创新吗？",
        "为什么预训练的思路是可行的？",
        "什么是语言模型？",
        "给定上文，预测紧跟的单词应该是哪个，你会怎么做？",
        "C(W_i) 是什么？",
        "Word2Vec 是怎么工作的？",
        "NNLM 是怎么训练的？",
        "为什么 Word2Vec 要这么处理？",
        "为什么要讲 Word2Vec？",
        "Word Embedding 这种做法能算是预训练吗？",
        "这乍看上去好像是个查表操作，不像是预训练的做法，为什么？",
        "Word Embedding 头上笼罩了好几年的乌云是什么？",
        "这些方法看上去都成本太高或者太繁琐了，有没有简单优美的解决方案？",
        "ELMO 的精髓在哪里？",
        "预训练好网络结构后，如何给下游任务使用？",
        "Embedding 后多义词问题解决了吗？",
        "ELMO 经过这般操作，效果如何？",
        "站在现在这个时间节点看，ELMO 有什么值得改进的缺点？",
        "什么是注意力机制？",
        "不同任务怎么改造才能靠近 GPT 的网络结构？",
        "站在现在的时间节点看，GPT 有什么值得改进的地方？",
        "如何使用 BERT 预训练好的模型参数？",
        "BERT 采用两阶段方式解决各种 NLP 任务效果如何？",
        "BERT 是怎么做的？",
        "根据上文 Context-Before 和下文 Context-after 去预测单词，BERT 怎么做？",
        "BERT 本身在模型和方法角度有什么创新？",
        "BERT 效果特别好，到底是什么因素起作用？",
        "如果你现在想看个电影，但你不知道具体看哪部，你会怎么做？",
        "找到相似的用户和物品，通过什么途径找到？",
        "什么时候用 item-based，什么时候用 user-based？",
        "如何进行最有效的推荐？",
        "如何对物品进行分类，分成几类？",
        "如何确定用户对哪些物品类别有兴趣，兴趣程度如何？",
        "模型之间内在的联系和演化思路如何揭示？",
        "如何迅速 get 到新模型的创新点和适用场景，快速提高读新论文速度，节约理解、复现模型的成本？",
        "为什么做评分卡的时候要用 WOE 编码，而不是用别的编码方式？",
        "仅是因为 WOE 可以把特征从非线性变成线性的吗？",
        "Transformer 模型的基本结构是什么？",
        "Transformer 是如何改变深度学习领域的？",
        "Transformer 为何能够有效地处理长距离依赖问题？",
        "与传统 RNN 和 LSTM 相比有哪些优势？",
        "多头注意力的作用是什么？",
        "Transformer模型如何平衡模型性能与计算资源的消耗？",
        "Transformer模型的自注意力机制如何实现并行处理？",
        "Transformer模型如何处理变长输入序列？",
        "Transformer模型的缩放点积注意力(Scaled Dot-Product Attention)是什么，其重要性在哪里？",
        "Transformer模型在实践中如何优化以处理超长序列？",
        "Transformer模型在自注意力层中如何解决多尺度表示问题？",
        "Transformer模型中的自注意力机制在计算效率和表示能力之间是如何权衡的？",
        "Transformer模型的参数共享策略对模型性能有何影响？",
        "Transformer encoder和decoder的区别？",
        "Transformer模型中的前馈网络(Feed-Forward Networks)的作用是什么？",
        "Pre-norm和post-norm有什么区别？",
        "Transformer网络很深，是怎么避免过拟合问题的？",
        "Transformer的两个mask机制是什么？",
        "Transformer为什么要用Layer norm？",
        "Encoder和decoder是如何进行交互的？",
        "如何提高Transformer模型中自注意力机制的计算效率？",
        "为什么self-attention要除以根号N？",
        "Transformer模型中注意力权重如何解释模型的决策？",
        "如何在自注意力机制中平衡局部信息和全局信息的捕获？",
        "基于attention有哪些代表性的改进方法？",
        "如何设计更有效的注意力机制来处理层次化或结构化数据？",
        "对于新用户，由于其特征非常的稀疏，使用基于深度学习（DL）的推荐系统效果会比较差，那有什么方法呢？",
        "GLM是什么？",
        "SVM的原理？",
        "怎么找到最优的线性分类器？",
        "支持向量是什么？",
        "介绍一下CNN？",
        "CNN中的卷积到底指什么？",
        "介绍决策树、信息熵？",
        "随机森林“随机”二字体现在什么地方？",
        "介绍一下XGBoost，与GBDT相比有什么不同？",
        "ReLU激活函数是如何解决梯度消失和梯度爆炸问题的？",
        "什么是梯度消失和梯度爆炸？",
        "什么单元更容易出现梯度消失梯度爆炸的问题？",
        "ReLU如何解决梯度消失问题？",
        "ReLU之前常用的激活函数？",
        "卷积神经网络中常见的层有哪些？",
        "m*n*3的图像输入进去，输出会有变化吗？",
        "分类问题的交叉熵是什么？",
        "分类问题是否可以用MSE？",
        "推荐系统中，相比于余弦相似度，是否可以用欧几里得距离判断相似度？",
        "过拟合怎么处理？",
        "L1、L2正则化的效果、区别、原理？",
        "Dropout的原理、在训练和测试时的区别？",
        "SGD、Adam、动量优化的SGD分别是什么？",
        "Adam和动量优化的SGD效率上的区别是什么？",
        "推荐系统中，如何进行负采样？",
        "NLP中常见的分词方法有哪些？",
        "讲一下BERT的结构？",
        "自然语言处理有哪些任务？",
        "L1、L2正则化的区别是什么？岭回归是L1正则化还是L2正则化？",
        "怎么处理类别不平衡？",
        "模型提速的方法有哪些？",
        "说一下广度优先遍历和深度优先遍历的区别？",
        "如何理解交叉熵的物理意义？",
        "过拟合如何解决？",
        "对于一个时间顺序的推荐数据，如何划分训练集和验证集，能不能随机划分？",
        "欠拟合如何解决？训练过程不收敛如何解决？",
        "分类任务常用的损失函数有哪些？",
        "多分类任务常用的损失函数是什么（Softmax 交叉熵）？",
        "为什么分类任务通常不用MSE而用交叉熵？",
        "YOLOv5相比之前版本增加了哪些特性？",
        "介绍一下Attention机制。",
        "在Attention机制中，Q、K、V矩阵分别有什么作用？",
        "生成式模型与判别式模型的区别是什么？",
        "模型的方差和偏差分别指什么？",
        "分类模型的评估指标有哪些？",
        "AUC刻画的是什么？",
        "交叉熵函数刻画的是什么？",
        "对于非常大的分类类别，Softmax有哪些优化方法？",
        "Softmax除了作为激活函数，在深度学习中还有哪些用途？",
        "解释一下熵，它的公式是什么？",
        "BERT base原始模型训练时，第一个epoch模型预测可能很差，这时熵还可信吗？",
        "交叉熵和KL散度有什么关系？",
        "BERT的缺点有哪些？",
        "RoBERTa相比BERT有哪些改进？",
        "BERT的输入由哪几种Embedding组成？",
        "你了解哪些解决BERT长度限制的方案？",
        "BERT是怎么缓解梯度消失的？",
        "LayerNorm和BatchNorm的区别是什么？",
        "如何解决prompt的泛化性问题？",
        "BERT的后续改进工作分别改进了哪些地方？",
        "你对知识蒸馏了解多少？有哪些改进工作用到了知识蒸馏？",
        "YOLO的正负样本是什么？",
        "模型压缩和加速的方法有哪些？",
        "什么是半精度（FP16）？",
        "半精度的理论原理是什么？",
        "你了解哪些知识蒸馏模型？",
        "自监督、半监督、无监督的区别是什么？",
        "如何同时解决过拟合和欠拟合？",
        "什么是交叉验证？",
        "统计学中的P值是什么含义，如何通俗地解释？",
        "如何构建多模态模型？",
        "GPT源码past_key_value是干啥的？",
        "模型输出的分布比较稀疏，怎么处理？",
        "描述下Transformer的结构？",
        "为什么Transformer可以处理多种模态，它是怎么处理的？",
        "如何解决Transformer长度限制的问题？",
        "Python迭代器是什么，构成是怎样的？",
        "亿个参数的模型，部署后占用多大显存？",
        "深度可分离卷积是什么？",
        "CNN中参数量和计算量怎么算？",
        "深度可分离卷积的参数量和计算量是多少？",
        "AUC和ROC是什么？",
        "Precision和Recall是什么？",
        "Transformer是什么？",
        "Python的深拷贝和浅拷贝的区别？",
        "赋值时浅拷贝还是深拷贝？",
        "如何查找某个元素在一个有序数组的第一次出现位置？",
        "BLIP-2的架构、优势和之前多模态模型的区别？",
        "知识蒸馏是什么？",
        "在自然语言处理模型训练中，评价指标是怎样设定的？",
        "自然语言处理中对低质量数据做数据清洗的方法？",
        "LSTM和RNN有什么区别？",
        "多任务学习各loss差异过大怎样处理？",
        "多模态融合后，怎样知道最终结果受哪种模态影响更大？",
        "过拟合应该怎样处理？",
        "BN层在训练和推理过程中有什么不一样？",
        "什么是堆？",
        "什么是完全二叉树？",
        "路径规划算法有哪些？",
        "如何判断链表是否有环？",
        "什么是信息增益？",
        "文本生成的几大预训练任务？",
        "多模态中常见的SOTA模型有哪些？",
        "对比学习负样本是否重要？",
        "负样本构造成本过高应该怎么解决？",
        "word2vec的原理，怎么训练的？",
        "样本不平衡问题怎么处理的，有什么方法？",
        "快速排序时间复杂度和稳定性怎么样？",
        "各种评估指标有哪些？",
        "XGBoost算法介绍？",
        "评分卡建模全流程？",
        "深度学习中，常见的损失函数有哪些？",
        "CV中数据增强的方法有哪些？",
        "多头注意力机制和单个注意力机制时间复杂度会变吗？",
        "大模型微调过程中如何避免灾难性遗忘？",
        "对话系统有哪几种？",
        "这几种对话系统的区别是什么？",
        "如何衡量对话系统质量：以用户的主观体验为主吗？",
        "如何衡量对话系统质量：以任务的完成情况来衡量对话质量吗？",
        "为什么要用多轮对话系统？",
        "常见的多轮对话系统解决方案是什么？",
        "什么是任务型对话系统？",
        "任务型对话系统的流程是怎么样的？",
        "什么是语言理解（SLU）？",
        "语言理解（SLU）的输入输出是什么？",
        "语言理解（SLU）所使用的技术是什么？",
        "什么是 DST（对话状态跟踪）？",
        "DST（对话状态跟踪）的输入输出是什么？",
        "DST（对话状态跟踪）存在的问题和解决方法是什么？",
        "DST（对话状态跟踪）实现方式是什么？",
        "DPO（对话策略学习）是什么？",
        "DPO（对话策略学习）的输入输出是什么？",
        "DPO（对话策略学习）的实现方法是什么？",
        "NLG（自然语言生成）是什么？",
        "NLG（自然语言生成）的输入输出是什么？",
        "NLG（自然语言生成）的实现方式是什么？",
        "为什么需要提示学习（Prompting）？",
        "什么是提示学习（Prompting）？",
        "提示学习（Prompting）有什么优点？",
        "提示学习（Prompting）有哪些方法？",
        "为什么需要前缀微调（Prefix-tining）？",
        "前缀微调（Prefix-tining）思路是什么？",
        "前缀微调（Prefix-tining）的优点是什么？",
        "前缀微调（Prefix-tining）的缺点是什么？",
        "为什么需要指示微调（Prompt-tuning）？",
        "指示微调（Prompt-tuning）思路是什么？",
        "指示微调（Prompt-tuning）优点是什么？",
        "指示微调（Prompt-tuning）缺点是什么？",
        "指示微调（Prompt-tuning）与 Prefix-tuning 的区别是什么？",
        "指示微调（Prompt-tuning）与 fine-tuning 的区别是什么？",
        "为什么需要 P-tuning？",
        "P-tuning 思路是什么？",
        "P-tuning 优点是什么？",
        "P-tuning 缺点是什么？",
        "大模型微调 P-tuning 和传统 fine-tuning 有什么区别？",
        "为什么需要 P-tuning v2？",
        "P-tuning v2 思路是什么？",
        "P-tuning v2 优点是什么？",
        "P-tuning v2 缺点是什么？",
        "什么是文本挖掘？",
        "文本挖掘的作用是什么？",
        "什么是文本摘要？",
        "文本摘要技术有哪些类型？",
        "抽取式摘要是怎么做的？",
        "句子重要性评估算法有哪些？",
        "基于约束的摘要生成方法有哪些？",
        "TextTeaser算法是怎么抽取摘要的？",
        "TextRank算法是怎么抽取摘要的？",
        "抽取式摘要的可读性问题是什么？",
        "压缩式摘要是怎么做的？",
        "生成式摘要是怎么做的？",
        "生成式摘要存在哪些问题？",
        "Pointer-generator network解决了什么问题？",
        "摘要质量的评估方法有哪些类型？",
        "什么是ROUGE？",
        "几种ROUGE指标之间的区别是什么？",
        "BLEU和ROUGE有什么不同？",
        "什么是知识图谱呢？",
        "什么是图（Graph）呢？",
        "什么是 Schema 呢？",
        "知识图谱的类别有哪些？",
        "知识图谱的价值在哪呢？",
        "怎么构建知识图谱呢？",
        "知识图谱的数据来源于哪里？",
        "信息抽取的难点在哪里？",
        "构建知识图谱所涉及的技术？",
        "知识图谱的具体构建技术是什么？",
        "知识图谱怎么存储？",
        "知识图谱可以做什么？",
        "知识表示相对于one-hot表示的优势是什么？",
        "有哪些文本表示模型？它们各有什么优缺点？",
        "word2vec与LDA模型之间的区别和联系？",
        "介绍下词向量空间中的平移不变现象？",
        "简要介绍下TransE模型的思想及优点？",
        "为什么需要适配器微调（Adapter-tuning）？",
        "适配器微调（Adapter-tuning）思路？",
        "适配器微调（Adapter-tuning）特点是什么？",
        "AdapterFusion思路是什么？",
        "AdapterDrop思路是什么？",
        "AdapterDrop特点是什么？",
        "MAM Adapter思路是什么？",
        "MAM Adapter特点是什么？",
        "请问⼈⼯神经⽹络中为什么 ReLU 要好过于 tanh 和 Sigmoid function？",
        "能写一下逻辑回归的损失函数吗？",
        "逻辑回归和最大似然有什么关系？",
        "逻辑回归用梯度下降优化，学习率对结果有什么影响？",
        "逻辑回归中样本不均衡我们怎么处理？",
        "lr 模型是线性模型还是非线性， 为什么？",
        "能推导逻辑回归的原理吗？",
        "LR/SVM/softmax/Adaboost 损失函数之间的差别？",
        "为什么逻辑回归做对数转换时选用以 e 为底？",
        "lr 为什么不采用 mse 而是采用交叉熵损失？",
        "SVM 的原理是什么？",
        "SVM 为什么采用间隔最大化？",
        "什么样的函数可以作为 SVM 的核函数？",
        "SVM 对缺失数据敏感吗，为什么？",
        "SVM 的损失函数是什么形式？可以用梯度下降优化吗？",
        "SVM 的高斯核为什么会把原始维度映射到无穷多维？",
        "为什么要将求解 SVM 的原始问题转换为其对偶问题？",
        "为什么 SVM 要引入核函数？",
        "解释一下决策树的建模过程？",
        "有几种不同的决策树，区别在哪？",
        "决策树的缺失值和数值型特征分别是怎么处理的？",
        "CART 树是如何做分类的，是如何做回归的，是如何处理多分类的？",
        "决策树怎么控制过拟合？",
        "决策树/随机森林的特征重要度是怎么获得的？",
        "树形结构为什么不需要归⼀化？",
        "树模型对于缺失值如何处理？",
        "Xgboost 的原理能讲一下么？",
        "xgboost 的树生长时的精确分裂与近似分裂分别是怎么做的？",
        "level-wise 的生长和 leaf-wise 的生长有什么不同，优缺点是什么？",
        "能解释一下 LightGBM 里基于 histogram 的决策树算法吗？",
        "为什么 xgboost 的近似算法比 lightgbm 还是慢很多呢？",
        "LightGBM 对类别型是怎么处理的？",
        "lightgbm 哪些方面做了并行？",
        "xgboost 和 LightGBM 有哪些控制过拟合的手段，通常需要调整的参数有哪些？",
        "xgboost 对于缺失值，训练和预测的时候都是怎么处理的？",
        "lgb,xgb 如何防止过拟合，有哪些参数？",
        "lgb 二分类的损失函数是什么？",
        "RF 与 boosting 之间差别？",
        "GBDT 和 xgboost 之间差别？",
        "xgboost 有哪些参数会影响模型的复杂度？",
        "xgboost 的并⾏化体现在哪？",
        "xgboost 的多分类如何做？",
        "写一下贝叶斯公式？",
        "朴素贝叶斯是一个什么算法，能解释一下吗？",
        "如果出现计数为 0 导致概率为 0，这种情况在朴素贝叶斯计算里是怎么解决的？",
        "PCA 算法原理，跟 svd 的区别。特征值越大代表什么？",
        "特征向量代表什么？有什么性质，是单位向量吗？",
        "特征工程有什么作用？",
        "请简述你知道的特征工程有哪些，以及它们的操作？",
        "有哪些特征选择的方法？",
        "有哪些异常值检测的方法？",
        "有哪些处理异常值的方法？",
        "常用的防止过拟合的技术手段有哪些？L1-norm 和 L2-norm 的区别是什么？",
        "预测函数与代价函数的关系是什么？在矩阵分解中如何体现？",
        "梯度下降中局部最优解和全局最优解的关系是什么？",
        "如何观察过拟合？",
        "有哪些模型评估方法？",
        "有哪些评估准则？",
        "AUC 怎么计算？为什么说 AUC 比较稳定？",
        "ReLU 有哪些改进变体（如 PReLU、Random ReLU）？",
        "LR 使用注意事项有哪些？相比别的分类模型为什么使用它？",
        "LR 和 DNN 的联系和区别是什么？",
        "决策树在某一节点上如何选择用哪个特征进行划分？",
        "决策树节点划分特征在待分类样本中缺失时怎么办？",
        "训练完成后对测试集样本分类时有缺失值怎么办？",
        "哪些模型需要做归一化（如 Adaboost、SVM、LR、KNN、KMeans）？为什么？",
        "为什么 XGBoost 的近似算法比 LightGBM 慢很多？",
        "分布式训练中如何汇总不同 worker 的不同 feature 直方图？原理是什么？",
        "“投影后类内方差最小，类间方差最大”是什么意思？",
        "线性回归分析中关于残差（Residuals）的说法哪些是正确的？",
        "关于异方差（Heteroskedasticity）的说法哪些是正确的？",
        "哪些指标可以用来评估线性回归模型？",
        "如果 X^T X 不可逆（奇异矩阵）怎么办？",
        "构建一个最简单的线性回归模型需要几个系数（只有一个特征）？",
        "如果两个变量相关，那么它们一定是线性关系吗？",
        "两个变量相关，它们的相关系数r可能为0，这句话是否正确？",
        "分类算法常用哪些？",
        "回归算法一般用哪些？",
        "回归方法中使用的评价指标是哪些？",
        "分类中使用的损失函数是哪些？",
        "为什么是交叉熵而不是MAE？",
        "对于小数据集一般怎么处理呢？",
        "小数据集中如何防止过拟合？",
        "常用什么激活函数？",
        "Sigmoid函数有使用过吗？与ReLU激活函数有什么不同？",
        "SVM中什么时候用线性核什么时候用高斯核？",
        "什么是支持向量机，SVM与LR的区别？",
        "机器学习中的距离计算方法有哪些？",
        "朴素贝叶斯（Naive Bayes）法的要求是？",
        "训练集中类别不均衡，哪个参数最不准确？",
        "生成模型和判别模型有哪些？",
        "SVM和全部数据有关还是和局部数据有关？",
        "Loss Function有哪些，怎么用？",
        "Stacking和Blending的区别？",
        "HMM隐马尔可夫模型的参数估计方法是？",
        "Bootstrap方法是什么？",
        "如何防止过拟合？",
        "EM算法是否一定收敛？",
        "正负样本不平衡的解决办法？",
        "评价指标的参考价值是什么？",
        "循环神经网络为什么好？",
        "训练过程中，若一个模型不收敛，那么是否说明这个模型无效？",
        "神经网络中权重共享的是？",
        "神经网络激活函数有哪些？",
        "在深度学习中，通常会finetuning（微调）已有的成熟模型，再基于新数据修改最后几层神经网络权值，为什么？",
        "微调时候网络参数是否更新？",
        "用过哪些移动端深度学习框架？",
        "RNN容易梯度消失，怎么解决？",
        "谈谈自己投稿的论文：论文投稿级别、论文内容、用到的方法、对比方法等？",
        "模型压缩效果评价指标有哪些？",
        "压缩和加速方法如何选择？",
        "对一千万个整数排序，整数范围在[-1000,1000]间，用什么排序最快？",
        "什么是 Python 的生成器？",
        "如何判断两个 dict 是否一样？",
        "如何从 list 头部删除元素？",
        "字符串如何拼接？",
        "PyTorch 中 cuda() 的作用是什么？两个 Tensor 一个调用了 cuda()、一个没有，相加会怎样？",
        "在程序里面智能指针的名字是啥？",
        "函数后面接 const 是什么意思？",
        "C++ 的一些库有哪些？",
        "什么是全局解释器锁（GIL）？",
        "什么是同步锁？为什么用同步锁？怎么使用同步锁？",
        "什么是死锁？死锁产生的必要条件是什么？处理死锁的基本方法有哪些？",
        "什么是递归锁？",
        "什么是乐观锁？",
        "什么是悲观锁？",
        "Python 常用的加锁方式有哪些？",
        "IP 报文经过一个路由器会改变哪些字段？",
        "什么是监督学习？",
        "什么是非监督学习？",
        "什么是过拟合？产生过拟合的原因是什么？如何避免过拟合问题？",
        "什么是欠拟合？如何避免欠拟合问题？",
        "什么是交叉验证？交叉验证的作用是什么？交叉验证主要有哪几种方法？",
        "什么是 K 折交叉验证？如何在 K 折交叉验证中选择 K？",
        "什么是准确率、精准率、召回率和 F1 分数？",
        "模型常用的评估指标有哪些？",
        "多标签分类怎么解决？",
        "什么是正则化？如何理解正则化？",
        "L0、L1、L2 正则化是什么？",
        "L1 和 L2 正则化有什么区别？",
        "L1 在 0 处不可导是怎么处理的？",
        "L1 正则化产生稀疏性的原因是什么？",
        "如何理解稀疏矩阵？",
        "为何要常对数据做归一化？",
        "需要归一化的算法有哪些？这些模型需要归一化的主要原因是什么？",
        "树形结构模型不需要归一化的原因是什么？",
        "为什么要处理类别特征？怎么处理？",
        "什么是组合特征？怎么有效地找到组合特征？",
        "如何处理高维组合特征？",
        "如何解决数据不平衡问题？",
        "数据中有噪声如何处理？",
        "简述一下 KNN 算法的原理？",
        "如何理解 kNN 中的 k 的取值？",
        "在 kNN 的样本搜索中，如何进行高效的匹配查找？",
        "KNN 算法有哪些优点和缺点？",
        "不平衡的样本可以给 KNN 的预测结果造成哪些问题，有没有什么好的解决方式？",
        "如何优化 Kmeans？",
        "曼哈顿距离是什么？",
        "为什么 SVM 对缺失数据敏感？",
        "SVM 如何处理多分类问题？",
        "带核的 SVM 为什么能分类非线性问题？",
        "RBF 核一定是线性可分的吗？",
        "常用核函数有哪些？核函数需要满足什么条件？",
        "为什么要将求解 SVM 的原始问题转换为对偶问题？",
        "SVM 怎么输出预测概率？",
        "如何处理数据偏斜？",
        "你是怎么理解偏差和方差的平衡的？",
        "模型受到低偏差和高方差问题时，应该使用哪种算法来解决问题呢？",
        "协方差和相关性有什么区别？",
        "把分类变量当成连续型变量会得到一个更好的预测模型吗？",
        "机器学习中分类器指的是什么？",
        "请简要说说一个完整机器学习项目的流程？",
        "什么是回归？",
        "哪些模型可用于解决回归问题？",
        "线性回归的损失函数为什么是均方差？",
        "什么是线性回归？什么时候使用它？",
        "什么是梯度下降？",
        "SGD 的推导是什么？",
        "什么是最小二乘法（最小平方法）？",
        "有哪些评估回归模型的指标？",
        "什么是正规方程？",
        "梯度下降法找到的一定是下降最快的方向吗？",
        "MBGD 需要注意什么？如何选择 m？",
        "什么是正态分布？为什么要重视它？",
        "如何检查变量是否遵循正态分布？",
        "为什么 LR 要使用 sigmoid 函数？",
        "为什么常常要做特征组合（特征交叉）？",
        "为什么 LR 比线性回归要好？",
        "LR 参数求解的优化方法？",
        "工程上，怎么实现 LR 的并行化？有哪些并行化的工具？",
        "LR 如何解决低维不可分问题？",
        "LR 与最大熵模型 MaxEnt 的关系？",
        "为什么 LR 用交叉熵损失而不是平方损失（MSE）？",
        "LR 能否解决非线性分类问题？",
        "用什么来评估 LR 模型？",
        "LR 如何解决多分类问题？",
        "为什么在训练的过程当中将高度相关的特征去掉？",
        "什么是 ROC 曲线？",
        "如何判断 ROC 曲线的好坏？",
        "如何解释 AU ROC 分数？",
        "什么是特征选择？为什么需要它？特征选择的目标？",
        "有哪些特征选择技术？",
        "既然信息增益可以计算，为什么 C4.5 还使用信息增益比？",
        "基尼指数和信息熵都表示数据不确定性，为什么 CART 使用基尼指数？",
        "基尼系数(Gini)存在的问题？",
        "决策树的数据 split 原理或者流程？",
        "构造决策树的步骤？",
        "决策树算法中如何避免过拟合和欠拟合？",
        "决策树怎么剪枝？",
        "决策树的优缺点？",
        "决策树和条件概率分布的关系？",
        "如果特征很多，决策树中最后没有用到的特征一定是无用吗？",
        "决策树怎么做回归？",
        "决策树算法的停止条件？",
        "为什么决策树之前用 PCA 会好一点？",
        "交叉熵代价函数是如何产生的？",
        "为什么信息增益偏向取值较多的特征(缺点)？",
        "如何使用信息增益比？",
        "GBDT 是训练过程如何选择特征？",
        "GBDT 如何防止过拟合？",
        "梯度提升的如何调参？",
        "GBDT 对标量特征要不要 one-hot 编码？",
        "为什么 GBDT 用负梯度当做残差？",
        "为什么 Adaboost 方式能够提高整体模型的学习精度？",
        "使用 m 个基学习器和加权平均使用 m 个学习器之间有什么不同？",
        "adaboost 的迭代次数(基学习器的个数)如何控制？",
        "adaboost 算法中基学习器是否很重要，应该怎么选择基学习器？",
        "XGBoost 使用泰勒二阶展开的原因？",
        "XGBoost 可以并行训练的原因是什么？",
        "XGBoost 为什么快？",
        "XGBoost 防止过拟合的方法有哪些？",
        "XGBoost 如何处理缺失值？",
        "为什么 XGBoost 相比某些模型对缺失值不敏感？",
        "XGBoost 如何处理不平衡数据？",
        "XGBoost 中叶子结点的权重如何计算？",
        "XGBoost 中一棵树的停止生长条件是什么？",
        "比较 LR 和 GBDT：什么情景下 GBDT 不如 LR？",
        "为什么此时树模型就过拟合得更严重？",
        "XGBoost 在什么地方做的剪枝，如何进行剪枝？",
        "XGBoost 如何选择最佳分裂点？",
        "XGBoost 的 Scalable 性如何体现？",
        "XGBoost 参数调优的一般步骤是什么？",
        "XGBoost 模型如果过拟合了怎么解决？",
        "XGBoost 如何寻找最优特征？",
        "随机森林的随机性指的是什么？",
        "为什么随机森林要随机抽样？",
        "为什么随机森林要有放回的抽样？",
        "为什么随机森林不用全样本训练？",
        "为什么随机森林要随机特征？",
        "随机森林需要剪枝吗？",
        "随机森林如何处理缺失值？",
        "随机森林如何评估特征重要性？",
        "随机森林与决策树的区别是什么？",
        "随机森林为什么比 bagging 效率高？",
        "随机森林为什么能够更鲁棒？",
        "随机森林在分类和回归问题中如何预测 y 值？",
        "为什么随机森林的树比 GBDT 的要深一点？",
        "K 值如何选取？",
        "K-means 算法中初始点的选择对最终结果有什么影响？",
        "K-means 不适用于哪些数据？",
        "K-means 中常用的距离度量有哪些？",
        "为什么在计算 K-means 之前要将数据点在各维度上归一化？",
        "聚类和分类的区别是什么？",
        "PCA 的优化目标是什么？",
        "PCA 白化是什么？",
        "为什么要用 SVD 进行降维？",
        "降维的作用是什么？",
        "矩阵的特征值和特征向量的物理意义是什么？",
        "什么是维度灾难？为什么要关心它？",
        "为什么朴素贝叶斯如此“朴素”？",
        "朴素贝叶斯的优缺点是什么？",
        "为什么引入条件独立性假设？",
        "在估计条件概率 P(X|Y) 时出现概率为 0 的情况怎么办？",
        "为什么属性独立性假设在实际情况中很难成立，但朴素贝叶斯仍能取得较好效果？",
        "如何对贝叶斯网络进行采样？",
        "什么是深度学习？",
        "深度学习的训练过程是什么？",
        "深度学习与机器学习有什么区别？",
        "p 值是什么？",
        "无监督和有监督算法的区别？",
        "SVM 的推导和特性是什么？",
        "多分类怎么处理？",
        "LR 的推导和特性是什么？",
        "决策树的特性是什么？",
        "SVM、LR、决策树的对比？",
        "GBDT 和随机森林的区别？",
        "如何判断函数是凸或非凸？",
        "什么是凸优化？",
        "如何解决类别不平衡问题？",
        "解释对偶的概念。",
        "为什么会产生过拟合，有哪些方法可以预防或克服过拟合？",
        "什么是偏差与方差？",
        "神经网络的原理是什么，如何进行训练？",
        "介绍卷积神经网络，和 DBN 有什么区别？",
        "采用 EM 算法求解的模型有哪些，为什么不用牛顿法或梯度下降法？",
        "聚类算法中的距离度量有哪些？",
        "解释贝叶斯公式和朴素贝叶斯分类。",
        "解释 L1 和 L2 正则化的作用。",
        "TF-IDF 是什么？",
        "文本中的余弦距离是什么，有哪些作用？",
        "最近关注的论文有哪些？例如多模态视觉大模型（CLIP、DALL·E）？",
        "BLIP-2 的架构是什么？它的优势是什么？与之前多模态模型的区别是什么？",
        "介绍一下 Stable Diffusion 的原理。",
        "LangChain 如何做 Embedding & vector store？",
        "Layer Norm 有什么特点？",
        "LLMs 中的不同位置有什么区别么？",
        "层归一化 Layer Norm 在大语言模型 LLMs 中的不同位置有什么区别么？",
        "词转化为其基本形式？",
        "文本语料库的可能特征是什么？",
        "TF（词频）和 IDF（逆文档频率）的乘积的正确值是多少？",
        "从句子中删除“and”、“is”、“a”、“an”、“the” 这样的词的过程被称为？",
        "从给定的句子、段落中识别人名、组织名的过程称为？",
        "转换为整数或浮点向量的操作？",
        "将词表示成向量被称为神经词嵌入（Neural Word Embeddings）？",
        "词嵌入捕获多维数据，并表示为向量？",
        "词嵌入向量有助于确定 2 个 tokens 之间的距离？",
        "相同的词可以通过什么方式来实现多个词嵌入？",
        "为什么进行 Query 扩写？",
        "Query 扩写的 Prompt 如何构建？",
        "介绍下 HyDE？",
        "什么是检索增强的语言模型（Retrieval-based LMs）？",
        "为什么要使用检索增强的语言模型（Retrieval-based LMs）？",
        "长文本如何存储用于检索？",
        "向量化模型都有哪些？",
        "如何构造微调 Bert 相似度向量模型数据？",
        "检索模块的评估指标有哪些？",
        "RAG 和 SFT 微调有什么不同？",
        "长篇知识如何产生问答对？",
        "使用什么相似度模型？",
        "为什么要微调 Bert 模型？",
        "如何提高搜索质量和大语言模型的推理能力？",
        "什么是交互型模型？",
        "输入文档的顺序对大模型是否有影响？",
        "基于 Retrieval-based LMs 的对话流程是怎么样？",
        "RAG 调用模式有几种？分别是什么？",
        "如何判断上下文是否关联？",
        "上下文长度过长怎么办？",
        "介绍下 RAG-Fusion？",
        "介绍下 SELF-RAG？",
        "Self-RAG 的训练过程是怎样的？",
        "Self-RAG 的推理过程是怎样的？",
        "介绍下 Rerank 模型？",
        "prompt 模板如何构建？",
        "为什么要进行文本切块？",
        "选择分块策略时，需要考虑哪些要素？",
        "分块策略都有哪些？",
        "语义分块模型都有哪些？",
        "什么是句子窗口检索？",
        "什么是父文档检索器？",
        "如何评估 RAG 系统的准确率上下限问题？",
        "大语言模型RLHF中的PPO主要分哪些步骤？",
        "举例描述一下大语言模型的RLHF？",
        "什么是PPO中的采样过程？",
        "介绍一下PPO中的采样策略？",
        "PPO中采样策略中，如何评估“收益”？",
        "介绍一下LLM的经典预训练Pipeline？",
        "具体介绍一下预训练（Pre-training）？",
        "具体介绍一下有监督微调（Supervised Finetuning）？",
        "有监督微调（Supervised Finetuning）的训练数据格式是什么样？",
        "预训练（Pre-training）和有监督微调（Supervised Finetuning）有什么区别？",
        "简单介绍一下对齐（Alignment）？",
        "简单介绍一下RLHF流程？",
        "如何在预训练好的模型上进行有监督微调？",
        "如何在有监督微调模型基础上创建一个RM模型？",
        "如何基于RM模型使用PPO算法微调SFT模型？",
        "InstructGPT的原理是什么？请讲讲RLHF和reward。",
        "介绍一下LLaMA 2的RLHF？",
        "LLaMA 2中Margin Loss的实现逻辑？",
        "LLaMA 2中两个RM模型的实现逻辑？",
        "LLaMA 2中拒绝采样逻辑？",
        "为什么需要RLHF替代方案？",
        "RLHF有哪些替代方案？",
        "RLHF训练过程中，怎么选取最优checkpoint？",
        "SL靠的是样本标签训练模型，RL依靠的是什么？",
        "MC、TD谁的方差大，为什么？",
        "Model-based和model-free的区别是什么？",
        "确定性策略和随机性策略的区别与联系？",
        "on-policy 和 off-policy 的区别与联系？",
        "重要性采样的推导过程、作用？",
        "Q-learning 是 off-policy 的方法，为什么不使用重要性采样？",
        "有哪些方法可以使得 RL 训练稳定？",
        "写出贝尔曼期望方程和贝尔曼最优方程？",
        "贝尔曼期望方程和贝尔曼最优方程什么时候用？",
        "策略梯度算法的目标函数和策略梯度计算？",
        "DQN 的原理？",
        "DQN 和 Sarsa 的区别？",
        "为什么使用优势函数？",
        "常见的平衡探索与利用的方法？",
        "TD3 如何解决过估计？",
        "TD3 和 DDPG 的区别？",
        "多臂老虎机和强化学习算法的差别？",
        "多臂老虎机算法的分类？",
        "有哪几种 Bandit 算法？",
        "简述 UCB 算法（Upper Confidence Bound）？",
        "简述重要性采样、Thompson sampling 采样？",
        "什么是强化学习？",
        "强化学习和监督学习、无监督学习的区别是什么？",
        "强化学习适合解决什么样子的问题？",
        "强化学习的损失函数（loss function）是什么，和深度学习的损失函数有何关系？",
        "POMDP 是什么？",
        "马尔科夫过程是什么？",
        "马尔科夫决策过程是什么？",
        "“马尔科夫”体现了什么性质？",
        "贝尔曼方程的具体数学表达式是什么？",
        "最优值函数和最优策略为什么等价？",
        "值迭代和策略迭代的区别？",
        "如果不满足马尔科夫性怎么办？",
        "求解马尔科夫决策过程都有哪些方法？",
        "有模型用什么方法？",
        "动态规划是怎么回事？",
        "简述动态规划（DP）算法？",
        "MC 和 TD 分别是无偏估计吗？",
        "写出用第 n 步的值函数更新当前值函数的公式（1-step，2-step，n-step 的意思）。当 n 的取值变大时，期望和方差分别变大、变小？",
        "TD（λ）方法：当 λ=0 时实际上与哪种方法等价，λ=1 呢？",
        "写出蒙特卡洛、TD 和 TD（λ）这三种方法更新值函数的公式？",
        "value-based 和 policy-based 的区别是什么？",
        "DQN 的两个关键 trick 分别是什么？",
        "阐述目标网络和 experience replay 的作用？",
        "手工推导策略梯度过程？",
        "描述随机策略和确定性策略的特点？",
        "不打破数据相关性，神经网络的训练效果为什么就不好？",
        "画出 DQN 玩 Flappy Bird 的流程图：在这个游戏中，状态是什么，状态是怎么转移的？",
        "奖赏函数如何设计，是否存在奖赏延迟问题？",
        "DQN都有哪些变种？",
        "引入状态奖励的是哪种算法？",
        "简述 Double DQN 原理？",
        "如果使用 Fixed Q-targets，是否相当于有两个 Q 网络？",
        "策略梯度方法中基线（baseline）如何确定？",
        "什么是 DDPG，并画出 DDPG 框架结构图？",
        "Actor-Critic 两者的区别是什么？",
        "Actor-Critic 框架中的 critic 起了什么作用？",
        "DDPG 是 on-policy 还是 off-policy，为什么？",
        "是否了解过 D4PG 算法？",
        "简述 A3C 算法？",
        "A3C 是 on-policy 还是 off-policy，为什么？",
        "A3C 算法是如何异步更新的？",
        "是否能够阐述 GA3C 和 A3C 的区别？",
        "简述 A3C 的优势函数？",
        "什么是重要性采样？",
        "为什么 TRPO 能保证新策略的回报函数单调不减？",
        "如何理解利用平均 KL 散度代替最大 KL 散度？",
        "简述 PPO 算法？",
        "简述 DPPO 和 PPO 的关系？",
        "强化学习如何用在推荐系统中？",
        "推荐场景中奖赏函数如何设计？",
        "场景中状态是什么，当前状态怎么转移到下一状态？",
        "自动驾驶和机器人的场景如何建模成强化学习问题？",
        "MDP 各元素对应真实场景中的哪些变量？",
        "强化学习需要大量数据，如何生成或采集到这些数据？",
        "是否用某种 DRL 算法玩过 Torcs 游戏，具体怎么解决？",
        "是否了解过奖励函数的设置（reward shaping）？",
        "强化学习中如何处理归一化？",
        "强化学习如何观察收敛曲线？",
        "强化学习如何确定收敛？",
        "影响强化学习算法收敛的因素有哪些，如何调优？",
        "多智能体强化学习算法有哪些？",
        "简述 Model Based Learning？",
        "Model Based Learning 有什么新的进展？",
        "什么是 World Model？",
        "什么是 Dream？",
        "什么是 MuZero？",
        "简述 Meta Reinforcement Learning？",
        "为什么 Reptile 应用的效果并不好？",
        "Meta RL 不好应用的原因有哪些？",
        "简述 Meta Gradient Reinforcement Learning？",
        "简述 Imitation Learning？",
        "什么是 GAIL？",
        "什么是 Deepminic？",
        "简述 DRL 的一些最新改进？",
        "什么是 R2D3？",
        "什么是 LASER？",
        "简述 Multi-Agent Reinforcement Learning？比如 MADDPG 比较早的，思想是什么？和一般的 DRL 有什么区别？",
        "简述 seed rl？",
        "对于大规模分布式强化学习，还有更好的提高 throughput 的方法吗？",
        "简述 AI-GAs？你对这个理论有什么看法？",
        "简述 Out-of-Distributon Generalization？",
        "DRL 要实现足够的泛化（Generalization）有哪些做法？",
        "简述 Neural-Symbolic Learning 的方法？怎么看待？",
        "简述 unsupervised reinforcement learning？",
        "Diversity is all you need？",
        "简述 offline reinforcement learning？",
        "简述 Multi-Task Reinforcement Learning？",
        "Policy Distillation？",
        "简述 sim2real？有哪些方法？",
        "对于 hard exploration 的问题，要怎么处理？",
        "简述 Transformer？能否具体介绍一下实现方法？",
        "简述 Pointer Network？和一般的 Attention 有什么不同？",
        "什么是 Importance Sampling？为什么 PPO 和 IMPALA 要使用？两者在使用方式上有何不同？能否结合？",
        "PPO 在实现上是怎么采样的？",
        "PPO 里使用的 GAE 是怎么实现的？能否写出计算过程？",
        "是否理解 Entropy、KL divergence 和 Mutual Information 的含义？",
        "AlphaStar 的 scatter connection 怎么实现的？",
        "对于多个 entity 的 observation，你会怎么预处理？神经网络要怎么构建？",
        "AlphaStar 的 League，能否解释一下？如何让 agent 足够 diverse？",
        "Inverse RL 能否解决奖励问题，如何解决的？",
        "分层强化学习的原理是什么？",
        "简述分层强化学习中基于目标的（goal-reach）和基于目标的（goal-reach）的区别与联系？",
        "请简述 IQL（independent Q-learning）算法过程？",
        "是否了解 α−Rank 算法？",
        "请简述 QMIX 算法？",
        "简述模仿学习与强化学习的区别、联系？",
        "简述 MADDPG 算法的过程和伪代码？",
        "多智能体之间如何通信、如何竞争？",
        "你熟悉的多智能体环境有哪些？",
        "你做过的强化学习项目有哪些，遇到的难点有哪些？",
        "请简述造成强化学习 inefficient 的原因？",
        "SARSA 的公式是什么？它和 Q-learning 的区别是什么？",
        "是否了解 RLlib？",
        "Ray 怎么做梯度并行运算的？",
        "A3C 中多线程如何更新梯度？",
        "GA3C 算法的 queue 如何实现？",
        "强化学习的动作、状态以及奖励如何定义？指标有哪些？包括状态和动作的维度是多少？哪些算法效果比较好？",
        "DQN 的 trick 有哪些？",
        "PPO 算法中的 clip 如何实现的？",
        "MADDPG 如何解决离散 action 的？",
        "强化学习在机器人的局限性有哪些？",
        "强化学习中如何解决高维度输入输出问题？",
        "基于值函数方法的算法有哪些？其损失函数是什么？",
        "TD(λ) 方法：当 λ=0 时实际上与哪种方法等价，λ=1 呢？",
        "为什么 policy 中输出的动作需要 sample，而不是直接使用呢？",
        "为什么连续动作环境下使用 DDPG 的表现还没有直接动作离散化后 Q-learning 表现好？",
        "PPO 算法中的损失函数由哪些组成？",
        "你在强化学习模型调试中，有哪些调优技巧？",
        "简述 PPO、DPPO 算法？",
        "简述 PER 算法、HER 算法？",
        "离散 action 和连续 action 在处理上有什么相似和不同的地方？",
        "什么是 Transformer？",
        "Transformer 这个黑盒子里面都有什么？",
        "为什么要引入 Transformer？",
        "Transformer 有何特点？",
        "你怎么理解注意力机制？",
        "你了解哪些 attention 机制？",
        "为什么要做 softmax 标准化？",
        "为什么后续有不少工作尝试对 softmax 进行替换？",
        "Transformer 的输入是什么样的？",
        "为什么要做 position embedding/encoding？",
        "为什么要使用 query、key、value 矩阵？",
        "Self-attention 部分怎么计算？",
        "Scaled dot-product attention 为什么要除以根号 dk？",
        "Position-wise feed-forward networks 具体是怎么设计的？",
        "为什么要加 FFN？",
        "Transformer 为何使用多头注意力机制？",
        "Transformer 计算 attention 的时候为何选择点乘而不是加法？",
        "在计算 attention score 的时候如何对 padding 做 mask 操作？",
        "为什么在进行多头注意力的时候需要对每个 head 进行降维？",
        "大概讲一下 Transformer 的 Encoder 模块？",
        "为何在获取输入词向量之后需要对矩阵乘以 embedding size 的开方？",
        "简单介绍一下 Transformer 的位置编码，有什么意义和优缺点？",
        "你还了解哪些关于位置编码的技术，各自的优缺点是什么？",
        "Encoder 端和 Decoder 端是如何进行交互的？",
        "Decoder 阶段的多头自注意力和 Encoder 的多头自注意力有什么区别？",
        "为什么需要 Decoder 自注意力进行序列掩码？",
        "Transformer 的并行化体现在哪个地方？",
        "Decoder 端可以做并行化吗？",
        "Transformer 是如何工作的？",
        "Transformer 的优势是什么？",
        "Transformer 的局限性是什么？",
        "什么是 Transformer 及其架构？它与传统神经网络有何不同？",
        "Transformer 是如何训练的？",
        "Transformer 中的自注意力机制是什么？",
        "训练和实现 Transformer 时有哪些常见挑战，如何改进其性能？",
        "如何决定 Transformer 中的层数和注意力头的数量？",
        "如何处理 Transformer 中的不同长度的输入序列？",
        "如何处理 Transformer 中的缺失/损坏数据并解决过拟合问题？",
        "如何微调预训练的 Transformer 以适应特定任务？",
        "如何确定 Transformer 的适当容量水平？",
        "Transformer 中的前馈神经网络是什么？",
        "其中使用了什么激活函数？",
        "Encoder 和 Decoder 端是如何进行交互的？",
        "decoder 阶段的多头注意力机制和 encoder 的多头注意力机制有什么区别？",
        "Transformer 的并行化体现在什么地方？",
        "Decoder 端可以做并行化么？",
        "为什么 decoder 需要 sequence mask？",
        "Transformer 哪里做了权重共享？为什么可以做权重共享？好处是什么？",
        "BERT 的 mask 为何不学习 Transformer 在 attention 处进行屏蔽 score 的操作？",
        "什么是 Transformer 模型？它与传统的 RNN 和 CNN 有何不同？",
        "Transformer 中的自注意力机制是如何工作的？",
        "Transformer 模型中的多头注意力机制有什么优点？",
        "什么是位置编码（Positional Encoding），为什么在 Transformer 中需要它？",
        "Transformer 模型的编码器和解码器结构是怎样的？",
        "在 Transformer 模型的训练过程中，为什么要使用掩码（Mask）？",
        "什么是 BERT 模型？它与原始的 Transformer 有何不同？",
        "GPT 模型的架构和特点是什么？",
        "Transformer 中的前馈神经网络有什么作用？",
        "什么是多任务学习，Transformer 如何应用于多任务学习？",
        "什么是注意力矩阵，如何计算？",
        "在 Transformer 模型中，如何处理长序列数据？",
        "什么是层归一化（Layer Normalization），它在 Transformer 中有什么作用？",
        "如何理解 Transformer 模型中的残差连接（Residual Connection）？",
        "什么是预训练和微调（Fine-tuning），在 Transformer 模型中如何应用？",
        "Transformer 在机器翻译任务中的应用是怎样的？",
        "什么是 Transformer 模型中的头（Head），它的作用是什么？",
        "在自然语言生成任务中，Transformer 如何确保生成文本的连贯性和一致性？",
        "如何评估和改进 Transformer 模型的性能？",
        "kaggle 上的 attention layer 到底实现的是啥？",
        "self-attention 无法学习到序列信息吗？",
        "为何不能使用同一个值进行自身的点乘？",
        "多头注意力和单头注意力在计算复杂度和效果上有什么区别？",
        "为什么在进行 softmax 之前需要对 attention 进行 size 的开方？",
        "为什么要设计多头注意力而不用单头注意力？",
        "Transformer 中的 self-attention 可以做并行化吗？",
        "如何处理 Transformer 中的缺失/损坏数据并解决过拟合？",
        "multi_head_self_attention 里为什么要进行屏蔽 score 的操作（Mask）？",
        "什么是位置编码（Positional Encoding），为什么 Transformer 中需要它？",
        "Transformer 为什么用 Layer Norm？有什么用？",
        "为什么 Transformer 不用 BN，而用 LN？",
        "Bert 为什么要搞一个 position embedding？",
        "Bert 为什么三个 embedding 可以相加？",
        "Transformer 为什么要用三个不一样的 QKV？",
        "Bert 中为什么要用 WordPiece/BPE 这样的 subword token？",
        "Bert 中为什么要在开头加个 [CLS]？为什么 [CLS] 可以建模整句话的语义表征？",
        "[CLS] 不放在句子开头的其他位置是否可行？",
        "不用[CLS]的语义输出，有其他方式可以代替吗？",
        "BERT中有哪些地方用到了mask？",
        "预训练阶段的mask有什么用？",
        "Attention中的mask有什么用？",
        "BERT是如何处理传统方法难以搞定的溢出词表词（OOV）的语义学习的？",
        "中文是如何处理溢出词表词（OOV）的语义学习的？",
        "为什么说GPT是单向的、BERT是双向的？",
        "BERT如何处理一词多义？",
        "BERT中的Transformer和原生的Transformer有什么区别？",
        "ALBERT是通过什么方法压缩网络参数的？",
        "预训练和微调是哪个阶段注入知识的？",
        "想让模型学习垂直领域的知识，是应该预训练还是微调？",
        "微调后的大模型出现灾难性遗忘是什么原因？",
        "什么是LLM的复读机问题？",
        "出现复读机问题的可能原因有哪些？",
        "解决大模型复读机问题可用哪些策略？",
        "LoRA怎么做的，讲一下？",
        "为什么可以用LoRA？",
        "国外开源的LLaMA的词表实际上兼容中文效果可能会大打折扣，那么扩充词表该怎么做？",
        "什么是指标体系？如何建立？业务应用场景？",
        "什么是漏斗分析？有哪些注意的点？",
        "你是怎么理解数据分析的？流程如何？",
        "如何理解假设检验中的 P 值和显著性水平 α？",
        "Dubbo支持分布式事务吗？",
        "EJB 的生命周期是什么，以及如何管理事务？",
        "Linux 中主要有哪几种内核锁？",
        "MySQL 支持事务吗？",
        "MySQL 的 MyISAM 与 InnoDB 两种存储引擎在事务、锁级别、各自的适用场景上有什么区别？",
        "MySQL 中有哪几种锁？",
        "Redis 事务相关的命令有哪些？",
        "Spring 的事务传播行为有哪些？",
        "ZooKeeper 是如何保证事务顺序一致性的？",
        "产生死锁的条件是什么？",
        "死锁的原因是什么？",
        "什么是乐观锁和悲观锁？",
        "什么是事务隔离级别？",
        "列举 Spring 支持的事务管理类型有哪些？",
        "如何使用 Redis 做分布式锁？",
        "怎么理解 Redis 事务？",
        "简洁描述 MySQL 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别？",
        "MYSQL 数据库服务器性能分析的方法命令有哪些？",
        "MYSQL 数据表在什么情况下容易损坏？",
        "MongoDB 成为最好NoSQL 数据库的原因是什么？",
        "MySQL 与MongoDB 之间最基本的差别是什么？",
        "MySQL 中控制内存分配的全局参数有哪些？",
        "MySQL 当记录不存在时insert，当记录存在时update，语句怎么写？",
        "NoSQL 数据库有哪些类型？",
        "Oracle 19c 中数据库的默认字符集是什么？",
        "Oracle 19c 中自动内存管理是如何工作的？",
        "Oracle 19c 的内存结构有哪些改进？",
        "Oracle 系统进程主要有哪些，作用是什么？",
        "什么是 SQL 注入攻击？如何防止 SQL 注入攻击？",
        "与Oracle 相比，Mysql 有什么优势？",
        "主要是通过什么方法来判断某些SQL 语句需要进行优化的？",
        "什么是通用SQL 函数？",
        "如何在Oracle 19c 中创建物化视图？",
        "如何在Oracle 19c 中配置分布式数据库？",
        "怎么优化复杂的SQL 查询？",
        "渗透测试中的 SQL 注入攻击是什么？",
        "如何构建数据索引？",
        "什么是倒排索引？",
        "Hash 索引和 B+ 树索引的区别？",
        "MongoDB 在 A:{B,C} 上建立索引，查询 A:{B,C} 和 A:{C,B} 都会使用索引吗？",
        "为什么不都用 Hash 索引而使用 B+ 树索引？",
        "为什么说 B+ 树比 B 树更适合实际应用中操作系统的文件索引和数据库索引？",
        "什么是索引分裂？",
        "什么是索引？",
        "什么样的字段适合建索引？",
        "在 MySQL 数据库中索引的工作机制是什么？",
        "你怎么查看表中定义的所有索引？",
        "可以使用多少列创建索引？",
        "在 MongoDB 中什么是索引？",
        "如何在 Oracle 19c 中启用自动索引？",
        "如何添加索引？",
        "索引的作用是什么？",
        "聚集索引和非聚集索引的区别？",
        "常用的索引有哪些种类？",
        "请解释一下索引的工作原理？",
        "除了使用索引以外，还有什么方法可以加快查询速度？",
        "RNNs 训练和传统 ANN 训练有哪些异同点？",
        "学习率太大（太小）时会发生什么？",
        "卷积神经网络在 NLP 与 CV 领域应用的区别是什么？",
        "BN 和 Dropout 在训练和测试时的差别是什么？",
        "全连接、局部连接、全卷积与局部卷积的区别是什么？",
        "sigmoid 和 softmax 的区别是什么？",
        "卷积神经网络的优点是什么？",
        "将 CNN 拆成 3x1 和 1x3 卷积的优点是什么？",
        "BN、LN、IN、GN 和 SN 的区别是什么？",
        "神经网络调参要往哪些方向考虑？",
        "前馈神经网络(FNN)、递归神经网络(RNN)和 CNN 的区别是什么？",
        "微调时先冻结底层、训练顶层的原因是什么？",
        "网络设计中为什么卷积核尺寸常用奇数？",
        "VGG 使用 3*3 卷积核的优势是什么？",
        "LSTM、RNN、GRU 的区别？",
        "如何防止神经网络过拟合？",
        "批量归一化(BN) 如何实现？",
        "×1 卷积的作用是什么？",
        "如何处理神经网络中的缺失数据？",
        "对 fine-tuning(微调模型)的理解是什么？",
        "Average pooling 和 Max pooling 哪个更合适？",
        "Softmax 的公式是什么？",
        "神经网络怎样进行参数初始化？",
        "CNN 模型所需的计算力 FLOPs 是什么？",
        "N、LN、IN、GN 都是什么？",
        "深度卷积网络中如何进行上采样？",
        "下采样的作用是什么？",
        "为什么在检测任务中常采用 max pooling，而分类任务中常采用 average pooling？",
        "为什么需要卷积？",
        "什么是数据增强？",
        "你用过哪些数据增强方法？",
        "你知道哪些数据增强方式？",
        "你知道有哪些深度学习框架吗？",
        "常用的归一化和标准化方法有哪些？",
        "梯度爆炸会引发哪些问题？",
        "模型的参数量指的是什么？",
        "还有哪些池化技术？",
        "随机梯度下降相比全局梯度下降的好处是什么？",
        "CNN-CRF、BiLSTM-CRF、IDCNN-CRF 的区别是什么？",
        "TextRCNN 相较于 TextCNN 的改进是什么？",
        "CNN 是怎样一步一步工作的？",
        "DPCNN 模型相较于 TextCNN 的改进是什么？",
        "什么是 Dilated CNN？为什么会有 Dilated CNN？Dilated CNN 的优点是什么？",
        "LSTM 神经网络输入输出是怎样的？",
        "使用 CNN 作为文本分类器时，不同通道（channels）对应着文本的什么信息？",
        "TextCNN 中卷积核的长与宽分别代表什么？",
        "如何解决 RNN 梯度爆炸和梯度消失的问题？",
        "基于（Bi-）LSTM 的词性标注是什么？",
        "Dropout 的原理是什么？训练和测试时有什么区别？",
        "R-CNN 与 Fast R-CNN 的区别是什么？",
        "ReLU 激活函数如何解决梯度消失和梯度爆炸问题？",
        "损失函数不是二次函数时该怎么办？",
        "什么单元更容易出现梯度消失和梯度爆炸的问题？",
        "多分类的 Softmax 损失函数是什么？",
        "BN 是对单个神经元的运算，那么在 CNN 的卷积层上要怎么做？",
        "是否可以用轻量级模型（如 TextCNN）去逼近 BERT 的效果？",
        "损失函数不是二次函数时怎么办？",
        "为何 GBDT 可以用负梯度近似残差？",
        "(Tom,0.6)(Chase,0.2) (Jerry,0.2) 是如何得到的呢？",
        "CRF 模型和 HMM、MEMM 模型有什么区别？",
        "Wordvec 指什么？",
        "neo4j 模块中执行 CQL（cypher）语句是什么？",
        "word2vec 训练 trick 中 window 设置多大？",
        "为什么有 one-hot？",
        "什么是图（Graph）？",
        "什么是类型识别？",
        "什么是角色识别？",
        "什么是触发词检测？",
        "什么是论元检测？",
        "传统的相似度算法所存在的问题？",
        "如何发现 FAQ 中标准问题？",
        "最大熵马尔科夫模型（MEMM）是什么？",
        "隐马尔科夫算法序列概率计算过程是什么样的？",
        "隐马尔科夫算法是什么？",
        "网卡或者硬盘有问题时，我们可以通过使用哪个命令查看相关信息？",
        "什么是 lambda 函数？",
        "机器学习和统计里面的 AUC 的物理意义是啥？",
        "常见的分类算法有哪些？",
        "什么是最小二乘法？",
        "MLP+softmax层 介绍？",
        "有哪些文本表示模型？",
        "Wordvec 中 CBOW 指什么？",
        "one-hot 是什么？",
        "Bert 预训练任务 Masked LM 怎么做？",
        "word2vec 为什么解决不了多义词问题？",
        "什么是 Schema？",
        "什么是知识图谱？",
        "任务型对话系统的流程是怎么样？",
        "模型蒸馏的论文有哪些？",
        "基于深度学习的命名实体识别方法的结构是怎么样？",
        "最大熵马尔科夫模型（MEMM）如何解决 HMM 问题？",
        "简单介绍混淆矩阵和 kappa？",
        "类型识别有哪些方法？",
        "角色识别有哪些方法？",
        "触发词检测有哪些方法？",
        "论元检测有哪些方法？",
        "为什么人工神经网络中 ReLU 要好过于 tanh 和 Sigmoid function？",
        "这几种对话系统的区别？",
        "阿里最新开源的 X-Deep Learning 为 Online Learning 提供了哪些解决方案？",
        "DST（对话状态跟踪）存在问题和解决方法？",
        "Dice 系数和 Jaccard 系数的区别？",
        "HMM 模型三个基本问题的联系？",
        "NLG（自然语言生成）的实现方式？",
        "QQ 匹配一般处理流程是怎么样？",
        "fastText 的结构是什么样的？",
        "one-hot 有什么特点？",
        "one-hot 存在哪些问题？",
        "事件抽取的评价指标是什么？",
        "指示微调（Prompt-tuning）的优点是什么？",
        "怎么通俗易懂地解释 EM 算法并且举个例子？",
        "指针网络层介绍？",
        "条件随机场（CRF）层介绍？",
        "构建知识图谱所涉及的技术有哪些？",
        "检索的方法在预测阶段如何做？",
        "词汇/实体类型信息增强方法有哪些？",
        "隐马尔可夫模型中的三个矩阵是什么？",
        "隐马尔可夫模型序列标注（解码）过程是什么样的？",
        "BERT 预训练任务 Next Sentence Prediction（NSP）怎么做？",
        "CBOW vs Skip-gram 哪一个好？",
        "隐马尔科夫算法中两个假设是什么？",
        "TF-IDF 怎么描述？",
        "写一个计算编辑距离（莱温斯坦距离）的编程题。",
        "可以用 for 循环直接删除 ArrayList 的特定元素吗？",
        "隐马尔科夫算法的工作流程是什么？",
        "fastText 词内 n-gram 信息的训练过程是什么？",
        "初期标注数据不足问题怎么解决？",
        "fastText 词内 n-gram 信息存在什么问题？",
        "时间是不是直接抽取就好了，其它属性该怎么办呢？",
        "Adam 和动量优化的 SGD 在效率上的区别是什么？",
        "Bert 采用这种两阶段方式解决各种 NLP 任务效果如何？",
        "Boosting 通过迭代多棵树来共同决策，这是怎么实现的？",
        "ELMO 的论文题目“Deep contextualized word representation”更能体现其精髓，精髓在哪里？",
        "GPT 是单向的，如何体现？",
        "Jensen 不等式是什么？",
        "KNN、KMeans 之类的算法为什么需要归一化？",
        "EM 算法中，M 步是最大化那一步，E 步是什么？",
        "M 步中如何求参数 θ 的极值？",
        "我们的目标还是估计 PA 和 PB，需要怎么做？",
        "为什么通过新闻可以预测网络故障？",
        "事件抽取一般有什么方法？",
        "事件抽取中触发词一般是预定义好的，还是需要做检测任务？",
        "不同任务对事件的定义不同，能具体解释下事件抽取的字段吗？",
        "事件抽取针对的是一段话还是一篇文章？",
        "事件抽取中的事件需要分类型吗？",
        "ReLU 之前常用的激活函数有哪些？",
        "回归（Regression）的部分加在哪？",
        "SGD、Adam、动量 SGD 的区别是什么？",
        "Self-Attention 有什么增益或好处？",
        "BLIP-2 的架构是什么？它的优势以及和之前多模态模型的区别是什么？",
        "SVM 的目标函数和哪些方法类似？为什么 SVM 这么 popular？",
        "GPT 源码里的 past_key_value 是干什么的？",
        "SVM 的 margin 公式 y(w^T x+b)=y f(x) 中的 y 只取 1 和 -1 吗？",
        "word2vec的原理是什么，怎么训练的？",
        "yolov5相比于之前增加的特性有哪些？",
        "y的唯一作用就是确保functional margin的非负性吗？",
        "事件抽取的定义/概念是什么？",
        "事件抽取有哪些常用的评测数据集和评测标准？",
        "事件抽取的一般过程是什么？有标注数据如何开展研究，如何扩展，没有数据怎么做？",
        "事件之间的关系如何表示？如何做事件之间的关系抽取？",
        "工业界如何选取核函数，有哪些经验方法？",
        "怎么把Z变成已知的？",
        "NLM是怎么训练的？",
        "下一个单词应该是哪个，你会怎么做？",
        "如何在一个有序数组中找到某个元素的第一次出现位置？",
        "ELMO预训练好网络结构后，如何给下游任务使用？",
        "继续训练LoRA，还是跟base模型合并后再套一层LoRA，或者从头开始训练一个LoRA？",
        "怎么理解Attention模型的物理含义？",
        "不再是类别而是数值（预测值）时，怎么确定？",
        "为什么一定会收敛？",
        "为什么非支持向量对应的等于零呢？",
        "为什么不用MSE分类用交叉熵？",
        "为什么我们做评分卡的时候要用woe编码，而不是用别的编码方式呢？",
        "为什么要初始化为全0？",
        "为什么要归一化呢？",
        "为什么输入数据需要归一化（Normalized Data）？",
        "交叉熵函数刻画的什么？",
        "什么是一元线性模型呢？",
        "什么是信息增益呢？",
        "WOE仅是因为可以把特征从非线性变成线性的吗？",
        "他们各自的优缺点是什么？",
        "可以使用Bert预训练好的模型参数吗？",
        "得到的最优的状态转换路径是1->1->1->1，为什么？",
        "作为输出词填写什么？",
        "根据哪个指标划分更好？",
        "该数据集的维度以减少模型计算时间，你的机器内存有限，你会怎么做？",
        "体识别方法的优点是什么？",
        "在项目初期标注数据不足，如何解决该问题？",
        "你有了解其他模型去尝试解决长度限制的方案吗？",
        "假定我们需要统计七月在线10万学员中男生女生的身高分布，怎么统计？",
        "假设预训练好了网络模型，后面下游任务怎么用？",
        "关于attention机制，三个矩阵K、Q、V的作用是什么？",
        "关于bert的后续改进工作，分别改进了哪些地方？",
        "种类型的无监督训练任务是哪三种？",
        "这种循环迭代方式的停止条件是什么，什么时候停止？",
        "什么是sum-product算法？",
        "半精度是什么？",
        "压缩至0到1有何用处？",
        "如何根据已经产生好的文档反推其主题？",
        "取候选框用到的算法“选择性搜索”怎么选出这些候选框？",
        "可以介绍一下attention机制吗？",
        "可以解释一下熵吗，它的公式怎么算的？",
        "可能会出现什么问题？",
        "为什么要输入输出都一样呢？",
        "这个转化过程中的关键泰勒二次展开是哪来的？",
        "提示学习（Prompting）有哪些方法？它们间有什么区别？",
        "假设你有一个标准的问题库，有一个新 query 进来，你会做什么操作？",
        "如何构造 Span 矩阵问题？",
        "如何衡量对话质量：以任务的完成情况来衡量？",
        "如何衡量对话质量：以用户的主观体验为主？",
        "如何解决 prompt 泛化性？",
        "如果来了一个新的房子/面积，假设在房屋销售价格的记录中没有的，我们怎么办？",
        "如果进行采样，策略是什么？",
        "它们各有什么优缺点？",
        "它们的特点是什么？",
        "它指的是street还是这个animal呢？",
        "它是如何改变深度学习领域的？",
        "它有什么好处？",
        "对于一个时间顺序的推荐数据，如何划分训练集和验证集，能不能随机？",
        "对于非常大的分类类别，对于softmax有哪些优化方法？",
        "对知识蒸馏知道多少，有哪些改进用到了？",
        "下⾯的代码可能会出现什么问题？",
        "归一化后有什么好处呢？",
        "当图像有很多物体怎么办？",
        "快速排序时间复杂度？",
        "怎么判断“头发长短”或者“是否有喉结”是最好的划分方式，效果怎么量化呢？",
        "Bert效果特别好，那么到底是什么因素起作用呢？",
        "找到相似的用户和物品，通过什么途径找到呢？",
        "据某关键字，如何找出重复出现次数最多的前100条？",
        "到底需要训练多少次才能得到最优分类超平面？",
        "遇到线性不可分的数据时，如何把两类数据分开？",
        "如何加入某种结构，使得后面全连接层得到的输入变成固定的？",
        "样本不平衡问题怎么处理，有什么方法？",
        "BERT 是怎么根据上文和下文去预测单词的？",
        "模型的方差和偏差是指什么？",
        "如何计算信息增益（Gain）？",
        "理解这个推导的关键在哪？",
        "生成式模型与判别式模型的区别？",
        "用大的数据集训练一个 general 的 model，还是根据垂直领域训练一个 specific 的 model？",
        "为什么 Word2Vec 这么处理？",
        "带权路径最短也符合信息论：希望越常用的词拥有更短的编码，如何编码？",
        "如何实现对 attention 信息的控制？",
        "想得到式(2)的最大值，怎么办？",
        "问题转换成寻找与样本分布最接近的概率分布模型，如何寻找？",
        "“Man”和“Woman”彼此之间为何比它们任一单词与“King”相比更相似？",
        "知识蒸馏和无监督样本训练有什么关系？",
        "知道了如何更新乘子，那么选取哪些乘子进行更新？",
        "类别不平衡如何处理？",
        "如何把这八个矩阵压缩成一个矩阵？",
        "对于新用户特征非常稀疏，基于深度学习的推荐系统效果较差，有什么方法？",
        "自然语言处理中对低质量数据做数据清洗的方法有哪些？",
        "评分卡建模全流程是什么？",
        "如何识别一幅图片包含字母“X”还是字母“O”？",
        "请专家对系统的自动摘要结果打分，但专家之间差异性较大，如何解决？",
        "输入句子单词的注意力分配概率分布值如何计算？",
        "DMP 的数据是哪里来的？",
        "Bert 在模型和方法角度有什么创新？",
        "什么是真、伪阳性率？",
        "什么是马尔科夫过程？",
        "马尔科夫过程的核心思想是什么？",
        "隐马尔可夫算法中的两个假设是什么？",
        "HMM 与 CRF 的区别是什么？",
        "隐马尔可夫算法存在哪些问题？",
        "A/B test 如何合理分流？",
        "AOP 有哪些实现方式？",
        "API 与微服务架构有何不同？",
        "DIM 层做了哪些事？",
        "Django 模型如何映射到数据库？",
        "Dubbo 和 Spring Cloud 有什么区别？",
        "Dubbo 有哪几种负载均衡策略，默认是哪种？",
        "Dubbo 能集成 Spring Boot 吗？",
        "Dubbo 可以对结果进行缓存吗？",
        "Efficient Router 介绍？",
        "EfficientNet 的原理是什么？基于什么模型的搜索？",
        "Flask 中如何配置路由规则？",
        "Flink 任务的并行度优先级如何设置？资源一般如何配置？",
        "Flink 写入 ClickHouse 怎么保证一致性？",
        "Flink 如何实现端到端一致性？",
        "GC 是什么？为什么要有 GC？",
        "GC 触发的条件是什么？",
        "HTTP 如何实现长连接？在什么时候会超时？",
        "HTTP 请求有哪些状态码？",
        "HTTP 的请求报文由哪些部分组成？",
        "HTTPS 的工作流程是怎样的？",
        "HTTP 和 HTTPS 有什么区别？",
        "Hash Join 是不是有排序？Hash Join 会在什么时候慢？",
        "IEEE 在计算机网络中的作用是什么？",
        "IP 地址有哪些分类？",
        "JDBC 访问数据库的基本步骤是什么？",
        "JVM 中一次完整的 GC 流程是怎样的，对象如何晋升到老年代？",
        "JVM 性能调优怎么做？",
        "JVM 调优命令有哪些？",
        "Java 中 ++ 操作符是线程安全的吗？",
        "Java 中 == 和 equals() 的区别？",
        "Java 中 interrupted 和 isInterrupted 方法的区别？",
        "Java 中 notify 和 notifyAll 有什么区别？",
        "Java 中什么是静态条件？",
        "Java 中堆和栈有什么区别？",
        "Java 中如何停止一个线程？",
        "Java 中怎么创建一个不可变对象？",
        "Java 中有几种类型的流？",
        "Java 中的引用类型有几种？",
        "Java 中的编译期常量是什么？使用它有什么风险？",
        "Java 中类的生命周期是什么？",
        "Java 内存模型是什么？",
        "Java 创建对象的几种方式？",
        "Java 创建线程之后，直接调用 start() 方法和 run() 的区别？",
        "Java 对象创建过程？",
        "Java 支持多继承吗？",
        "Java 的内存划分？",
        "Java 的基础类型和字节大小？",
        "Java 的多态表现在哪里？",
        "Java 集合类：List、Set、Queue、Map、Stack 的特点与用法？",
        "Java 面向对象的特征有哪些？",
        "Jedis 与 Redisson 对比有什么优缺点？",
        "Kafka 如何压测？",
        "Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别？",
        "Linux 中有哪几种设备？",
        "Linux 中的浮点运算由应用程序实现还是内核实现？",
        "Linux 中的用户模式和内核模式是什么含义？",
        "Linux 调度程序是根据进程的动态优先级还是静态优先级来调度进程的？",
        "Linux 软中断和工作队列的作用是什么？",
        "Linux 通过什么方式实现系统调用？",
        "MQ 的优缺点？",
        "MVC 的各个部分都有哪些技术来实现？如何实现？",
        "Memcache 与 Redis 的区别都有哪些？",
        "Minor GC、Full GC 触发条件？",
        "MongoDB 中的分片是什么意思？",
        "MongoDB 中的命名空间是什么意思？",
        "MongoDB 哪个命令可以切换数据库？",
        "MongoDB 支持主键外键关系吗？",
        "MongoDB 支持哪些数据类型？",
        "MongoDB 支持存储过程吗？如果支持的话，怎么用？",
        "MongoDB 是由哪种语言写的？",
        "MongoDB 有哪些可替代产品？",
        "MongoDB 的优势有哪些？",
        "MongoDB 存储特性与内部原理？",
        "MyBatis 框架使用的场合？",
        "MyBatis 框架的缺点？",
        "MyBatis 的优点？",
        "MyBatis 中 #{} 和 ${} 的区别是什么？",
        "Mybatis 是如何将 SQL 执行结果封装为目标对象的？都有哪些映射形式？",
        "MySQL 中使用什么存储引擎？",
        "MySQL 中有哪些不同的表类型？",
        "MySQL 如何优化 DISTINCT？",
        "MySQL 服务器默认端口是什么？",
        "MySQL 查询是否区分大小写？",
        "MySQL 的技术特点是什么？",
        "MySQL 表中允许有多少个 TRIGGERS？",
        "MySQL 驱动程序是什么？",
        "Nginx 优化的方式有哪些？",
        "Nginx 如何处理一个请求？",
        "Nginx 的调度算法有哪些？",
        "Nginx 的进程模型是什么？",
        "Nginx 负载均衡的 4 种分配方式是什么？",
        "Nginx 负载均衡调度状态有哪些？",
        "PCA 为什么要中心化？PCA 的主成分是什么？",
        "Python 中 is 和 == 的区别是什么？两者分别在比较什么？",
        "Python 中如何实现多线程？",
        "Python 中是否需要缩进？",
        "Python 中的字典是什么？",
        "Python 中的标识符长度有多长？",
        "Python 中的闭包是什么？",
        "Python 和 Java 之间的主要区别是什么？",
        "Python 如何实现函数式编程？",
        "Python 的优势有哪些？",
        "Python 中 range 和 xrange 的区别是什么？",
        "Python 中 remove、del 以及 pop 之间的区别是什么？",
        "Python 中列表和元组的区别是什么？",
        "Python 中的 None 代表什么？",
        "Python 中的可变对象和不可变对象是什么？",
        "Python 中的实例方法、静态方法和类方法三者有什么区别？",
        "Python 是解释型语言还是编译型语言？",
        "Python 里有多线程吗？",
        "ReID 项目中 Triplet loss 的原理是什么？",
        "Redis key 的过期时间和永久有效分别怎么设置？",
        "Redis 与其他 key-value 存储有什么不同？",
        "Redis 中的管道有什么用？",
        "Redis 主要消耗什么物理资源？",
        "Redis 分区有什么缺点？",
        "Redis 和 Memcache 的区别是什么？",
        "Redis 和 Redisson 有什么关系？",
        "Redis 回收使用的是什么算法？",
        "Redis 回收进程如何工作？",
        "Redis 如何做内存优化？",
        "Redis 如何做大量数据插入？",
        "Redis 如何设置密码及验证密码？",
        "Redis 存储的是 k-v 类型，为什么还会有 Hash？",
        "Redis 官方为什么不提供 Windows 版本？",
        "Redis 常见性能问题和解决方案有哪些？",
        "Redis 常见的性能问题都有哪些？如何解决？",
        "Redis 持久化数据和缓存怎么做扩容？",
        "Redis 提供了哪几种持久化方式？",
        "Redis 支持哪些数据结构？",
        "Redis 支持哪几种数据类型？",
        "Redis 支持的 Java 客户端都有哪些？官方推荐用哪个？",
        "Redis 是单线程的，如何提高多核 CPU 的利用率？",
        "Redis 有哪些适合的场景？",
        "Redis 有哪几种数据淘汰策略？",
        "Redis 的全称是什么？",
        "Redis 的内存占用情况怎么样？",
        "Redis 的内存用完了会发生什么？",
        "Redis 的同步机制了解么？",
        "Redis 集群之间是如何复制的？",
        "Redis 集群会有写操作丢失吗？为什么？",
        "Redis 集群如何选择数据库？",
        "Redis 集群方案什么情况下会导致整个集群不可用？",
        "Redis 集群方案应该怎么做？都有哪些方案？",
        "Redis 集群最大节点个数是多少？",
        "Redis 集群的主从复制模型是怎样的？",
        "Redo 日志文件（Redo Log Files）的作用是什么？",
        "SENet 的原理说一下，和 Attention 机制的区别？",
        "SENet 的原理，以及画出 block 的图？",
        "Servlet Filter Listener 启动顺序？",
        "Spark 的并行度指的是什么？",
        "Spring AOP（面向切面）编程的原理？",
        "Spring Boot 中的监视器是什么？",
        "Spring Boot 有哪些优点？",
        "Spring MVC 框架有什么用？",
        "Spring bean 的生命周期？",
        "Spring 中 @Autowire 与 @Resource 的区别？",
        "Spring 中 beanFactory 和 ApplicationContext 的联系和区别？",
        "Spring 中的事件处理？",
        "Spring 框架中都用到了哪些设计模式？",
        "Spring 框架的事物管理有哪些优点？",
        "Spring 的重要注解？",
        "Spring 运行原理？",
        "Spring IOC 是什么？",
        "Spring IOC 注入的几种方式？",
        "Spring MVC 和 struts2 的区别有哪些？",
        "Spring MVC 工作流程？",
        "TCP/IP 三次握手的过程以及对应的状态转换？",
        "TLB 中缓存的是什么内容？",
        "TCP 和 UDP 的区别？",
        "UML 是什么？",
        "Were you ever dismissed from your job for a reason that seemed unjustified?",
        "What are your outstanding qualities?",
        "What aspects of your job do you consider most crucial?",
        "What contribution did you make to your current/previous organization?",
        "What did you like/dislike about your last job?",
        "What did you look for when you hired people in the past?",
        "What interests you most about this job?",
        "What leadership qualities did you develop as an administrative personnel?",
        "What makes this job different from your current/last one?",
        "What range of pay-scale are you interested in?",
        "What sort of people do you find it difficult to work with?",
        "What type of decisions did you make on your last job?",
        "What was the last book you read? How did it affect you?",
        "Where did you think you'd be at this stage in your life?",
        "Why did you leave your last job?",
        "Layer normalization 方法篇：Deep Norm 有什么优点？",
        "attention 注意机制是什么？请简单介绍 self attention。",
        "baichuan 进行微调时，领域数据与通用数据如何配比？",
        "dubbo 服务负载均衡策略有哪些？",
        "fastText 的分类过程是什么？fastText 的优点是什么？",
        "forward 和 redirect 的区别是什么？",
        "glove 和 word2vec 对比有什么区别？",
        "hibernate 和 mybatis 的区别是什么？",
        "http 中重定向和请求转发的区别是什么？",
        "http 协议的状态码有哪些？含义是什么？",
        "https 的建立过程是什么？",
        "ips 和 ids 的区别是什么？",
        "jsp 和 servlet 的区别、共同点、各自应用的范围是什么？",
        "kmeans 算法为什么一定会收敛？讲一下 EM 算法。kmeans 算法有什么缺点？",
        "lora 的矩阵怎么初始化？为什么要初始化为全",
        "lr 模型是线性模型还是非线性，为什么？能推导它的原理吗？",
        "mysql 中 myisam 与 innodb 的区别是什么？",
        "mysql 支持的复制类型有哪些？",
        "mysql 有关权限的表都有哪几个？",
        "mysql_fetch_array 和 mysql_fetch_object 的区别是什么？",
        "nginx 中多个 worker 进程是如何监听同一个端口的？如何处理客户连接的惊群问题？",
        "nginx 相对于 apache 的优点是什么？",
        "nginx 程序的热更新是如何做的？",
        "nn.DataParallel（DP）和 DistributedDataParallel（DDP）有什么区别？",
        "python 常用的爬取数据的框架或者方法有哪些？",
        "python2 和 python3 的 range(100) 有什么区别？",
        "redis 单线程为什么还能处理速度那么快？",
        "redis 如何实现高可用？",
        "redis 常见的性能问题和解决方案有哪些？",
        "redis 有哪些数据结构？",
        "redis 的主从复制的实现过程是什么？",
        "redis 的哨兵机制的作用是什么？",
        "redis 的淘汰策略有哪些？",
        "Redis 相比 Memcached 有哪些优势？",
        "Redis 缓存穿透、缓存雪崩、缓存击穿分别是什么？如何解决？",
        "Redis 集群如何保证一致性？",
        "request.getAttribute() 和 request.getParameter() 有何区别？",
        "RNN、LSTM 和 GRU 的区别？",
        "Scrapy 怎么做分布式爬虫？",
        "Servlet 的生命周期是什么？",
        "Sigmoid 和 Softmax 的区别是什么？Softmax 的公式是什么？",
        "SQL Server 提权的方法有哪些？",
        "SQL Server 注入怎么判断目标是不是 SQL Server？",
        "SQL 注入写文件都有哪些函数？",
        "SQLMap 的 --os-shell 原理是什么？",
        "SQL 注入 GetShell 有哪些方式？",
        "SQL 注入报错注入常用函数有哪些？说几个报错函数。",
        "SQL 注入比较了解哪个数据库？",
        "SQL 注入类型有哪些？SQL 注入的方式有哪些？",
        "SVM 不同核方法有什么区别？",
        "介绍一下 SVM。",
        "t-SNE 无法在线部署时，如何设计“轻量级可视化”供生产环境实时监控？",
        "TCP 三次握手和四次挥手是什么？",
        "Tomcat 容器是如何创建 Servlet 类实例的？用到了什么原理？",
        "torch.multiprocessing 介绍一下。",
        "Word2Vec 伪代码推导。",
        "Word2Vec 和 FastText 有什么区别？",
        "Word2Vec 有哪些优化方法？",
        "网络层（IP）与数据链路层（MAC）有什么关系？",
        "为什么需要对 Llama2 做基于 LoRA 的二次预训练？",
        "介绍一下 Gradient Accumulation 的显存优化方式。",
        "个巨大的圆形水池，周围布满了老鼠洞。猫追老鼠到水池边，老鼠未来得及进洞就掉入水池里。猫继续沿水池边缘企图捉住老鼠（猫不入水）。已知 V猫=4V鼠。问老鼠是否有办法摆脱猫的追逐？",
        "如何使用基于 LoRA 的 Llama2 做推理？",
        "介绍一下 MOE（Mixture-of-Experts）分布式并行策略。",
        "基于 LoRA 的 Llama2 二次预训练的思想是什么？",
        "在有序数组中查找某个元素第一次出现的位置。",
        "为什么 TIME_WAIT 等待的时间是 2MSL？",
        "为什么 Redis 的操作是原子性的？怎么保证原子性？",
        "为什么 Redis 需要把所有数据放到内存中？",
        "为什么 Redis 是单线程？",
        "为什么参数化查询可以防止 SQL 注入？",
        "为什么在 MongoDB 中使用 ObjectId 数据类型？",
        "为什么用 MongoDB？",
        "为什么要做 Redis 分区？",
        "为什么要在 MongoDB 中使用分析器？",
        "为什么要在 MongoDB 中使用 Code 数据类型？",
        "为什么要在 MongoDB 中使用 Regular Expression 数据类型？",
        "为什么要用MQ？",
        "为什么要用Nginx？",
        "为什么需要 TIME_WAIT 状态？",
        "为什么需要可靠的UDP？",
        "为什么需要进行参数微调？参数微调的原因有哪些？",
        "介绍一下 gradient checkpointing 显存优化方式？",
        "基于lora的llama2二次预训练 的目标是什么？",
        "如何 配置 LoraConfig？",
        "Lora的矩阵怎么初始化？为什么要初始化为全0？",
        "如何 基于lora的llama2二次预训练？",
        "交叉熵公式，分类为什么用交叉熵不用平方差？",
        "什么叫特征工程？有哪些评估模型好坏的指标？",
        "什么叫线程安全？",
        "什么叫视图？游标是什么？",
        "什么是 A/B test？核心原理和应用场景？",
        "什么是Apache Kafka？",
        "什么是EDA(Exploratory Data Analysis)？",
        "什么是Flask？",
        "什么是Http 协议无状态协议？怎么解决Http 协议无状态协议？",
        "什么是Java 序列化，如何实现Java 序列化？",
        "什么是Java 虚拟机？为什么Java 被称作是无关平台的编程语言？",
        "什么是JavaConfig？",
        "什么是MongoDB？",
        "什么是Nginx？",
        "什么是Python 模块？Python 中有哪些常用的内置模块？",
        "什么是Redis, 具有哪些特点？",
        "什么是Redis？简述它的优缺点？",
        "什么是Servlet？",
        "什么是Spring Boot？",
        "什么是Spring Cloud Bus？我们需要它吗？",
        "什么是Spring Cloud？",
        "什么是Spring bean？",
        "什么是Swagger？你用Spring Boot 实现了它吗？",
        "什么是TCP粘包问题？",
        "什么是WebSocket？",
        "什么是n元语法？为什么要用n-gram？",
        "什么是redis 持久化？rdb 和aof 的比较？",
        "什么是spring 自动装配？",
        "什么是交叉验证？交叉验证的作用是什么？",
        "什么是代理服务器，他们如何保护计算机网络？",
        "什么是入侵检测系统（IDS）和入侵防御系统（IPS）？它们有何不同？",
        "什么是分类？业务应用场景？常见算法？",
        "什么是北极星指标？什么是虚荣指标？",
        "什么是反向代理？",
        "什么是同比、环比，意义是什么？",
        "什么是图灵完备语言？",
        "什么是基数（Cardinality）和可选择率（Selectivity）？",
        "什么是堆？什么是完全二叉树？",
        "什么是多线程的上下文切换？",
        "什么是安全监控？",
        "什么是待定的统计信息（Pending Statistic）？",
        "什么是控制反转（IOC），什么是依赖注入（DI）？",
        "什么是数据库？",
        "什么是正向代理？",
        "什么是直方图（Histogram）？",
        "什么是相关性分析？相关和因果的区别是什么？",
        "什么是线程局部变量？",
        "什么是线程？",
        "什么是网络拓扑？为什么它很重要？",
        "什么是网络流量分析？如何进行网络流量分析？",
        "什么是网络钓鱼？如何避免成为受害者？",
        "什么是负载均衡？",
        "什么是非关系型数据库？",
        "介绍一下文件描述符（file descriptor）？",
        "介绍图片分类 demo，怎么对数据集进行的处理？",
        "你对语义 web 栈了解多少？",
        "你怎么比较 MongoDB、CouchDB 及 CouchBase？",
        "你怎么理解统计学？生活中统计学应用举例？",
        "你理解的指标是什么？有哪些组成部分？",
        "你知道有哪些 Redis 分区实现方案？",
        "你知道进程吗？有进程为何还有线程？",
        "你知道哪些降维算法？知道 t-SNE 吗？",
        "你觉得用 Dubbo 好还是 Spring Cloud 好？",
        "你觉得做模型最重要的是什么？一个好的模型算法工程师所必须的技能有哪些？",
        "你觉得机器学习算法在阿里巴巴哪些场景中可以落地？",
        "你还了解别的分布式框架吗？",
        "使用 MQ 会有什么问题？",
        "使用 Redis 有哪些好处？",
        "使用 Spring Cloud 有什么优势？",
        "使用反向代理服务器的优点是什么？",
        "保护网络的一种方法是使用密码。什么可以被认为是好的密码？",
        "修改配置不重启 Redis 会实时生效吗？",
        "公平调度器容器集中在同一个服务器上？",
        "如何基于 LoRA 对 Llama2 微调？",
        "内存泄漏和内存溢出有什么区别？",
        "分布式数据库是什么？",
        "什么是分布式缓存？",
        "分析器在 MongoDB 中的作用是什么？",
        "分片（sharding）和复制（replication）是怎样工作的？",
        "分类任务有哪些类别？它们都有什么特征？",
        "列出5个Python标准库？",
        "创建进程的系统调用有哪些？",
        "如何判断是否存在CDN、如何绕过CDN、网站有CDN时怎么找真实IP？",
        "协方差与相关系数的区别和联系是什么？",
        "单例模式的几种实现方式及优化是什么？",
        "反射中，Class.forName() 和 ClassLoader.loadClass() 的区别是什么？",
        "可以从哪些方面来优化Nginx服务？",
        "可以作为GC Roots的对象有哪些？",
        "可以简单介绍一下word2vec吗？",
        "右图是由9个等边三角形拼成的六边形，已知中间最小的等边三角形的边长是a，问这个六边形的周长是多少？",
        "向量数据库有哪些？各自优点与区别是什么？",
        "哪些算法不需要对特征进行标准化处理？",
        "哪些语言支持MongoDB？",
        "基于LoRA的Llama2二次预训练语料构建思路是什么？",
        "为什么使用Macro-F1而不是Precision、Recall？",
        "在.java源文件中可以有多个类吗（内部类除外）？",
        "在MongoDB中什么是副本集？",
        "在MongoDB中如何创建一个新的数据库？",
        "在MongoDB中如何创建一个集合？",
        "在MongoDB中如何删除一个集合？",
        "在MongoDB中如何在集合中插入一个文档？",
        "在MongoDB中如何排序？",
        "在MongoDB中如何更新数据？",
        "在MongoDB中如何查看一个已经创建的集合？",
        "在MongoDB中如何查看数据库列表？",
        "在MongoDB中如何删除一个数据库？",
        "在MySQL中ENUM的用法是什么？",
        "在Nginx中，如何使用未定义的服务器名称来阻止处理请求？",
        "在Nginx中，如何在URL中保留双斜线？",
        "在Python中如何实现快速排序？",
        "在Spring中如何注入一个Java集合？",
        "在哪些场景使用MongoDB？",
        "在排除计算机网络问题时，可能会发生哪些常见的硬件相关问题？",
        "在有shell的情况下，如何使用XSS实现对目标站的长久控制？",
        "垃圾回收器的基本原理是什么？",
        "多线程和多进程的区别是什么？",
        "多输入多输出网络如何批量校验？",
        "如何使用Unix shell登录MySQL？",
        "如何保证Redis集群的数据一致性？",
        "如何保证线程安全？",
        "如何减小两个概率分布之间的KL散度？讲讲优化方法。",
        "如何创建、销毁线程？",
        "如何创建一个简单的 Flask 应用？",
        "如何初始化神经网络的权重？神经网络怎样进行参数初始化？",
        "如何判断目标主机是 Windows 还是 Linux？",
        "如何判断自己被 getshell？",
        "如何区分单栏还是双栏 PDF？如何重新排序？",
        "如何在 Python 中管理内存？",
        "如何在 Spring Boot 中禁用 Actuator 端点安全性？",
        "如何在 Unix 和 MySQL 时间戳之间进行转换？",
        "如何处理粘包和拆包？",
        "如何处理缓存雪崩问题？",
        "如何实现可靠的 UDP？",
        "如何对档案进行分类？标准是什么？",
        "如何杀死一个进程？",
        "如何查看 TCP 的连接状态？",
        "如何查看使用 MongoDB 的连接？",
        "如何理解 MongoDB 中的 GridFS 机制？MongoDB 为何使用 GridFS 来存储文件？",
        "如何用 Python 实现多线程编程？",
        "如何获取当前的 MySQL 版本？",
        "如何解决 NAT 潜在的问题？",
        "如何解决 TCP 粘包问题？",
        "如何进行网络安全风险评估？",
        "如何通过日志分析数据库性能瓶颈？",
        "如何避免僵尸进程？",
        "如何重新加载 Spring Boot 上的更改，而无需重新启动服务器？",
        "如何验证 A/B test 的结果？",
        "如果底库涨到 10 亿，单机内存不足，如何设计分布式 HNSW？",
        "如果我在使用复制技术（replication），可以一部分使用日志（journaling）而其他部分则不使用吗？",
        "如果提交任务时，线程池队列已满，这时会发生什么？",
        "如果有一个特别大的访问量到数据库上，怎么做优化？",
        "字符串常量池到底存在于内存空间的哪里？",
        "字符设备驱动程序的关键数据结构是哪个？",
        "守护线程是什么？它和非守护线程的区别？",
        "定时线程的使用？",
        "实现多线程有几种方式？",
        "实现数据质量监控，你具体怎么做？",
        "对 fine-tuning（微调模型）的理解？为什么要修改最后几层神经网络权值？",
        "对于 EfficientNet，说明一下原理？",
        "对于一个取值较多的类别变量在不能进行 one-hot 的情况下如何使用？",
        "对于图像拼接，基于什么特征？为什么选择这个特征？",
        "对文件或设备的操作函数保存在那个数据结构中？",
        "导致 Full GC 一般有哪些情况？",
        "就一般的企业而言，如何进行档案的分类？",
        "常用的 Python 库有哪些？",
        "常用的第三方数据统计平台有哪些？",
        "常见的垃圾回收算法有哪些？简述其原理。",
        "并发峰值多少？大概哪个时间点？",
        "多卡并行时通信成为瓶颈，如何隐藏？",
        "当我试图更新一个正在被迁移的块(chunk)上的文档时会发生什么？",
        "微调方法是什么？如何微调？",
        "快速排序算法是什么？",
        "怎么用 UDP 实现可靠传输？",
        "怎么保护计算机网络？",
        "怎么保证 MQ 的高可用？",
        "怎么唤醒一个阻塞的线程？",
        "怎么处理网络不收敛、类别不平衡等问题？",
        "怎么安装 nginx？",
        "怎么提高并发量？请列举你所知道的方案。",
        "怎么构建知识图谱？",
        "怎么测试 Redis 的连通性？",
        "怎么看待计算机网络和操作系统在 DL 中的作用？",
        "怎么设置 Redis 过期策略？",
        "怎样申请大块内核内存？",
        "思维图 Graph of Thoughts（GOT）核心思想是什么？",
        "我们如何在 MySQL 中运行批处理模式？",
        "我应该启动一个集群分片(sharded)还是一个非集群分片的 MongoDB 环境？",
        "手写 softmax 公式、BN 公式，并说明 softmax 层的 label 是什么。",
        "指标和维度的区别和联系是什么？",
        "推导一下 FM 模型和 DeepFM 模型。",
        "描述一下 JVM 加载 class 文件的原理机制。",
        "描述网络地址转换（NAT）技术。",
        "描述网络拓扑。",
        "数据库三范式是什么？",
        "数据库查询有哪些常用的优化方法？",
        "数据库运行很慢，如何解决？",
        "数据库连接池的原理是什么？为什么要使用连接池？",
        "数组在内存中如何分配？",
        "日志保存多久？有什么作用？",
        "日志记录被人删除了，你该怎么做？",
        "时间序列预测的原理是什么？有哪些应用场景？",
        "是否使用过 Redis 集群？集群的原理是什么？",
        "有哪些常用的机器学习方法？",
        "服务器的分类有哪些？",
        "服务注册和发现是什么意思？Spring Cloud 如何实现？",
        "机器学习会影响 Web3 吗？",
        "查看 Redis 使用情况及状态信息用什么命令？",
        "桥接模式是什么？",
        "模型参数微调的方式有哪些？你最常用哪些方法？",
        "次完整的 HTTP 请求是怎样的？",
        "注册类和活跃类指标，你会看哪个？",
        "测试活动中统计了哪些数据？",
        "深度学习如何替代传统滤波？",
        "特征方程的几何意义是什么？",
        "用 Python 设计算法实现圆周率的计算。",
        "用 Nginx 服务器解释 -s 的目的是什么？",
        "用哪两种方式来实现集合的排序？",
        "用户进程间通信主要哪几种方式？",
        "你知道哪些矩阵分解的方法？",
        "Znode 有哪些类型的数据节点？",
        "端侧 INT8 部署如何保持 Lipschitz？",
        "端侧部署的极限优化有哪些？",
        "等待事件的分类有哪些？常见等待事件有哪些？",
        "策略模式是什么？",
        "简单工厂和抽象工厂的区别是什么？",
        "你是否看过开源算法的源代码，或是否自己手动实现过？",
        "系统的用户量有多少？多用户并发访问时如何解决？",
        "线程 B 怎么知道线程 A 修改了变量？",
        "线程同步的方法有哪些？",
        "线程池的优点是什么？",
        "线程池的作用是什么？",
        "线程池的工作原理是什么？有哪些重要参数？",
        "线程池的拒绝策略有哪些？",
        "线程池的类型有哪些？",
        "线程池的阻塞队列有哪些？",
        "线程有哪几种状态？",
        "线程的创建方式有哪些？",
        "线程间通信中 wait 和 notify 的理解和使用是什么？",
        "线程阻塞有哪些原因？",
        "给你 100G 数据、1G 内存，如何排序？",
        "给你一个无序数组，怎么才能合理采样？",
        "网线的排列方式有哪些？",
        "网络协议（protocol）是什么？",
        "网络层常见的协议有哪些？",
        "网络拓扑如何影响您在建立网络时的决策？",
        "聊聊五层计算机网络体系结构中，每一层对应的网络协议有哪些？",
        "能否使用日志特征进行安全备份？",
        "视图的作用是什么，视图可以更改吗？",
        "Nginx 是否支持将请求压缩到上游？",
        "Spring 支持的几种 Bean 作用域是什么？",
        "解释一下代理模式？",
        "如何在 Nginx 中获得当前时间？",
        "如何在 Nginx 服务器上添加模块？",
        "解释栈（stack）、堆（heap）和方法区（method area）的用法？",
        "设计模式的优点是什么？",
        "设计模式的六大基本原则是什么？",
        "设计模式的分类有哪些？",
        "详细介绍一种非参数统计方法，并叙述其优缺点？",
        "SVD 的时间复杂度是多少？",
        "说一下你熟悉的设计模式？",
        "说几个常见的编译时异常？",
        "说出 Servlet 的生命周期，并说出 Servlet 和 CGI 的区别？",
        "说说 HTTP 的状态码，301 和 302 的区别？",
        "实现线程安全的方式有哪些？",
        "列举 Nginx 和 Apache 之间的不同点？",
        "列举 Nginx 的一些特性？",
        "描述 HTTP、HTTPS 分别是什么协议、作用及端口号？",
        "简述 CBOW 和 FastText 之间的区别？",
        "解释 Nginx 服务器上的 Master 和 Worker 进程分别是什么？",
        "ngx_http_upstream_module 的作用是什么？",
        "如何通过不同于 80 的端口开启 Nginx？",
        "是否有可能将 Nginx 的错误替换为 502 错误、503？",
        "解释残差连接的公式和原理，并说明它在深度神经网络中的作用？",
        "说一说 PCA？",
        "调用 schedule() 进行进程切换的方式有几种？",
        "谈到网络，什么是权限？",
        "负载均衡的原理是什么？",
        "转发（forward）和重定向（redirect）的区别是什么？",
        "轻量化检测（如移动端 NanoDet）把 BN 替换为 GN+EMA 是否还需同步？",
        "迁移之后的数据一致性怎么校验？",
        "进程和线程的区别是什么？",
        "进程调度的核心数据结构是哪个？",
        "通过伙伴系统申请内核内存的函数有哪些？",
        "有哪些办法可以降低 Redis 的内存使用情况？",
        "有哪些垃圾回收器？",
        "为什么要加入 reading-gate？为什么不直接把控制向量加在输入中？",
        "集群（Cluster）特有的后台进程有哪些？",
        "非关系型数据库有哪些类型？",
        "为什么不用 DiskANN？",
        "如何把 SQ/RQ 做成实时在线监控？",
        "制作原型应该在项目生命周期的哪个阶段？",
        "你将如何监控/管理顾问？",
        "店铺VIP顾客对于您推荐的服装一直非常不满意，语气不好，这时你如何处理？",
        "高并发情况下，我们系统是如何支撑大量的请求的？",
        "RF与GBDT之间的区别与联系是什么？",
        "机器学习中使用正则化来防止过拟合的原理是什么？",
        "L1、L2正则化的效果、区别、原理是什么？",
        "请简单阐述决策树、回归、SVM、神经网络等算法各自的优缺点。",
        "对于非线性的数据，SVM如何处理？",
        "回归树是什么？回归树是如何工作的？",
        "分类属性选择完成，对训练样本分类时发现属性缺失怎么办？",
        "训练完成后，给测试集样本分类时有缺失值怎么办？",
        "为什么信息增益偏向取值较多的特征？",
        "什么是特征选择？",
        "什么是过拟合？",
        "决策树的数据 split 原理或者流程是什么？",
        "GBDT 在训练过程中如何选择特征？",
        "KNN 的 K 值如何选取？",
        "RF 为什么比 bagging 效率高？",
        "RF 为什么能够更鲁棒？",
        "RF 在分类和回归问题中如何预测 y 值？",
        "为什么 RF 的树比 GBDT 的要深一点？",
        "为什么要随机抽样？",
        "K-means 不适用哪些数据？",
        "为什么要有放回的抽样？",
        "梯度提升如何调参？",
        "为什么不用全样本训练？",
        "为什么要随机特征？",
        "聚类和分类有什么区别？",
        "决策树需要剪枝吗？",
        "RF 与决策树的区别是什么？",
        "MBGD 需要注意什么？",
        "决策树算法的停止条件是什么？",
        "list 头上删除元素的方法是什么？",
        "字符串拼接有哪些方式？",
        "PyTorch 中 cuda() 的作用是什么？两个 Tensor，一个调用了 cuda()、一个没调用，相加会怎样？",
        "在 C++ 里面智能指针有哪些？",
        "基尼系数（Gini）存在的问题是什么？",
        "如何避免过拟合问题？",
        "构造决策树的步骤是什么？",
        "AdaBoost 的迭代次数（基学习器的个数）如何控制？",
        "什么是支持向量机？SVM 与 LR 的区别是什么？",
        "朴素贝叶斯（Naive Bayes）法的要求是什么？",
        "训练集中类别不均衡时，哪个评估指标最不准确？",
        "什么是机器学习的欠拟合？",
        "什么是线性回归？",
        "回归方法中使用的评价指标有哪些？",
        "XGBoost 使用泰勒二阶展开的原因是什么？",
        "XGBoost 在什么地方做的剪枝？",
        "XGBoost 参数调优的一般步骤？",
        "XGBoost 如何分布式？",
        "XGBoost 可以并行训练的原因？",
        "XGBoost 防止过拟合的方法？",
        "XGBoost 中叶子结点的权重如何计算出来？",
        "XGBoost 中的一棵树的停止生长条件？",
        "生成模型和判别模型基本形式有哪些？",
        "分类算法有哪些？",
        "LR 参数求解的优化方法有哪些？",
        "为什么要处理类别特征？",
        "分类中使用的损失函数有哪些？",
        "如何避免欠拟合问题？",
        "模型低偏差和高方差时，应该使用哪种算法来解决？",
        "不平衡样本会给 KNN 预测结果造成哪些问题，如何解决？",
        "什么是组合特征？",
        "决策树的优缺点是什么？",
        "怎么理解偏差方差的平衡？",
        "stacking 和 blending 的区别是什么？",
        "对于小数据集一般怎么处理？",
        "为什么属性独立性假设在实际情况中很难成立，但 NB 仍能取得较好效果？",
        "交叉验证主要有哪几种方法？",
        "决策树和条件概率分布的关系是什么？",
        "怎么有效地找到组合特征？",
        "什么是 K 折交叉验证？",
        "把分类变量当成连续型变量会更得到一个更好的预测模型吗？",
        "如何在 K 折交叉验证中选择 K？",
        "常用核函数及核函数的条件？",
        "需要归一化的算法有哪些？",
        "神经网络激活函数？",
        "AUC 为什么稳定？",
        "Adaboost、SVM、LR、Knn、KMeans 之类是否需要归一化？",
        "LR 的推导，特性？",
        "SGD 的推导？",
        "SVM 的损失函数是什么形式？",
        "SVM 的推导，特性？",
        "lr 使用注意事项，相比别的分类模型为什么使用它？",
        "python常用的加锁方式？",
        "交叉验证的作用是什么？",
        "什么是全局解释器锁？",
        "什么是同步锁？",
        "什么是正态分布？",
        "什么是死锁？",
        "向量代表什么？特征向量有什么性质，是单位向量吗？",
        "决策树的特性？",
        "处理死锁的基本方法？",
        "如果 XTX 矩阵不可逆，是奇异矩阵怎么办呢？",
        "如何判断函数凸或非凸？",
        "如何理解正则化？",
        "如何进行剪枝？",
        "如何选择 m？",
        "对稀疏矩阵的理解？",
        "怎么使用同步锁？",
        "采样是有放回还是无放回？",
        "什么是曼哈顿距离？",
        "有哪些并行化的工具？",
        "树模型对于缺失值如何处理？比如该节点是根据 a 属性划分，但是待分类样本 a 属性缺失，怎么办呢？",
        "梯度下降中局部最优解和全局最优解的关系？",
        "死锁产生的必要条件？",
        "特征分布式和数据分布式的区别是什么？",
        "特征选择的目标是什么？",
        "维度灾难是什么？",
        "预测函数与代价函数的关系，在矩阵分解中如何体现的？",
        "LR 和 DNN 联系和区别是什么？",
        "XGBoost 的原理能讲一下吗？",
        "最近关注的论文有哪些？多模态视觉大模型（CLIP、DALLE）？",
        "BLIP-2 的架构是什么？优势以及与之前多模态模型的区别是什么？",
        "BERT 输入输出表征长啥样？",
        "BERT 如何 fine-tuning？",
        "文本分类任务使用的评估算法和指标有哪些？",
        "个具体的文本分类任务可以使用哪些特征？",
        "BERT 预训练任务有哪些？",
        "为什么说「词汇增强」方法对于中文 NER 任务有效？",
        "N-gram 最大概率分词是什么？",
        "BERT 为什么需要预训练任务 Masked LM？",
        "BERT 预训练任务 Masked LM 存在什么问题？",
        "预训练和微调之间的不匹配有哪些解决方法？",
        "BERT 三个关键点是什么？",
        "ALBERT 所用的方法是什么？",
        "BERT 为什么需要预训练任务 Next Sentence Prediction？",
        "BERT 预训练任务 Next Sentence Prediction 怎么做？",
        "BERT 的输入有哪几种 Embedding？",
        "NER 标注数据噪声问题如何处理？",
        "NER 标注数据不均衡问题如何处理？",
        "词向量选取：词向量和字向量如何选择？",
        "为什么不直接蒸馏为一个浅层 BERT？",
        "分词结果会把两个词合并，那么合并与否对LDA的训练是否有影响呢？",
        "Deep Norm 代码实现？",
        "Layer normalization？",
        "Norm 的计算公式写一下？",
        "什么是 LLMs 复读机问题？为什么会出现 LLMs 复读机问题？如何缓解 LLMs 复读机问题？",
        "介绍一下使用 GeLU 作为激活函数的 GLU 块计算公式？",
        "介绍一下使用 Swish 作为激活函数的 GLU 块计算公式？",
        "将词表示成向量被称为神经词嵌入（Neural Word Embeddings）吗？",
        "层归一化（Layer Norm）在大语言模型（LLMs）中的不同位置有什么区别？",
        "排列语言模型（Permutation Language Models）的特点是什么？",
        "相同的词可以通过什么方式实现多个词嵌入？",
        "词嵌入向量是否有助于确定两个 tokens 之间的距离？",
        "词嵌入是否捕获多维数据并表示为向量？",
        "词转化为其基本形式的过程是什么？",
        "将数据转换为整数或浮点向量的操作是什么？",
        "文本分类任务有哪些应用场景？",
        "文本分类的具体流程？",
        "文本分类任务使用的评估指标有哪些？",
        "在做NER任务时，LSTM后面可以不用加CRF吗？",
        "统计语言模型如何应用于分词？N-gram最大概率分词？",
        "赋值时是浅拷贝还是深拷贝？",
        "Python 的深拷贝和浅拷贝的区别是什么？赋值时是浅拷贝还是深拷贝？",
        "什么是 Python 中的生成器和迭代器？",
        "装饰器怎么用？装饰器解释下，基本要求是什么？",
        "谈下 Python 的 GIL？",
        "可不可以采取类似于上面的subword的思路来产生更好的word embedding呢？",
        "embedding 的物理意义是什么？",
        "embedding 的作用是什么？",
        "向量化模型有哪些？",
        "向量库有哪些？各自优点与区别是什么？",
        "RAG 存在什么问题？",
        "什么是 RAG？",
        "介绍一下 RAG 典型实现方法？",
        "介绍一下 RAG 典型案例？",
        "RAG 有哪些评价方法？",
        "RAG 调用模式有几种？",
        "什么是糖尿病？",
        "冠心病怎么治疗？",
        "冠心病的治疗方法有哪些？",
        "什么是冠心病？",
        "冠心病的症状是什么？",
        "什么是大模型？",
        "介绍一下强化学习中Value-based的优化方法？",
        "介绍一下强化学习中的贝尔曼方程？",
        "介绍一下强化学习中的优势函数（Advantage Functions）？",
        "强化学习有哪些Policy策略？",
        "介绍一下强化学习的轨迹？",
        "介绍一下强化学习的奖赏函数？",
        "介绍一下强化学习问题？",
        "介绍一下强化学习的状态（States）和观测（Observations）？",
        "介绍一下强化学习？",
        "RLHF 训练过程，怎么选取最优 checkpoint？",
        "什么是 PPO 中采样过程？",
        "具体介绍一下 有监督微调（Supervised Tinetuning）？",
        "介绍一下 PPO 中采样策略？",
        "有监督微调（Supervised Tinetuning）的训练数据格式是什么样？",
        "预训练（Pre-training） vs 有监督微调（Supervised Tinetuning）区别？",
        "InstructGPT 的原理：讲讲 RLHF 和 reward？",
        "强化学习不同于其它学习算法的原因是什么？",
        "强化学习的马尔科夫性质是什么？",
        "TD(λ) 方法中，当 λ=0 时与哪种方法等价，λ=1 呢？",
        "TD3 和 DDPG 的区别是什么？",
        "TD3 如何解决过估计问题？",
        "在 actor-critic 框架中，critic 起什么作用？",
        "advantage（优势函数）如何推导，如何计算？",
        "on-policy 和 off-policy 的区别与联系是什么？各自的优缺点是什么？",
        "SARSA 的公式是什么？与 Q-learning 的区别是什么？",
        "value-based 和 policy-based 方法的区别与关系是什么？",
        "为什么不打破数据相关性会导致神经网络训练效果不好？",
        "为什么 Policy 输出的动作需要采样（sample），而不是直接使用？",
        "为什么连续动作环境下 DDPG 的表现可能不如将动作离散化后用 Q-learning？",
        "什么是 DDPG？请画出 DDPG 框架结构图。",
        "什么是 Importance Sampling（重要性采样）？",
        "你做过哪些强化学习项目？遇到的难点有哪些？",
        "值迭代和策略迭代的区别是什么？",
        "请写出用第 n 步的值函数更新当前值函数的公式（1-step、2-step、n-step）。当 n 变大时，期望和方差如何变化？",
        "请写出蒙特卡洛、TD 和 TD(λ) 三种方法更新值函数的公式。",
        "请写出贝尔曼期望方程和贝尔曼最优方程。",
        "在一个强化学习场景中，状态是什么？当前状态如何转移到下一状态？",
        "基于值函数方法的算法有哪些？",
        "多臂老虎机与强化学习的差别是什么？",
        "多臂老虎机算法有哪些分类？",
        "如何理解用平均 KL 散度代替最大 KL 散度？",
        "你怎么看 DRL 在机器人上的应用？",
        "如何处理 hard exploration 问题？",
        "对于包含多个 entity 的 observation，你会怎么预处理？",
        "常见的平衡探索与利用的方法有哪些？",
        "强化学习中如何做归一化？",
        "强化学习中如何解决高维输入输出问题？",
        "强化学习与监督学习、无监督学习的区别是什么？",
        "强化学习在机器人上的局限性有哪些？",
        "强化学习如何判断是否收敛？",
        "强化学习如何应用在推荐系统中？",
        "强化学习是什么？",
        "强化学习用来解决什么问题？",
        "强化学习的损失函数是什么？",
        "是否了解过奖励函数的设置(reward shaping)？",
        "是否用某种DRL算法玩过Torcs游戏？",
        "有那几种Bandit算法？",
        "深度强化学习中的DQN和A3C区别与联系？",
        "策略梯度和actor-critic的关系与对比？",
        "策略梯度方法中基线baseline如何确定？",
        "策略梯度的推导过程？",
        "简述AI-GAs？",
        "简述Multi-Agent Reinforcement Learning？",
        "简述Neural-Symbolic Learning的方法？",
        "简述Pointer Network？",
        "简述Transformer？",
        "简述go-explore？",
        "简述 sim2real？",
        "简述值函数逼近的想法？",
        "简述动态规划(DP)算法？",
        "简述重要性采样与Thompson sampling？",
        "蒙特卡洛、TD、动态规划的关系？",
        "蒙特卡洛和时间差分的对比：MC和TD分别是无偏估计吗，为什么？",
        "请简述IQL（independent Q-learning）的算法过程？",
        "重要性采样的推导过程与作用？",
        "从Q-learning的算法中可以看出，其行为策略为ε-greedy策略，目标策略是greedy策略，因此属于off-policy方法。那么为什么没有用重要性采样呢？",
        "奖赏函数如何设计，有没有奖赏延迟问题？",
        "如何让agent足够diverse？",
        "引入状态奖励的是哪种？",
        "比如MADDPG比较早的，思想是什么？",
        "神经网络要怎么构建？",
        "SSRF 有哪些常见的利用方式？",
        "SSRF 的攻击原理是什么？",
        "什么是 Redis 哈希槽？",
        "什么是 DDoS 攻击？如何防范？",
        "什么是 Metasploit 框架？",
        "什么是 SSRF（服务器端请求伪造）？",
        "什么是交换机？",
        "什么是加密算法？有哪些常见的加密算法？",
        "什么是安全事件响应？",
        "什么是安全运营工程师？",
        "什么是数字证书？有什么作用？",
        "什么是渗透测试？",
        "什么是漏洞扫描？",
        "什么是社会工程学攻击？如何预防？",
        "什么是跨站点脚本攻击？如何防范？",
        "什么是路由器？",
        "什么是远程桌面协议（RDP）攻击？如何避免？",
        "什么是防火墙？它的作用是什么？",
        "什么是黑客攻击？如何预防？",
        "加密在网络上的重要性是什么？",
        "动态场景：当点云随时间移动，如何增量更新哈希表？",
        "如何使用 Python 实现哈希表？",
        "如何检测 WebShell？",
        "如何解决 XSS 攻击问题？",
        "如何进行安全漏洞扫描？",
        "如何进行安全漏洞管理？",
        "如何防御和修复 SSRF 漏洞？",
        "如何防止网络钓鱼攻击？",
        "如何防范恶意软件攻击？",
        "如何验证存在 XSS 漏洞？",
        "怎么检测 CSRF？",
        "怎么进行横向移动？",
        "端口号是什么？",
        "支持一致性哈希的客户端有哪些？",
        "渗透测试中常用的网络协议分析工具有哪些？",
        "渗透测试中的网络钓鱼攻击是什么？",
        "如果看到一个告警 IP，如何判断是否是真实攻击？",
        "FasterTransformer 的核心是什么？",
        "Transformer 判别器如何加 SN？",
        "与 Transformer-based 检测头结合时，DFL 是否还有优势？",
        "如果未来 Transformer Decoder 替代 CNN，通道数还会是 2 的幂次吗？",
        "BERT 的 mask 为何不在 attention 处进行屏蔽 score 的操作？",
        "为什么 Transformer 用 Layer Norm？",
        "BERT 中为什么要在开头加个 [CLS]？",
        "Multi-head self-attention 里，为什么这样做？",
        "Self-attention 部分怎么计算的？",
        "BERT 是如何处理 OOV 的语义学习的？",
        "Transformer 哪里做了权重共享？",
        "中文如何处理溢出词表词（OOV）的语义学习？",
        "为什么 BERT 的三个 Embedding 可以进行相加？",
        "为什么可以做权重共享？",
        "为什么在进行 softmax 之前需要对 attention 进行 scaled（为什么除以 dk 的平方根）？",
        "什么是 BERT 模型？",
        "什么是 Transformer 及其架构？",
        "什么是层归一化（Layer Normalization）？",
        "什么是预训练和微调（Fine-tuning）？",
        "Transformer 可以做并行化吗？",
        "为什么能舍弃使用 norm 时被丢弃的其他维度信息？",
        "Transformer 中使用了什么激活函数？",
        "国外开源的 LLaMA 词表兼容中文效果可能会大打折扣，扩充词表该怎么做？",
        "它与传统的 RNN 和 CNN 有何不同？",
        "它与原始的 Transformer 有何不同？",
        "既然前面说了是 CV 中用 BN，那为什么 NLP 中不用 BN，而用 LN 呢？",
        "简单介绍一下 Transformer 的位置编码，它在 Transformer 中有什么作用？",
        "为什么 [CLS] 可以建模整句话的语义表征呢？",
        "什么是 Keras 搭建 CNN？",
        "CNN 拆成 3×1 和 1×3 卷积的优点是什么？",
        "什么是 CNN VS RNN？",
        "什么是 CNN-LSTMs？",
        "为什么检测常用 max pooling，而分类常用 average pooling？",
        "CNN 的优缺点是什么？",
        "CNN 怎么做文本分类？优势是什么？缺点是什么？",
        "CNN 在文本中的用法是什么？Pooling 的作用是什么？",
        "CNN 算法的原理是什么？Word2vec 的特点是什么？",
        "数据预处理是否做了图像增强？为什么要这样做？样本中有没有噪声？怎么处理噪声？",
        "SSD、YOLO 和 R-CNN 的区别是什么？",
        "TextCNN 的结构是什么？卷积核的层数应该怎么取？",
        "RNN 和 CNN 的区别是什么？",
        "详细推导一下 CNN 模型的工作原理。",
        "CNN 和 Transformer 相比有什么区别？",
        "介绍下 YOLOv8 算法的模块。",
        "什么是 Dilated CNN（空洞卷积）？",
        "为什么会有 Dilated CNN（空洞卷积）？",
        "Dilated CNN（空洞卷积）的优点是什么？",
        "CNN-CRF vs BiLSTM-CRF vs IDCNN-CRF 有什么区别？",
        "TextCNN 中的 pooling 操作与一般 CNN 的 pooling 操作有何不同？",
        "CNN 拆成 3x1 和 1x3 的优点是什么？",
        "什么是 Keras搭建RNN？",
        "什么是 RNN扩展改进？",
        "什么是 Bidirectional RNNs？",
        "什么是 Bidirectional LSTMs？",
        "反序列化漏洞原理是什么？",
        "请解释LSTM中遗忘门的计算公式以及其作用？",
        "如何用 Ring Attention 将序列拆分到 64 卡并计算通信开销？",
        "当序列长度 128k 时，如何采用 FlashAttention-2 减少显存？",
        "如何采用 fribidi 库处理阿拉伯语双向文本？",
        "Transformer 模型介绍及与 RNN/LSTM 的区别是什么？",
        "RNN 的优缺点是什么？",
        "RNN 原理是什么？",
        "讲讲LSTM 和实习项目中做的改进？",
        "怎么理解“长短时记忆单元”？RNN 中的隐状态 ht 与 LSTM 中的记忆状态 Ct 有什么区别？",
        "LSTM 与GRU 关系是怎样的？",
        "elmo 为什么用的是两层单向的LSTM 而不是 bi-LSTM？",
        "LSTM 的计算过程是什么？请举例说明每一步各个参数的维度和变化。",
        "隐马尔科夫算法中两个序列是什么？",
        "隐马尔科夫算法序列标注（解码）过程是什么样的？",
        "什么是基于(Bi-)LSTM的词性标注？",
        "LSTM 和 GRU 的原理是什么？",
        "LSTM 跟 RNN 有什么区别？",
        "LSTM 与 GRU 有什么区别？",
        "LSTM 的产生原因是什么？",
        "为什么 LSTM 比 RNN 好？",
        "LSTM、RNN、GRU 有什么区别？",
        "Oracle 数据库中的序列（Sequence）是什么？",
        "回归预测和时间序列预测的区别是什么？",
        "比较LR和GBDT，说说什么情景下GBDT不如LR？",
        "为什么XGBoost的近似算法比lightgbm慢很多呢？",
        "RF与决策树的区别？",
        "Gradient boosting算法(GBM)和随机森林都是基于树的算法，它们有什么区别？",
        "阐述GBDT、xgboost、lightGBM的异同，xgb的优势，lgb的优势，二者的并行如何",
        "tf-idf 的原理是什么？",
        "word2vec 和 fastText 对比有什么区别？",
        "请简述 CBOW 和 fastText 之间的区别？",
        "word2vec 伪代码推导是什么？",
        "word2vec 与 LDA 模型之间的区别和联系是什么？",
        "WordPiece 算法如何选择相邻子词进行合并加入词表？",
        "文本相似度计算常用算法有哪些，tfidf和textrank的不同和适用场景是什么？",
        "如何将词向量转句向量？",
        "名词解释：点击率CTR、转化率CVR是什么？",
        "当示例顺序改变导致结果抖动 >8% 时，如何采用排序熵进行稳定性筛选？",
        "如何采用 HNSW 的增量插入算法并设置 efConstruction 保证召回？",
        "写个堆排序。",
        "有哪些矩阵分解的方法？",
        "BLOB 和 TEXT 类型之间的唯一区别是什么？",
        "What contribution did you make to your current (previous) organization？",
        "如何对图片提取OCR+布局信息并生成统一向量表示？",
        "有哪些语义分割的网络，简述U-Net 特点",
        "销售额下降了如何分析？",
        "在浏览器中输入URL并按下回车之后会发生什么？",
        "从输入URL到页面展示发生了什么？",
        "URL和URI是什么？",
        "去中心化在web3中的重点是什么？去中心化如何帮助创建用户数据存储和管理的分布式模型？",
        "区块链如何为智能合约提供不可篡改的存储介质？",
        "如何查看DeepSpeed的环境配置是否正确？",
        "如何监控各任务在验证集上的loss曲线并自动触发Early Stopping？",
        "如何采用强化学习策略决定压缩时机与长度？",
        "如何评估在线RLHF对留存率的提升？",
        "介绍一下强化学习中的优化方法 Value-based？",
        "介绍一下强化学习中的优势函数 Advantage Functions？",
        "t-SNE 无法在线部署，如何设计“轻量级可视化”供生产环境实时监控？",
        "我应该启动一个集群分片（sharded）还是一个非集群分片的 MongoDB 环境?",
        "在 Nginx 中，解释如何在 URL 中保留双斜线?",
        "测试环境是谁搭建的？",
        "IPS 和 IDS 有什么区别？",
        "reverse_tcp 和 bind_tcp 有什么区别？",
        "Cookie 和 Session 有什么区别？",
        "通过扫描和抓包时，HTTPS 和 HTTP 有什么区别？",
        "请描述 HTTP、HTTPS 分别是什么协议，它们的作用及端口号？",
        "在 OSI 参考模型方面，TCP/IP 应用层的等同层或多层是什么？",
        "OSI 会话层的功能是什么？",
        "说说 DNS 的解析过程？",
        "DNS 是什么？",
        "HTTP 特性与简述",
        "HTTP 版本演变",
        "HTTP/1.1 协议的性能问题有哪些？",
        "HTTP/2 并发是如何实现的？",
        "公有 IP 地址由谁管理？",
        "如何缓解 IPv4 地址耗尽的问题？",
        "路由器与交换机的区别是什么？",
        "路由器的基本原理是什么？",
        "什么是 TCP 粘包问题？如何解决 TCP 粘包问题？",
        "TCP粘包和拆包问题是什么？如何处理粘包和拆包？",
        "UDP会不会产生粘包问题？",
        "HTTP/1.0 和 HTTP/1.1 的区别是什么？",
        "HTTP/1.1 有哪些特性？",
        "HTTP/2.0 和 HTTP/1.1 有什么区别？",
        "TCP 与 UDP 的区别是什么？",
        "TCP KeepAlive 是什么？",
        "TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是一个东西吗？",
        "Cookie 和 Session 是什么？",
        "Cookie 的工作原理是什么？",
        "Session 的工作原理是什么？",
        "HTTP 请求过程是怎样的？",
        "描述一种区块链的扩容技术（如侧链或闪电网络）。",
        "如何使用 Apex 或 TorchScript 等工具来优化模型性能？",
        "介绍一下 BLIP/BLIP2 的原理。",
        "当注释长度限制 80 字时，如何采用指针生成网络进行压缩？",
        "千亿模型 checkpoint 约 200GB，网络拷贝耗时 10 分钟，如何做到秒级回滚？",
        "流水线并行（Pipeline Parallelism）图解？",
        "BLIP-2 的架构、优势以及与之前多模态模型的区别是什么？",
        "训练时网络不收敛怎么办？类别不平衡怎么办？在数据和模型都与他人相同的情况下如何排查？",
        "怎么看待计算机网络和操作系统在深度学习中的作用？",
        "如何判断网络上是否有原题？",
        "描述一种区块链扩容技术（如侧链或闪电网络）。",
        "HTTPS 的特点是什么？",
        "UDP 组播发送时目标地址填组播地址，组播组内的机器都能收到数据包吗？",
        "IP 协议是什么？",
        "产生 TCP 粘包和拆包的原因是什么？",
        "TCP 中 Nagle 算法的作用是什么？",
        "TCP 和 UDP 的概念和特点是什么？",
        "HTTPS 三次握手流程是什么？",
        "TCP 和 UDP 的区别是什么？",
        "HTTP 与 HTTPS 的区别是什么？",
        "什么是 HTTP 无状态协议？如何解决 HTTP 无状态带来的问题？",
        "HTTPS 的工作原理是什么？",
        "DistCp 的原理是什么？",
        "端侧 INT8 部署如何保持 Lipschitz 约束？",
        "Lipschitz 约束如何实现？",
        "请解释 ueuued.max.requests 的含义是什么？默认值是多少？",
        "Kafka 中 acks=0 的含义是什么？会带来哪些可靠性影响？",
        "请解释 ngx_http_upstream_module 的作用是什么？",
        "TCP 的三次握手过程是什么？",
        "TCP/IP 三次握手的过程以及对应的状态转换是什么？",
        "HTTP/1.0、HTTP/1.1、HTTP/2.0 的区别是什么？",
        "判断是否存在 CDN 的方法有哪些？如何绕过 CDN 找到网站真实 IP？",
        "抓包分析 HTTPS 和 HTTP 有什么区别？",
        "什么是 tcpdump？如何使用它进行抓包分析？",
        "什么可以被认为是好的密码？",
        "网络拓扑如何影响你在建立网络时的决策？",
        "等保测评中的网络安全管理主要包括哪些方面？",
        "等保测评中的网络安全技术主要包括哪些方面？",
        "等保测评中的网络安全事件处置主要包括哪些方面？",
        "等保测评中的网络安全监测主要包括哪些方面？",
        "请描述 HTTP、HTTPS 分别是什么协议，作用，以及端口号？",
        "什么是代理服务器？它们如何保护计算机网络？",
        "说说 WebSocket 与socket 的区别",
        "说下HTTP/1.0，1.1，2.0 的区别",
        "Https 流程是怎样的？",
        "Http 请求的过程与原理是什么？",
        "Give me a summary of your current job description.",
        "什么是 DNS服务器？其工作原理是什么？",
        "TCP 3次握手和4次挥手是什么？",
        "http/https 的区别是什么？",
        "匿名管道和命名管道之间的区别是什么？",
        "信号和信号量有什么区别？",
        "Redis 是单线程吗？",
        "Redis 为什么又要引入多线程？",
        "如何处理关键帧（可以参考 ORBSLAM2 中的 Tracking 线程）？",
        "DDP 通过多进程实现，也就是说操作系统会为每个 GPU 创建一个进程，从而避免了 Python 解释器 GIL 带来的什么问题？",
        "如何设计迭代级调度算法并计算平均吞吐提升？",
        "当 prefill 与 decode 阶段计算密度差异 10× 时，如何分离调度？",
        "当插件崩溃时，如何采用沙箱进程防止主服务宕机？",
        "如何设置稀疏度调度从 0% 到 90% 并保证收敛？",
        "什么是自动内存管理（Automatic Memory Management）？",
        "Oracle 系统进程主要有哪些？分别有什么作用？",
        "RFS、LNSn、MRP、LSP 进程的作用分别是什么？",
        "Manager 进程是 OGG 的控制进程，运行在源端和目标端上。它的主要作用是什么？",
        "如果 blockDim.x 不是 32 的整数倍，最后一条 warp 不足 32 线程怎么办？",
        "线程间通信中，wait和notify的理解和使用？",
        "进程和线程的区别？",
        "线程的几种状态？",
        "线程池的优点？",
        "线程池的作用？",
        "产生死锁的条件？",
        "请写出实现线程安全的几种方式？",
        "线程池的工作原理及几个重要参数？",
        "线程池的拒绝策略都有哪些？",
        "Redis单线程还能处理速度那么快，原因是什么？",
        "Spark的工作流程是什么？",
        "Spark的调度流程是什么？",
        "Spark的任务调度原理是什么？",
        "Spark的任务提交和执行流程是什么？",
        "死锁避免和死锁预防的区别是什么？",
        "公平调度器容器为什么集中在同一个服务器上？",
        "用户进程间通信主要有哪几种方式？",
        "请解释Nginx服务器上的Master和Worker进程分别是什么？",
        "Redis回收进程如何工作的？",
        "Oracle 19c 中的多线程服务器（MTS）模式是如何工作的？",
        "进程 mman、mmnl 和 mmon 这 3 个进程的作用分别是什么？",
        "Gauss-Newton 和最快下降法混合方法是 Dog-Leg 法，代替阻尼项，用 trust region：请解释其原理？",
        "在讲解这段代码如何运行之前，我们先回顾下传统 Java 程序的运行方式？",
        "How would you go about establishing your credibility quickly within the team?",
        "请阐述 Python 中迭代器的概念。",
        "请解释 Python 中生成器有什么作用？",
        "Python 是解释语言还是编译语言？",
        "Python 中 range 和 xrange 的区别？",
        "Python 中列表和元组的区别？",
        "Python 中互换变量有不用创建临时变量的方法吗？讲讲原理。",
        "Python 中的可变对象和不可变对象？",
        "Python 中的实例方法、静态方法和类方法三者区别？",
        "Python 中 remove、del 以及 pop 之间的区别？",
        "Python 中 is 和 == 的区别，两者分别在比较什么？",
        "如何用 Python importlib 实现插件运行时加载并隔离命名空间？",
        "Python2 和 Python3 的 range(100) 的区别？",
        "Python 的深拷贝和浅拷贝的区别？赋值时浅拷贝还是深拷贝？",
        "Python 中列表（List）中的 del、remove、pop 的用法和区别是什么？",
        "@property、@staticmethod、@classmethod 装饰器的用法和区别是什么？",
        "Python 中的私有变量应该如何定义和访问？",
        "Python 中单下划线前缀/后缀和双下划线前缀/后缀的含义和区别是什么？",
        "Python 退出时，是否会清除所有分配的内存？",
        "请解释一下 Python 的垃圾回收机制。",
        "解释 Python 装饰器的工作原理。",
        "dir() 函数的作用是什么？",
        "Python 中是否需要缩进？为什么？",
        "Java 集合类 List、Set、Queue、Map、Stack 的特点与用法是什么？",
        "Java 的基础类型及其字节大小分别是多少？",
        "Java 中 == 和 equals() 的区别是什么？",
        "Java 的多态体现在哪里？",
        "Java 创建对象的几种方式有哪些？",
        "Java 的内存划分是怎样的？",
        "什么是 Java 内存模型？",
        "Java 对象创建过程是怎样的？",
        "Java 中的引用类型有哪几种？",
        "Java 中 notify 和 notifyAll 的区别是什么？",
        "Java 中 interrupted() 和 isInterrupted() 的区别是什么？",
        "Spring AOP（面向切面）编程的原理是什么？",
        "如何自定义类继承 Partitioner 并重写 getPartition() 方法？",
        "Scala 和 Java 有什么区别？",
        "如何继承 Thread 类并重写 run() 方法？",
        "Python中的可变对象和不可变对象有何区别？",
        "什么是图灵完备语言？ Python是图灵完备语言吗？",
        "Python支持多重继承吗？谈谈它的优点和缺点。",
        "使用 Django框架开发 web应用的基本步骤是什么？",
        "当Python退出时，是否会清除所有分配的内存？",
        "什么是 Python的元类？",
        "GoldenGate 的作用是什么？",
        "牛顿法原理是什么？",
        "什么是数据增强？为什么需要它？有哪些增强方法？",
        "LSTM遗忘门的作用是什么？",
        "LSTM输入门的作用是什么？",
        "LSTM输出门的作用是什么？",
        "反向传播中的链式求导法则如何使用？",
        "归一化和标准化的区别是什么？",
        "小批量梯度下降（MBGD）需要注意什么？",
        "如何选择mini-batch大小m？",
        "为什么逻辑回归（LR）要使用sigmoid函数？",
        "工程上怎么实现LR的并行化？有哪些并行化工具？",
        "LR与最大熵模型（MaxEnt）的关系是什么？",
        "采用分箱技术时，需要确定哪些关键问题？",
        "对大量未知标注的数据集，按数据的内在相似性将数据集划分为多个类别，使类别内的数据相似度较大而类别间的数据相似度较小：这描述的是什么算法/任务？",
        "K值的如何选取？",
        "K-means 中常用的距离度量？",
        "PCA其优化目标是什么？",
        "常见的应急排查方式有哪些？",
        "入侵之后如何做权限维持？应急时发现了权限维持，那么怎么解决？",
        "socks代理原理是什么？",
        "什么是端口扫描？如何防止端口扫描？",
        "什么是端口扫描？它可以用于什么目的？",
        "什么是安全审计？它的目的是什么？",
        "什么是安全事件响应计划？它的作用是什么？",
        "什么是 SOC（安全运营中心）？它的作用是什么？",
        "什么是多因素身份验证？为什么它比单一因素身份验证更安全？",
        "什么是等保测评？等保测评的主要目的是什么？",
        "等保测评的评估周期是多长时间？",
        "等保测评的实施流程是什么？",
        "建立 VLAN 的一个基本要求是什么？",
        "简要描述 NAT 的作用及优缺点。",
        "什么是数字签名？什么是数字证书？",
        "简要描述交换机的工作原理。",
        "层交换机的作用是什么？",
        "交换机如何进入配置界面？",
        "OSPF 的主要目的是什么？",
        "描述什么是端口号。",
        "ARP 是如何知道对方的 MAC 地址的？",
        "NAT 有缺点吗？",
        "GET 和 POST 请求的区别是什么？",
        "单目相机原理是什么？",
        "ToF 相机原理是什么？",
        "相似变换、仿射变换、射影变换的区别是什么？",
        "单应矩阵和基础矩阵的区别是什么？",
        "SVO 中深度滤波器原理是什么？",
        "SURF 跟 SIFT 的区别是什么？",
        "如何求解 Ax=b？",
        "g2o 流程是什么？",
        "Ceres 流程是什么？",
        "如何对匹配好的点做进一步的处理，以更好保证匹配效果？",
        "描述下 GN、LM 方法。",
        "为什么要引入李群李代数？",
        "什么是极线约束（对极几何约束）？",
        "EKF 和 BA 的区别是什么？",
        "常用的边缘检测算子有哪些？各自优缺点是什么？",
        "如何优化重投影误差？采用什么方法求解？如果误匹配的点重投影之后误差很大，如何解决它对整个优化问题的影响？",
        "组成镜头达到小孔成像的原理是什么？感光显像是通过胶片、CCD 和 CMOS 吗？",
        "SVO 中深度滤波器的原理是什么？",
        "SURF 和 SIFT 的区别是什么？",
        "如何对匹配好的点做进一步处理以保证匹配效果？",
        "PnP 问题的常见求解方法有哪些（DLT、P3P、EPnP、UPnP、非线性优化）？",
        "P3P 方法的原理是什么？",
        "Ceres 的流程是什么？",
        "描述 GN 和 LM 方法。",
        "LM 中阻尼因子 μ 的作用是什么？",
        "为什么要引入李群和李代数？",
        "位置信息丢失时如何重新确定自己的位置？",
        "常用的边缘检测算子有哪些？各自的优缺点是什么？",
        "如何优化重投影误差？采用什么方法？",
        "PoW（工作量证明）和 PoS（权益证明）有什么区别？",
        "用一句话讲一下 AMM 机制？",
        "你玩过哪些应用？",
        "请描述你在项目中遇到的困难、解决问题的方法，以及你与团队如何合作克服障碍并取得结果？",
        "解释什么是工作量证明（PoW）以及如何实现它？",
        "什么是委托权益证明（DPoS），与 PoS 有何不同？",
        "什么是去中心化交易所（DEX），与传统交易所有何不同？",
        "PoW 和 PoS 有什么区别？",
        "什么是 Gas？",
        "研发期间遇到过什么问题？",
        "OpenSea 和 LooksRare 的区别？",
        "权益证明（PoS）机制的工作原理是什么？与 PoS 有何不同？",
        "描述加密货币钱包的工作原理及其安全？",
        "自的优缺点是什么？",
        "解释什么是非同质化代币（NFT）及其？",
        "合约中的安全风险？",
        "Monero）是如何工作的？",
        "softmax 和 sigmod 区别？",
        "5 基于批内负采样的对比学习方法",
        "MLP+softmax层怎么介绍？",
        "TF-IDF 的应用是什么？",
        "pdfplumber 如何进行表格抽取？",
        "LLaMA 2 中 Margin Loss 的实现逻辑是什么？",
        "多查询生成技术如何实现（提示工程）？",
        "如何解决未能提取答案问题？",
        "如何解决脱离上下文的问题？",
        "LLaMA 2 中两个 RM 模型的实现逻辑是什么？",
        "模型显存占用有哪些优化策略？",
        "RRF 的技术实现是什么？",
        "KL 散度与交叉熵的区别是什么？",
        "Pretrain 阶段，为什么需要拼接拼接？",
        "不同 ZeRO 如何配置？",
        "为什么单卡的情况也可以使用 DeepSpeed？",
        "介绍一下 gradient checkpointing 的显存优化方式？",
        "如何准确衡量模型的推理速度？",
        "如何配置安装 pdsh？",
        "RAG-Fusion 优势？",
        "什么是 RAGAS？",
        "什么是 ZeRO-2？",
        "分布式并行及显存优化技术有哪些，都有什么特点？",
        "显存优化技术有哪些，都有什么特点？",
        "RAG-Fusion 挑战？",
        "什么是 ZeRO-3？",
        "什么是 ZeRO-stage-0？",
        "为什么第一块卡的显存会占用的更多一些？",
        "多向量检索器多模态 RAG 是什么？",
        "什么是 ZeRO-stage-1？",
        "模块化 RAG 优化策略有哪些？",
        "RAG 新模式优化策略有哪些？",
        "bit 量化优化主要用于优化静态显存吗？",
        "_find_and_replace() 的实现思路是什么？",
        "AdapterDrop 的思路是什么？",
        "AdapterDrop 的特点是什么？",
        "AdapterFusion 的思路是什么？",
        "BPE 是否是选择频次最大的相邻子词合并？",
        "DistributedDataParallel（DDP）有哪些优点？",
        "DistributedDataParallel（DDP）有哪些缺点？",
        "DP 只支持单机多卡场景吗？在多机多卡场景下 DP 的通信问题会被放大吗？",
        "HIR 是如何工作的？",
        "LangChain 存在哪些问题及对应的方法方案？",
        "Llama 2 的 Margin Loss 是什么？",
        "MAM Adapter 的思路是什么？",
        "MAM Adapter 的特点是什么？",
        "PDF 解析存在哪些问题？",
        "PDF 解析有哪些方法？它们的区别是什么？",
        "pdsh 是什么？它有哪些优点？",
        "RAG 流程之前，务必先要清理数据？",
        "RAG 的水平扩展？",
        "RAG 的组织方法具有高度灵活性，能够根据特定问题的上下文，对 RAG 流程中的模块进行替换或重新配置。在？",
        "RAG（Retrieval-Augmented Generation）评测面？",
        "ZeRO-3 中未使用 allgather_partitions、allgather_bucket_size 和 reduce_scatter？",
        "ZeRO-Infinity 需要使用 ZeRO-3？",
        "ZeRO-Offload to CPU and NVMe？",
        "ZeRO Offload后的计算流程是怎么样？",
        "ZeRO 优化策略是怎么样？",
        "上节讲到 DP 只支持 单机多卡场景，主要原因是 DP 无法数据并行中通讯负载不均的问题， 而 DDP 能够解决？",
        "为什么需要 对 pdf 进行解析？",
        "以ZeRO为例，你的转换流程是什么？",
        "如何定义 LongContextReorder 作为查询引擎构建时的节点后处理器？",
        "使用ZeRO-offload将部分数据offload到CPU以降低显存需求的原理是什么？",
        "在探索和优化RAG的过程中，如何有效评估其性能？",
        "根本无法获得「真实分数」时，如何找到优化目标的「最高点」？",
        "对比loss通过在原loss基础上添加对比loss来解决生成式模型重复单调问题的原理是什么？",
        "为什么会出现一直是同一个词反复重复的解码退化问题？",
        "卸载（Offload）技术是什么？它如何用通信换显存？",
        "混合精度训练中，如何判断什么时候用torch.FloatTensor、什么时候用半精度？",
        "在推理时如何先进行weight合并再加载模型进行推理？",
        "加载第一个适配器时，如何通过 PeftModel.from_pretrained 并指定 adapter_name 参数为适配器命名？",
        "在 RAG 技术流程中，处理大量数据时如何高效管理和加工这些数据？",
        "在简单的RAG模型中，比较性问题往往处理得不够好，如何提升RAG的推理能力？",
        "如果实现不了，又是因为什么原因呢？",
        "如果有，能介绍一下区别么？",
        "推理加速框架有哪一些？",
        "推理过程：反复加载巨大的KV cache，导致内存开销大，性能是内存受限？",
        "提供了对显存的管理，减少显存中的碎片？",
        "本质上还是BPE的思想。与BPE最大区别在于：如何选择两个子词进行合并？",
        "检索后处理流程？",
        "检索增强生成（RAG）有哪些优化策略？",
        "此模式要同时处理文本与表格数据，其核心流程是什么？",
        "最初的一步是提取文档的嵌入向量，但这样做会带来哪些问题？",
        "由于ckpt存储时间不可控，不能确定是否小于下一个step的执行时间，所以内存踩踏的问题不可避免？",
        "混合检索是什么？它如何结合矢量搜索和关键词检索？",
        "如何确定关键负样本：根据具体任务的特点，重点关注哪些负样本？",
        "如何保持和加载多个模型？",
        "什么是自动纠正用户查询？如何通过生成多个查询变体实现 RAG Fusion？",
        "为什么 nn.DataParallel 会导致第一块 GPU 的显存占用比其他卡更多？",
        "如何解决基于 LLaMA 家族模型对中文支持不太友好的问题？",
        "采样时如何选择温度（temperature）？",
        "What contribution did you make to your current (previous) job?",
        "Are you a multi-tasked individual?",
        "How do you normally handle criticism?",
        "If you could start again, what career decisions would you make differently?",
        "Are you a multi-tasked individual, or do you work well under stress or pressure?",
        "现在队长要求你们每个人将救生筏上备用的15件物品按其在求生过程中的重要性进行排列，把最重要的物品放在第一位，次重要的放在第二位，直至第15件物品。请你们一起讨论，在25分钟内定出一个统一方案。",
        "假设有一个池塘，里面有无穷多的水。现有2个空水壶，容积分别为5升和6升。问题是如何只用这2个水壶从池塘里取得3升的水。",
        "在一张长方形的桌面上放了n个一样大小的圆形硬币。这些硬币中可能有一些不完全在桌面内，也可能有一些彼此重叠；当再多放一个硬币而它的圆心在桌面内时，新放的硬币便必定与原先某些硬币重叠。请证明整个桌面可以用4n个硬币完全覆盖。",
        "某城市发生了一起汽车撞人逃跑事件，该城市只有两种颜色的车：蓝色15%，绿色85%。事发时有一个人在现场看见了，他指证是蓝车；但根据专家在现场分析，当时条件下能看正确的可能性是80%。那么肇事的车是蓝车的概率是多少？",
        "个家庭有两个小孩，其中有一个是女孩，问另一个也是女孩的概率是多少（假定生男生女的概率一样）？",
        "Have you done the best work you are capable of doing?",
        "Describe a difficult problem you have had to deal with?",
        "What was the last book you read? How did it effect you?",
        "Could you please give me your contact information for me to follow up?",
        "DDIM是不是确定性生成，为什么？",
        "Stable Diffusion核心模块有哪些？",
        "LDM相关：Diffusion Model + UNet，去噪声核心步骤是什么？",
        "使用RAG的好处是什么？",
        "当调用量突增10×时，自托管方案与API方案的成本拐点如何计算？",
        "如何证明KV-cache INT4量化对PPL影响<2%并提供实验数据？",
        "如何用模拟器预估在8×A100下最大并发请求数？",
        "如何用Megatron-LM 计算175B 模型在 128GPU 下的最优pp×tp×dp 组合？",
        "当遇到层间激活内存爆炸时，如何启用 selective activation recomputation？",
        "当 ARM Cortex-A78 只有4GB RAM 时，如何采用内存映射加载7B 模型？",
        "如何定义流式 SSE 响应格式并兼容OpenAI API 语义？",
        "如何设计幂等性机制防止重复扣费？",
        "当某租户触发 OOM 时，如何自动熔断而不影响其他租户？",
        "如何采用 Guided Decoding 强制输出符合 JSON Schema？",
        "当模型违反格式时，如何基于重试策略保证 99.9% 可用？",
        "如何基于 OpenTelemetry 采集 token 级延迟并上报 Prometheus？",
        "如何用 KL 散度监控输出分布漂移并设置动态阈值？",
        "如何基于知识库对比生成声明并计算事实一致性得分？",
        "如何记录每次推理的输入、输出、模型版本并满足 GDPR 可删除要求？",
        "如何评估摘要的 ROUGE-L 与人工一致性（κ 值）？",
        "如何用 NNAPI 在 Android SoC 上加速 INT8 推理并降低功耗 40%？",
        "当工具返回空结果时，如何采用候补 API 保证任务继续？",
        "当缓存命中率 >90% 时，如何评估对整体延迟的提升？",
        "当 k=10 时，如何用缓存执行结果加速 Pass@k 评估？",
        "如何采用语法检查器实时拦截编译错误并反馈？",
        "如何基于静态分析工具（Bandit）扫描生成代码并评分？",
        "如何评估生成注释的 ROUGE-L 与开发者人工一致性？",
        "如何基于 SymPy 验证等式推导并给出自动评分？",
        "如何基于重要性得分将 90% 旧 token 转存到向量库？",
        "当向量检索延迟 >500ms 时，如何采用 LRU 缓存优化？",
        "如何验证记忆机制对多轮对话一致性提升？",
        "如何基于 ICU 库自动转换并缓存格式模板？",
        "当生成 HTML 时，如何自动添加 dir=\"rtl\" 属性？",
        "当标注者一致性 κ<0.6 时，如何采用专家仲裁？",
        "如何评估解释与人类标注的一致性？",
        "如何基于 CI 自动更新模型卡片并发布？",
        "进⾏SFT操作的时候，基座模型选⽤Chat还是Base?",
        "LangChain 包含哪些 核⼼概念？",
        "如何使⽤ LangChain ?",
        "为什么大模型需要外挂(向量)知识库？",
        "nn.DataParallel(DP) vs DistributedDataParallel(DDP)介绍一下？",
        "RAG 评估框架都有哪些？",
        "WordPiece 和 Byte Pair Encoding 的流程是什么？",
        "WordPiece 和 Byte Pair Encoding 的作用是什么？",
        "WordPiece 和 Byte Pair Encoding 的原理是什么？",
        "Byte Pair Encoding (BPE) 原理是什么？",
        "Byte Pair Encoding (BPE) 流程是什么？",
        "Byte Pair Encoding (BPE) 作用是什么？",
        "迭代器和生成器的区别是什么？",
        "垃圾回收机制是什么？",
        "两个矩阵同构和相似的定义是什么？",
        "并行和并发的区别是什么？",
        "emission score 与 transition score 是如何得到的？",
        "NumPy 中的数组和 list 有什么区别？",
        "请说一说PCA？",
        "如何在有序数组中找到某个元素第一次出现的位置？",
        "Deep Norm 思路是什么？",
        "DistributedSampler 的作用是什么？",
        "nn.parallel.DistributedDataParallel 参数更新机制介绍一下？",
        "Efficient Router 介绍一下？",
        "MOE 如何与数据并行结合？",
        "MOE 如何与模型并行结合？",
        "HMM与CRF的区别？",
        "RAG 有哪些评测方法？",
        "如何让 RAG 支持半结构化（文本+表格）？",
        "CRF模型和 HMM 和 MEMM 模型区别？",
        "LangChain 存在哪些问题及解决方案?",
        "数据并行、张量并行、流水线并行的原理及区别是什么?",
        "LR 模型是线性模型还是非线性模型，为什么？能推导它的原理吗？",
        "如果要设计一个高并发、高性能的系统，你应该考虑哪些因素？",
        "分布式系统有哪些常见设计模式，如 CAP 理论、BASE 理论等？",
        "单目相机中，F 和 H 矩阵有何不同？E 和 F 矩阵有何不同？只旋转不平移能不能求 F？",
        "解释什么是工作证明（PoW）以及如何实现它。",
        "CDN 是什么？",
        "CDN 的工作流程是什么？",
        "并行和并发是什么？",
        "分段和分页的区别是什么？",
        "缓存中的热点数据和冷数据是什么？",
        "单例模式6种实现及各实现的优缺点？",
        "设计模式的概念是什么？",
        "代理模式和适配器模式有什么区别？",
        "多卡并行时通信成为瓶颈，如何隐藏通信开销？",
        "什么是迭代器（Iterator）？",
        "字符串常量池存在于内存空间的哪里？",
        "JSP和Servlet的区别、共同点、各自应用范围是什么？",
        "说出Servlet的生命周期，并说明Servlet和CGI的区别？",
        "Servlet Filter Listener启动顺序是什么？",
        "GC触发的条件有哪些？",
        "Minor GC和Full GC的触发条件分别是什么？",
        "如何进行JVM性能调优？",
        "JVM 调优工具有哪些？",
        "什么是单例模式？",
        "各种设计模式的功能是什么？",
        "什么是桥接模式？",
        "什么是策略模式？",
        "MyBatis 的优点是什么？",
        "MyBatis 框架的缺点是什么？",
        "MyBatis 框架使用的场合有哪些？",
        "SpringMVC 工作流程是什么？",
        "Spring MVC 的运行流程是什么？",
        "Spring 中 BeanFactory 和 ApplicationContext 的联系和区别是什么？",
        "Spring IOC 注入的几种方式有哪些？",
        "Spring Bean 的生命周期是什么？",
        "Spring 中的事件处理是什么？",
        "解释 Spring 支持的几种 Bean 的作用域？",
        "Spring 的重要注解有哪些？",
        "Spring 框架的事务管理有哪些优点？",
        "Spring 运行原理是什么？",
        "Nginx 相对于 Apache 的优点有哪些？",
        "Nginx 如何处理一个请求的？",
        "Nginx 是如何实现高并发的？",
        "如何在 Spring Boot 中重新加载更改而无需重启服务器？",
        "什么是 Swagger？你用 Spring Boot 实现过吗？",
        "高并发情况下，系统如何支撑大量请求？",
        "多用户并发访问时如何解决？",
        "大面积并发时在不增加服务器的情况下，如何解决服务器响应不及时的问题？",
        "HDFS 文件写入和读取流程是什么？",
        "介绍一下 HDFS 存数据原理。",
        "SecondaryNameNode 的作用是什么？",
        "HDFS 的作用是什么？",
        "HDFS 的基础概念有哪些？",
        "DataNode 如何保证数据完整性？",
        "Distinct 的实现原理是什么？",
        "Kafka 的特点、优缺点是什么？",
        "Kafka 的 leader 挂掉之后如何处理？",
        "Kafka 的工作流程是什么？",
        "Kafka 幂等性实现原理是什么？",
        "幂等性实现生产者流程是什么？",
        "Kafka 新旧 API 有什么区别？",
        "Zookeeper 在 Kafka 中的作用是什么？",
        "HBase 的优缺点是什么？",
        "说下 HBase 原理。",
        "HBase 读写数据流程是什么？",
        "HBase 的 RowKey 设置讲究有什么原因？",
        "HBase 常见避免热点问题的方法有哪些？",
        "HBase 和 Phoenix 的区别是什么？",
        "说下Spark中的Transform和Action，为什么Spark要把操作分为Transform和Action？常用的列举一些，说下算子原理",
        "Spark的并行度指的是什么？Spark中的并行度等于什么？",
        "Apache Calcite是什么？",
        "Spark Streaming和Storm的区别是什么？",
        "Hive和HBase的存储区别是什么？",
        "Shell中单引号和双引号有什么区别？",
        "HDFS的读数据流程是什么？",
        "HDFS的写数据流程是什么？",
        "taildir底层原理是什么？",
        "Kafka Broker总体工作流程是什么？",
        "Kafka的幂等性原理是什么？",
        "Kafka高吞吐的原因是什么？Kafka如何保证高吞吐量？Kafka为什么低延迟高吞吐？",
        "Watermark在多并行度下的传递、生成原理是什么？",
        "Flink分布式快照的原理是什么？",
        "HBase的写流程是什么？",
        "HBase的读流程是什么？",
        "Kafka 高效读写的原因是什么？",
        "并发峰值多少？大概在哪个时间点？",
        "扑克牌 54 张平均分成 2 份，求这 2 份都有 2 张 A 的概率。",
        "什么是中心极限定理？",
        "Linux 中的用户模式和内核模式是什么意思？",
        "Linux 中的文件包括哪些？",
        "如果使用复制（replication），可以一部分使用日志（journaling）而其他部分不使用吗？",
        "请解释什么是 Nginx？",
        "请列举 Nginx 的一些特性？",
        "请列举 Nginx 和 Apache 之间的不同点？",
        "是否有可能将 Nginx 的错误替换为 502、503？",
        "如何在 Nginx 中获得当前的时间？",
        "Nginx 服务器中 -s 的目的是什么？",
        "反向 shell 和正向 shell 的区别是什么？",
        "Linux 给文件权限的命令是什么？",
        "nginx 怎么安装的？",
        "base64 编码到后端，会继续解析吗？",
        "网线的排列？",
        "forward 和 redirect 的区别？",
        "Heap 表是什么？",
        "如何区分 FLOAT 和 DOUBLE？",
        "区分 CHAR_LENGTH 和 LENGTH？",
        "如何定义 REGEXP？",
        "CHAR 和 VARCHAR 的区别？",
        "TIMESTAMP 在 UPDATE CURRENT_TIMESTAMP 数据类型上做什么？",
        "主键和候选键有什么区别？",
        "myisamchk 是用来做什么的？",
        "如何控制 HEAP 表的最大尺寸？",
        "MyISAM Static 和 MyISAM Dynamic 有什么区别？",
        "federated 表是什么？",
        "如果一个表有一列定义为 TIMESTAMP，将发生什么？",
        "列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？",
        "怎样才能找出最后一次插入时分配了哪个自动增量？",
        "LIKE 声明中的 % 和 _ 是什么意思？",
        "列对比运算符是什么？",
        "我们如何得到受查询影响的行数？",
        "LIKE 和 REGEXP 操作有什么区别？",
        "BLOB 和 TEXT 有什么区别？",
        "MyISAM 表格将在哪里存储，并且还提供其存储格式？",
        "ISAM 是什么？",
        "InnoDB 是什么？",
        "如何输入字符为十六进制数字？",
        "如何显示前 50 行？",
        "NOW() 和 CURRENT_DATE() 有什么区别？",
        "什么是非标准字符串类型？",
        "请解释一下主键、外键和唯一约束的区别",
        "如何对慢查询进行优化？",
        "Linux命令行工具中grep的常用选项有哪些？",
        "请解释一下代码覆盖率的概念及如何度量它？",
        "在你的职业生涯中，你觉得最大的挑战是什么？你是怎么解决的？",
        "当你面对多个优先级不同的任务时，你会如何决定处理顺序？",
        "个编码为GBK的字符串S，要将其转成UTF-8编码的字符串，应如何操作？",
        "单引号、双引号、三引号的区别是什么？",
        "什么是猴子补丁？",
        "主键和唯一约束有什么区别？外键用来做什么？",
        "深拷贝和浅拷贝之间的区别是什么？",
        "什么是元组的解封装？",
        "什么是PEP？",
        "列表和元组之间的区别是什么？",
        "什么是bugzilla？",
        "什么是loadrunner？",
        "什么是桩模块？什么是驱动模块？",
        "什么是扇入和扇出？",
        "需求确定中不确定的需求怎么解决？",
        "在您以往的工作中，一条软件缺陷（Bug）记录都包含了哪些内容？",
        "如何提交高质量的软件缺陷（Bug）记录？",
        "你对软件配置管理工作的认识是什么？",
        "什么是系统瓶颈？",
        "发现的缺陷越多，说明软件缺陷越多吗？",
        "所有的软件缺陷都能修复吗？所有的软件缺陷都要修复吗？",
        "开发人员老是犯一些低级错误怎么解决？",
        "开发人员说不是 bug时，你如何应付？",
        "软件的评审一般由哪些人员参加？其目的是什么？",
        "什么是 bug？",
        "开发人员修复缺陷后，如何保证不影响其他功能？",
        "知道 restful 风格吗？怎么做的？",
        "需求文档是谁编写的？",
        "你最擅长哪部分工作？",
        "DATA BLOCK、EXTENT 和 SEGMENT 的区别是什么？",
        "行链接和行迁移有什么区别？",
        "如何解决 ORA-04030 和 ORA-04031 错误？",
        "什么是检查点？如何调优检查点？",
        "什么是大文件表空间（Bigfile Tablespace）？",
        "本地管理表空间（LMT）和字典管理表空间（DMT）的特点有哪些？",
        "请描述 UNDO 的作用？",
        "请描述对 UNDO Retention 的理解？",
        "如何评估所需 UNDO 大小？",
        "什么是物理读和逻辑读？",
        "什么是直接路径访问？",
        "执行计划里的 access 和 filter 有什么区别？",
        "什么是动态采样（Dynamic Sampling）？",
        "ROWID 和 ROWNUM 有什么区别？",
        "在高并发、高负载的情况下，如何给表添加字段并设置 DEFAULT 值？",
        "若临时表空间使用率过高有什么调优思路？",
        "如何有效地删除一个大表（即表的 EXTENT 数很多）？",
        "常用的 10046 及 10053 诊断事件的区别是什么？",
        "集群有哪几种心跳机制？",
        "RAC 的脑裂和健忘分别指的是什么？",
        "什么是 GPnP？",
        "oraInventory 目录的作用是什么？",
        "如果 $GRID_HOME 下的权限被人为修改过，那么如何来修复该权限问题？",
        "RAC 等待事件 gc buffer busy acquire 和 gc buffer busy release 的区别是什么？",
        "RAC 节点被踢出可能有哪些原因？",
        "Switchover 和 Failover 的区别是什么？",
        "主库丢失归档，物理 DG 如何恢复？",
        "实例恢复和介质恢复的区别是什么？",
        "DELETE 了一条数据并且提交了，该如何找回？",
        "LogMiner 是什么？有哪些用途？",
        "什么是 BBED？有哪些作用？",
        "归档模式和非归档模式有什么不同？各自的优缺点是什么？",
        "控制文件丢失且无备份的情况下如何恢复？",
        "Undo 表空间数据文件丢失的情况下如何恢复？",
        "控制文件损坏如何恢复？",
        "AWR 报告中主要关注哪些内容？",
        "DATA BLOCK、EXTENT 和 SEGMENT 的大小分别是多少？如何查询？",
        "典型的连接类型共有哪 3 种？",
        "直接路径加载比常规路径加载快很多的原因是什么？",
        "临时表空间使用率过高有什么调优思路？",
        "46 和 10053 诊断事件的区别是什么？",
        "如果 $GRID_HOME 下的权限被人为修改过，如何修复该权限问题？",
        "LogMiner 是什么？其有哪些用途？",
        "什么是 BBED？它有哪些作用？",
        "归档和非归档模式之间的不同点是什么？",
        "在控制文件丢失且无备份的情况下如何恢复？",
        "在Undo表空间数据文件丢失的情况下如何恢复？",
        "如果控制文件损坏如何恢复？",
        "AWR 报告中主要关注哪些方面内容？",
        "如何对特殊模式对象上的 DML语句进行审计，记录作用在指定对象上的操作？",
        "段顾问的作用是什么？",
        "如何使用段顾问？",
        "自动健康检查的作用是什么？",
        "如何使用自动健康检查？",
        "如何使用 ADMF？",
        "如何使用 AWR？",
        "如何使用 AOSC？",
        "并行查询的原理是什么？",
        "并行 DML 操作的原理是什么？",
        "回滚段的作用是什么？",
        "RMAN 的作用是什么？",
        "Data Guard 的作用是什么？",
        "Streams 的作用是什么？",
        "逻辑备库（Logical Standby）的区别是什么？",
        "存储过程和函数的区别是什么？",
        "如何启用和配置审计？",
        "如何设置资源限制？",
        "内存顾问的作用是什么？",
        "如何使用内存顾问？",
        "DNS 解析过程是什么？",
        "HTTP 有哪些特性？请简述。",
        "HTTP 版本是如何演变的？",
        "HTTP/1.1 协议有哪些常见性能问题？",
        "HTTP/2 的并发是如何实现的？",
        "HTTPS 和 HTTP 的区别是什么？",
        "NAT 如何缓解 IPv4 地址耗尽的问题？",
        "NAT 有哪些缺点？",
        "如何解决 NAT 的潜在问题？",
        "什么是 TCP 粘包和拆包问题？",
        "如何解决 TCP 粘包和拆包问题？",
        "如何用 UDP 实现可靠传输？",
        "HTTP 请求过程是什么？",
        "如何创建和销毁线程？",
        "个海盗夜里依次把椰子分成5份，每次都多1个给猴子并藏起1份，再把剩下的混回去；第2天早上再分成5份仍多1个给猴子。这堆椰子最少有多少个？",
        "个人住旅馆三间房共付30元，次日老板退5元，小弟每人退1元自己拿2元；三人各花9元共27元，加小弟2元为29元，问少的1元在哪里？",
        "李明从图书馆借来一批图书：先给甲5本和剩下的1/5；再给乙4本和剩下的1/4；又给丙3本和剩下的1/3；又给丁2本和剩下的1/2；最后自己还剩2本。李明共借了多少本书？",
        "右图是由9个等边三角形拼成的六边形，已知中间最小等边三角形边长为a，问六边形的周长是多少？",
        "如图所示，A、B、C、D、E五所学校间有公路相通，图上标出了每段公路的长度；出席会议代表人数为A校6人、B校4人、C校8人、D校7人、E校10人。为使代表所走路程总和最小，会议应选在哪个学校召开？",
        "数列填空：2，3，6，12，22，()",
        "数列填空：14，45，139，()",
        "数列填空：2，4，4，1，()",
        "数列填空：11，13，34，58，105，()",
        "数列填空：2，3，7，8，17，15，()",
        "世纪60年代出现的“绿色革命”的含义是什么？",
        "世界上第一台被称作 ENIAC 的电子计算机是在何时何地问世的？冯·诺依曼提出的存储程序和程序控制的基本思想是什么？",
        "如果图里带有专色，在制作时专色在图片处理软件里是以什么形式反映出来的？",
        "与所给图形相同规律的图形是哪一个？",
        "店铺 VIP 顾客对你推荐的服装非常不满意且语气不好，你会如何处理？",
        "电话接听要注意哪些事项？",
        "访客接待如何安排？",
        "会议服务应该注意哪些方面？",
        "办公用品管理的流程包括哪些？",
        "考勤统计是怎样做的？",
        "How can you evaluate your suppliers?",
        "What's your purchasing plan for next season?",
        "Python 中的实例方法、静态方法和类方法三者区别是什么？",
        "为什么 SFT 之后感觉 LLM 变笨了？",
        "大模型是怎么让生成的文本丰富而不单调的呢？",
        "机器学习中的梯度消失、爆炸原因及其解决方法是什么？",
        "Stable Diffusion 的核心模块有哪些？",
        "在 LDM 中，Diffusion Model + U-Net 的去噪核心步骤是什么？",
        "LLMs 已经具备了较强能力了，存在哪些不足点？",
        "Prompt 注入、敏感信息套取等风险，攻击者往往用 Base64 多层嵌套+自定义协议时如何防御？",
        "启用 DID 回溯：取功能上线前 14 天与上线后 14 天同一批留存用户，验证是否？",
        "LangChain 如何 Embedding 与 vector store？",
        "指示微调（Prompt-tuning）与 Prefix-tuning 区别是什么？",
        "指示微调（Prompt-tuning）与 fine-tuning 区别是什么？",
        "流水线并行（Pipeline Parallelism）优缺点是什么？",
        "介绍一下 nn.parallel.DistributedDataParallel 的参数更新过程？",
        "介绍一下 nn.DataParallel（DP）与 DistributedDataParallel（DDP）的区别？",
        "讲解一下 accelerate 分布式训练的原理？",
        "旋转位置编码 RoPE 被哪些 LLM 应用？",
        "ALiBi（Attention with Linear Biases）被哪些 LLM 应用？",
        "如何用 vLLM 做离线批量推理？",
        "如何使用 vLLM API Server？",
        "如何使用 docker 运行 Text generation inference 的 web server？",
        "介绍一下 Token Attention？",
        "介绍一下 Efficient Router？",
        "介绍一下 LightLLM 的性能表现？",
        "Graph RAG 的思路是什么？",
        "如何用代码介绍 Graph RAG？",
        "如何用示例介绍 Graph RAG？",
        "举例介绍不同大模型（LLMs）的分词方式。",
        "不同大模型（LLMs）的分词方式有哪些区别？",
        "哪些技术能用于计算两个词向量之间的距离？",
        "将词表示成向量是否被称为神经词嵌入（Neural Word Embeddings）？",
        "哪种嵌入方式支持双向上下文（Bidirectional Context）？",
        "词嵌入是否能捕获多维数据并表示为向量？",
        "Transformer 架构最初由哪项工作引入？",
        "排列语言模型（Permutation Language Models）是哪些模型的特点？",
        "微调 BERT 模型的层次选择及其原因是什么？",
        "RAG 评估框架有哪些？",
        "被索引内容的特点是什么？",
        "Transformer 为什么 Q 和 K 使用不同的权重矩阵生成，为什么不能使用同一个？",
        "Transformer 计算 attention 时为何选择点乘而不是加法？",
        "介绍 Transformer 模型及其与 RNN/LSTM 的区别。",
        "WordPiece model 和 Byte Pair Encoding 的流程是什么？",
        "WordPiece model 和 Byte Pair Encoding 的作用是什么？",
        "Query 矩阵输出的 q 向量和 Key 矩阵输出的 k 向量做点积相似度计算得到一个 attention，这个过程怎么做？",
        "Transformer 为什么 Q 和 K 使用不同的权重矩阵生成？",
        "Transformer 计算 attention 的时候为何选择点乘而不是？",
        "为什么在进行 softmax 之前需要对 attention 进行什么处理？",
        "为何在获取输入词向量之后需要对矩阵乘以 embedding？",
        "训练和实现 Transformer 时有哪些常见挑战，如何改进？",
        "word piece model 和 byte pair encoding 的原理是什么？",
        "单例模式的几种实现方式及优化有哪些？",
        "python2和python3的range（100）的区别？",
        "最近关注的论文，多模态视觉大模型(CLIP,DALLE)？",
        "使用top查看系统资源占用情况时，哪一列表示内存占用呢？",
        "请详细说说支持向量机（support vector machine，SVM）的原理",
        "常见的分类算法有哪些？他们各自的优缺点是什么？",
        "机器学习中的正则化到底是什么意思？",
        "SMO算法的步骤是什么？",
        "梯度下降算法流程是什么？",
        "Adaboost算法流程是什么？",
        "贝叶斯网络的定义是什么？",
        "因子图的定义是什么？",
        "TF-IDF算法步骤？",
        "RNN 的优缺点？",
        "CNN 的优缺点？",
        "说下知识图谱项目的基本情况，如何对数据进行处理的，结果如何？",
        "L1 范式和 L2 范式的区别？",
        "RNN 原理？",
        "神经网络处理过拟合的方法有哪些？",
        "XGBoost 的算法原理是什么？",
        "Python 中的数据结构有几种，分别是什么？",
        "VC 维是什么？",
        "深度学习有哪些处理过拟合的方法？了解哪些激活函数？激活函数怎么选用？各有什么优缺点？",
        "说一下并行和并发的区别。",
        "解释一下反向传播算法，Pooling 层的作用是什么？",
        "机器学习常用的一些方法有哪些？以及原理是什么？",
        "介绍图片分类 demo：怎么对数据集进行处理？",
        "分类器如何判断物品属于同一类？",
        "针对实习项目：为什么要加入 reading-gate？为什么不直接把控制向量加在输入中？",
        "SENet 的原理是什么？和 Attention 机制的区别是什么？",
        "怎么解决过拟合的问题？",
        "SENet 的原理是什么？画出 block 的图。",
        "大概说明细粒度分类项目中的数据集：多少个类，每个类多少张图片？",
        "数据的预处理是否做了图像增强？为什么要这样做？样本中有没有噪声，怎么处理？",
        "网络不收敛怎么办？类别不平衡怎么办？数据和模型都跟别人用的一样，怎么改进？",
        "SSD、YOLO、R-CNN 的区别是什么？",
        "有哪些语义分割网络？简述 U-Net 的特点。",
        "RNN 怎么解决长期依赖问题？LSTM 的结构是怎样的？",
        "LSTM 和 GRU 的关系是怎样的？",
        "LSTM 和 GRU 的区别是什么？",
        "ELMo 为什么用的是两层单向 LSTM 而不是 Bi-LSTM？",
        "CRF 中 emission score 与 transition score 分别是如何得到的？",
        "Python 的数据库连接操作一般用什么实现？服务器开发时连接数据库的原理是什么？",
        "NumPy 中的数组和 Python list 有什么区别？",
        "为什么项目中使用 macro-F1？为什么不用 Precision、Recall？",
        "了解 Python 的浅拷贝和深拷贝吗？装饰器呢？",
        "介绍一下 LSTM 的计算过程，举例说明每一步各个参数的维度和变化。",
        "主要通过什么方法判断某些 SQL 语句需要优化？",
        "逻辑回归和 SVM 的区别和联系是什么？",
        "SMO 算法在求解 SVM 的超平面方程中扮演什么角色？",
        "你知道哪些降维算法？了解 t-SNE 吗？",
        "知道哪些矩阵分解的方法？",
        "你是通过什么方法来判断模型欠拟合和过拟合的？",
        "简单介绍一下聚类。",
        "什么是 attention 注意机制？简单介绍 self-attention。",
        "过拟合的解决方法是什么？",
        "介绍一下逻辑回归：公式推导、损失函数及其图像、与线性回归的关系、你在什么地方用过？",
        "介绍一下 GBDT：GBDT 的基模型是分类树还是回归树？Gradient 如何体现？",
        "你遇到过拟合的情况吗？过拟合是怎样解决的？",
        "GRU 和 LSTM 的区别是什么？",
        "L1 正则化和 L2 正则化的区别是什么？",
        "阐述 GBDT、XGBoost、LightGBM 的异同：XGB 的优势是什么？LGB 的优势是什么？二者如何并行？",
        "写公式并说一下 KNN、K-means、朴素贝叶斯的原理。",
        "Transformer encoder 和 decoder 的区别是什么？",
        "讲讲 word2vec 和 word embedding 的区别。",
        "分类的分类损失函数有哪些？",
        "为什么分类不用 MSE 而用交叉熵？",
        "BERT 的 base 版本原始模型训练时，第一个 epoch 模型判定结果很可能是错的，这个时候熵还可信吗？",
        "讲一下 Transformer 的原理。",
        "讲一下 LoRA 的原理。",
        "讲一下 Flash Attention 的原理。",
        "常见的深度学习优化方法有哪些？",
        "LSTM 的特点是什么？",
        "LSTM 和 Transformer 的优缺点分别是什么？",
        "Transformer 的多头注意力的作用是什么？",
        "在一个有序数组中，如何找到某个元素第一次出现的位置？",
        "RNN 和 LSTM 的优缺点分别是什么？",
        "LSTM 和 RNN 有什么区别？解决什么问题？",
        "XGBoost 算法介绍一下？",
        "Transformer 和 LSTM 的结构与原理是什么？",
        "主流大模型的 loss 有哪些？有哪些异同？",
        "你既然做过 RAG，能不能介绍一下 RAG，大模型在里面主要是起到什么作用？",
        "大模型训练的三种并行是什么？通讯开销如何对比？",
        "Transformer 中求和与归一化中，“求和”是什么？",
        "大模型进行 SFT 操作时在学习什么？",
        "Layer Norm 的计算公式是什么？",
        "RMS Norm 的计算公式是什么？",
        "Self-RAG 的代码实战？",
        "介绍一下大语言模型（LLM）的安全挑战问题？",
        "微调时批处理大小对 GPU 显存和速度有什么影响？",
        "Peft 和全量微调区别？",
        "微调大模型时，优化器如何？",
        "预训练（Pre-training）vs 有监督微调（Supervised Finetuning）有什么区别？",
        "InstructGPT 的原理是什么？讲讲 RLHF 和 reward？",
        "介绍一下强化学习中优化方法 Value-based？",
        "多种并行方式可以叠加吗？",
        "分布式并行及显存优化技术有哪些？各自有什么特点？",
        "常见的分布式训练框架有哪些？各自有什么特点？",
        "流水线并行（Pipeline Parallelism）有什么优缺点？",
        "什么是 DistributedDataParallel 的核心——Ring-AllReduce？",
        "nn.parallel.DistributedDataParallel 介绍一下？",
        "nn.parallel.DistributedDataParallel 的实现流程介绍一下？",
        "nn.DataParallel（DP）vs DistributedDataParallel（DDP）介绍一下？",
        "DistributedDataParallel（DDP）缺点有哪些？",
        "如何为每个位置的词向量注入位置信息呢？",
        "多分类的分类损失函数(Softmax)是什么？",
        "对预训练模型进行指令微调，tokenization 如何构建？",
        "什么是模型量化？",
        "大模型进行 SFT 操作的时候在学习什么？",
        "大模型训练的 loss 突刺是什么？为什么会出现 loss 突刺？如何解决？",
        "RAG 思路是怎么样的？",
        "有监督微调（Supervised Finetuning）的训练数据格式是什么？",
        "微调大模型时如何选取和构建微调数据？",
        "基于 LLM + 向量库的文档对话思路是怎样的？",
        "LangChain 的替代方案有哪些？",
        "LoRA 微调中可训练参数的比例如何确定？",
        "隐马尔科夫算法中三个矩阵是什么？",
        "隐马尔科夫算法中工作流程是什么？",
        "隐马尔科夫算法学习训练过程是什么样的？",
        "最大熵马尔科夫模型（MEMM）是什么样？",
        "Dilated CNN的优点？",
        "CNN-CRF vs BiLSTM-CRF vs IDCNN-CRF?",
        "如果一个样本同时拥有多个标签，甚至标签同时还构成了DAG（有向无环图），如何建模和学习？",
        "文本分类的过程？",
        "fastText的分类过程？",
        "TextCNN的局限性？",
        "分类问题使用的损失函数还有有哪些？",
        "为什么要用层次化Softmax回归(Hierarchical Softmax)？",
        "层次化Softmax回归(Hierarchical Softmax) 的思想是什么？",
        "层次化Softmax回归(Hierarchical Softmax) 的步骤？",
        "开源的 RAG 框架有哪些？你比较了解哪些?",
        "向量数据库有哪些？各自优点与区别?",
        "LangChain 如何进行 Embedding 与 vector store 集成?",
        "LR（逻辑回归）模型是线性模型还是非线性模型？为什么？能推导它的原理吗？",
        "频率学派和贝叶斯学派的区别是什么？",
        "L1 和 L2 正则化的区别是什么？",
        "DBSCAN 原理和算法伪代码是什么？与 k-means、OPTICS 的区别是什么？",
        "层次聚类的分裂法与凝聚法分别是什么？",
        "LSTM 跟 RNN 的区别是什么？",
        "LSTM 与 GRU 的区别是什么？",
        "堆和栈的区别是什么？",
        "Python 中 is 和 == 的区别是什么？",
        "为什么用同步锁？",
        "死锁产生的必要条件有哪些？",
        "处理死锁的基本方法有哪些？",
        "Python 中列表（List）里的 del、remove 和 pop 的用法和区别是什么？",
        "@property、@staticmethod、@classmethod 装饰器的作用、区别与使用方法是什么？",
        "如果要降低数据集维度以减少模型计算时间，但机器内存有限，你会怎么做？",
        "梯度下降法找到的一定是下降最快的方向吗？为什么？",
        "LR 能否解决非线性分类问题？如果可以，怎么做？",
        "L1 正则化产生稀疏性的原因是什么？对稀疏矩阵的理解是什么？",
        "哪些算法需要归一化？这些模型需要归一化的主要原因是什么？",
        "随机森林（RF）分类和回归问题如何预测 y 值？",
        "模型受到低偏差和高方差问题时，应该使用哪种算法来解决？",
        "你能解释卷积神经网络（CNN）和循环神经网络（RNN）的区别吗？",
        "对 fine-tuning（微调模型）的理解是什么？为什么要修改最后几层神经网络权值？",
        "网络初始化为 0 的话有什么问题？",
        "前馈神经网络（FNN）、递归神经网络（RNN）和 CNN 的区别是什么？",
        "什么是自动空间重新碎片整理（Automatic Space Redfragmentation）？",
        "Oracle 数据库中的数据块、区和段分别是什么？",
        "Oracle 数据库中的并行查询和并行 DML 操作原理是什么？",
        "Oracle 数据库中 Data Guard 的作用是什么？",
        "Oracle 数据库中 SQL 优化器的作用是什么？",
        "Oracle 数据库中执行计划（Explain Plan）的作用是什么？",
        "Oracle 数据库中绑定变量（Bind Variables）是什么？",
        "Oracle 数据库中统计信息（Statistics）的作用是什么？",
        "Oracle 数据库中的直方图（Histogram）是什么？",
        "Oracle 数据库中并行执行（Parallel Execution）是什么？",
        "Oracle 数据库中物化视图（Materialized View）是什么？",
        "Oracle 数据库中触发器（Trigger）的作用是什么？",
        "Oracle 数据库中序列（Sequence）是什么？",
        "Oracle 数据库中同义词（Synonym）是什么？",
        "Oracle 数据库中的权限（Privilege）和角色（Role）分别是什么？",
        "Oracle 数据库中的审计（Auditing）是什么？",
        "Oracle 数据库中的资源限制（Resource Limits）是什么？",
        "什么是自动诊断和监控框架（ADMF）？",
        "什么是自动优化统计信息收集（AOSC）？",
        "什么是自动索引管理（AIM）？",
        "什么是自动性能优化（Automatic Performance Tuning）？",
        "什么是自动存储参数调整（Automatic Storage Parameter Tuning）？",
        "什么是自动空间碎片整理（Automatic Space Defragmentation）？",
        "什么是自动空间监控（Automatic Space Monitoring）？",
        "什么是自动空间再平衡（Automatic Space Rebalancing）？",
        "什么是自动空间重分配（Automatic Space Redistribution）？",
        "什么是自动空间重构（Automatic Space Restructuring）？",
        "什么是自动空间重新构建（Automatic Space Rebuilding）？",
        "Oracle 系统进程主要有哪些，作用分别是什么？",
        "Python 中单下划线前缀和结尾、双下划线前缀结尾的命名有什么区别？",
        "请解释一下Python 中的垃圾回收机制。",
        "BA 算法的流程是什么？",
        "阶梯度下降、G-N 和 L-M 三种方法有什么区别？",
        "高精度地图的制作流程是什么？",
        "UDP 组播时，目标地址填组播地址，那么在组播组内的机器都能收到数据包吗？",
        "TCP 中的 Nagle 算法是什么？有什么用途？",
        "HTTP/1.1 和 HTTP/1.0 有什么区别？",
        "进程的概念是什么？",
        "局部性原理是什么？",
        "进程的状态有哪些？",
        "单例模式6种实现及各实现的优缺点是什么？",
        "当学习率=1e-3，LSTM在100步后梯度范数<1e-6，如何诊断原因？",
        "给出一种自适应anchor聚类(K-means++)的完整流程。",
        "给出一种基于知识蒸馏的INT8检测模型微调流程。",
        "给出一种无监督光流在线微调降低域差异的方法。",
        "写出攻击者损失logit与阴影模型训练流程。",
        "写出一致性正则化Lcons对实例特征的作用。",
        "端侧部署的极限优化？",
        "如果 blockDim.x 不是 32 的整数倍，最后一条 warp 不足 32 线程怎么处理？",
        "指针文件与实体文件分离带来的克隆加速、并行下载、带宽节省原理是什么？",
        "深度学习替代传统滤波可行吗？",
        "当多卡并行时，通信成为瓶颈，如何隐藏？",
        "为什么说B+比B 树更适合实际应用中操作系统的文件索引和数据库索引？",
        "Java 的基础类型有哪些？各自占用多少字节？",
        "Java（OOP）面向对象的特征有哪些？",
        "Java 的内存划分是什么？",
        "Minor GC、Full GC 的触发条件分别是什么？",
        "Java 对象创建过程是什么？",
        "都有哪些垃圾回收器？",
        "线程间通信，wait 和 notify 的理解和使用？",
        "线程同步的方法？",
        "线程的创建方式？",
        "Java 中 interrupted 和 isInterruptedd 方法的区别？",
        "死锁的原因？",
        "线程池的工作原理，几个重要参数？",
        "线程池的类型？",
        "简单工厂和抽象工厂的区别？",
        "设计模式的优点？",
        "设计模式的六大基本原则？",
        "单例模式？",
        "设计模式的分类？",
        "hibernate 和 mybatis 的区别？",
        "Spring IOC 注入有哪几种方式？",
        "MyBatis 是如何将 SQL 执行结果封装为目标对象的？有哪些映射形式？",
        "Spring 框架中用到了哪些设计模式？",
        "Spring 中的事件处理机制是什么？",
        "Spring 中 @Autowired 与 @Resource 的区别是什么？",
        "Spring 的运行原理是什么？",
        "什么是 Redis 持久化？RDB 和 AOF 的区别是什么？",
        "Redis 哈希槽是什么？",
        "Redis 中缓存穿透、缓存雪崩、缓存击穿分别是什么？",
        "Redis 单线程为什么还能处理速度很快？",
        "为什么 Redis 的操作是原子性的，如何保证原子性？",
        "Redis 主从复制的实现过程是什么？",
        "Nginx 的优化方式有哪些？",
        "Nginx 负载均衡调度状态？",
        "HTTP 的请求报文组成？",
        "HTTP 中重定向和请求转发的区别？",
        "HTTP 与 HTTPS 的区别？",
        "什么是 HTTP 协议无状态？怎么解决 HTTP 协议无状态？",
        "HTTPS 工作原理是什么？",
        "MySQL 的 MyISAM 与 InnoDB 在事务、锁级别、适用场景方面有什么区别？",
        "高并发情况下，我们系统是如何支撑大量请求的？",
        "大面积并发，在不增加服务器的情况下，如何解决服务器响应不及时问题？",
        "介绍一下HDFS的作用。",
        "介绍HDFS的基础概念。",
        "Kafka的特点和优缺点是什么？",
        "Kafka生产者幂等性实现流程是什么？",
        "HBase的原理是什么？",
        "Phoenix二级索引有什么特点？",
        "HBase的RowKey设置有哪些讲究，原因是什么？",
        "MySQL 中事务的实现原理是什么？",
        "数据库事务的四大特性是什么？ACID 分别是什么？",
        "乐观锁有哪些实现方式？它们的区别是什么？",
        "分布式数据库是什么？分布式数据库系统的特点有哪些？",
        "索引是什么？",
        "创建索引的方法有哪些？",
        "为什么 InnoDB 使用 B+ 树而不是 B 树？",
        "聚簇索引和非聚簇索引的区别是什么？",
        "Kafka 高吞吐的原因是什么？",
        "Kafka 如何保证高吞吐量？",
        "Kafka 为什么低延迟高吞吐？",
        "HDFS 的读流程是什么？",
        "HDFS 的写流程是什么？",
        "幂等性原理是什么？",
        "Watermark 多并行度下的传递、生成原理是什么？",
        "请描述 HBase 的读流程。",
        "HBase 二级索引的原理是什么？",
        "Flink 写入 ClickHouse 时如何保证一致性？",
        "Java 创建线程的方式有哪些？（如继承 Thread 并重写 run()、实现 Runnable 并重写 run()）",
        "Kafka 高效读写的原因有哪些？",
        "你们系统的并发峰值是多少？大概在哪个时间点？",
        "缓存未命中时如何处理？如何避免缓存击穿/穿透/雪崩？",
        "如何实现数据质量监控？你具体怎么做？",
        "什么是渐进时间复杂度？如何理解算法执行时间增长率与 f(n) 的关系？",
        "公平调度器会导致容器集中在同一个服务器上吗？为什么？",
        "你怎么理解统计学？生活中统计学有哪些应用？",
        "什么是 EDA（Exploratory Data Analysis）？",
        "时间序列预测需要注意哪些点？和回归有何区别？",
        "SQL 窗口函数是什么？有哪些常见用法？",
        "请详细介绍一种非参数统计方法，并叙述其优缺点。",
        "给你一个无序数组，怎么做合理采样？",
        "Dubbo 的服务负载均衡策略有哪些？默认是哪种？",
        "你了解哪些其他分布式框架？",
        "Dubbo 能集成 Spring Boot 吗？如何集成？",
        "你觉得用 Dubbo 好还是 Spring Cloud 好？为什么？",
        "Linux 中主要有哪些内核锁？",
        "Linux 的用户态和内核态分别是什么含义？",
        "如何申请大块内核内存？",
        "用户进程间通信主要有哪些方式？",
        "在 MongoDB 中如何除去一个数据库?",
        "MongoDB 存储特性与内部原理是什么?",
        "分片(sharding)和复制(replication)是怎样工作的?",
        "如果我在使用复制技术(replication)，可以一部分使用日志(journaling)而其他部分则不使用吗?",
        "视图的作用，视图可以更改么？",
        "mysql 支持的复制类型?",
        "mysql 中myisam 与innodb 的区别？",
        "请解释一下什么是Nginx?",
        "请解释你如何通过不同于80 的端口开启Nginx?",
        "请解释是否有可能将Nginx 的错误替换为502 错误、503?",
        "解释Nginx 是否支持将请求压缩到上游?",
        "解释如何在Nginx 中获得当前的时间?",
        "解释如何在Nginx 服务器上添加模块?",
        "nginx 中多个work 进程是如何监听同一个端口的？如何处理客户连接的惊群问题？",
        "什么是 Redis？",
        "Redis 常见性能问题和解决方案？",
        "数据库的三范式？",
        "为什么使用贪心和启发式搜索建立决策树，而不直接使用暴力搜索建立最优决策树？",
        "如何搭建内网代理隧道？",
        "Windows哈希怎么抓取？",
        "Windows哈希怎么传递？",
        "TCP协议是什么？",
        "tcpdump怎么用？",
        "reverse_tcp和bind_tcp的区别是什么？",
        "MySQL数据库5.0和5.0后的区别是什么？",
        "判断是否存在CDN，如何绕过CDN，网站有CDN怎么找真实IP？",
        "用扫描和抓包时，HTTPS 和 HTTP 有什么区别？",
        "SQL 注入绕过方法有哪些？",
        "SQL 注入报错注入常用函数有哪些？你知道哪些报错函数？",
        "sqlmap 的 --os-shell 利用条件以及原理是什么？",
        "SQL Server 注入怎么判断是不是 SQL Server？",
        "有文件上传漏洞，Linux 下怎么找 xx.conf 文件？",
        "Windows、Linux 提权有哪些方法？",
        "MySQL 数据库 5.0 和 5.0 之后的区别是什么？",
        "在排除计算机网络问题时，可能会发生什么常见的硬件相关问题？",
        "SQL 注入防护方法？",
        "HTTPS 的建立过程？",
        "请描述 HTTP、HTTPS 分别是什么协议、作用及端口号？",
        "Word2vec训练流程是什么？",
        "LR 和 SVM 的区别是什么？",
        "softmax 和 sigmoid 区别是什么？",
        "softmax 是否可以作为激活函数，为什么？",
        "MLP + softmax 层如何介绍？",
        "fastText 词内的n-gram信息存在哪些问题？",
        "Word2vec 中负采样是什么？",
        "word2vec 训练 trick 中 window 一般设置多大？",
        "LR/SVM/softmax/Adaboost 损失函数之间的差别是什么？",
        "SVM 核函数之间的区别是什么？"
      ]
    },
    "数据分析": {
      "count": 11,
      "questions": [
        "指标的异常波动变化（例如日活下跌）如何分析？",
        "指标和维度的区别和联系？",
        "如何评估一场活动的效果？",
        "上一份工作的主要内容包括哪些？",
        "如何构建差分隐私（ε=1）保证统计查询不泄露个体？",
        "如何采用 Kendall Tau 相关性验证 RM 与人类一致性？",
        "当抽检比例 5% 时，如何计算统计功效并保证 95% 置信？",
        "Oracle 数据库中的统计信息（Statistics）的作用是什么？",
        "自动优化统计信息收集（AOSC）的概念是什么？",
        "如何使用 AB Test 评估算法效果？",
        "Oracle 数据库中的统计信息（Statistics）的作用？"
      ]
    },
    "数据库": {
      "count": 198,
      "questions": [
        "sqlmap 中 --os-shell 的利用条件以及原理是什么？",
        "MySQL 5.0 和 5.0 之后的区别是什么？",
        "有回显的联合查询注入怎么注入（MySQL）？",
        "对于长文档（书籍），如何获取其中关键信息并构建索引？",
        "通过程序合成进行符号推理（例如 Python、SQL 等）如何实现？",
        "当每天新增 100 万篇文档时，如何设计分层索引避免全量重建？",
        "如何用 Kafka + FAISS 实现近实时（<5min）索引更新？",
        "当面对千万级日志时，如何用 Loki 索引并保留 30 天冷热分层？",
        "如何基于 Redis + Protobuf 缓存天气查询结果并设置 TTL？",
        "如何构建对抗测试集检测 SQL 注入风险？",
        "当模型输出动态 SQL 时，如何采用参数化查询重写？",
        "L1 范式和 L2 范式的区别是什么？",
        "Python 的数据库连接操作用什么实现？服务器开发时连接数据库的原理是什么？",
        "主要通过什么方法判断某些 SQL 语句需要进行优化？",
        "Faiss 的索引（Index）有哪些？",
        "Faiss 的索引（Index）都怎么用？",
        "索引组织表的作用是什么？",
        "Oracle 数据库中的数据块、区和段的概念是什么？",
        "Oracle 数据库中的并行查询和并行DML 操作的原理是什么？",
        "Oracle 数据库中的Data Guard 的作用是什么？",
        "Oracle Database Streams 的作用是什么？",
        "Oracle 数据库中的执行计划（Explain Plan）的作用是什么？",
        "Oracle 数据库中的绑定变量（Bind Variables）的概念是什么？",
        "Oracle 数据库中的直方图（Histogram）概念是什么？",
        "Oracle 数据库中的并行执行（Parallel Execution）概念是什么？",
        "Oracle 数据库中的物化视图（Materialized View）概念是什么？",
        "Oracle 数据库中的触发器（Trigger）作用是什么？",
        "Oracle 数据库中的同义词（Synonym）概念是什么？",
        "Oracle 数据库中的权限（Privilege）和角色（Role）概念是什么？",
        "Oracle 数据库中的审计（Auditing）概念是什么？",
        "Oracle 数据库中的资源限制（Resource Limits）概念是什么？",
        "SQL 顾问的作用是什么？",
        "自动索引管理（AIM）的概念是什么？",
        "自动空间重分配（Automatic Space Redistribution）的概念是什么？",
        "你怎么看到为表格定义的所有索引？",
        "Mysql 中有哪些不同的表格？",
        "请解释一下 Redis 集群的工作原理。",
        "读写锁的特点是什么？",
        "主键、外键、索引的区别是什么？",
        "索引的优缺点是什么？",
        "MongoDB 和 MySQL 有哪些区别？",
        "Redis 是什么，有哪些特点？",
        "Redis 哨兵机制是什么？",
        "Redis 切片集群的工作原理是什么？",
        "Redis 过期删除策略是什么？",
        "Redis 的 LRU 算法和 LFU 算法有什么区别？",
        "Redis 与 MySQL 的区别是什么？",
        "Redis 与 Memcached 有什么区别？",
        "Redis 集群模式有哪些？",
        "Redis 过期删除策略有哪些？",
        "列举 Spring 支持的事务管理类型。",
        "什么是 Redis 持久化，RDB 和 AOF 如何比较？",
        "Redis 最适合的场景有哪些？",
        "Redis 哈希槽的概念是什么？",
        "什么是 Redis 缓存穿透、缓存雪崩、缓存击穿？",
        "Redis 如何实现高并发？",
        "Redis 哨兵机制的作用是什么？",
        "Zookeeper 是如何保证事务的顺序一致性的？",
        "MySQL 的存储引擎有哪些，区别是什么？",
        "Hash 索引和 B+ 树索引的区别是什么？",
        "聚集索引和非聚集索引的区别是什么？",
        "如果数据库访问量特别大，怎么做优化？",
        "Phoenix 二级索引特点是什么？",
        "维度建模和范式建模的区别是什么？",
        "单事务事实表、多事务事实表的区别与作用是什么？",
        "Hive on Spark 与 Spark SQL 的区别是什么？",
        "Hive 和传统数据库的区别是什么？",
        "数据库事务的 ACID 分别是什么？",
        "乐观锁几种方式的区别是什么？",
        "MyISAM 与 InnoDB 的区别是什么？",
        "MySQL 有哪些存储引擎？它们有什么区别？",
        "哈希索引是什么？",
        "如何创建索引？",
        "关系型数据库与非关系型数据库的区别是什么？",
        "MySQL 与 Redis 的区别是什么？",
        "HBase 为什么比 MySQL 快？",
        "HBase 跟 MySQL 的区别是什么？",
        "SparkSQL 中 RDD、DataFrame、DataSet 三者的转换及区别是什么？",
        "HBase 二级索引原理是什么？",
        "窗口函数是什么？窗口函数有什么用？",
        "为什么要在 MongoDB 中用 \"Code\" 数据类型？",
        "为什么要在 MongoDB 中用 \"Regular Expression\" 数据类型？",
        "如何执行事务/加锁？",
        "请简洁描述 MySQL 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别？",
        "请简述常用的索引有哪些种类？以及在 MySQL 数据库中索引的工作机制是什么？",
        "Redis 的数据淘汰策略有哪些？",
        "说说 Redis 哈希槽的概念？",
        "Redis 事务相关的命令有哪几个？",
        "都有哪些办法可以降低 Redis 的内存使用情况呢？",
        "MySQL 中 InnoDB 支持的四种事务隔离级别名称分别是什么？它们之间逐级有什么区别？",
        "MySQL 支持哪几种存储引擎？分别有什么特点？",
        "MySQL 数据库服务器性能分析的方法/命令有哪些？",
        "数据库的三范式是什么？",
        "MySQL 表中允许有多少个 TRIGGER？",
        "列表中实际有 9 个 Redis 实例，当需要扩容时增加一台物理机，步骤是什么？",
        "MySQL 和 SQL Server 有什么相似之处？",
        "sqlmap 常用的参数有哪些？",
        "SQL Server 注入有了解吗？怎么判断是不是 SQL Server？",
        "SQL 注入防护方法有哪些？",
        "聊聊 SQL 注入？",
        "MySQL 版本是什么？",
        "如何在 MySQL 中运行批处理模式？",
        "什么是事务隔离级别？MySQL 支持哪些事务隔离级别？",
        "Oracle 19c 新特性有哪些？",
        "在 Oracle 19c 中如何使用多租户架构？",
        "如何升级到 Oracle 19c？",
        "Oracle 19c 中的 Data Guard 有哪些改进？",
        "如何在 Oracle 19c 中优化查询性能？",
        "Oracle 19c 中如何管理闪回恢复区？",
        "如何在 Oracle 19c 中使用临时表？",
        "Oracle 19c 中如何配置自动工作负载管理？",
        "如何在 Oracle 19c 中创建基于角色的访问控制？",
        "如何在 Oracle 19c 中使用分区表？",
        "如何在 Oracle 19c 中进行表空间管理？",
        "如何在 Oracle 19c 中设置自动备份？",
        "Oracle 19c 中的快照稳定性是如何实现的？",
        "Oracle NET 相关的三个文件具体路径在什么地方？",
        "控制文件是数据库启动第几阶段加载的文件？",
        "在 Oracle 中，数据块、Redo 日志块及控制文件数据块的大小分别是多少？如何查询？",
        "请描述什么是 Oracle Undo？",
        "如何找到 ORA-01555对应的 SQL？",
        "Oracle 的SCN是什么？",
        "如何处理 Oracle中的坏块？",
        "如果必须利用备份恢复数据库，但是又没有控制文件，如何解决问题？",
        "是否设置了 Oracle限制？",
        "全索引扫描和索引快速扫描之间的明显区别是什么？",
        "请解释 Oracle数据库中的 undo表空间的作用。",
        "请解释 Oracle数据库中的 redo log 的作用。",
        "请解释 Oracle数据库中的控制文件的作用。",
        "请解释 Oracle数据库中的临时表空间的作用。",
        "请解释 Oracle数据库中的归档模式和非归档模式的区别。",
        "请解释 Oracle数据库中的索引组织表（IOT）的作用。",
        "请解释 Oracle数据库中的并行查询和并行 DML操作的原理。",
        "请解释 Oracle数据库中的回滚段（rollback segment）的作用。",
        "请解释 Oracle数据库中的 RMAN（恢复管理器）的作用。",
        "请解释 Oracle数据库中的 Data Guard 的作用。",
        "请解释 Oracle数据库中的 Streams 的作用。",
        "请解释 Oracle数据库中的 Golden Gate 的作用。",
        "请解释 Oracle数据库中的执行计划（explain plan）的作用。",
        "请解释 Oracle数据库中的触发器（trigger）的作用。",
        "请解释Oracle数据库中的内存顾问（Memory Advisor）的作用。",
        "请解释Oracle数据库中的段顾问（Segment Advisor）的作用。",
        "请解释Oracle数据库中的 SQL顾问（SQL Advisor）的作用。",
        "如何使用 SQL 顾问？",
        "行SQL查询并查看这些视图，你可以了解数据库是如何使用内存？",
        "Jenkins Pipeline 中 post 的 always 与 cleanup 有什么区别？cleanup 是否会在其它 post 条件执行之后执行？",
        "Jenkins Pipeline 的 environment 主要用于配置环境变量吗？根据配置的位置如何决定环境变量的作用域？",
        "Jenkins Pipeline 的 input 步骤中 message 参数有什么作用？",
        "TIMESTAMP 在 UPDATE CURRENT_TIMESTAMP 中起什么作用？",
        "如何查看为表定义的所有索引？",
        "如何得到受查询影响的行数？",
        "对 BLOB 值进行排序和比较时是否区分大小写？",
        "MyISAM 表格将在哪里存储，并提供其存储格式？",
        "什么是图灵完备语言？Python 是图灵完备的吗？",
        "MySQL 支持哪几种存储引擎？",
        "什么是事务隔离级别？MySQL 支持哪些？",
        "HTTP 和 HTTPS 的区别？",
        "黑盒测试和白盒测试的区别是什么？",
        "Python 支持多重继承吗？",
        "Python 中的私有变量应该如何定义？",
        "分布式系统有哪些常见设计模式？",
        "CAP 理论和 BASE 理论是什么？",
        "Python 中单引号、双引号、三引号的区别是什么？",
        "在不需要转义的时候，单引号和双引号无区别吗？",
        "如何定制支持 datetime 类型？",
        "help() 函数的作用是什么？",
        "白盒测试和黑盒测试的区别？",
        "测试用例设计的完整过程？",
        "单元测试、集成测试、系统测试的区别？",
        "测试用例的颗粒度划分？",
        "高中低优先级的测试用例的比例占多少？",
        "什么叫预测试？预测试是怎么进行的？预测试一般为多长时间？",
        "您在从事性能测试工作时，是否使用过一些测试工具？如果有，请试述该工具的工作原理，并以一个具体的工作中的例子描述该工具是如何在实际工作中应用的。",
        "在您以往的工作中，一条软件缺陷（或者叫 Bug）记录都包含了哪些内容？如何提交高质量的软件缺陷（Bug）记录？",
        "软件配置管理工作开展的情况和认识是什么？",
        "请问功能测试和性能测试的区别是什么？",
        "什么是软件测试？",
        "软件测试的目的是什么？",
        "以前一天能够编写多少条测试用例？",
        "项目一共有多少条测试用例？",
        "你熟悉的测试用例设计方法有哪些？",
        "你认为做好测试用例设计工作的关键是什么？",
        "你在从事性能测试工作时是否使用过测试工具？",
        "如果使用过，请说明该工具的工作原理，并举例说明该工具如何在实际工作中应用。",
        "你认为性能测试工作的目的是什么？做好性能测试工作都包含哪些内容？",
        "你对软件配置管理工作开展的情况和认识是什么？",
        "缺陷测试报告的组成是什么？",
        "完成测试需要多少工作量？需要多少人员？",
        "系统会采取什么技术？系统会采用什么架构？这些信息如何有助于确定测试策略？",
        "系统开发和测试分配的时间有多长？截止日期是什么时候？",
        "是否有不正确或遗漏的功能？",
        "功能实现是否满足用户需求和系统设计的隐藏需求？",
        "能否正确接收输入并正确输出结果？"
      ]
    },
    "机器学习": {
      "count": 162,
      "questions": [
        "SVM 核函数之间的区别？",
        "SMO 算法在求解 SVM 的超平面方程中，扮演了一个什么样的角色？",
        "SVM 为什么使用拉格朗日乘子法？软间隔怎么做？",
        "SVM 怎么处理过拟合？",
        "SVM 有哪些可以调节的参数？",
        "SVM 的原理是什么？怎么找到最优的线性分类器？支持向量是什么？",
        "SVM 的推导过程是什么？",
        "如何使用 SVM 处理多分类问题？",
        "常用的 SVM 核函数有哪些？",
        "请你简单介绍一下 SVM？",
        "请你说说支持向量机（SVM）？SVM 与 LR 之间有什么样的区别和联系？",
        "DFL能否用于实例分割的Mask回归？",
        "为什么逻辑回归用sigmoid激活函数？多分类逻辑回归是否也是sigmoid？",
        "什么是回归？业务应用场景？常见回归算法？",
        "什么是回归？哪些模型可用于解决回归问题？",
        "回归模型和分类模型的评价指标都有什么？",
        "回归、分类、聚类方法的区别和联系并举例，简要介绍算法思路？",
        "时间序列预测需要注意的点？和回归有何区别？",
        "简单介绍一下逻辑回归？",
        "线性回归的推导？",
        "说一说逻辑回归和SVM的区别和联系？",
        "逻辑回归与线性回归的联系、异同？",
        "逻辑回归为什么要对特征进行离散化？为什么要对特征进行标准化？",
        "LR如何解决多分类问题？（OvR vs OvO）？",
        "在训练的过程当中，如果有很多的特征高度相关或者说有一个特征重复了100遍，会造成怎样的影响？",
        "LR参数求解的优化方法？(机器学习中常用的最优化方法)？",
        "什么是监督学习？什么是非监督学习？",
        "为了解决KNN算法计算量过大的问题，可以使用分组的方式进行计算，简述一下该方式的原理？",
        "在k-means或kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用曼哈顿距离？",
        "归一化和标准化的区别？",
        "K-means是否会一直陷入选择质心的循环停不下来（为什么迭代次数后会收敛）？",
        "什么是深度学习？深度学习的训练过程是什么？",
        "什么是聚类？业务应用场景？常见算法？",
        "去掉高度相关的特征会让模型的可解释性更好？",
        "名词解释：点击率CTR、转化率CVR？",
        "如何建立价格预测模型？价格是否正态分布？需要对价格进行预处理吗？",
        "对统计这一块了解吗？p值是什么？",
        "朴素贝叶斯，怎么平滑？",
        "熟悉哪些聚类算法，解释下K-means 算法？什么时候或条件下停止迭代？",
        "维度灾难是什么？为什么要关心它？",
        "请说一说朴素贝叶斯模型？它的假设条件是什么？",
        "采用分箱技术时，需要确定的两个主要问题就是：如何分箱以及如何对每个箱子中的数据进行平滑处理？",
        "XGBoost如何寻找最优特征？是有放回还是无放回？",
        "GBDT使用基学习器是CART树，CART树是二叉树，每次使用yes or no进行特征选择，数值连续特征使用的最小均方误差，离散值使用的gini指数。在每次划分特征的时候会遍历所有可能的划分点找到最有的特征分裂点，这是为什么gbdt会比rf慢的主要原因之一？",
        "GBDT如何防止过拟合？由于gbdt是前向加法模型，前面的树往往起到决定性的作用，如何改进这个问题？",
        "XGBoost如何分布式？特征分布式和数据分布式？各有什么问题？",
        "为什么使用贪心和启发式搜索建立决策树，为什么不直接使用暴力搜索建立最优的决策树？",
        "如何避免决策树过拟合？",
        "L1正则化产生稀疏性的原因？对稀疏矩阵的理解？",
        "MoE如何解决Fine-Tuning过程中的过拟合问题？",
        "t-SNE图好看但指标掉点，如何防止“可视化过拟合”？",
        "xgboost中哪些参数可以控制过拟合？",
        "什么是过拟合？产生过拟合原因？",
        "交叉验证是用来评估模型在新的数据集上的预测效果，也可以一定程度上减小模型的过拟合吗？",
        "如何检验过拟合，数据量很小怎么办？",
        "如何简单理解过拟合？如何防止过拟合？",
        "请说一下你是通过什么方法来判断模型欠拟合和过拟合的？",
        "神经网络处理过拟合的方法？",
        "神经网络的正则化方法？过拟合的解决方法？",
        "什么是ROC曲线？如何判断 ROC 曲线的好坏？",
        "什么是准确率、精准率、召回率和F1分数？什么是混淆矩阵？",
        "回归、分类、聚类方法的区别和联系是什么？请举例并简要介绍算法思路。",
        "模型受到低偏差和高方差问题时，应该使用哪种算法来解决问题？",
        "无监督学习中的聚类是什么？聚类的目的是什么？聚类算法通常需要哪些信息才能开始工作？",
        "去掉高度相关的特征会让模型的可解释性更好吗？",
        "如何解释AUC-ROC分数？",
        "什么是特征选择？为什么需要它？特征选择的目标是什么？",
        "如果特征很多，决策树中最后没有用到的特征一定是无用的吗？",
        "什么是随机森林？它的基本原理是什么？",
        "RF 分类和回归问题如何预测 y 值？",
        "在 K-means 中，如果特征量级差异很大（如 F 和 M），不做归一化会有什么影响？",
        "PCA 降维的原理是什么？",
        "LDA 降维的原理是什么？",
        "什么是聚类？有哪些业务应用场景？常见算法有哪些？",
        "什么是分类？有哪些业务应用场景？常见算法有哪些？",
        "什么是回归？有哪些业务应用场景？常见回归算法有哪些？",
        "稀疏特征匹配和稠密匹配的区别是什么？",
        "LSD-SLAM 中将直接法应用到半稠密单目 SLAM，有哪些优缺点？",
        "特征点主方向计算方法与 SIFT 有何不同？",
        "Kd 树是什么？建立 Kd 树时要注意什么？",
        "预测步骤中如何从上一时刻状态与输入推断当前时刻状态分布（先验）并计算协方差？",
        "机器人学中地图的表示方法有哪些？",
        "RAG 检索召回率低一般有哪些解决方案？",
        "如何解决 torch.multiprocessing 共享内存文件泄漏问题？",
        "在大规模知识库场景中如何提高检索效率和文档召回率？",
        "如何保障企业数据安全？",
        "就一般企业而言，如何进行档案分类？",
        "交叉熵公式是什么？分类为什么用交叉熵不用平方差？",
        "CLIP 编码特征的优缺点是什么？",
        "当草案模型接受率 <60% 时，如何动态切换回自回归？",
        "如何构建多语言敏感分类器并保证 F1>95%？",
        "如何采用 CLIP 相似度聚类抽取 10 个关键帧并覆盖 90% 内容？",
        "如何用 SHAP 解释分类结果并可视化 top token？",
        "当聚类纯度 <0.7 时，如何采用半监督 refine？",
        "如何采用交叉验证检测标注者系统偏差？",
        "机器学习和统计中的 AUC 的物理意义是什么？",
        "最大间隔分类器（Maximum Margin Classifier）的定义是什么？",
        "介绍图片分类demo时，你是怎么对数据集进行处理的？",
        "分类器如何判断物品属于同一类物品？",
        "请介绍细粒度分类项目中的数据集：多少个类，每个类多少张图片？",
        "为什么使用macro-F1？为什么不用Precision、Recall？",
        "简单介绍下聚类？",
        "介绍下GBDT？GBDT的基模型是什么，是分类树还是回归树？Gradient如何体现？",
        "逻辑回归与线性回归有什么区别？",
        "逻辑回归的优缺点是什么？",
        "分类与聚类的区别是什么？",
        "分类问题是否可以用MSE？为什么分类不用MSE而用交叉熵？",
        "文本分类的具体流程是什么？",
        "（一个具体的）文本分类任务可以使用哪些特征？",
        "文本分类任务使用的评估方法和指标有哪些？",
        "LR和线性回归的区别是什么？",
        "DBSCAN聚类算法原理是什么？",
        "IP分类的优缺点是什么？",
        "给出一种自适应anchor聚类（K-means++）的完整流程是什么？",
        "Java（OOP）面向对象的特征有哪些方面？",
        "Kafka、ActiveMQ、RabbitMQ、RocketMQ各自的优缺点是什么？",
        "XSS的分类有哪些？",
        "越权漏洞的分类有哪些？",
        "审计如何分类？",
        "MRP（Managed Recovery Process）进程只针对物理备库，它的作用是什么？",
        "SVM的推导？",
        "朴素贝叶斯的优缺点？",
        "如何用贝叶斯序贯检验减少实验样本量并提前收敛？",
        "LR 和SVM 的区别",
        "频率学派和贝叶斯学派的区别",
        "给出一种基于贝叶斯优化的离线增强策略搜索流程",
        "什么是过拟合？产生过拟合的原因是什么？",
        "什么是L0、L1、L2正则化？",
        "L1正则化产生稀疏性的原因是什么？如何理解稀疏矩阵？",
        "树模型为什么不需要归一化？",
        "不平衡样本会给KNN的预测结果造成哪些问题？有什么解决方式？",
        "为了解决KNN算法计算量过大的问题，可以使用分组的方式进行计算，请简述该方式的原理。",
        "在K-means或KNN中常用欧氏距离计算距离，为什么不用曼哈顿距离？",
        "SVM的推导是什么？",
        "SVM不同核函数之间的区别是什么？",
        "决策树的数据划分（split）原理或流程是什么？",
        "决策树如何剪枝？",
        "决策树和条件概率分布有什么关系？",
        "为什么使用贪心搜索建立决策树，而不直接使用暴力搜索建立最优决策树？",
        "决策树如何做回归？",
        "决策树算法的停止条件有哪些？",
        "为什么在决策树之前做 PCA 可能会更好？",
        "GBDT 的训练过程中如何选择特征？",
        "GBDT 为什么会比 RF 慢？",
        "GBDT 如何防止过拟合？由于 GBDT 是前向加法模型，前面的树往往起到决定性作用，如何改进这个问题？",
        "GBDT 与 Boosting 的关系是什么？",
        "GBDT 对标量特征要不要做 one-hot 编码？",
        "为什么 GBDT 用负梯度当作残差？",
        "为什么 AdaBoost 能够提高整体模型的学习精度？",
        "使用 m 个基学习器加权平均与使用 m 个学习器之间有什么不同？",
        "AdaBoost 的迭代次数（基学习器个数）如何控制？",
        "AdaBoost 中基学习器是否重要，应该怎么选择基学习器？",
        "为什么树模型在高维稀疏特征下更容易过拟合？",
        "XGBoost 在什么地方做剪枝？如何进行剪枝？",
        "基于决策树算法的分布式梯度提升框架是对GBDT的高效实现，原理上它和GBDT及XGBoost类似，都采用损失函数的负梯度作为当前决策树的残差近似值，去拟合新的决策树？",
        "One-hot编码可以在预处理阶段或在训练期间完成吗？如何处理类别型特征更鲁棒？",
        "K-means是否会一直陷入选择质心的循环停不下来？为什么迭代次数后会收敛？"
      ]
    },
    "测试": {
      "count": 87,
      "questions": [
        "如何测试显卡利用率？",
        "TopK 采样（从 Softmax 输出中选择 logit 最大的 K 个 token）存在什么问题？",
        "请提出一个问题，让模型给出多个不同的答案或解决方案，以测试模型的创造力和多样性。",
        "请模型回答关于不同主题的问题，以测试其对不同领域的知识掌握程度。",
        "在什么情况下撒谎是可以接受的？",
        "能否简述一下黑盒测试和白盒测试的区别？",
        "如何使用 unittest 模块进行单元测试？",
        "描述一下你在过去的一个项目中是如何进行测试设计的。",
        "如何编写高效的测试脚本？",
        "你认为什么是好的测试策略？",
        "什么是兼容性测试？兼容性测试侧重哪些方面？",
        "常用的测试方法有哪些？",
        "静态测试和动态测试有什么区别？",
        "测试用例设计的完整过程是什么？",
        "Beta 测试与 Alpha 测试有什么区别？",
        "你认为做好测试工作的关键是什么？",
        "软件的安全性应该从哪几个方面去测试？",
        "单元测试、集成测试、系统测试的区别是什么？",
        "怎么进行需求测试？",
        "什么是测试点？测试点包含哪些内容？",
        "什么是测试方案？什么是测试策略？",
        "测试方案是谁编写的？",
        "测试方案包含哪些内容？",
        "测试方案编写的输入条件是什么？",
        "测试用例设计方法有哪些？",
        "测试用例内容有哪些？",
        "什么是好的测试用例？",
        "测试用例的颗粒度如何划分？",
        "测试用例为什么需要有优先级？有哪些优先级？",
        "你们以前一天能够编写多少条测试用例？",
        "你们项目一共有多少条测试用例？",
        "高中低优先级的测试用例比例各占多少？",
        "测试用例需要哪些人来评审？",
        "个项目需要写多少测试用例？怎么估算？",
        "测试用例是谁写的？",
        "不能发现 BUG 的测试用例就不是好的测试用例吗？",
        "为什么要进行交叉测试？",
        "你们测试版本是在哪获取的？",
        "什么叫预测试？预测试是怎么进行的？预测试一般多长时间？",
        "你的测试职业发展是什么？",
        "你认为测试人员需要具备哪些素质？",
        "你为什么能够做测试这一行？",
        "测试的目的是什么？",
        "测试分为哪几个阶段？",
        "您所熟悉的测试用例设计方法都有哪些？",
        "您认为做好测试用例设计工作的关键是什么？",
        "您在从事性能测试工作时，是否使用过测试工具？如果有，请描述该工具的工作原理。",
        "您认为性能测试工作的目的是什么？做好性能测试工作的关键是什么？",
        "你对测试最大的兴趣在哪里？为什么？",
        "测试活动中，如果发现文档不完善或者不准确，怎么处理？",
        "你认为做好测试计划工作的关键是什么？",
        "你觉得软件测试通过的标准应该是什么样的？",
        "简述软件系统中用户文档的测试要点？",
        "没有产品说明书和需求文档的情况下能够进行黑盒测试吗？",
        "为什么尽量不要让时间富裕的员工去做一些测试？",
        "完全测试程序是可能的吗？",
        "软件测试的风险主要体现在哪里？",
        "您在以往的测试工作中都曾经具体从事过哪些工作？其中最擅长哪部分工作？",
        "软件测试项目从什么时候开始？为什么？",
        "功能测试用例需要详细到什么程度才是合格的？",
        "缺陷测试报告的组成？",
        "你都用什么测试方法？",
        "什么是软件测试？软件测试的目的是什么？",
        "什么是兼容性测试？",
        "软件测试的对象有哪些？",
        "当测试过程发生错误时，有哪几种解决办法？",
        "怎么才能够全面的测试到每一个点？",
        "开发与测试的关系是什么？",
        "进行测试时产生了哪些文档或记录？",
        "怎样做好测试计划？",
        "什么时候进行功能测试？",
        "功能测试和性能测试的区别是什么？",
        "为什么选择测试这行？",
        "什么是黑盒测试和白盒测试？",
        "什么是单元测试和集成测试？",
        "UAT测试和预生产测试的内容是什么？",
        "白盒测试和黑盒测试的区别是什么？",
        "高中低优先级的测试用例比例占多少？",
        "不能发现BUG的测试用例不是好的测试用例吗？",
        "你们测试版本是从哪获取的？",
        "什么叫预测试？预测试是怎么进行的？",
        "您在从事性能测试工作时，是否使用过一些测试工具？",
        "您认为性能测试工作的目的是什么？",
        "您在以往的测试工作中都曾经具体从事过哪些工作？",
        "测试技术达到一定程度后，如何带领一个测试团队？",
        "缺陷测试报告的组成有哪些？",
        "进行测试时会产生哪些文档或记录？"
      ]
    },
    "深度学习": {
      "count": 303,
      "questions": [
        "Max pooling如何工作？还有其他池化技术吗？",
        "卷积核是否一定越大越好？它的优点有哪些？",
        "CNN中的卷积到底指什么？举个例子？",
        "CNN是否抗旋转？如果旋转图像，CNN的预测会怎样？",
        "TextCNN 的结构可以说一下吗？卷积核的层数应该怎么取？",
        "卷积神经网络的优点是什么？为什么用小卷积核？",
        "在卷积神经网络中，卷积操作的数学表达式是什么？请解释卷积核、步长和填充在其中的作用。",
        "当网络里出现转置卷积stride=2做上采样时，如何防止棋盘效应？",
        "说说R-CNN、Fast R-CNN和Faster R-CNN的区别。",
        "为什么 LSTM 比 RNN 好？请推导并解释 forget gate、input gate、cell state、hidden state 的更新过程，以及其如何缓解梯度消失/爆炸。",
        "请写出 LSTM 的前向公式，并手推其反向传播（梯度）过程。",
        "LSTM 与 GRU 的关系是什么？",
        "LSTM 与 GRU 有哪些区别？",
        "LSTM 和 RNN 有什么区别？分别解决什么问题？",
        "请解释 RNN 的原理。",
        "RNN 和传统前馈神经网络最大的区别是什么？",
        "ELMo 为什么用两层单向 LSTM 而不是 Bi-LSTM？",
        "什么是双向 RNN（Bidirectional RNN）？",
        "什么是双向 LSTM（Bidirectional LSTM）？",
        "RNN 如何解决长期依赖问题？LSTM 的结构是怎样的？",
        "请解释 LSTM 中遗忘门（forget gate）的计算公式及其作用。",
        "什么是微调（fine-tune）？",
        "阶优化和二阶优化的方法有哪些？为什么不使用二阶优化？",
        "神经网络数据预处理方法有哪些（如中心化/零均值、归一化）？",
        "在 LSTM 中，遗忘门 Ft 和 Ct-1 做点积的作用是什么？",
        "在 LSTM 中，遗忘门的作用是什么？",
        "在 LSTM 中，输入门的作用是什么？",
        "在 LSTM 中，输出门的作用是什么？",
        "什么是 LeNet？",
        "batch size 和 epoch 如何平衡？",
        "什么是 AlexNet？",
        "为什么样本要做归一化？",
        "什么是 Inception（GoogLeNet）？",
        "什么是 ResNet？",
        "如何合理使用预训练网络？",
        "什么是 DenseNet？",
        "什么是实例分割（对象分割）？你知道有哪些框架吗？",
        "什么是数据增强？为什么需要它？你知道哪些增强方式？",
        "什么是目标检测？你知道有哪些框架吗？",
        "什么是迁移学习？它是如何工作的？",
        "反向传播中链式求导法则如何使用？",
        "牛顿法的原理是什么？",
        "LR（逻辑回归）损失函数是什么？怎么来的？为什么这么定义？里面取 log 是为了什么？",
        "什么是 Adam？Adam 和 SGD 之间的主要区别是什么？",
        "学习率太大或太小时会发生什么？如何设置学习率？",
        "神经网络中的梯度消失和梯度爆炸是什么？怎么解决？梯度爆炸会引发什么问题？",
        "批量归一化（BN）如何实现？作用是什么？",
        "什么是 Dropout？为什么有用？它是如何工作的？",
        "什么是梯度下降？SGD 的推导是什么？",
        "使用验证集如何判断什么时候开始降低学习率，以及什么时候停止训练？",
        "各个激活函数的优缺点？",
        "梯度消失和梯度爆炸的解决方案？梯度爆炸引发的问题？",
        "批量归一化(BN)如何实现？作用？",
        "神经网络中权值共享的理解？",
        "对fine-tuning(微调模型)的理解？为什么要修改最后几层神经网络权值？",
        "学习率太大(太小)时会发生什么？如何设置学习率？",
        "sigmoid和softmax的区别？softmax的公式？",
        "神经网络数据预处理方法有哪些？中心化/零均值、归一化？",
        "什么是鞍点问题？梯度为0、海森矩阵不定的点不是极值点？",
        "用Keras如何搭建CNN？",
        "什么是Inception(GoogLeNet)？",
        "卷积神经网络的优点？为什么用小卷积核？",
        "LSTM的原理、写LSTM的公式、手推LSTM的梯度反向传播？",
        "微调先冻结底层，训练顶层的原因？",
        "为什么需要激活功能？",
        "Dropout在训练和测试的区别？",
        "DenseNet 比 ResNet 好？",
        "DenseNet 直接连接不同层的特征图，而不是像 ResNet 一样 element-wise sum。为什么 DenseNet 比 ResNet 更耗显存？",
        "为什么采用 max pooling，而分类使用 average pooling？",
        "什么是数据增强？为什么需要它？你知道哪些增强？",
        "什么是对象分割？你知道有哪些框架吗？",
        "RNN 和传统神经网络最大的区别？",
        "RNN 的缺点有哪些？",
        "LSTM 结构推导，为什么比 RNN 好？推导 forget gate、input gate、cell state、hidden information 等的变化。",
        "推导：链式求导法则反复用？",
        "什么是batch size和epoch的平衡？",
        "什么是合理使用预训练网络？",
        "反向传播层数很多时为什么会出现梯度消失，导致越往前传梯度越小、训练变慢？",
        "验证集在决定何时降低学习率和何时停止训练中起什么作用？",
        "DenseNet 的连接方式与 ResNet 有什么区别？为什么 DenseNet 比 ResNet 更耗显存？",
        "RNN 和传统神经网络最大的区别是什么？",
        "为什么 LSTM 比 RNN 好，如何从门控机制解释其缓解梯度消失/爆炸？",
        "什么是过拟合？产生过拟合的原因有哪些？",
        "什么是欠拟合？",
        "L0、L1、L2 正则化分别是什么？",
        "L1 正则化为什么会产生稀疏性？",
        "线性回归的基本原理是什么（线性函数拟合、MSE 损失、梯度下降求解）？",
        "线性回归的损失函数为什么常用均方误差（MSE）？",
        "训练过程中如果很多特征高度相关或某个特征重复多次，会造成什么影响？",
        "为什么训练过程中要去掉高度相关的特征？",
        "什么是交叉验证？它在评估泛化性能和减小过拟合方面有什么作用？",
        "决策树中限制叶子节点最小样本数（小于阈值不再分裂）为什么能缓解过拟合？",
        "GBDT 训练过程中如何选择特征？",
        "GBDT 如何防止过拟合？前面的树起决定性作用的问题如何改进？",
        "为什么 GBDT 用负梯度作为残差？",
        "梯度提升（GBDT）如何调参？",
        "XGBoost 中叶子节点的权重如何计算？",
        "树模型在什么情况下更容易过拟合，原因是什么？",
        "为什么在高维稀疏特征场景下，带正则化的线性模型可能比非线性模型更好？",
        "XGBoost 模型过拟合了怎么解决？",
        "随机森林为什么通常不需要剪枝？",
        "梯度下降方法，从 GN、LM、DogLeg 中怎么选？",
        "ORB-SLAM 初始化流程是什么？",
        "高斯-牛顿（G-N）和 Levenberg–Marquardt（L-M）方法有什么区别？",
        "手写 softmax 公式；手写 BN 公式；softmax 层的 label 是什么？",
        "如何基于 n-gram 频率训练小型草案模型并设置接受阈值？",
        "哪种词嵌入可以自定义训练特定主题？",
        "fastText 利用词内 n-gram 信息的训练过程是什么？",
        "Word2vec 的训练 trick 有哪些，window 一般设置多大？",
        "LR/SVM/softmax/AdaBoost 的损失函数之间有什么差别？",
        "微调大模型时优化器怎么选、怎么配？",
        "为什么需要 Prefix-tuning？",
        "Prefix-tuning 的思路是什么？",
        "训练式位置编码的应用场景有哪些？",
        "RLHF 训练过程是什么，怎么选取最优 checkpoint？",
        "预训练（Pre-training）是什么？",
        "大模型训练的 loss 突刺是什么？",
        "为什么需要 Prompt-tuning？",
        "Prompt-tuning 的思路是什么？",
        "Prompt-tuning 与 Prefix-tuning 的区别是什么？",
        "Prompt-tuning 与 fine-tuning 的区别是什么？",
        "有监督微调（SFT）的训练数据格式是什么样的？",
        "如何在 SFT 模型基础上训练一个奖励模型（RM）？",
        "预训练（Pre-training）与有监督微调（SFT）的区别是什么？",
        "如何基于 RM 使用 PPO 算法微调 SFT 模型？",
        "ChatGLM-6B 做 LoRA 后的权重多大？",
        "LoRA 微调的优点是什么？",
        "LoRA 微调的参数量怎么确定？",
        "LoRA 为什么能加速训练？",
        "LoRA 和全参数微调相比有什么劣势？",
        "model_name_or_path：预训练模型地址是什么？",
        "训练模型需要多少显存？",
        "tokenizer_name_or_path：预训练模型 tokenizer 地址是什么？",
        "为什么要做增量预训练？",
        "交叉熵损失函数如何写？物理意义是什么？",
        "分类问题为什么用交叉熵损失函数而不用均方误差（MSE）？",
        "在初始预训练中使用 Rewarmup 对大模型继续预训练的性能有什么影响？",
        "增量预训练训练流程是怎么样的？",
        "增量预训练过程中 loss 上升正常吗？",
        "多 GPU 并行训练的原理是什么？具体如何实现？",
        "大模型训练 loss 突刺的原因和解决办法是什么？",
        "如何基于 LoRA 的 LLaMA2 做二次预训练？",
        "如何基于 LoRA 的 LLaMA2 做微调？",
        "如何解决 PPO 训练过程同时存在 4 个模型（2 训练，2 推理）导致计算资源要求较高的问题？",
        "用 PyTorch 实现同步梯度更新并自研数据接口时，出现第一个 epoch 结尾处程序卡死，可能原因是什么？如何排查？",
        "学习率大小对大模型继续预训练后下游任务有什么影响？",
        "样本量规模增大时训练出现 OOM 错，可能原因是什么？如何解决？",
        "自回归语言模型的预训练和下游应用是否完全一致？是否严格遵守只有后面的 token 才能看到前面的 token？",
        "基于LoRA的LLaMA2二次预训练参数如何设置？",
        "训练大语言模型常见问题有哪些？",
        "训练数据如何设计与介绍？",
        "常见的分布式训练框架有哪些，都有什么特点？",
        "如何保存和加载多GPU训练模型？",
        "如果想构建一个大规模并行训练系统，训练框架如何选？",
        "大模型微调中，P-Tuning和传统Fine-tuning有什么区别？",
        "利用对比学习微调方式构建负例的方法有哪些？",
        "AMP混合精度训练如何实现？",
        "Apex是什么，它如何用于混合精度训练？",
        "DDP支持哪些通信操作（如all-reduce、broadcast、send、receive），各自作用是什么？",
        "DeepNorm如何提升训练稳定性？",
        "DeepSpeed支持哪些主要优化器，它们与ZeRO如何配合？",
        "gloo是什么，它在分布式训练中的作用是什么？",
        "GPU数量与训练速度的关系是什么？",
        "LoRA几乎不添加任何推理延迟的原因是什么？",
        "Memory-Efficient 的 LLMs 的训练/微调/推理方法有哪些？",
        "modules_to_save：除了 LoRA 部分之外，还有哪些层可以被训练，并且需要保存？",
        "module 是要放到多卡训练的模型吗？",
        "mpi 是一种跨节点通信库，常用于 CPU 集群上的分布式训练吗？",
        "nccl 是 NVIDIA 提供的 GPU 专用通信库，被广泛应用于 GPU 上的分布式训练吗？",
        "PandaLM：是否直接训练了一个自动化打分模型，用 0/1/2 三分制让模型对两个候选模型进行打分？",
        "process group 中的训练进程都起来后，rank=0 的进程会将网络初始化参数 broadcast 到其它每个进程中吗？",
        "RAG 与微调（Fine-tuning）如何协同？",
        "step 2 训练时是否只更新 Prefix 部分的参数，而 Transformer 中的其他部分参数固定？",
        "什么是 Trainer 训练类？",
        "如何编写 Trainer 训练类？",
        "ZeRO-Offload 的原理是什么，如何利用 CPU 和 GPU 内存训练更大的模型？",
        "ZeRO（Zero Redundancy Optimizer）的原理是什么？",
        "Softmax 交叉熵损失函数如何写？",
        "交叉熵损失函数是什么，为什么可从二分类泛化到多分类？",
        "混合精度训练中的动态损失缩放是什么？",
        "数据并行是什么：将数据集切分为多份，每张 GPU 分配到不同的数据进行训练，每个进程都有一个完整的模型副本？",
        "LoRA 的原理是什么：通过低秩分解来模拟参数的改变量，从而以极小的参数量实现大模型的间接训练？",
        "什么是 ZeRO 等优化器相关的并行，它与数据并行/模型并行的关系是什么？",
        "传统微调范式下为什么每个任务都要保存一份微调后的模型权重？",
        "梯度检查点（Gradient Checkpointing）有什么作用？",
        "如何对继续预训练数据进行预处理？",
        "如何让 Prompt Tuning 能够在不同参数规模的预训练模型、不同下游任务上达到匹敌 Fine-tuning 的效果？",
        "遇到 OOM 时，如何选择混合精度策略（Ampere GPU 用 bf16，旧 GPU 用 fp16）？",
        "在某个模型基础上做全参数微调需要多少显存？",
        "训练数据存在假负例（False Negative）时，应该如何训练模型？",
        "什么是对齐（Alignment）？如何通过微调将语言模型与人类偏好对齐？",
        "如何将 batch_size 设为 1 并通过梯度累积实现任意有效 batch_size？",
        "并行化训练如何加速？",
        "从单卡到多卡做分布式训练时，总体目标是什么？",
        "为什么多 GPU 训练可能不是负载均衡的（例如 0 卡占用更多）？",
        "未经过预训练的模型无论是上游任务还是下游任务，都不如预训练过的模型效果吗？",
        "梯度检查点（gradient checkpointing）的原理是什么？",
        "模型全量微调对每个任务训练一个模型，开销和部署成本都比较高吗？",
        "混合精度训练为什么采用 bfloat16 而不是 float16？",
        "已有的 LoRA 模型只训练了一部分数据，要训练另一部分数据，是在这个 LoRA 上继续训练，还是跟 base 模型合并后再套一层 LoRA，或者从头开始训练一个 LoRA？",
        "相同训练数据下，Reward Model 越大 actor 模型能够获得更高的真实 reward 吗？",
        "为什么训练开始前通常会将 0 号卡的模型参数通信同步到其他卡？",
        "为什么每张卡上的 loss 要汇总到第 0 张卡上求梯度，更新后再把权重分发到其余卡？",
        "分布式训练中为什么要在后向传递之后、优化器更新参数之前插入 reduce 通信操作来规约梯度？",
        "学习率越大，下游性能最好，上游性能最差（忘得最多）吗？",
        "专门针对某个领域进行训练的大模型是否可以更好地掌握该领域的语言特点，生成更符合该领域要求的文本？",
        "解释一下这里为什么这么关注训练前期？",
        "这样的训练目标为什么可能使得模型更倾向于生成与输入相似的文本，导致复读机问题的出现？",
        "训练大语言模型时，计算效率方面通常会遇到哪些问题？",
        "训练大语言模型时，训练成本为什么会很高？",
        "多机多卡训练时，增加训练机器是否可以线性缩短训练时间？",
        "有监督微调（Supervised Finetuning）与预训练（Pre-training）的训练数据格式有什么不同？",
        "有监督微调（Supervised Finetuning）与预训练（Pre-training）的训练数据量有什么不同？",
        "训练时原模型固定，只训练降维矩阵A和升维矩阵B的做法是什么？",
        "训练更大的模型时，为什么每块GPU里不仅要存模型参数，还要存中间结果（用于Backward）？",
        "大型语言模型的训练目标通常是什么？",
        "训练类型是否支持数据并行、张量并行、流水线并行、多维混合并行、自动并行等？",
        "数据并行的优缺点是什么？",
        "进行多任务同时训练时，为什么要尽量使各个任务的数据量平衡？",
        "选取训练数据时，为什么要保证数据干净并具有代表性？",
        "训练崩溃后，如何选择一个好的断点跳过训练崩溃的数据段并进行断点重训？",
        "重新训练时是否可以直接加载向量化后的数据？",
        "为什么要针对不同任务采用不同的提示长度？",
        "什么是长度外推问题（训练、推理长度不一致）？",
        "什么是位置编码不一致问题（推理时出现训练没见过的位置编码）？",
        "训练时用bf16、使用时用fp16可能导致什么问题？",
        "为什么训练样本数量从10万增大到300万可能导致OOM？",
        "学习率在微调时为什么不要大于预训练时的学习率？",
        "为什么随着预训练模型参数量增加，Prompt Tuning的方法会逼近全参数微调的结果？",
        "为什么训练和运行大模型会显著增加计算与存储资源消耗？",
        "预训练数据参数如何介绍？",
        "预训练模型参数如何介绍？",
        "为什么预训练模型参数量变多后，在特定任务下进行全量微调会更昂贵且耗时？",
        "请解释残差连接的公式和原理，并说明它在深度神经网络中的作用？",
        "领域模型微调时，指令与数据输入格式有什么要求？",
        "想让模型学习某个领域或行业的知识，应该继续预训练还是微调？",
        "微调大模型时，如果 batch size 设置太大会出现什么问题？",
        "Memory-Efficient 的 LLM 训练/微调/推理方法有哪些？",
        "过拟合怎么解决？",
        "机器学习中的梯度消失、爆炸原因及其解决方法有哪些？",
        "深度学习为什么在计算机视觉领域效果好？",
        "Batch Normalization 的作用是什么？",
        "如何用 DVC + Git LFS 管理 500GB 微调数据集并支持回滚到任意版本？",
        "当三类任务样本量差异 100× 时，如何设置 softmax 温度系数防止过拟合？",
        "如何用 EWC（Elastic Weight Consolidation）计算重要权重矩阵并加入损失？",
        "当候选段落长度差异 10× 时，如何采用动态 padding 提升 batch 吞吐？",
        "如何基于 AIMET 对 Transformer 层进行权重量化并校准？",
        "如何设计用户举报闭环，将错误样本回流到微调集？",
        "如何用 GitHub Actions 触发数据→训练→评估→部署全链路？",
        "当监管部门要求出具算法备案表时，如何一键导出训练数据来源？",
        "如何采用强化学习对抗训练提升模型鲁棒性？",
        "当视觉编码器占 70% 计算时，如何采用 MobileViT 替换并微调？",
        "如何记录失败轨迹并用于后续微调提升成功率？",
        "当答案为“无法确定”时，如何设置阈值防止过拟合？",
        "当扩展后 PPL 上升 15% 时，如何采用课程长度微调恢复？",
        "如何评估并行方案对训练吞吐的提升？",
        "如何监控 entropy 崩溃并自动重启训练？",
        "当压缩比 8× 时，如何采用微调恢复 98% 准确率？",
        "baichuan 进行微调时，领域数据与通用数据的配比如何确定？",
        "微调模型中正负样本比例的策略是什么？",
        "微调 BERT 模型时如何选择微调的层次，原因是什么？",
        "Transformer 为什么 Q 和 K 使用不同的权重矩阵生成，为什么不能使用同一个值进行生成？",
        "解释一下深度学习中迁移学习的概念。",
        "解释一下反向传播在神经网络中是如何工作的。",
        "如何评估一个深度学习模型的性能？",
        "解释一下卷积神经网络和循环神经网络的区别。",
        "LR（逻辑回归）损失函数？怎么来的？为什么这么定义？里面取log是为了什么？",
        "如何防止过拟合的？",
        "牛顿法和梯度下降的区别",
        "深度学习有哪些过拟合方法？了解哪些激活函数？激活函数怎么选用？各有什么优缺点？",
        "解释一下反向传播算法，Pooling层的作用",
        "深度学习的损失函数有哪些？",
        "神经网络中的梯度消失和梯度膨胀是什么，怎么解决？",
        "循环神经网络RNN怎么解决长期依赖问题？LSTM的结构是怎样的？",
        "有遇到过拟合的情况吗？过拟合是怎样解决的？",
        "L1正则化和L2正则化的区别",
        "L1，L2正则化的区别，岭回归是L1正则化还是L2正则化？",
        "欠拟合如何去解决，训练过程不收敛如何去解决？",
        "分类的损失函数有哪些？",
        "多分类的分类损失函数(Softmax)？",
        "BERT的base版本的原始模型，训练的时候，第一个epoch模型的判定结果很可能是错的，这个时候熵还可信吗？",
        "讲一下微调方法p-tuning v2的原理",
        "常见的深度学习的优化方法有哪些？",
        "讲一下batchnorm的计算过程",
        "微调方法是啥？如何微调？",
        "如何基于LoRA的Llama2微调？",
        "是否可以避开训练集来处理LLMs测试集数据泄露问题？",
        "RAG与微调（Fine-tuning）的协同作用是什么？",
        "在微调大模型时，如何选择和构建大模型微调数据？",
        "隐马尔可夫算法的学习训练过程是什么样的？",
        "循环神经网络 RNN 层介绍？",
        "分类问题使用的激活函数 sigmoid 简介？",
        "分类问题使用的损失函数还有哪些？",
        "BERT 预训练和微调之间的不匹配的解决方法？",
        "领域模型微调指令和数据输入格式要求？",
        "L1 和 L2 正则化的区别？",
        "什么是梯度下降？SGD 的推导？",
        "Oracle数据库中的SQL优化器的作用？",
        "简而言之，10046事件记录SQL如何运行，而10053记录优化器为什么为这个？",
        "通过解释执行计划，开发者可以理解查询优化器是如何选择和执行？"
      ]
    },
    "算法": {
      "count": 38,
      "questions": [
        "需要归一化的算法有哪些？这些模型需要归一化的主要原因？",
        "树形结构的不需要归一化的原因？",
        "K-means算法中初始点的选择对最终结果的影响？",
        "BA算法的流程？",
        "为什么使用占据栅格地图构建算法构建地图？",
        "什么是占据栅格地图构建算法？",
        "高精度地图的制作流程？",
        "算法是否看过开源的源代码，或是否自己手动实现过？",
        "SENet 的原理是什么？并画出 block 的结构图。",
        "为什么 k-means 一定会收敛？请讲一下 EM 算法，并说明 k-means 有什么缺点？",
        "叉搜索树和二叉堆的区别是什么？",
        "多头注意力机制和单个注意力机制的时间复杂度会变吗？",
        "隐马尔可夫模型中的两个假设是什么？",
        "隐马尔可夫模型存在哪些问题？",
        "隐马尔可夫模型是什么？",
        "隐马尔可夫模型的工作流程是什么？",
        "如果一个样本同时拥有多个标签，甚至标签同时还构成了 DAG（有向无环图），该如何建模或处理？",
        "知识图谱的价值在哪里？",
        "构建知识图谱涉及哪些技术？",
        "传统的相似度算法存在哪些问题？",
        "k-means 算法流程是什么？",
        "DBSCAN 的原理和算法伪代码是什么？与 k-means、OPTICS 有什么区别？",
        "栈和堆有什么区别？",
        "关联规则具体有哪两种算法，它们之间的区别是什么？",
        "若显示器伽马未知，设计一种自动标定算法并给出实验步骤。",
        "直方图均衡导致局部过增强的数学原因是什么？",
        "给出一种无标定板场景下利用 SLAM 地图重优化内参的方法。",
        "给出一种基于遗传算法的 anchor 自动压缩流程。",
        "视图的优缺点是什么？",
        "B 树和 B+ 树的区别是什么？",
        "InnoDB 为什么使用 B+ 树作为存储引擎？为什么不用 B 树？",
        "对文件或设备的操作函数保存在什么数据结构中？",
        "当我试图更新一个正在被迁移的块（chunk）上的文档时会发生什么？",
        "请解释一下哈希表（Hash Table）的工作原理及其时间复杂度。",
        "你能描述一下二叉搜索树（Binary Search Tree）的特点吗？"
      ]
    },
    "网安": {
      "count": 89,
      "questions": [
        "介绍一下大语言模型（LLM）的安全挑战有哪些？",
        "OpenAI evals 的核心思路是否是通过写 prompt 模板来自动化评估？",
        "如何解决大语言模型（LLM）的安全挑战？",
        "在探索和优化 RAG（检索增强生成）的过程中，如何有效评估其性能？",
        "给你一个网站的登录页面你要如何进行渗透测试？",
        "CSRF、XSS和XXE有什么区别，以及修复方式？",
        "CSRF、SSRF和重放攻击有什么区别？",
        "拿到一个待检测网站，你该如何渗透？",
        "应急响应流程是什么？",
        "了解哪些命令执行漏洞？说一下命令执行漏洞原理。",
        "红队攻击和渗透测试最主要的区别是什么？",
        "给你一个网站，一般怎么做渗透测试的？",
        "SQL注入的流程是什么？",
        "SQL注入防范机制有哪些？",
        "登录页的SQL注入怎么测试？测试哪些动作？",
        "XSS攻击原理是什么？",
        "文件包含漏洞的原理是什么？",
        "说一下SSRF：显示页面相同怎么判断是开还是关？",
        "通过SSRF进行内网探测，探测了IP和端口之后，如何利用？",
        "CSRF和XSS怎么结合使用？",
        "有文件上传漏洞了，Linux下怎么找xx.conf的文件？",
        "MySQL数据库提权中，UDF提权怎么利用？",
        "Windows应急响应一般的流程是什么？",
        "木马查杀流程是什么？",
        "服务器被入侵了，怎么做应急响应（Windows和Linux）？用到了什么工具？",
        "你对内网渗透有了解吗？",
        "内网渗透信息收集怎么做？",
        "APT攻击流程是什么？",
        "域控/域渗透：拿下一个服务器后，怎么判断是否存在域，如何进行域渗透？",
        "什么是漏洞扫描？如何进行漏洞扫描？",
        "什么是安全漏洞？如何发现和修复安全漏洞？",
        "渗透测试中的社会工程学攻击是什么？",
        "渗透测试中的暴力破解攻击是什么？",
        "渗透测试中的缓冲区溢出攻击是什么？",
        "渗透测试中的跨站脚本攻击是什么？",
        "什么是跨站点脚本攻击（XSS）？如何防止XSS攻击？",
        "什么是跨站请求伪造（CSRF）攻击？如何防止CSRF攻击？",
        "什么是点击劫持攻击？如何防止点击劫持攻击？",
        "什么是会话劫持攻击？如何防止会话劫持攻击？",
        "什么是文件包含漏洞？如何防止文件包含漏洞？",
        "什么是缓冲区溢出攻击？如何防止缓冲区溢出攻击？",
        "什么是中间人攻击？如何防止中间人攻击？",
        "什么是密码破解攻击？如何防止密码破解攻击？",
        "什么是漏洞评估？它可以用于什么目的？",
        "什么是内网防火墙？为什么需要它？",
        "什么是漏洞管理？为什么它很重要？",
        "为什么 aspx 木马权限比 asp 大？",
        "什么是 DoS、DDoS、DRDoS 攻击？",
        "什么是 SQL 注入攻击？如何防范？",
        "渗透测试的步骤是什么？",
        "渗透测试中的漏洞利用是什么？",
        "你如何防止 DDoS 攻击？",
        "什么是防火墙",
        "XSS 是如何攻击的呢",
        "SQL 注入是如何攻击的",
        "当攻击采用 Base64 编码混淆时，如何构建多阶段解码检测？",
        "sql 注入类型、sql 注入的方式？",
        "sql 注入绕过方法",
        "sql 注入报错注入常用函数有哪些？",
        "mysql 上传 webshell 需要哪些条件",
        "sql server 提权的方法？",
        "windows、linux 提权",
        "CSRF、XSS、XXE 有什么区别，以及如何修复？",
        "你了解 Java 反序列化吗？",
        "你了解 PHP 反序列化吗？",
        "Burp Suite 如何爆破密码？",
        "你了解哪些命令执行漏洞？请说明命令执行漏洞原理。",
        "请说明钓鱼攻击的原理以及怎么实施。",
        "MySQL 5.0 和 5.0 后的区别是什么？",
        "WAF（安全狗）绕过你了解吗？",
        "宽字节注入是怎么注入的？怎么判断是不是 GBK 编码？",
        "SQL 注入的防范机制有哪些？",
        "已知参数形如 ?id=1，怎么进行注入并查到数据？",
        "SQL Server 注入你了解吗？怎么判断是不是 SQL Server？",
        "SSRF 显示页面相同，怎么判断是开还是关？",
        "通过 SSRF 进行内网探测，探测到 IP 和端口之后如何利用？",
        "SSRF 和 CSRF 有什么区别？",
        "如果存在文件上传漏洞，Linux 下怎么找 xx.conf 文件？",
        "Windows 应急响应的一般流程是什么？",
        "服务器被入侵后，如何做应急响应（Windows 和 Linux）？会用到哪些工具？",
        "入侵后如何做权限维持？应急时发现权限维持后如何解决？",
        "你对内网渗透了解吗？",
        "内网渗透的信息收集怎么做？",
        "日志记录被删除了，你该怎么做？",
        "拿下一个服务器后，如何判断是否存在域？如何进行域渗透？",
        "什么是端口扫描？它可以用于什么目的？如何防止端口扫描？",
        "说说什么是数字签名？什么是数字证书？",
        "如何防范 SQL 注入攻击？",
        "XSS 是如何攻击的？"
      ]
    }
  }
}