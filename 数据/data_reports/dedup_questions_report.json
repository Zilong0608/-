{
  "input_dir": "C:\\Users\\15048\\Desktop\\AI面试官\\数据\\第一轮仔细清洗",
  "input_files": [
    "CLEAN_ALL.json",
    "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
    "dl_questions_theory_v3.json",
    "interview_questions_categorized.json",
    "llm_tech_questions_FINAL.json",
    "llm_tech_questions_full_v2.json",
    "ml_questions_theory_v3.json",
    "Oracle_面试题_only_questions.json",
    "questions_only_from_pdf_strict.json",
    "questions_tech_clean_v2.json",
    "recovered_tech_from_removed_v2.json",
    "SLAM_算法_面试题_only.json",
    "web3_questions_only_clean.json",
    "数据分析常考面试题101题_only_questions_theory.json",
    "测试_Jenkins_MySQL_Python_only_questions.json",
    "综合_面试题_only_questions_raw.json",
    "网安_合并题目_only_questions_strict_v2.json"
  ],
  "raw_questions": 21288,
  "removed_noise": 100,
  "llm_cleaned": 15139,
  "unique_questions": 7298,
  "total_batches": 502,
  "duplicates": [
    {
      "question": "各个激活函数的优缺点是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何确定是否出现梯度爆炸？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "批量归一化（BN）如何实现？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "对 fine-tuning（微调模型）的理解是什么？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "如何选择 dropout 的概率？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 Adam？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Adam 和 SGD 之间的主要区别是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 Momentum 可以加速训练？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么时候使用 Adam 和 SGD？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "学习率太大(太小)时会发生什么？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "神经网络为什么不用拟牛顿法而是用梯度下降？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BN 和 Dropout 在训练和测试时的差别？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "若网络初始化为 0 的话有什么问题？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "sigmoid 和 softmax 的区别？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "softmax 的公式？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "改进的 softmax 损失函数有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "深度学习调参有哪些技巧？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络调参，要往哪些方向想？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "深度学习训练中是否有必要使用 L1 获得稀疏解？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络数据预处理方法有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何初始化神经网络的权重？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么构建深度学习模型需要使用 GPU？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络可以解决哪些问题？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何提高小型网络的精度？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是鞍点问题？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "网络设计中，为什么卷积核设计尺寸都是奇数？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "卷积层有哪些基本参数？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何计算卷积层的输出大小？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何计算卷积层参数数量？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "有哪些池化方法？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "*1 卷积的作用？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json"
      ]
    },
    {
      "question": "卷积层和池化层有什么区别？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "卷积核是否一定越大越好？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "卷积在图像中有什么直观作用？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CNN 中空洞卷积的作用是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎样才能减少卷积层参数量？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "在进行卷积操作时，必须同时考虑通道和区域吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "采用宽卷积、窄卷积的好处有什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何提高卷积神经网络的泛化能力？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "卷积神经网络在 NLP 与 CV 领域应用的区别？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "全连接、局部连接、全卷积与局部卷积的区别？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json"
      ]
    },
    {
      "question": "卷积层和全连接层的区别？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json"
      ]
    },
    {
      "question": "Max pooling 如何工作？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "卷积神经网络的优点？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "BN、LN、IN、GN 和 SN 的区别？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RNNs 训练和传统 ANN 训练异同点？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 RNN 训练的时候 Loss 波动很大？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RNN 中为什么会出现梯度消失？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何解决 RNN 中的梯度消失问题？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LSTM 结构推导，为什么比 RNN 好？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 LSTM 模型中既存在 sigmoid 又存在 tanh 两种激活函数，而不是选择统一一种 sigmoid 或者 tanh？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LSTM 中为什么经常是两层双向 LSTM？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LSTM、RNN、GRU 区别？",
      "sources": [
        "CLEAN_ALL.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LSTM 是如何实现长短期记忆功能的？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "反向传播是如何工作的？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络中包含哪些超参数？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要进行超参数调优？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "极端批样本数量下，如何训练网络？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调有哪些不同方法？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "不同的数据集特性下如何微调？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "自动化超参数搜索方法有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么 dropout 可以解决过拟合？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "阶优化和二阶优化的方法有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "每层卷积是否只能用一种尺寸的卷积核？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Inception 结构能不能缓解梯度消失？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "ResNet 为什么不用 Dropout？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "ResNet 网络越来越深，准确率会不会提升？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CNN 是否抗旋转？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果旋转图像，CNN 的预测会怎样？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "fastText 存在什么问题？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "什么是正则化？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何离线评价召回阶段各种模型算法的好坏？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是BiLSTM-CRF？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 的矩阵怎么初始化？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "微调方法是啥？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下 PEFT。",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "能不能总结一下各种参数高效微调方法？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要适配器微调（Adapter-tuning）？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MAM Adapter特点是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "为什么需要提示学习（Prompting）？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是提示学习（Prompting）？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "指示微调（Prompt-tuning）思路是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "指示微调（Prompt-tuning）优点是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "指示微调（Prompt-tuning）缺点是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "指示微调（Prompt-tuning）与 Prefix-tuning 的区别是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "指示微调（Prompt-tuning）与 fine-tuning 的区别是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LoRA 权重是否可以合入原模型？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ChatGLM-6B LoRA 后的权重多大？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何在已有 LoRA 模型上继续训练？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 这种微调方法和全参数比起来有什么劣势吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何估算模型所需的 RAM？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是3D并行？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LLMs 存在模型幻觉问题，请问如何处理？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "基于 LLM + 向量库的文档对话思路是怎么样？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "基于 LLM + 向量库的文档对话核心技术是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于 LLM + 向量库的文档对话 prompt 模板如何构建？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LLaMA 输入句子长度理论上可以无限长吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何让大模型处理更长的文本？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SFT 指令微调数据如何构建？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何训练自己的大模型？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调后的模型出现能力劣化，灾难性遗忘是怎么回事？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调模型需要多大显存？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 微调优点是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "AdaLoRA 的思路是怎么样的？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有哪些省内存的大语言模型训练/微调/推理方法？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 包含哪些核心概念？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 支持哪些功能？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 存在哪些问题及方法方案？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "LangChain 中 Components and Chains 是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 中 Prompt Templates and Values 是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 中 Example Selectors 是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 中 Output Parsers 是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 中 Indexes and Retrievers 是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 中 Chat Message History 是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 中 Agents and Toolkits 是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 如何调用 LLMs 生成回复？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 如何修改提示模板？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 如何链接多个组件处理一个特定的下游任务？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 如何 Embedding & vector store？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "为什么大模型推理时显存涨得那么多还一直占着？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型在 GPU 和 CPU 上推理速度如何？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "推理速度上，int8 和 fp16 比起来怎么样？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "大模型有推理能力吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型生成时的参数怎么设置？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何让大模型输出合规化？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "目前主流的开源模型体系有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "请简述什么是大模型，以及它与传统模型的主要区别是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "请简述你了解的大模型的主要结构特点。",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "请描述一种你熟悉的 Tokenizer 实现方法，并解释其原理。",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "请简述大模型性能评估的主要步骤。",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "什么情况用 BERT 模型，什么情况用 LLaMA、ChatGLM 类大模型，如何选择？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何给 LLM 注入领域知识？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "WordPiece 与 BPE 异同点是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "举例介绍一下不同大模型 LLMs 的分词方式？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "介绍一下不同大模型 LLMs 的分词方式的区别？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果有N张显存足够大的显卡，怎么加速训练？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如果显卡的显存不够装下一个完整的模型呢？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "种并行方式可以叠加吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Colossal-AI 有1D/2D/2.5D/3D，是什么情况？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "除了3D并行有没有其他方式大规模训练？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有了ZeRO系列，为什么还需要3D并行？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "平民适不适合玩3D并行？",
      "sources": [
        "CLEAN_ALL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "平民适不适合直接上多机多卡的ZeRO3（万兆网）？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如果想构这样一个大规模并行训练系统，训练框架如何选？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "为何现在的大模型大部分是 Decoder-only 结构？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "进行增量预训练需要做哪些准备工作？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是大模型幻觉？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么LLM会产生幻觉？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "幻觉一定是有害的吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LLMs什么时候最容易产生幻觉？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "进行 SFT 操作的时候，基座模型选用 Chat 还是 Base？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调大模型时，优化器如何选择？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "哪些因素会影响内存使用？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型大概有多大，模型文件有多大？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "nB模型推理需要多少显存？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "nB模型训练需要多少显存？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何查看多机训练时的网速？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何查看服务器上显卡的具体型号？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何查看训练时的flops？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "tf32格式有多长？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "模型压缩和加速的方法有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些大模型的训练集？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型怎么评测？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型的 honest 原则是如何实现的？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何衡量大模型水平？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "大模型评估方法有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型评估工具有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 LLMs 复读机问题？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么会出现 LLMs 复读机问题？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何缓解 LLMs 复读机问题？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么情况用 Bert 模型，什么情况用 LLaMA、ChatGLM 类大模型，咋选？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "各个专业领域是否需要各自的大模型来服务？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "涌现能力是啥原因？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "奖励模型需要和基础模型一致吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RLHF 在实践过程中存在哪些不足？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果想要快速体验各种模型，该怎么办？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 SFT 之后感觉 LLM 傻了？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "领域模型 Continue PreTrain 数据选取？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "领域数据训练后，通用能力往往会有所下降，如何缓解模型遗忘通用能力？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "领域模型微调指令&数据输入格式要求？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "领域模型微调领域评测集构建？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "训练中文大模型有啥经验？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "预训练和微调哪个阶段注入知识的？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "多轮对话任务如何微调模型？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型 LLM 进行 SFT 操作的时候在学习什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型 LLM 进行 SFT 如何对样本进行优化？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调需要多少条数据？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "进行领域大模型预训练应用哪些数据集比较好？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Layer Norm 的计算公式写一下？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RMS Norm 的计算公式写一下？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RMS Norm 相比于 Layer Norm 有什么特点？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "写一下 Deep Norm 代码实现？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LN 在 LLMs 中的不同位置有什么区别？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LLMs 各模型分别用了哪种 Layer Normalization？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下 FFN 块计算公式？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下 GeLU 计算公式？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下 Swish 计算公式？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下使用 GLU 线性门控单元的 FFN 块计算公式？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下使用 GeLU 的 GLU 块计算公式？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下使用 Swish 的 GLU 块计算公式？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "各 LLMs 都使用哪种激活函数？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 Multi-Query Attention？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对比一下 Multi-head Attention 和 Multi-Query Attention？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有哪些模型使用 Multi-Query Attention？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有哪些大模型使用 Grouped-query Attention？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "多任务学习各loss差异过大怎样处理？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是信息增益？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "对比学习负样本是否重要？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "分布式训练框架如何选择？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LLMs 训练时有哪些有用的建议？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "模型大小如何选择？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "加速卡如何选择？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "为什么大模型需要外挂（向量）知识库？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "导致模型不收敛的原因有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "VGG 使用 3×3 卷积核的优势是什么？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "ReLU 比 Sigmoid 的效果好在哪里？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "SVM 的原理是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "SVM 为什么采用间隔最大化？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "为什么 SVM 要引入核函数？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "常见的损失函数有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是AUC？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何进行特征选择？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多模态融合后，怎样知道最终结果受哪种模态影响更大？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多模态中常见的SOTA模型有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "prefix LM 和 causal LM 区别是什么？",
      "sources": [
        "CLEAN_ALL.json"
      ]
    },
    {
      "question": "大模型 LLM 的架构介绍？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Byte-Pair Encoding (BPE) 如何构建词典？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "简单介绍一下 SentencePiece 思路？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Deep Norm思路？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Deep Norm 有什么优点？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 有哪些评估方法？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 有哪些评估框架？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MC、TD谁的方差大，为什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是深度学习，它与传统机器学习有什么不同？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "权重初始化如何影响深度学习模型的性能？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你能解释感知器和 S 形神经元的区别吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释反向传播在神经网络中是如何工作的吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络中常用的激活函数有哪些？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何防止神经网络的过拟合？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何决定神经网络的层数和神经元数？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何处理神经网络中缺失的数据？",
      "sources": [
        "CLEAN_ALL.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你能解释一下深度学习中迁移学习的概念吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你如何评估一个深度学习模型的性能？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "过拟合和欠拟合的区别是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络中 Dropout 的目的是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "批归一化是如何工作的？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "激活函数在神经网络中的作用是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "深度神经网络和浅层神经网络的区别是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "梯度下降法和随机梯度下降法有什么区别？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么在进行多头注意力的时候需要对每个 head 进行降维？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释卷积神经网络和循环神经网络的区别吗？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是多任务学习，Transformer 如何应用于多任务学习？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是层归一化（Layer Normalization），它在 Transformer 中有什么作用？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何理解 Transformer 模型中的残差连接（Residual Connection）？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是预训练和微调（Fine-tuning），在 Transformer 模型中如何应用？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 Transformer 模型中的头（Head），它的作用是什么？",
      "sources": [
        "CLEAN_ALL.json",
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 常用的加锁方式有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是递归锁？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Faiss的索引Index有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Faiss的索引Index都怎么用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要创建索引？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要卷积？不能使用全连接层吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "TextCNN可以调整哪些参数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TextCNN进行文本分类的过程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是反向传播？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么 DenseNet 比 ResNet 更耗显存？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何选择要使用的数据增强？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "多分类的分类损失函数（Softmax）是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分类问题为什么用交叉熵损失函数不用均方误差（MSE）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "深度学习中，常见的损失函数有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "模型的 FLOPs（计算量）指的是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "神经网络中 1×1 卷积有什么作用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SGD每步做什么，为什么能online learning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是递归神经网络？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "卷积层和全连接层的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "深度学习中验证集和测试集的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么神经网络中常用 ReLU 作为激活函数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Dropout 为什么能解决过拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "AlexNet 对比 LeNet 的优势是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "前馈神经网络和循环神经网络的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下深度学习中权重初始化的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "softmax 函数和 sigmoid 函数的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下深度学习中集成学习的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下深度学习中权重衰减的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "深度学习中 L1 和 L2 正则化的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "学习率在深度学习中的作用是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下深度学习中早停法的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下深度学习中数据增强的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "批归一化和层归一化有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "PyTorch 和 TensorFlow 的特点分别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "ReLU 函数在 0 处不可导，为什么还能用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 max pooling 更常用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要反向传播？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "梯度消失和梯度爆炸的解决方案有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "VGG使用2个3*3卷积的优势在哪里？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下长短期记忆(LSTM)网络的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "深度学习中生成模型和判别模型的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下生成对抗网络(GANs)的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "深度信念网络和深度神经网络的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下深度学习中强化学习的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你能解释一下深度学习中注意机制的概念吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Softmax + Cross Entropy 如何反向求导？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "为什么在模型训练开始会有 warmup？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "DNN 的梯度是如何更新的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "目标检测中使用预训练模型的优劣？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "神经网络中有哪些正则化技术？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ResNet v1 与 ResNet v2的区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json"
      ]
    },
    {
      "question": "目标检测中如何从零开始训练(train from scratch)？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "dl_questions_theory_v3.json"
      ]
    },
    {
      "question": "DenseNet 比 ResNet 好吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "神经网络中权值共享如何理解？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 Dropout？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Dropout 在训练和测试阶段有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "L1 正则与 L2 正则的特点是什么，各有什么优势？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "深度学习中 batch 的大小对学习效果有何影响？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要反向传播？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要做特征归一化、标准化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么不使用二阶优化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么用小卷积核？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要修改最后几层神经网络权值？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要激活函数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是对象分割？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是目标检测？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是迁移学习？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "增大感受野的方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何设置学习率？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些经典的卷积类型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "梯度消失和梯度爆炸的原因是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "激活函数是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "神经网络的优缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络的正则化方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络的深度和宽度分别指的是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "过拟合的解决方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BERT 的两个预训练任务对应的损失函数是什么（用公式形式展示）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "归一化为什么能提高梯度下降法求解最优解的速度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要用BiLSTM？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "GRU是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 Lattice LSTM，存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 WC-LSTM，存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分类问题常用的损失函数有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "循环神经网络RNN层是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在TextCNN中的pooling操作与一般CNN的pooling操作有何不同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何修复梯度爆炸问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "TextCNN的局限性是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RNN是怎么从单层网络一步一步构造的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BERT是怎么缓解梯度消失的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CNN中参数量和计算量怎么算？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CNN中的卷积到底指什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "GRU对LSTM做了哪些改动？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LSTM和RNN有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "ReLU如何解决梯度消失问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "与传统 RNN 和 LSTM 相比有哪些优势？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是梯度消失和梯度爆炸？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下CNN？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "卷积神经网络中常见的层有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "深度可分离卷积是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "深度可分离卷积的参数量和计算量是多少？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CNN究竟是怎样一步一步工作的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是梯度下降法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是梯度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CRF的优点在哪里？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Elmo存在的问题是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Elmo的特点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "FAQ检索式问答系统是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Faiss如何安装？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "HMM和MEMM存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HMM存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "NLG（自然语言生成）是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "QQ匹配的优点有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "知识表示相对于one-hot表示的优势是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "Word2vec 中霍夫曼树是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "fastText的分类过程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "softmax函数是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "word-level Model是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Word2vec 和 NNLM 对比有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多义词问题是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "one-hot 存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "中文命名实体识别与英文命名实体识别的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么会有Elmo？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要用多轮对话系统？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要 P-tuning v2？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要 P-tuning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要前缀微调（Prefix-tuning）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要指示微调（Prompt-tuning）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "事件抽取中常见的英文数据集有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "事件抽取和命名实体识别（即实体抽取）有什么异同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "分类问题使用的激活函数sigmoid是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 Adaptive Embedding 范式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是CRF？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 DST（对话状态跟踪）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 Dynamic Architecture？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是Faiss？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 TF-IDF？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "什么是词汇/实体类型信息增强？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是词汇增强？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是语言理解（SLU）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是马尔可夫过程？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是n元语法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是事件？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是任务型对话系统？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是低秩因式分解？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是剪枝？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是实体嵌套？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是归一化，它与标准化的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是文本摘要？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是概率图模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是蒸馏？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是量化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下主题建模任务？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你了解哪些预训练模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "分类任务有哪些类别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "压缩式摘要是怎么做的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "句子重要性评估算法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "命名实体识别评价指标是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在 C++ 程序中调用被 C 编译器编译后的函数，为什么要加 extern \"C\"？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于规则的命名实体识别方法是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何计算两段文本之间的距离？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "对话系统有哪几种？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "抽取式摘要是怎么做的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "摘要质量的评估方法有哪些类型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "标签解码器是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "模式匹配方法怎么用在事件抽取中？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "生成式摘要是怎么做的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "知识图谱的数据来源于哪里？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "问答系统的动机是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "亿个参数的模型，部署后占用多大显存？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是非极大值抑制（NMS）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是深度学习中的anchor？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是TF-IDF算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当神经网络的调参效果不好时，从哪些角度思考？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Python 里面如何拷贝一个对象？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何降低数据集的维度以减少模型计算时间？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "怎么解决推荐系统中的冷启动问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何提升已经达到 96% 精度的分类模型性能？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CRF的主要思想是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CRF的缺点在哪里？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "DST（对话状态跟踪）的输入输出是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Elmo的思想是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "FAQ如何做拆分？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Faiss如何使用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "NLG（自然语言生成）的输入输出是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Neo4J 怎么下载？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Neo4j 怎么创建节点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "P-tuning v2 思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "P-tuning 思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "QQ匹配的语义空间是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Sigmod的缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "TF-IDF 如何评估词的重要程度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "Word2vec 中为什么要使用霍夫曼树？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "fastText 是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "fastText的优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "n-gram算法的局限性是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "py2neo 模块是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "query匹配标准QA的核心是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "softmax函数怎么求导？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "word-level Model存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Word2vec 和 TF-IDF 在相似度计算时的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "为什么CRF模型会比HMM被普遍使用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么DNN后面要加CRF？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么QQ匹配比较常用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "事件抽取中常见的中文数据集有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "事件抽取和关系抽取有什么异同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是随机场？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是jaccard距离？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是事件抽取？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是多线程？多线程与多任务有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是跨层参数共享？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "信息抽取的难点在哪里？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "前缀微调（Prefix-tining）思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于无监督学习的命名实体识别方法是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "基于约束的摘要生成方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "常见的多轮对话系统解决方案是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "抽取式摘要的可读性问题是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "文本摘要技术有哪些类型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "树形结构为什么不需要归一化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "检索的方法的训练阶段如何做？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "生成式摘要存在哪些问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "统计机器学习方法怎么用在事件抽取中？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "语言理解（SLU）的输入输出是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "问答系统是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "隐马尔可夫算法中两个序列是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "隐马尔可夫算法学习训练过程是什么样的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "马尔可夫过程的核心思想是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何在一个数据集上选择重要的变量？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是wide&deep模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "怎样将知识图谱引入推荐系统？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "芝麻信用分的主要计算维度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么我们做评分卡的时候要用woe编码？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "word2vec 存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "ACE测评中事件抽取涉及的几个基本术语及任务是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CRF的定义是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Character-Level Model是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "GPT 处理的有监督任务有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Neo4J 怎么安装？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Neo4j 怎么创建关系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "P-tuning v2 优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "P-tuning 优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Pointer-generator network解决了什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "QQ匹配的语料的稳定性是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "word2vec与LDA模型之间的区别和联系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "TF-IDF 的思想是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "TF-IDF算法是做什么的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "TextTeaser算法是怎么抽取摘要的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Word2vec 中使用霍夫曼树的好处是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "Word2vec 中 Skip-gram 指什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是事理图谱？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么样的数据集不适合用深度学习？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分布式输入层是什么，有哪些方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "前缀微调（Prefix-tuning）的优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "P-tuning 的缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "P-tuning v2 的缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "基于特征的监督学习的命名实体识别方法是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CRF的三个基本问题是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "深度学习方法怎么用在事件抽取中？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "知识图谱的类别有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "能不能简单介绍下词袋模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "词汇增强方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "语言理解（SLU）所使用的技术是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Character-Level Model的优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "DST（对话状态跟踪）实现方式是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "FAQ标准库如何实时更新？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Faiss如何使用GPU？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Neo4j 怎么创建出生地关系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "QQ匹配的业务回答与算法模型的解耦是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TF-IDF 的计算公式是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "tf-idf高意味着什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "TextRank算法是怎么抽取摘要的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 ELMo、GPT、BERT 能够解决多义词问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 Word2vec 中会用到负采样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "事件抽取怎么发展的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 FLAT，存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "前缀微调（Prefix-tining）的缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "同样是编辑距离，莱文斯坦距离和汉明距离的区别在哪里？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在一个严格单调递增的整数数组中找到 a[x] == x 的位置？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "知识图谱的价值在哪呢？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ELMo 存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CRF的流程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Character-Level Model存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Cypher 查询语言是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Neo4j 怎么查询？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "QQ匹配的新问题发现与去重是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简要介绍下TransE模型的思想及优点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Word2vec 中的负采样是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "事件抽取存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么说神经网络是端到端的网络？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Character-Level Model问题的解决方法是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Neo4j 怎么删除和修改？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "TF-IDF 的优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Word2vec 中负采样的采样方式是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "为什么 xgboost 要用泰勒展开，优势在哪里？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何看当前 Linux 系统有几颗物理 CPU 和每颗 CPU 的核数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是感受野？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "TF-IDF 的缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "使用 top 查看系统资源占用情况时，哪一列表示内存占用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "谈谈判别式模型和生成式模型。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "工业界中遇到上亿的图像检索任务，如何提高图像对比效率？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TF-IDF 的应用有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "如何查看当前系统都有哪些进程？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "词干提取和词形还原有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "one-stage 和 two-stage 目标检测方法的区别和优缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BN层在训练和推理过程中有什么不一样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BERT 值得这么高的评价吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "C(W_i) 是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果你现在想看个电影，但你不知道具体看哪部，你会怎么做？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "ELMO 经过这般操作，效果如何？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Encoder和decoder是如何进行交互的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "GLM是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LayerNorm和BatchNorm的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Normalization 为什么效果好？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "PEFT 存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "PEFT 有什么优点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "PEFT 和全量微调有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Pre-norm和post-norm有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Precision和Recall是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "能简单介绍一些事件抽取的应用背景吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Word2Vec 是怎么工作的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "YOLO的正负样本是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "extern \"C\"是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "m*n*3的图像输入进去，输出会有变化吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Softmax除了作为激活函数，在深度学习中还有哪些用途？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SVM的训练过程如何优化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "特征提取器如何选择？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "专有名称怎么处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "标注数据不足怎么处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "XGBoost算法介绍？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "事件抽取有哪些应用场景和实际的产品？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "深度学习在事件抽取上有哪些应用，与传统方法比有什么优势/劣势？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "通过 Self Attention 到底学到了哪些规律或者抽取出了哪些特征？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是最大似然估计？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是文本挖掘？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "MAM Adapter思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "适配器微调（Adapter-tuning）特点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何利用 Python 操作 Neo4j 图数据库？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "提示学习（Prompting）有什么优点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "知识图谱怎么存储？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "核函数到底是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "不同任务怎么改造才能靠近 GPT 的网络结构？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么LDA的最大似然难求？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么self-attention要除以根号N？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么用角点作为特征点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么目标检测问题更难？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么在实际的 kaggle 比赛中 gbdt 和 random forest 效果非常好？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要用n-gram？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要 PEFT？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "了解Linux的管道命令吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "了解对比学习吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "事理图谱怎么构建？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "怎么构建知识图谱呢？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "文本挖掘的作用是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "适配器微调（Adapter-tuning）思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "分类模型的评估指标有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "AdapterDrop思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "交叉熵和KL散度有什么关系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是交叉验证？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是完全二叉树？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是查询向量、键向量和值向量？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是规则？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是语言模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "从袋子中取得白球的概率是多少？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "因子图到底是干嘛的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你了解的知识蒸馏模型有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何比较两个概率分布？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是注意力机制？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "AdapterDrop特点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "分类问题是否可以用MSE？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分类问题的交叉熵是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是EM算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Rank 如何选取？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "alpha 参数如何选取？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "半精度的理论原理是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "各种评估指标有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "AdapterFusion思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "模型压缩存在哪些问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "知识图谱可以做什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在自然语言处理模型训练中，评价指标是怎样设定的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "基于attention有哪些代表性的改进方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何判断链表是否有环？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何对物品进行分类，分成几类？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何建立这棵用于判断的树形结构？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何构建多模态模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何理解交叉熵的物理意义？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何确定节点的 w 以及最小的 loss function？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何确定用户对哪些物品类别有兴趣，兴趣程度如何？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解决 0-1 标签稀疏问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果新估计出来的PA和PB和我们初始化的值差别很大，怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "定位的问题的解决思路有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "怎么处理类别不平衡？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "怎么找到最优的线性分类器？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "怎样通俗地理解泰勒级数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "我们把 functional margin 定为 1 了吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Word Embedding 这种做法能算是预训练吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何确保EM收敛？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "推荐系统中，如何进行负采样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "推荐系统中，相比于余弦相似度，是否可以用欧几里得距离判断相似度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "支持向量是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "文本生成的几大预训练任务？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "样本之前（或观察到 X 之前），有着怎样的分布？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "条件独立是什么意思？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "模型输出的分布比较稀疏，怎么处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "欠拟合如何解决？训练过程不收敛如何解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么时候用 item-based，什么时候用 user-based？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "只要知道树的结构就能得到该结构下的最好分数，如何确定树的结构？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "知识图谱的具体构建技术是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何确定分裂用的 feature？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "能否结合 region proposal 的思想实现更精准的定位？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "最终分类器的误差界是多少？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "统计学中的P值是什么含义，如何通俗地解释？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "能不能手写下attention？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "能不能找出一个更加高效的方法来求出这些候选框？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "自然语言处理有哪些任务？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "自监督、半监督、无监督的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "解码组件最后会输出一个实数向量，如何把浮点数变成一个单词？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "说一下广度优先遍历和深度优先遍历的区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "负样本构造成本过高应该怎么解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "超参数 α、β 对训练的影响是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "路径规划算法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "输入不是序列而输出为序列的情况怎么处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Word Embedding 头上笼罩了好几年的乌云是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何进行最有效的推荐？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BERT 是怎么做的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在每次迭代中如何更新乘子？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何建立某个位置和其特征的对应关系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "站在现在的时间节点看，GPT 有什么值得改进的地方？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "站在现在这个时间节点看，ELMO 有什么值得改进的缺点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是拉格朗日对偶性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CV中数据增强的方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是多义词？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是标准化和归一化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "ALiBi (Attention with Linear Biases) 的偏置矩阵是什么，有什么作用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "D 并行策略有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "nn.parallel.DistributedDataParallel 的参数更新机制是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "nn.parallel.DistributedDataParallel 的实现流程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "fastText 的分类过程是什么？fastText 的优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么通过新闻可以预测网络故障呢？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果 softmax 的 e 次方超过 float 的值了怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "事件是要分类型的吧？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 PagedAttention？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 MOE（Mixture-of-Experts）分布式并行策略。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 Stable Diffusion 的原理。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "softmax 和交叉熵损失怎么计算？二值交叉熵呢？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "前缀微调（Prefix-tuning）思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何对baichuan-13B进行微调？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何使用 transformers 库加载 sentencepiece 模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何提取表格和图片中的数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "工程上，怎么实现 LR 的并行化？有哪些并行化的工具？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "常见的分类算法有哪些？它们各自的优缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "流水线并行（Pipeline Parallelism）优缺点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是Nginx？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "需要归一化的算法有哪些？这些模型需要归一化的主要原因是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "DPO（对话策略学习）是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "QLoRA 的思路是怎么样的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 LoRA？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DPO（对话策略学习）的输入输出是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 的思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "QLoRA 的特点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DPO（对话策略学习）的实现方法是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 的特点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简单描述一下 LoRA？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型微调 P-tuning 和传统 fine-tuning 有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "LoRA 微调结果如何保存？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 微调计算可训练参数的比例如何确定？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 微调方法为啥能加速训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "是否可以逐层调整 LoRA 的最优 rank？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 微调参数量怎么确定？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 高效微调如何避免过拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型微调过程中如何避免灾难性遗忘？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 low-rank adaptation of large language models？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "前缀微调（Prefix-tuning）的缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "发动机如何将燃料转化为机械能？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "发动机的基本功能是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "发动机运行涉及哪些关键部件，它们如何提高发动机的效率？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Multi-head Attention 存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 如何提升索引数据的质量？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "baichuan-53B相比于baichuan-7B和baichuan-13B有哪些优势？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "self-attention 的公式及参数量是什么，为什么用多头，为什么要除以根号 d？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "self-attention 的计算方式是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "vLLM 的功能有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要对 RAG 进行评测？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 Grouped-query Attention？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 LightLLM？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是长度外推问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是位置编码？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "介绍一下 Text generation inference？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下 KL 散度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下规划（planning）。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下现在几种流行的大模型架构？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "传统 Attention 存在哪些问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "假如有超多的8卡A100节点（DGX A100），如何应用3D并行策略？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分布式训练框架都了解哪些，能不能简单介绍一下？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "PP推理时是一个串行的过程，1个GPU计算、其他空闲，有没有其他方式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Attention优化方向？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RAG 各模块有哪些优化策略？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Self-RAG：如何让大模型对召回结果进行筛选？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Text generation inference 的功能有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "baichuan-53B如何对预训练数据做处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "vLLM 的优点有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "长度外推问题的解决方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要 LightLLM？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要 vLLM？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么大模型训练会出现 loss 突刺？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "交叉熵损失函数写一下，物理意义是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是点对点通信？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是绝对位置编码？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "介绍一下记忆（Memory）。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型加速框架了解多少，知不知道原理，如何进行加速优化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何让 RAG 支持多模态 RAG（文本+表格+图片）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何通过添加元数据提升 RAG 效果？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Attention 变体有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Efficient Router 介绍？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "KL 散度与交叉熵的区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RAG 如何优化索引结构？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 有哪些关键指标和能力？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 架构优化有哪些优化策略？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Text generation inference 的优点有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "baichuan-53B如何进行搜索增强？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "vLLM 具有哪些特点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "vLLM 的缺点有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "目前 LLM 推理框架有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是集体通信？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是相对位置编码？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "介绍一下工具使用（tool use）。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型LLM的训练目标是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Text generation inference 如何使用 docker 运行 web server？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ChatGPT 对比 GPT-3 的性能提升主要来源于哪些方面？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何通过查询重写和扩展提升 RAG 效果？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何通过重新排名提升 RAG 效果？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "数据并行如何提升效率？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型训练的三种并行是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简单介绍一下大模型（LLMs）。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "哪里看各类显卡算力比较？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型中常见的位置编码有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型（LLMs）具有什么优点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型高效参数微调方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "（torch profiler）如何查看自己的训练中通信开销？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型（LLMs）具有什么缺点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DDO 与 DPO 的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Deep Norm 的思路是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "GPT 和 BERT 在文本表征方面有哪些结构和工作原理上的差异？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LLMs训练数据和数据量对比如何？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LLaMA-adapter 如何实现稳定训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LSH 与向量数据库如何协同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 包含哪些特点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 替代方案？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "LightLLM 支持哪些 LLMs 模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LoRA 原理与使用技巧有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 权重合入 chatglm 模型的方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "OCR 抽取效果不好，需要怎么排查问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "P-tuning 讲一下？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "PPO（强化学习）的数据格式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Prompt 是如何生成的，优化目标是什么，任务是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RAG prompt 模板如何构建？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RAG 如何解决多实体提问问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RAG 思路是怎么样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAG 核心技术是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 项目里面有哪一些亮点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RAG(检索增强生成)对于大模型来说，有什么好处？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RM（奖励模型）的数据格式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RNN 与 GNN 之间有哪些区别，以及它们各自适用于哪些场景？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "SFT（有监督微调）的数据集格式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Self-attention 的公式及参数量？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Stable Diffusion API 如何同时满足图片审核和版权过滤？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer 在自然语言处理中有哪些应用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "baichuan-7B如何提高训练稳定性和吞吐？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "baichuan-7B如何收集原始数据并构建训练数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "head 数不一致怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LLaMA2 中使用的注意力机制是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "margin 值怎么调？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何设计增量召回 + 滑动窗口标注？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Prefix Decoder、Causal Decoder 和 Encoder-Decoder 的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Prefix LM 和 Causal LM 的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "prompt tuning 和 prefix tuning 在微调上的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "warmup 的步数对大模型继续预训练是否有影响？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "“差异>10%”是否一定需要重采样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "pytorch中的GPU操作默认是什么样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "vLLM 用于大模型并行推理加速存在什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "vLLM 如何优化大模型并行推理加速？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "vLLM 性能如何？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "适配器微调（Adapter-tuning）思路？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要对预训练模型进行指令微调？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要进行继续预训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何对继续预训练数据预处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何对原始数据预处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么需要 DeepSpeed？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要 FasterTransformer？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LightLLM 介绍一下？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要 Graph RAG？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 Graph RAG？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于 LLM + 向量库的文档对话存在哪些痛点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要 accelerate 分布式训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是思维链提示？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "思维链提示本质是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍一下nn.DataParallel函数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "流水线并行（Pipeline Parallelism）优化目标是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要自动混合精度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要构建中文 tokenization？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何区分单栏还是双栏 PDF？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "思维链提示对实现真正的通用人工智能仍面临哪些挑战？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何获取模型参数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果需要你对思维链提示进行改进，你觉得你会改进哪些地方？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型（LLMs）后面跟的 175B、60B、540B 等指什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是大模型（LLMs）agent？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是生成式大模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LoRA 微调方法为什么能加速训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何在 PyTorch 中使用自动混合精度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何提取文章标题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何缓解LLM幻觉？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "思维链提示对推动语言模型复杂推理能力研究有哪些启发和影响？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "FasterTransformer 核心是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Graph RAG 思路介绍？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LightLLM 性能表现如何？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要 ZeRO？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要解决LLM的幻觉问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型（LLMs）agent 主要利用了大模型哪些能力？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何构建模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何构建中文的词库？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "思维链提示与标准的提示学习方法有什么不同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "混合精度训练的优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "谈一下对模型量化的了解。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "业内常用的分布式 AI 框架有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 Transformer 使用位置编码（Positional Encoding）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要思维图Graph of Thoughts（GOT）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要思维算法Algorithm of Thoughts（AOT）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 SFT 之后感觉 LLM 变傻了？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么不用交叉熵而用 Margin？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要增量预训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要 AMP 混合精度训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要 nn.parallel.DistributedDataParallel？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要思维树Tree of Thoughts（TOT）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要nn.DataParallel？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要对大模型进行微调？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要进行模型量化及原理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "了解 LangChain 吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "了解半精度训练吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型是怎么让生成的文本丰富而不单调的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对知识蒸馏知道多少，有哪些改进用到了？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LightLLM 如何安装？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "vLLM 如何使用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "用示例介绍 Graph RAG？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何从长文档（书籍）中提取关键信息？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何合并英文词表和中文词表？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "幻觉有哪些不同类型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "思维链提示适用场景有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "混合精度训练的关键技术是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 LangChain Agent？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 LangChain model？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 LangChain？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是思维图Graph of Thoughts（GOT）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是思维树Tree of Thoughts（TOT）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是思维链Chain-of-Thought（COT）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "任务间共享底层 Transformer 时，如何防止某任务 loss 爆炸拖垮整体？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "位置编码有哪些优缺点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你了解baichuan-7B解构么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "使用什么向量数据库？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "使用外挂知识库主要是为了解决什么问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何保证标注一致性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何做敏感实体识别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何度量幻觉？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LightLLM 如何使用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "nn.DataParallel（DP）和 DistributedDataParallel（DDP）有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "思维链提示目前还存在哪些不足点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "千亿模型 ckpt 200GB，网络拷贝耗时 10 分钟，如何做到秒级回滚？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何提升 batch 吞吐？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "参数微调的原因有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "句子、语义段之间召回不会有包含关系吗，是否会造成冗余？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "可微几何约束能否直接写进 Transformer loss？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "向量数据库有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "商业模型比如 ChatGPT 和 Claude 到底是怎么做的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "DeepSpeed 如何使用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LightLLM 依赖包有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ZeRO 的核心思想是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "accelerate 分布式训练如何实践？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "vLLM 如何安装？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "用代码介绍 Graph RAG？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何使用模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "思维链提示为什么可以提高语言模型的复杂推理能力？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "提示学习（Prompting）有哪些方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "混合精度训练的缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "结合代码讲解大模型（LLMs）agent 思路？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "国产化算力瓶颈怎么破？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "国内内容安全审核要求200ms内返回首字，如何与RTF<0.3共存？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "国内合规要求训练日志留痕，selective 策略动态调整时如何审计重算层？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "国内机房夜间断网演练导致监控中心失联，如何防止误停？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "国内算力资源紧张，如何降低社区重复跑基座模型的成本？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "国密算法性能在GPU推理节点上可能成为瓶颈，怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在初始预训练中使用 Rewarmup 对大模型继续预训练性能影响？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "在多模态对话里，图片 token 的熵如何定义？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在大模型中，除了位置编码，还有哪些方法可以用来处理序列中的位置信息？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在大模型性能评估中，你通常使用哪些评估指标？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在大模型设计中，如何权衡模型的复杂度和性能？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在大模型评测中，你如何进行特征选择和模型调优？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在实际应用中，如何调整注意力机制的参数以优化模型性能？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在开发大模型时，你如何确保模型的可解释性和公平性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在模型训练和推理过程中，如何保证 Tokenizer 的一致性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在进行大模型微调时，有哪些常见的策略或技巧？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "增量预训练一般需要多大数据量？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "增量预训练所用训练框架是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "增量预训练训练流程是怎么样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "增量预训练过程中，loss 上升正常么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "增量预训练过程中，lr 如何设置？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "增量预训练过程中，warmup_ratio 如何设置？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "多头自注意力机制的作用是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多模态参数：图片里嵌了非法二维码，如何校验？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "多模态边界：当输入出现图片+文字时，如何定义单元？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多模态长链如何校验？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多源坐标系混用（WGS-84、GCJ-02、BD-09）时，如何统一约束？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "多租户场景下，如何做到租户级告警隔离？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型中的优化算法有哪些常见的选择？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型中的注意力机制是如何工作的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大模型可控性如何实现，怎么保证可控性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型时代，BERT 向量是否还够用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型输出内容哈希上链后，如何防止“先上链后篡改”的链下文件掉包？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型进行训练用的是什么框架？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何对baichuan-13B进行推理和部署？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何与推理加速联动？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何优化 Transformer 模型的性能？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何使用 LangChain？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何在80%置信度下补足剩余20%不确定性，使报告达到“高度盖然”？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何在百亿级向量、天级更新的 LLMOps 管线里落地？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何在线动态调整 buffer 大小，兼顾成本与效果？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何处理大模型训练过程中的梯度消失或梯度爆炸问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何实现窗口上下文检索？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何对抗“隐蔽矛盾”？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何对齐流与批的事件时间窗口？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何将外部知识注入大模型？最直接的方法：利用外部知识对大模型进行微调。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何提升大模型的检索效果？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何构建轻量级 rehearsal buffer？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何查看对deepspeed的环境配置是否正确？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何查看服务器上的多卡之间的NVLINK topo？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何衡量大模型的效果？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解决 PPO 的训练过程同时存在 4 个模型（2 训练，2 推理），对计算资源的要求较高问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解决人工产生的偏好数据集成本较高、很难量产问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解决三个阶段的训练（SFT->RM->PPO）过程较长、更新迭代较慢问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何让 RAG 支持多模态数据格式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何评价 RAG 项目的效果好坏，即指标是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何评估你的显卡利用率？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何选取和构建大模型微调数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何重新排序？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何防止模型把正例 score 打爆到 1 之后梯度消失？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果业务方要求ε=0.1但延迟只能增加2ms，该如何权衡？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果业务要求准确率93%但模型必须<800M，如何再压缩？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果就是想要试试65b模型，但是显存不多怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如果想要在某个模型基础上做全参数微调，究竟需要多少显存？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果白名单膨胀到 10 万条以上，配置中心性能瓶颈如何解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果知识库本身过期或矛盾，如何给知识置信度再打分？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果社区提交的是多模态任务（图文混合），如何复用现有YAML描述？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果院方只给 10 条私有种子，如何快速扩增？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "对位置编码熟悉吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "对分布式训练有经验么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何用广播与优先级队列避免 GPU 资源死锁？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "开源的 RAG 框架有哪些，你比较了解？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "强化学习微调（RLHF）能否替代重试？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当前优化模型最主要技术手段有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "当生成解释引入多模态（图文混排）后，满意度评估指标需要如何升级？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么让英文大语言模型支持中文？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "思维图 Graph of Thoughts（GOT）核心思想是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "思维链 Chain-of-Thought（COT）有哪些应用场景？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "思维链 Chain-of-Thought（COT）有哪些局限性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "总结一下构建中文 tokenization？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "数据集哪里找？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "指令微调的好处？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "推理优化技术 Flash Attention 的作用是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "推理优化技术 Paged Attention 的作用是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "推理加速框架有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "插件想要访问外部HTTPS服务，如何既放行又审计？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "插件热更新时，如何做到“零中断+零信任”？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "数据并行、张量并行、流水线并行的原理及区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "数据集怎么构建的，什么规模，评估指标是什么，这些指标存在哪些问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "既然大模型微调不是将外部知识注入大模型的最优方案，那是否有其它可行方案？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "是否了解上下文压缩方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "显存不够一般怎么解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "更长链（>50 步）怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "未来监管要求“豁免需可解释”，如何自动化生成解释报告？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "极端大场景（千亿级参数+城市级路网）如何横向扩展？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "样本量规模增大，训练出现 OOM 报错，怎么解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "梯度噪声过大怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "模型参数微调的方式有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "模型如何判断回答的知识是训练过的已知知识，怎么训练这种能力？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "模型部署的平台是什么，推理效率怎么样，如何提升推理效率？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "注意力机制中计算注意力分数时为什么会除以根号 dk？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "注意力机制如何解决长序列依赖问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "注意力机制是如何工作的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "混合云架构能否降低合规溢价？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "用于大模型微调的数据集如何构建？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "相比于baichuan-7B，baichuan-13B的特点体现在哪？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "相对位置编码和绝对位置编码有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简单介绍一下 RLHF？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简单介绍强化学习？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "聊一下 RAG 项目总体思路？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "聚类结果如何反哺大模型微调？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "能否用 4 * V100 32G 训练 Vicuna 65B？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "节点特征指的是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "若未来芯片进一步受限（仅48GB显存），如何单卡完成7B→1B蒸馏？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "若要支持实时流式生成（直播字幕），如何做到逐句验证不阻塞？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "政务客户担心开源后数据泄露机密，如何平衡？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "尝试过不同大小的 chunk 和混合检索，效果都不太好，如何优化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "训练一个通用大模型的流程有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "训练中文大模型有哪些经验？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请简述 Transformer 中的位置编码是如何实现的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "请简述 Transformer 的基本结构和工作原理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请解释什么是位置编码，为什么在大模型中需要位置编码？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "请谈谈你对 A/B 测试的理解，并说明它在大模型中的应用。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "请谈谈你对 Transformer 未来发展的看法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "谈谈你对 Transformer 模型的理解，以及它在自然语言处理中的应用。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "采样时如何选择温度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "遇到多跳事实（A的B的C是多少）怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "遇到恶意刷榜（偷偷在测试集里加训练语料）怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "重训后模型效果“虚假回升”（指标好看但人工评测下降）怎么发现？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何让 LLM 简要、准确回答细粒度知识？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何让 LLM 回答出全面的粗粒度（跨段落）知识？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么样的数据才是最优的大模型微调数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何构建大模型微调数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "面对大模型训练和推理所需的庞大计算资源，你有什么解决方案或建议？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "预训练和 SFT 操作有什么不同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "预训练数据 Token 重复是否影响模型性能？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "领域模型Continue PreTrain，如何让模型在预训练过程中就学习到更多的知识？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "领域模型词表扩增是不是有必要的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何用 torch profiler 查看训练中的通信开销？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "PPO（强化学习）的数据格式是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RM（奖励模型）的数据格式是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "SFT（有监督微调）的数据集格式是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何缓解 LLM 复读机问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "大模型LLM进行SFT时如何对样本进行优化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "大模型LLM进行SFT时在学习什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解决人工产生的偏好数据集成本较高、很难量产的问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如果想在某个模型基础上做全参数微调，需要多少显存？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "想让模型学习某个领域或行业的知识，应该预训练还是微调？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "指令微调的好处是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "预训练和微调哪个阶段注入知识？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "领域模型微调指令与数据输入格式有什么要求？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "领域模型微调领域评测集如何构建？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "ALiBi (Attention with Linear Biases) 被哪些 LLMs 应用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DistributedDataParallel（DDP）优点有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LoRA 应该作用于 Transformer 的哪个参数矩阵？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ZeRO Offload后的计算流程是怎么样的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "ZeRO 的优化策略是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "ZeRO 显存如何分配？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "nn.DataParallel 常见问题有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "torch.multiprocessing 如何使用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "vLLM 支持哪些 Huggingface 模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LLMs 已经具备较强能力了，还存在哪些不足？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "StreamingLLM 的优点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要提取标题甚至是多级标题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要 StreamingLLM？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 DistributedDataParallel 的核心机制 Ring-AllReduce？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "什么是 accelerate 分布式训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MoE 大模型具备哪些缺点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 gradient checkpointing 显存优化方式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "几种主流大模型的 loss 你了解哪些，它们有哪些异同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "MoE 大模型具备哪些优势？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何 配置 LoraConfig？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何使用 AMP混合精度训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何选择一款分布式训练框架？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "想要训练1个LLM，如果只想用1张显卡，那么对显卡的要求是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "推导一下旋转位置编码 RoPE？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "是否可以避开训练集来处理 LLM 测试集数据泄露问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "直接使用 nn.DataParallel 进行多卡训练时出现 warning 的原因是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Bert 在 RAG 中具体起到什么作用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "为什么需要流水线并行（Pipeline Parallelism）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是张量并行（intra-layer）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分布式并行及显存优化技术有哪一些，都有什么特点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何使用基于 LoRA 的 Llama2 做推理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要对 Llama2 做基于 LoRA 的二次预训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "举例描述一下大语言模型的RLHF？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下LLM的经典预训练Pipeline？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于RM模型使用PPO算法微调SFT模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于 LoRA 的 Llama2 二次预训练的思想是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对预训练模型进行指令微调时，tokenization 如何构建？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LLM 什么时候最容易产生幻觉？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何缓解大模型幻觉？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何评估大模型幻觉问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要用层次化 Softmax 回归（Hierarchical Softmax）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "层次化 Softmax 回归（Hierarchical Softmax）的思想是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "层次化 Softmax 回归（Hierarchical Softmax）的步骤是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Gradient Boosting 算法（GBM）和随机森林都是基于树的算法，它们有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 KNN 最近邻分类算法的过程。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何理解模型的过拟合与欠拟合，以及如何解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "机器学习中的正则化是什么意思？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "L1、L2正则化的区别是什么？岭回归是L1正则化还是L2正则化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 L2 正则化可以获得值很小的参数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "添加 L1 和 L2 正则化有什么用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何通俗理解贝叶斯方法和贝叶斯网络？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "boosting集成学习由多个相关联的决策树联合决策，什么叫相关联？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "AUC刻画的是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "AUC和ROC是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么AUC和logloss比accuracy更常用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "可以直接优化AUC来训练分类器吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下XGBoost，与GBDT相比有什么不同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍决策树、信息熵？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何构造每个逻辑回归单元的输入？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是线性回归？什么时候使用它？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是特征选择？为什么需要它？特征选择的目标？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些特征选择技术？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "梯度提升的如何调参？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要处理类别特征？怎么处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是正规方程？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是正态分布？为什么要重视它？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何检查变量是否遵循正态分布？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "XGBoost 在什么地方做的剪枝，如何进行剪枝？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "L1 和 L2 正则化有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是正则化？如何理解正则化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 LR 要使用 sigmoid 函数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是准确率、精准率、召回率和 F1 分数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是回归？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你是怎么理解偏差和方差的平衡的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "基尼指数和信息熵都表示数据不确定性，为什么 CART 使用基尼指数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何使用信息增益比？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "既然信息增益可以计算，为什么 C4.5 还使用信息增益比？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "简述一下 KNN 算法的原理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "PCA 的优化目标是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "随机森林的随机性指的是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "GBDT 如何防止过拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "K-means 算法中初始点的选择对最终结果有什么影响？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "PCA 白化是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "GBDT 对标量特征要不要 one-hot 编码？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "K-means 中常用的距离度量有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么 GBDT 用负梯度当做残差？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么在计算 K-means 之前要将数据点在各维度上归一化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "随机森林如何处理缺失值？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "随机森林如何评估特征重要性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么要将求解 SVM 的原始问题转换为对偶问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "树形结构模型不需要归一化的原因是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "用什么来评估 LR 模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请简要说说一个完整机器学习项目的流程？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "用过哪些移动端深度学习框架？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RNN容易梯度消失，怎么解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LR 如何解决多分类问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "SVM 怎么输出预测概率？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么决策树之前用 PCA 会好一点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何处理数据偏斜？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "模型压缩效果评价指标有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "压缩和加速方法如何选择？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么在训练的过程当中将高度相关的特征去掉？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "对一千万个整数排序，整数范围在[-1000,1000]间，用什么排序最快？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是 Python 的生成器？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何判断两个 dict 是否一样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "函数后面接 const 是什么意思？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "IP 报文经过一个路由器会改变哪些字段？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "分类算法常用哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "L0、L1、L2 正则化是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么常常要做特征组合（特征交叉）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么朴素贝叶斯如此“朴素”？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "回归算法一般用哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何理解 kNN 中的 k 的取值？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "模型常用的评估指标有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "线性回归的损失函数为什么是均方差？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 Adaboost 方式能够提高整体模型的学习精度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么要用 SVD 进行降维？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "使用 m 个基学习器和加权平均使用 m 个学习器之间有什么不同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "adaboost 算法中基学习器是否很重要，应该怎么选择基学习器？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SVM中什么时候用线性核什么时候用高斯核？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "机器学习中的距离计算方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 LR 比线性回归要好？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "决策树算法中如何避免过拟合和欠拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "在 kNN 的样本搜索中，如何进行高效的匹配查找？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "多标签分类怎么解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "朴素贝叶斯的优缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "比较 LR 和 GBDT：什么情景下 GBDT 不如 LR？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost 如何选择最佳分裂点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost 的 Scalable 性如何体现？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost 模型如果过拟合了怎么解决？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "XGBoost 如何寻找最优特征？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 XGBoost 的近似算法比 LightGBM 慢很多？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "XGBoost 为什么快？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost 如何处理缺失值？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么 XGBoost 相比某些模型对缺失值不敏感？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost 如何处理不平衡数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "KNN 算法有哪些优点和缺点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "L1 在 0 处不可导是怎么处理的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么 SVM 对缺失数据敏感？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "为什么引入条件独立性假设？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是梯度下降？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是监督学习？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "决策树怎么剪枝？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "SVM和全部数据有关还是和局部数据有关？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Loss Function有哪些，怎么用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "L1 正则化产生稀疏性的原因是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是最小二乘法（最小平方法）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "在估计条件概率 P(X|Y) 时出现概率为 0 的情况怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "降维的作用是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是 ROC 曲线？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解释 AU ROC 分数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LR 如何解决低维不可分问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "SVM 如何处理多分类问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为何要常对数据做归一化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "协方差和相关性有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "矩阵的特征值和特征向量的物理意义是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HMM隐马尔可夫模型的参数估计方法是？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Bootstrap方法是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何防止过拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "常用什么激活函数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LR 与最大熵模型 MaxEnt 的关系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何优化 Kmeans？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "如何处理高维组合特征？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "带核的 SVM 为什么能分类非线性问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有哪些评估回归模型的指标？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "正负样本不平衡的解决办法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RBF 核一定是线性可分的吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么 LR 用交叉熵损失而不是平方损失（MSE）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如果特征很多，决策树中最后没有用到的特征一定是无用吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "机器学习中分类器指的是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "循环神经网络为什么好？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LR 能否解决非线性分类问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "决策树怎么做回归？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "数据中有噪声如何处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "梯度下降法找到的一定是下降最快的方向吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "训练过程中，若一个模型不收敛，那么是否说明这个模型无效？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "神经网络中权重共享的是？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在深度学习中，通常会finetuning（微调）已有的成熟模型，再基于新数据修改最后几层神经网络权值，为什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "微调时候网络参数是否更新？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "EM算法是否一定收敛？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "GBDT 和 xgboost 之间差别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "GBDT 和随机森林的区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LR/SVM/softmax/Adaboost 损失函数之间的差别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LightGBM 对类别型是怎么处理的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RF 与 boosting 之间差别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "SVM 对缺失数据敏感吗，为什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "SVM 的高斯核为什么会把原始维度映射到无穷多维？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "SVM、LR、决策树的对比？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "TF-IDF 是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "level-wise 的生长和 leaf-wise 的生长有什么不同，优缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "lgb 二分类的损失函数是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "lgb,xgb 如何防止过拟合，有哪些参数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "lr 模型是线性模型还是非线性， 为什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "p 值是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "xgboost 和 LightGBM 有哪些控制过拟合的手段，通常需要调整的参数有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "xgboost 对于缺失值，训练和预测的时候都是怎么处理的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "xgboost 有哪些参数会影响模型的复杂度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "xgboost 的多分类如何做？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "xgboost 的并⾏化体现在哪？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "xgboost 的树生长时的精确分裂与近似分裂分别是怎么做的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 xgboost 的近似算法比 lightgbm 还是慢很多呢？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么会产生过拟合，有哪些方法可以预防或克服过拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么是交叉熵而不是MAE？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要将求解 SVM 的原始问题转换为其对偶问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是乐观锁？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "交叉熵代价函数是如何产生的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是偏差与方差？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是凸优化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是深度学习？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是非监督学习？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么样的函数可以作为 SVM 的核函数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍卷积神经网络，和 DBN 有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "价格是否正态分布？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是悲观锁？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "写一下贝叶斯公式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "决策树/随机森林的特征重要度是怎么获得的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "决策树怎么控制过拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "决策树的缺失值和数值型特征分别是怎么处理的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "哪些模型可用于解决回归问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多分类怎么处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果两个变量相关，那么它们一定是线性关系吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何判断 ROC 曲线的好坏？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何对贝叶斯网络进行采样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "如何建立价格预测模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何观察过拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解决类别不平衡问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果出现计数为 0 导致概率为 0，这种情况在朴素贝叶斯计算里是怎么解决的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "小数据集中如何防止过拟合？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "常用的防止过拟合的技术手段有哪些？L1-norm 和 L2-norm 的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "文本中的余弦距离是什么，有哪些作用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "无监督和有监督算法的区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有几种不同的决策树，区别在哪？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些处理异常值的方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些异常值检测的方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些模型评估方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些特征选择的方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些评估准则？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "朴素贝叶斯是一个什么算法，能解释一下吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "构建一个最简单的线性回归模型需要几个系数（只有一个特征）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "深度学习与机器学习有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "深度学习的训练过程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "特征工程有什么作用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络的原理是什么，如何进行训练？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "聚类算法中的距离度量有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "能写一下逻辑回归的损失函数吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "能解释一下 LightGBM 里基于 histogram 的决策树算法吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "解释 L1 和 L2 正则化的作用。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "解释一下决策树的建模过程？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "解释对偶的概念。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "解释贝叶斯公式和朴素贝叶斯分类。",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "逻辑回归中样本不均衡我们怎么处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "逻辑回归和最大似然有什么关系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "逻辑回归用梯度下降优化，学习率对结果有什么影响？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "采用 EM 算法求解的模型有哪些，为什么不用牛顿法或梯度下降法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "需要对价格进行预处理吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么逻辑回归做对数转换时选用以 e 为底？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "lr 为什么不采用 mse 而是采用交叉熵损失？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "CART 树是如何做分类的，是如何做回归的，是如何处理多分类的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "PCA 算法原理，跟 svd 的区别。特征值越大代表什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "GNN图神经网络如何应用于文本分类领域？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 BERT 需要 fine-tuning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解决长文本分类任务？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "文本分类任务的数据预处理方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BERT 是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是ROUGE？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "几种ROUGE指标之间的区别是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BLEU和ROUGE有什么不同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你使用过哪些分词方法和工具？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "中文文本分词的方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "NLP中常见的分词方法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "基于字符串匹配的分词方法的原理是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "统计语言模型如何应用于分词？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "基于序列标注的分词方法是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "文本分类任务相较于其他领域的分类任务有何不同之处？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "文本分类的过程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Bert 预训练任务 Masked LM 怎么做？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "GPT 和 BERT 有什么不同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍下词向量空间中的平移不变现象？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 LEX-BERT？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BERT的缺点有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RoBERTa相比BERT有哪些改进？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "NER 实体 span 过长怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "事件抽取与其他信息抽取任务（关系抽取、NER等）有什么联系，难点在哪？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "工业界如何解决 NER 问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "注意力机制如何应用于文本分类领域？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "讲一下BERT的结构？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LLMs 中的不同位置有什么区别么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Layer Norm 有什么特点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "TF（词频）和 IDF（逆文档频率）的乘积的正确值是多少？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer 架构首先是由下列哪项引入的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "以下哪项可用于减少数据维度？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "下列哪一项不是预处理技术？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "下列哪些技术能被用于计算两个词向量之间的距离？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "下列哪种嵌入方式支持双向上下文（Bidirectional Context）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "下列哪种词嵌入可以自定义训练特定主题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "下列哪种词嵌入支持上下文建模（Context Modeling）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "下列哪项是关键词归一化技术？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "下面哪个是 NLP 用例？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "从句子中删除“and”、“is”、“a”、“an”、“the” 这样的词的过程被称为？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "从给定的句子、段落中识别人名、组织名的过程称为？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "以下哪种 NLP 模型的准确性最高？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "以下哪种架构可以更快地训练，且需要更少的训练数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "文本语料库的可能特征是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Python的深拷贝和浅拷贝的区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Python迭代器是什么，构成是怎样的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Embedding 后多义词问题解决了吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Query 扩写的 Prompt 如何构建？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么进行 Query 扩写？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍下 HyDE？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要使用大模型辅助召回？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要使用检索增强的语言模型（Retrieval-based LMs）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是检索增强的语言模型（Retrieval-based LMs）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "基于 LLM + 向量库的文档对话思路是怎么样的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何构造微调 Bert 相似度向量模型数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "检索模块的评估指标有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "长文本如何存储用于检索？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RAG 有哪些优点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要 RAG-Fusion？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 存在哪些局限性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何合成 RAG 测试集？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 索引数据优化有哪些优化策略？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 索引优化有哪些优化策略？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说一下 RAG-Fusion 工作流程？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说一下 RAG-Fusion 核心技术？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在做 RAG 项目过程中遇到哪些问题，怎么解决的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 和 SFT 微调有什么不同？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Self-RAG 的推理过程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Self-RAG 的训练过程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "上下文长度过长怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要微调 Bert 模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是交互型模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍下 RAG-Fusion？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "介绍下 SELF-RAG？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "使用什么相似度模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "基于 Retrieval-based LMs 的对话流程是怎么样？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何判断上下文是否关联？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何提高搜索质量和大语言模型的推理能力？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "输入文档的顺序对大模型是否有影响？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "长篇知识如何产生问答对？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Graph RAG 排序优化方式？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍下 Rerank 模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "prompt 模板如何构建？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要进行文本切块？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是句子窗口检索？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是父文档检索器？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "分块策略都有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "语义分块模型都有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "选择分块策略时，需要考虑哪些要素？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何评估 RAG 系统的准确率上下限问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么需要RLHF替代方案？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下LLaMA 2的RLHF？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "具体介绍一下预训练（Pre-training）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "简单介绍一下RLHF流程？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简单介绍一下对齐（Alignment）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LLaMA 2中Margin Loss的实现逻辑？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "RLHF有哪些替代方案？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何在预训练好的模型上进行有监督微调？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LLaMA 2中两个RM模型的实现逻辑？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "PPO中采样策略中，如何评估“收益”？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何在有监督微调模型基础上创建一个RM模型？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LLaMA 2中拒绝采样逻辑？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Ray 怎么做梯度并行运算的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 TRPO 能保证新策略的回报函数单调不减？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么使用优势函数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "什么是强化学习？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你在强化学习模型调试中，有哪些调优技巧？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你熟悉的多智能体环境有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "分层强化学习的原理是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多智能体之间如何通信、如何竞争？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多智能体强化学习算法有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如果不满足马尔科夫性怎么办？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "强化学习如何观察收敛曲线？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "强化学习适合解决什么样子的问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "强化学习需要大量数据，如何生成或采集到这些数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "影响强化学习算法收敛的因素有哪些，如何调优？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "手工推导策略梯度过程？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "推荐场景中奖赏函数如何设计？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "描述随机策略和确定性策略的特点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "是否了解 RLlib？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "是否了解 α−Rank 算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "是否了解过 D4PG 算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "是否理解 Entropy、KL divergence 和 Mutual Information 的含义？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "最优值函数和最优策略为什么等价？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "有哪些方法可以使得 RL 训练稳定？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "求解马尔科夫决策过程都有哪些方法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "画出 DQN 玩 Flappy Bird 的流程图：在这个游戏中，状态是什么，状态是怎么转移的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "确定性策略和随机性策略的区别与联系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "离散 action 和连续 action 在处理上有什么相似和不同的地方？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "策略梯度算法的目标函数和策略梯度计算？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 A3C 的优势函数？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 A3C 算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 DPPO 和 PPO 的关系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 DRL 的一些最新改进？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 Imitation Learning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 MADDPG 算法的过程和伪代码？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 Meta Gradient Reinforcement Learning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 Meta Reinforcement Learning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 Model Based Learning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 Multi-Task Reinforcement Learning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 Out-of-Distributon Generalization？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 PER 算法、HER 算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 PPO、DPPO 算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 PPO 算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 UCB 算法（Upper Confidence Bound）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 Double DQN 原理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 offline reinforcement learning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 seed rl？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述 unsupervised reinforcement learning？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "简述模仿学习与强化学习的区别、联系？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "自动驾驶和机器人的场景如何建模成强化学习问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "请简述 QMIX 算法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "请简述造成强化学习 inefficient 的原因？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "贝尔曼方程的具体数学表达式是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "贝尔曼期望方程和贝尔曼最优方程什么时候用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "阐述目标网络和 experience replay 的作用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "A3C 是 on-policy 还是 off-policy，为什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "MDP 各元素对应真实场景中的哪些变量？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "SL靠的是样本标签训练模型，RL依靠的是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大语言模型RLHF中的PPO主要分哪些步骤？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对于大规模分布式强化学习，还有更好的提高 throughput 的方法吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "是否能够阐述 GA3C 和 A3C 的区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "马尔科夫决策过程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "马尔科夫过程是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "基于Transformer的预训练模型如何应用于文本分类领域？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer encoder和decoder的区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer为什么要用Layer norm？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer 为何能够有效地处理长距离依赖问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer模型中注意力权重如何解释模型的决策？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer模型中的前馈网络(Feed-Forward Networks)的作用是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer模型中的自注意力机制在计算效率和表示能力之间是如何权衡的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer模型在实践中如何优化以处理超长序列？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer模型在自注意力层中如何解决多尺度表示问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer模型如何处理变长输入序列？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer模型如何平衡模型性能与计算资源的消耗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer模型的参数共享策略对模型性能有何影响？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer 模型的基本结构是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer模型的缩放点积注意力(Scaled Dot-Product Attention)是什么，其重要性在哪里？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer模型的自注意力机制如何实现并行处理？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer的两个mask机制是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer网络很深，是怎么避免过拟合问题的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么Transformer可以处理多种模态，它是怎么处理的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多头注意力机制和单个注意力机制时间复杂度会变吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多头注意力的作用是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何在自注意力机制中平衡局部信息和全局信息的捕获？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何提高Transformer模型中自注意力机制的计算效率？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何解决Transformer长度限制的问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "如何设计更有效的注意力机制来处理层次化或结构化数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "描述下Transformer的结构？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "多头注意力机制（Multi-head Attention）是什么？它相比单头注意力有什么优势？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 FasterTransformer？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "FasterTransformer 如何优化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Decoder 端可以做并行化吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Decoder 阶段的多头自注意力和 Encoder 的多头自注意力有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Encoder 和 Decoder 端是如何进行交互的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "GPT 模型的架构和特点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "LoRA怎么做的，讲一下？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Position-wise feed-forward networks 具体是怎么设计的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer 中的前馈神经网络有什么作用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 中的自注意力机制是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 中的自注意力机制是如何工作的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 为何使用多头注意力机制？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 在机器翻译任务中的应用是怎样的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 是如何工作的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 是如何训练的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 有何特点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 模型中的多头注意力机制有什么优点？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 模型的编码器和解码器结构是怎样的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 的优势是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 的局限性是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 的并行化体现在什么地方？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Transformer 计算 attention 的时候为何选择点乘而不是加法？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Bert 为什么要搞一个 position embedding？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Bert 为什么三个 embedding 可以相加？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer 为什么要用三个不一样的 QKV？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Bert 中为什么要用 WordPiece/BPE 这样的 subword token？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "不用[CLS]的语义输出，有其他方式可以代替吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BERT中有哪些地方用到了mask？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "预训练阶段的mask有什么用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Attention中的mask有什么用？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "self-attention 无法学习到序列信息吗？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "Transformer 的输入是什么样的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 这个黑盒子里面都有什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么说GPT是单向的、BERT是双向的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BERT如何处理一词多义？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "ALBERT是通过什么方法压缩网络参数的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "BERT中的Transformer和原生的Transformer有什么区别？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 decoder 需要 sequence mask？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么可以用LoRA？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么后续有不少工作尝试对 softmax 进行替换？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "为什么要使用 query、key、value 矩阵？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要做 position embedding/encoding？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要做 softmax 标准化？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "为什么要加 FFN？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么要引入 Transformer？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要设计多头注意力而不用单头注意力？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为何在获取输入词向量之后需要对矩阵乘以 embedding size 的开方？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是LLM的复读机问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是位置编码（Positional Encoding），为什么在 Transformer 中需要它？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是注意力矩阵，如何计算？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你了解哪些 attention 机制？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你怎么理解注意力机制？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "你还了解哪些关于位置编码的技术，各自的优缺点是什么？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "出现复读机问题的可能原因有哪些？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "在 Transformer 模型中，如何处理长序列数据？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在 Transformer 模型的训练过程中，为什么要使用掩码（Mask）？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在自然语言生成任务中，Transformer 如何确保生成文本的连贯性和一致性？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在计算 attention score 的时候如何对 padding 做 mask 操作？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "大概讲一下 Transformer 的 Encoder 模块？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何决定 Transformer 中的层数和注意力头的数量？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何处理 Transformer 中的不同长度的输入序列？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何处理 Transformer 中的缺失/损坏数据并解决过拟合问题？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何微调预训练的 Transformer 以适应特定任务？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何确定 Transformer 的适当容量水平？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何评估和改进 Transformer 模型的性能？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调后的大模型出现灾难性遗忘是什么原因？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "想让模型学习垂直领域的知识，是应该预训练还是微调？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "解决大模型复读机问题可用哪些策略？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "训练和实现 Transformer 时有哪些常见挑战，如何改进其性能？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "预训练和微调是哪个阶段注入知识的？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "kaggle 上的 attention layer 到底实现的是啥？",
      "sources": [
        "CLEAN_MERGED_KEEP_VARIANTS_v3.json"
      ]
    },
    {
      "question": "为什么 ReLU 常用于神经网络的激活函数？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 Dropout？为什么有用？它是如何工作的？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是 Adam？Adam 和 SGD 之间的主要区别是什么？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "batch size 和 epoch 如何平衡？",
      "sources": [
        "dl_questions_theory_v3.json"
      ]
    },
    {
      "question": "如何初始化神经网络的权重？神经网络怎样进行参数初始化？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "前馈神经网络(FNN)、递归神经网络(RNN)和 CNN 区别？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 LeNet？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是 AlexNet？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是 ResNet？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是 DenseNet？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Max pooling如何工作？还有其他池化技术吗？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "CNN 拆成 3x1、1x3 的优点？",
      "sources": [
        "dl_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是微调（fine-tune）？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "阶优化和二阶优化的方法有哪些？为什么不使用二阶优化？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "AlexNet 对比 LeNet 的优势？",
      "sources": [
        "dl_questions_theory_v3.json"
      ]
    },
    {
      "question": "VGG 使用 2 个 3×3 卷积的优势在哪里？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "卷积核是否一定越大越好？它的优点有哪些？",
      "sources": [
        "dl_questions_theory_v3.json"
      ]
    },
    {
      "question": "CNN是否抗旋转？如果旋转图像，CNN的预测会怎样？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是迁移学习？它是如何工作的？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是目标检测？你知道有哪些框架吗？",
      "sources": [
        "dl_questions_theory_v3.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "各个激活函数的优缺点？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "梯度消失和梯度爆炸的解决方案？梯度爆炸引发的问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "批量归一化(BN)如何实现？作用？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "神经网络中权值共享的理解？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "对fine-tuning(微调模型)的理解？为什么要修改最后几层神经网络权值？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "学习率太大(太小)时会发生什么？如何设置学习率？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "神经网络数据预处理方法有哪些？中心化/零均值、归一化？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "卷积神经网络的优点？为什么用小卷积核？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LSTM的原理、写LSTM的公式、手推LSTM的梯度反向传播？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "微调先冻结底层，训练顶层的原因？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "目标检测中如何从零开始训练（train from scratch）？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何避免过拟合问题？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何避免欠拟合问题？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是梯度下降？SGD 的推导是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "XGBoost 可以并行训练的原因是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "XGBoost 防止过拟合的方法有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么不用全样本训练？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是深度学习？深度学习的训练过程是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "word2vec的原理是什么，怎么训练的？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是 训练式位置编码？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "训练式位置编码存在哪些问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "大模型训练出现 loss 突刺如何解决？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "大模型（LLM）的训练目标是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么要初始化为全",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "使用 LoRA 对大模型进行高效参数微调，如何进行存储？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于lora的llama2二次预训练 的目标是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于LoRA的Llama2二次预训练语料构建思路是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何解决三个阶段的训练（SFT->RM->PPO）过程较长、更新迭代较慢的问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调大模型时 batch size 如何设置？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调大模型时，batch size 设置太大会出现什么问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "微调大模型时，batch size 设置太小会出现什么问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "领域模型微调的领域评测集如何构建？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么多机训练效率不如单机？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "accelerate 分布式训练的主要优势是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "accelerate 分布式训练的原理是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "deepspeed 训练过程中报“找不到主机”可能是什么原因？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "nn.parallel.DistributedDataParallel如何多卡加速训练？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Reward Model 训练数据集的 Scaling Law 是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么不能使用 Apex 进行混合精度训练？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "为什么大模型分布式训练需要故障恢复？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是自动混合精度训练？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "模型训练过程中出现 loss spike（loss 突然尖峰）会导致哪些问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "对预训练模型进行指令微调时，数据如何处理？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "对预训练模型进行指令微调时，模型如何构建？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "梯度累积的原理是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "适配器微调（Adapter-tuning）的特点是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么逻辑回归用sigmoid激活函数？多分类逻辑回归是否也是sigmoid？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在卷积神经网络中，卷积操作的数学表达式是什么？请解释卷积核、步长和填充在其中的作用。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调大模型时如果 batch size 设置太小会出现什么问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "随机梯度下降相比全局梯度下降的好处是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何自动化扫描 Docker 镜像中携带的 GPL 组件与模型权重冲突？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于用户点击反馈在线微调双塔模型并避免灾难性遗忘？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于 profiling 结果自动调整 micro-batch 数并减少气泡？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何对 100GB 训练镜像做分层构建并缓存 pip 依赖？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何基于用户接受率在线微调小模型提升草案命中率？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何基于用户反馈在线微调压缩模型？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何评估弱监督标签对微调效果影响？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "领域模型微调的指令与数据输入格式有什么要求？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有哪些省内存的大语言模型训练、微调、推理方法？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "常见的分布式训练框架有哪些，都有什么特点？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 哪里做了权重共享？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SVM 怎么处理过拟合？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络处理过拟合的方法？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何检验过拟合，数据量很小怎么办？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "样本量多少？为什么使用深度神经网络？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请说一下你是通过什么方法来判断模型欠拟合和过拟合的？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "xgboost中哪些参数可以控制过拟合？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "L1、L2正则化的效果、区别、原理？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Lora的矩阵怎么初始化？为什么要初始化为全0？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "大模型训练的三种并行是什么？通讯开销比？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "想让模型学习某个领域或行业的知识，是应该预训练还是应该微调？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "前缀微调（Prefix-tining）的优点是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何 基于lora的llama2二次预训练？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "具体介绍一下 有监督微调（Supervised Tinetuning）？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "baichuan 进行微调时，领域数据与通用数据如何配比？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MoE为什么可以实现更大模型参数、更低训练成本？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MoE如何解决Fine-Tuning过程中的过拟合问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "学习率大小对大模型继续预训练后上下游任务影响？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "基于深度学习的命名实体识别方法的结构是怎么样的？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "BERT 预训练任务 Next Sentence Prediction（NSP）怎么做？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "BERT 为什么需要预训练任务 Next Sentence Prediction（NSP）？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "想让模型学习某领域或行业知识，是应该预训练还是应该微调？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要进行参数微调？参数微调的原因有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "模型参数微调的方式有哪些？你最常用哪些方法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "是否接触过 embedding 模型的微调方法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是过拟合？产生过拟合原因？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "L1正则化产生稀疏性的原因？对稀疏矩阵的理解？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "XGBoost 可以并行训练的原因？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "XGBoost 防止过拟合的方法？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何简单理解过拟合？如何防止过拟合？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何避免决策树过拟合？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Inception(GoogLeNet)？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "×1 卷积的作用是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "全连接、局部连接、全卷积与局部卷积的区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "ResNet v1 与 ResNet v2 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "说说R-CNN、Fast R-CNN和Faster R-CNN的区别。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CNN中的卷积到底指什么？举个例子？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "使用 CNN 作为文本分类器时，不同通道（channels）对应着文本的什么信息？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "TextCNN中卷积核的长与宽代表了什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简单介绍DPCNN模型相较于TextCNN的改进？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简要介绍TextRCNN相较于TextCNN的改进？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果未来 Transformer Decoder 替代 CNN，通道数还会是 2 的幂次吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当网络里出现转置卷积stride=2做上采样时，如何防止棋盘效应？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "K-means是否会一直陷入选择质心的循环停不下来（为什么迭代次数后会收敛）？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "时间序列预测的原理是什么？有哪些应用场景？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "时间序列预测需要注意的点？和回归有何区别？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "JAVA 反序列化了解吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在做NER任务时，LSTM后面可以不用加CRF吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "隐马尔科夫算法序列概率计算过程是什么样的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Java 序列化，如何实现Java 序列化？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是EDA(Exploratory Data Analysis)？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是 Sinusoidal 位置编码？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ALiBi (Attention with Linear Biases) 的偏置矩阵是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "ALiBi (Attention with Linear Biases) 有什么优点？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "旋转位置编码 RoPE 有什么优点？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "旋转位置编码 RoPE 被哪些 LLMs 应用？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "InstructGPT 的原理：讲讲 RLHF 和 reward？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "huggingface 大模型如何加载多个 LoRA 并随时切换？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要位置编码？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "使用 LoRA 对大模型进行推理，如何进行加载？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何利用 transformers 加载 BERT 模型？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "PEFT 库中 LoRA 模块 _find_and_replace() 的实现思路是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "PEFT 库中 LoRA 层的实现思路是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Multi-Query Attention 这样做的好处是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型【LLMs】具有什么优点？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "大模型【LLMs】具有什么缺点？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "PEFT 库中 LoRA 模块如何使用？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何把贡献者数据喂给大模型做价值观对齐？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "多业务共用一套大模型底座时，如何设计“复合北极星”？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型恢复后，如何防止上下文断裂导致用户体验跳变？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Token Attention 介绍？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "将词表示成向量被称为神经词嵌入（Neural Word Embeddings）吗？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是大模型？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么在进行 softmax 之前需要对 attention 进行 scaled（为什么除以 dk 的平方根）？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 Transformer 及其架构？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Attention 怎么做，self-attention 怎么做？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Self-attention 部分怎么计算的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "最近关注的论文有哪些？例如多模态视觉大模型（CLIP、DALL·E）？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "embedding 的作用是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "embedding 的物理意义是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型进行 SFT 时如何对样本进行优化？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下大语言模型（LLM）的安全挑战有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "大模型（LLMs）agent 有哪些部分组成？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "常见 LLM Agent 框架或者应用有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ALiBi（Attention with Linear Biases）的偏置矩阵是什么？有什么作用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 LLMs 的文本生成过程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "StreamingLLM 思路是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何缓解大模型幻觉问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么会出现大模型幻觉？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 LLMs 测试集数据泄露问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何解决 LLMs 测试集数据泄露问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BERT 在 RAG 中具体起到了什么作用？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型词表扩充的方法及工具有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "搭建大模型应用遇到过哪些问题，如何解决的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Attention 机制的作用是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "与 Transformer-based 检测头结合时，DFL 是否还有优势？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 判别器如何加 SN？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是监督学习？什么是非监督学习？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是交叉验证？交叉验证的作用是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "交叉验证主要有哪几种方法？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 K 折交叉验证？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何在 K 折交叉验证中选择 K？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是准确率、精准率、召回率和F1分数？什么是混淆矩阵？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是组合特征？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么有效地找到组合特征？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "把分类变量当成连续型变量会得到一个更好的预测模型吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线性回归的推导？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是回归？哪些模型可用于解决回归问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LR 参数求解的优化方法有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "LR如何解决多分类问题？（OvR vs OvO）？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是ROC曲线？如何判断 ROC 曲线的好坏？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么信息增益偏向取值较多的特征？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost如何寻找最优特征？是有放回还是无放回？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost如何分布式？特征分布式和数据分布式？各有什么问题？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要随机特征？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "聚类和分类的区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "协方差与相关系数的区别和联系是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "如何对档案进行分类？标准是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何利用 Elo 评级算法给指令难度打分并防止标注者偏差？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请简单阐述下决策树、回归、SVM、神经网络等算法各自的优缺点？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何使用 SVM 处理多分类问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "回归模型和分类模型的评价指标都有什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你觉得机器学习算法在阿里巴巴哪些场景中可以落地？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有哪些常用的机器学习方法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说一说逻辑回归和SVM的区别和联系？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "简单介绍一下逻辑回归？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你知道哪些降维算法？知道 t-SNE 吗？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "逻辑回归为什么要对特征进行离散化？为什么要对特征进行标准化？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "哪些算法不需要对特征进行标准化处理？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "特征方程的几何意义是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "熟悉哪些聚类算法，解释下K-means 算法？什么时候或条件下停止迭代？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么叫特征工程？有哪些评估模型好坏的指标？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SVM 的原理是什么？怎么找到最优的线性分类器？支持向量是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对于非常大的分类类别，对于softmax有哪些优化方法？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "torch.multiprocessing 函数介绍一下？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "文本分类任务有哪些应用场景？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "文本分类任务使用的评估指标有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分类任务有哪些类别？它们都有什么特征？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "关于特征选择，下列对 Ridge 回归和 Lasso 回归说法正确的是？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RF 分类和回归问题如何预测 y 值？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "等待事件的分类有哪些？常见等待事件有哪些？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "机器学习会影响 Web3 吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DFL能否用于实例分割的Mask回归？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "设计模式的分类有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "能否使用日志特征进行安全备份？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "服务器的分类有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "IP 地址有哪些分类？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "审计如何分类？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "不平衡的样本可以给 KNN 的预测结果造成哪些问题，有没有什么好的解决方式？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为了解决KNN算法计算量过大的问题，可以使用分组的方式进行计算，简述一下该方式的原理？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "在k-means或kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用曼哈顿距离？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "SVM 核函数之间的区别？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "常用核函数及核函数的条件？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "SVM 有哪些可以调节的参数？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "SVM 为什么使用拉格朗日乘子法？软间隔怎么做？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "SMO 算法在求解 SVM 的超平面方程中，扮演了一个什么样的角色？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请说一说朴素贝叶斯模型？它的假设条件是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "朴素贝叶斯，怎么平滑？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请你说说支持向量机（SVM）？SVM 与 LR 之间有什么样的区别和联系？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基尼系数(Gini)存在的问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "决策树的数据 split 原理或者流程？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "构造决策树的步骤？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "决策树的优缺点？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "决策树和条件概率分布的关系？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么使用贪心和启发式搜索建立决策树，为什么不直接使用暴力搜索建立最优的决策树？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "决策树算法的停止条件？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "adaboost 的迭代次数(基学习器的个数)如何控制？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "XGBoost 使用泰勒二阶展开的原因？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "XGBoost 中的一棵树的停止生长条件？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RF 为什么比 bagging 效率高？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么 RF 的树比 GBDT 的要深一点？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "相同的词可以通过什么方式来实现多个词嵌入？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "glove 和 word2vec 对比有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "可以简单介绍一下word2vec吗？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Word2Vec 有哪些优化方法？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "什么是n元语法？为什么要用n-gram？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "fastText 的结构是什么样？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "fastText 词内的 n-gram 信息存在什么问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "one-hot 是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "one-hot 有什么特点？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "one-hot 存在哪些问题？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "word2vec 为什么解决不了多义词问题？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "如何为每个位置的词向量注入位置信息？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "词嵌入捕获多维数据，并表示为向量？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "词嵌入向量有助于确定 2 个 tokens 之间的距离？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "排列语言模型（Permutation Language Models）是下列哪项的特点？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "统计语言模型如何应用于分词？N-gram最大概率分词？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何区分单栏还是双栏 PDF？如何重新排序？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Hash Join 是不是有排序？Hash Join 会在什么时候慢？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "在Python中如何实现快速排序？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "用哪两种方式来实现集合的排序？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "快速排序算法是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "给你 100G 数据、1G 内存，如何排序？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中如何排序？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 支持的 Java 客户端都有哪些？官方推荐用哪个？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DAO将如何在web环境中工作？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "强化学习有哪些动作空间（Action Spaces）？它们之间的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Agent 如何获取上下文对话信息？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何基于强化学习（RLPO）自动选择最佳示例并定义奖励函数？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于强化学习奖励模型自动选择最优窗口数？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于强化学习奖励自动决定图文 token 比例？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RLHF 的具体工程是什么？包含了哪几个模型？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下强化学习？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下强化学习的状态（States）和观测（Observations）？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "强化学习有哪些Policy策略？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下强化学习的轨迹？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下强化学习的奖赏函数？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下强化学习问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下强化学习中的贝尔曼方程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对统计这一块了解吗？p值是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "你是怎么理解数据分析的？流程如何？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "注册类和活跃类指标，你会看哪个？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "你理解的指标是什么？有哪些组成部分？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是北极星指标？什么是虚荣指标？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是指标体系？如何建立？业务应用场景？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是漏斗分析？有哪些注意的点？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是同比、环比，意义是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是相关性分析？相关和因果的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "如何理解假设检验中的 P 值和显著性水平 α？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "详细介绍一种非参数统计方法，并叙述其优缺点？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "常用的第三方数据统计平台有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当指标滞后 7 天时，如何采用代理指标实时指导？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是待定的统计信息（Pending Statistic）？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "测试活动中统计了哪些数据？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你怎么理解统计学？生活中统计学应用举例？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如果看到一个告警 IP，如何判断是否是真实攻击？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何检测 WebShell？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何验证存在 XSS 漏洞？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是 SSRF（服务器端请求伪造）？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "SSRF 的攻击原理是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "SSRF 有哪些常见的利用方式？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何防御和修复 SSRF 漏洞？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "怎么检测 CSRF？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试中的网络钓鱼攻击是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试中的 SQL 注入攻击是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是 SQL 注入攻击？如何防止 SQL 注入攻击？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是远程桌面协议（RDP）攻击？如何避免？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "在有shell的情况下，如何使用XSS实现对目标站的长久控制？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "CSRF、XSS和XXE有什么区别，以及修复方式？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "CSRF、SSRF和重放攻击有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是 DDoS 攻击？如何防范？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是黑客攻击？如何预防？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是跨站点脚本攻击？如何防范？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是漏洞扫描？如何进行漏洞扫描？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是社会工程学攻击？如何预防？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是安全漏洞？如何发现和修复安全漏洞？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是渗透测试？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试中的社会工程学攻击是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试中的暴力破解攻击是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试中的缓冲区溢出攻击是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试中的跨站脚本攻击是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是点击劫持攻击？如何防止点击劫持攻击？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是会话劫持攻击？如何防止会话劫持攻击？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是文件包含漏洞？如何防止文件包含漏洞？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何防止网络钓鱼攻击？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何防范恶意软件攻击？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何进行安全漏洞管理？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是防火墙？它的作用是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何进行安全漏洞扫描？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是漏洞管理？为什么它很重要？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "为什么 aspx 木马权限比 asp 大？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是 DoS、DDoS、DRDoS 攻击？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何解决 XSS 攻击问题？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如果您在区块链代码中发现安全漏洞，您会怎么做？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "SQL 注入比较了解哪个数据库？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SQL 注入 GetShell 有哪些方式？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "以下链接存在 SQL 注入漏洞，对于这个变形注入，你有什么思路？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 SQL 注入攻击？如何防范？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试中常用的网络协议分析工具有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HTTP 和 HTTPS 有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何判断是否存在CDN、如何绕过CDN、网站有CDN时怎么找真实IP？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是网络流量分析？如何进行网络流量分析？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是网络钓鱼？如何避免成为受害者？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是网络拓扑？为什么它很重要？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "网络拓扑如何影响您在建立网络时的决策？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "HTTP 如何实现长连接？在什么时候会超时？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "HTTPS 的工作流程是怎样的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "说说 HTTP 的状态码，301 和 302 的区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何进行网络安全风险评估？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "网络协议（protocol）是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是路由器？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "怎么保护计算机网络？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "如何查看 TCP 的连接状态？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "怎么用 UDP 实现可靠传输？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么需要可靠的UDP？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "Cookie 和 Session 有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "您如何描述区块链网络？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释硬分叉和软分叉的区别及其对网络的影响？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释什么是闪电网络，以及它如何实现即时交易？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "流水线并行（Pipeline Parallelism）的优化目标是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ReID 项目中 Triplet loss 的原理是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下文件描述符（file descriptor）？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么通过新闻可以预测网络故障？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "CBOW 和 Skip-gram 哪个更好？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "HTTP 请求有哪些状态码？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "TCP 三次握手和四次挥手是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Flask 中如何配置路由规则？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "网络层（IP）与数据链路层（MAC）有什么关系？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是WebSocket？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "http 协议的状态码有哪些？含义是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HTTP 的请求报文由哪些部分组成？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "次完整的 HTTP 请求是怎样的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "http 中重定向和请求转发的区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "多输入多输出网络如何批量校验？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TCP 和 UDP 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "https 的建立过程是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "ips 和 ids 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "在排除计算机网络问题时，可能会发生哪些常见的硬件相关问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "聊聊五层计算机网络体系结构中，每一层对应的网络协议有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "描述网络拓扑。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "网络层常见的协议有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "描述网络地址转换（NAT）技术。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "IEEE 在计算机网络中的作用是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "谈到网络，什么是权限？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "加密在网络上的重要性是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说说 DNS 的解析过程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "What leadership qualities did you develop as an administrative personnel?",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是线程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何避免僵尸进程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "如何创建、销毁线程？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何保证线程安全？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "如何杀死一个进程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "进程和线程的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 Redis 是单线程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "Python 里有多线程吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于 cgroups v2 对 GPU 时间片做公平调度？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "多线程和多进程的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你知道进程吗？有进程为何还有线程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是同步锁？为什么用同步锁？怎么使用同步锁？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是死锁？死锁产生的必要条件是什么？处理死锁的基本方法有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Oracle 19c 中自动内存管理是如何工作的？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "集群（Cluster）特有的后台进程有哪些？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何用 Python 实现多线程编程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "为什么说 B+ 树比 B 树更适合实际应用中操作系统的文件索引和数据库索引？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Java 中 ++ 操作符是线程安全的吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 创建线程之后，直接调用 start() 方法和 run() 的区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程 B 怎么知道线程 A 修改了变量？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "定时线程的使用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程同步的方法有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么叫线程安全？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中如何停止一个线程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "实现多线程有几种方式？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程的创建方式有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "守护线程是什么？它和非守护线程的区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是多线程的上下文切换？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程阻塞有哪些原因？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "死锁的原因是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "怎么唤醒一个阻塞的线程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果提交任务时，线程池队列已满，这时会发生什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是线程局部变量？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程池的类型有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "线程池的阻塞队列有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Nginx 的进程模型是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Nginx 的调度算法有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Nginx 负载均衡调度状态有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "创建进程的系统调用有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "调用 schedule() 进行进程切换的方式有几种？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Linux 调度程序是根据进程的动态优先级还是静态优先级来调度进程的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "进程调度的核心数据结构是哪个？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "nginx 中多个 worker 进程是如何监听同一个端口的？如何处理客户连接的惊群问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Redis 的同步机制了解么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 中的管道有什么用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 是单线程的，如何提高多核 CPU 的利用率？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 中如何实现多线程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Oracle 系统进程主要有哪些，作用是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是死锁？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RFS、LNSn、MRP、LSP 进程的作用分别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Manager 进程是 OGG 的控制进程，运行在源端和目标端上。它的主要作用是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "SQL Server 注入怎么判断目标是不是 SQL Server？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么参数化查询可以防止 SQL 注入？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是区块链的Oracles，它们如何与智能合约交互？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "典型 RAG 架构中，向量数据库进行上下文增强存在哪些问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何构建数据索引？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "数据库查询有哪些常用的优化方法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "除了使用索引以外，还有什么方法可以加快查询速度？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是倒排索引？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "向量数据库有哪些？各自优点与区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "python常用的加锁方式？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何在Oracle 19c 中配置分布式数据库？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何在 Oracle 19c 中启用自动索引？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Oracle 19c 中数据库的默认字符集是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何在Oracle 19c 中创建物化视图？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Oracle 19c 的内存结构有哪些改进？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是索引分裂？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "数据库运行很慢，如何解决？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 的技术特点是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "MySQL 服务器默认端口是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "与Oracle 相比，Mysql 有什么优势？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "在MySQL中ENUM的用法是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何使用Unix shell登录MySQL？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何在 Unix 和 MySQL 时间戳之间进行转换？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "MySQL 查询是否区分大小写？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "mysql_fetch_array 和 mysql_fetch_object 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "我们如何在 MySQL 中运行批处理模式？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 如何优化 DISTINCT？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "可以使用多少列创建索引？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 表中允许有多少个 TRIGGERS？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是通用SQL 函数？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "MYSQL 数据表在什么情况下容易损坏？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "mysql 有关权限的表都有哪几个？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "MySQL 中有哪几种锁？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是事务隔离级别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么优化复杂的SQL 查询？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "请解释一下索引的工作原理？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何通过日志分析数据库性能瓶颈？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Redis 支持哪些数据结构？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "怎么设置 Redis 过期策略？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何使用 Redis 做分布式锁？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何保证Redis集群的数据一致性？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Django 模型如何映射到数据库？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "EJB 的生命周期是什么，以及如何管理事务？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "JDBC 访问数据库的基本步骤是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "数据库连接池的原理是什么？为什么要使用连接池？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是乐观锁和悲观锁？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Mybatis 是如何将 SQL 执行结果封装为目标对象的？都有哪些映射形式？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Spring 的事务传播行为有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "使用 Redis 有哪些好处？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么理解 Redis 事务？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "redis 的淘汰策略有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "redis 如何实现高可用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 Redis 的操作是原子性的？怎么保证原子性？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "redis 的主从复制的实现过程是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "redis 常见的性能问题和解决方案有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 的 MyISAM 与 InnoDB 两种存储引擎在事务、锁级别、各自的适用场景上有什么区别？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是索引？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "索引的作用是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么样的字段适合建索引？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么不都用 Hash 索引而使用 B+ 树索引？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是数据库？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "分布式数据库是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Redis 存储的是 k-v 类型，为什么还会有 Hash？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Dubbo支持分布式事务吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Linux 中主要有哪几种内核锁？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是MongoDB？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 是由哪种语言写的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 的优势有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 哪个命令可以切换数据库？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是非关系型数据库？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "非关系型数据库有哪些类型？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么用 MongoDB？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在哪些场景使用MongoDB？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 中的命名空间是什么意思？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "哪些语言支持MongoDB？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中如何创建一个新的数据库？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中如何查看数据库列表？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 中的分片是什么意思？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何查看使用 MongoDB 的连接？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中如何在集合中插入一个文档？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中如何删除一个数据库？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "在MongoDB中如何创建一个集合？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中如何查看一个已经创建的集合？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中如何删除一个集合？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要在 MongoDB 中使用分析器？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 支持主键外键关系吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 支持哪些数据类型？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么在 MongoDB 中使用 ObjectId 数据类型？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在 MongoDB 中什么是索引？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何添加索引？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 有哪些可替代产品？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中如何更新数据？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在MongoDB中什么是副本集？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 与MongoDB 之间最基本的差别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你怎么比较 MongoDB、CouchDB 及 CouchBase？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 成为最好NoSQL 数据库的原因是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分析器在 MongoDB 中的作用是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 在 A:{B,C} 上建立索引，查询 A:{B,C} 和 A:{C,B} 都会使用索引吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 支持存储过程吗？如果支持的话，怎么用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何理解 MongoDB 中的 GridFS 机制？MongoDB 为何使用 GridFS 来存储文件？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何获取当前的 MySQL 版本？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 中使用什么存储引擎？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "MySQL 驱动程序是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "MYSQL 数据库服务器性能分析的方法命令有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 支持事务吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "数据库三范式是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有哪些数据库优化方面的经验？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "mysql 支持的复制类型有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "mysql 中 myisam 与 innodb 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "MySQL 中控制内存分配的全局参数有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 当记录不存在时insert，当记录存在时update，语句怎么写？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 相比 Memcached 有哪些优势？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Memcache 与 Redis 的区别都有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 常见的性能问题都有哪些？如何解决？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "是否使用过 Redis 集群？集群的原理是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群如何保证一致性？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Redis？简述它的优缺点？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 支持哪几种数据类型？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 主要消耗什么物理资源？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 的全称是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 官方为什么不提供 Windows 版本？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么 Redis 需要把所有数据放到内存中？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群方案应该怎么做？都有哪些方案？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群方案什么情况下会导致整个集群不可用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 有哪些适合的场景？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 和 Redisson 有什么关系？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Jedis 与 Redisson 对比有什么优缺点？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 如何设置密码及验证密码？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群的主从复制模型是怎样的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群会有写操作丢失吗？为什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群之间是如何复制的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群最大节点个数是多少？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群如何选择数据库？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么测试 Redis 的连通性？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis key 的过期时间和永久有效分别怎么设置？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 如何做内存优化？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 回收使用的是什么算法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 如何做大量数据插入？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要做 Redis 分区？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你知道有哪些 Redis 分区实现方案？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 分区有什么缺点？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 持久化数据和缓存怎么做扩容？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 与其他 key-value 存储有什么不同？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 的内存占用情况怎么样？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "查看 Redis 使用情况及状态信息用什么命令？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 的内存用完了会发生什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 提供了哪几种持久化方式？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "修改配置不重启 Redis 会实时生效吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SQLMap 的 --os-shell 原理是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "SQL 注入写文件都有哪些函数？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Mysql 中有哪些不同的表格？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "请解释一下 Redis 集群的工作原理。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "请描述什么是 Oracle Undo？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释Oracle数据库中的段顾问（Segment Advisor）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释Oracle数据库中的 SQL顾问（SQL Advisor）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何使用 SQL 顾问？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的 undo表空间的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的 redo log 的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的控制文件的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的临时表空间的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的归档模式和非归档模式的区别。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的索引组织表（IOT）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的并行查询和并行 DML操作的原理。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的 RMAN（恢复管理器）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的 Data Guard 的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的 Streams 的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的 Golden Gate 的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的执行计划（explain plan）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的触发器（trigger）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请解释Oracle数据库中的内存顾问（Memory Advisor）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "用 Python 设计算法实现圆周率的计算。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "描述您在用于区块链开发的编程语言和软件方面的经验？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "您认为区块链开发人员最需要了解哪些编程语言？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "Python 中的 None 代表什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "思维算法 Algorithm of Thoughts（AOT）思路是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "思维算法 Algorithm of Thoughts（AOT）vs 其他 COT 的区别？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "装饰器怎么用？装饰器解释下，基本要求是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "谈下 Python 的 GIL？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "列出5个Python标准库？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "python 常用的爬取数据的框架或者方法有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 和 Java 之间的主要区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Python 如何实现函数式编程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是 Python 中的生成器和迭代器？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何使用 Python 实现哈希表？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何在 Python 中管理内存？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Python 中的字典是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Python 中的标识符长度有多长？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Python 中的闭包是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Python 的优势有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是Python 模块？Python 中有哪些常用的内置模块？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "说几个常见的编译时异常？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中怎么创建一个不可变对象？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在.java源文件中可以有多个类吗（内部类除外）？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 支持多继承吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中的编译期常量是什么？使用它有什么风险？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中有几种类型的流？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Java 虚拟机？为什么Java 被称作是无关平台的编程语言？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中堆和栈有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中类的生命周期是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在Spring中如何注入一个Java集合？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是JavaConfig？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "常用的 Python 库有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 中的私有变量应该如何定义和访问？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Python 中是否需要缩进？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "解释 Python 装饰器的工作原理。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "“买了这个的客户，也买了......”亚马逊的建议是哪种算法的结果？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是加密算法？有哪些常见的加密算法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是共识算法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述区块链中的 Merkle 树及其重要性？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释区块链的共识算法有哪些，它们各自的优缺点是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如何利用知识图谱（KG）进行上下文增强？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何让 RAG 支持私有化多模态 RAG（文本+表格+图片）？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SVD 的时间复杂度是多少？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你觉得做模型最重要的是什么？一个好的模型算法工程师所必须的技能有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是堆？什么是完全二叉树？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "隐马尔可夫模型中的三个矩阵是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是知识图谱？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是图（Graph）？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "怎么构建知识图谱？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是直方图（Histogram）？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是图灵完备语言？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么使用占据栅格地图构建算法构建地图？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "流行的共识算法之间有什么不同？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你对语义 web 栈了解多少？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "常见的垃圾回收算法有哪些？简述其原理。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "解释栈（stack）、堆（heap）和方法区（method area）的用法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么叫视图？游标是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "字符设备驱动程序的关键数据结构是哪个？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Linux 软中断和工作队列的作用是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "视图的作用是什么，视图可以更改吗？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何构建 GitHub 监控机器人并自动汇总 release note？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何基于 Docker 多版本镜像快速切换对比？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是兼容性测试？兼容性测试侧重哪些方面？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "常用的测试方法有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "静态测试和动态测试有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试用例设计的完整过程是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Beta 测试与 Alpha 测试有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你认为做好测试工作的关键是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "软件的安全性应该从哪几个方面去测试？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "单元测试、集成测试、系统测试的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "怎么进行需求测试？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是测试点？测试点包含哪些内容？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是测试方案？什么是测试策略？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试方案是谁编写的？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试方案包含哪些内容？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试方案编写的输入条件是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试用例设计方法有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试用例内容有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是好的测试用例？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试用例的颗粒度如何划分？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试用例为什么需要有优先级？有哪些优先级？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你们以前一天能够编写多少条测试用例？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你们项目一共有多少条测试用例？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试用例需要哪些人来评审？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "个项目需要写多少测试用例？怎么估算？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试用例是谁写的？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "为什么要进行交叉测试？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你的测试职业发展是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你认为测试人员需要具备哪些素质？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你为什么能够做测试这一行？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试的目的是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试分为哪几个阶段？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "您所熟悉的测试用例设计方法都有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "您认为做好测试用例设计工作的关键是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你对测试最大的兴趣在哪里？为什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你认为做好测试计划工作的关键是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你觉得软件测试通过的标准应该是什么样的？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "简述软件系统中用户文档的测试要点？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "为什么尽量不要让时间富裕的员工去做一些测试？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "完全测试程序是可能的吗？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "软件测试的风险主要体现在哪里？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "软件测试项目从什么时候开始？为什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "功能测试用例需要详细到什么程度才是合格的？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你都用什么测试方法？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是软件测试？软件测试的目的是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是兼容性测试？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "软件测试的对象有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "当测试过程发生错误时，有哪几种解决办法？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "怎么才能够全面的测试到每一个点？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "开发与测试的关系是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么时候进行功能测试？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "功能测试和性能测试的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "为什么选择测试这行？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是黑盒测试和白盒测试？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是单元测试和集成测试？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "UAT测试和预生产测试的内容是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "怎样理解 Web3？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "web3将如何彻底改变在线用户体验？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "比特币和以太坊有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是区块链智能合约？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "在智能合约中产生随机数有哪些困难？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是智能合约？智能合约的安全隐患有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述区块链上的智能合约安全最佳实践？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "你熟悉区块链的概念吗？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "区块链有哪些不同类型？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "公共区块链和私有区块链有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "你什么时候会使用私有区块链而不是公共区块链？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如果要您从头开始创建区块链，您会做的第一件事是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "你认为区块链技术的未来是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "您多久更新一次对区块链技术的了解？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "区块链技术有了新的发展，可以改进你当前的代码。您将如何决定是否值得花费时间和精力进行升级？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "在区块链中，什么是孤块，它们如何产生？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释区块链中的交易池是如何工作的？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释区块链的共识机制和它为什么重要？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述区块链上的交易如何被验证？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释什么是区块链的分叉，以及它为什么会发生？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如何在区块链项目中实现跨链通信？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是侧链，它如何帮助区块链扩容？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "在区块链中，如何处理交易的隐私保护？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如何在区块链上实现匿名交易？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释在区块链中如何实现数据的去中心化存储？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述区块链的分片技术及其如何解决扩展性问题？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是代币化，它在区块链上如何工作？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述如何使用区块链技术进行身份验证和授权？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "区块链技术如何解决数字身份认证问题？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "区块链技术如何促进供应链管理的透明度？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释什么是非同质化代币（NFT）及其在区块链上的应用？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "NFT是如何出现在web3中的？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述区块链中的“永久性”是如何实现的？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述区块链上的 DAO（去中心化自治组织）及其工作原理？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "区块链如何促进版权保护和知识产权管理？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释区块链的可扩展性问题及其当前解决方案？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如何在区块链项目中处理交易拥堵和高手续费？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释区块链技术如何实现跨境支付，并阐述其优势？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如何在区块链项目中管理和减少智能合约中的安全风险？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "区块链上的隐私层（如Zcash和Monero）是如何工作的？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如何通过区块链技术提高供应链的效率和透明度？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述什么是区块链的“气体费用”，以及它的作用？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是 Web3？Web2 和 Web3 的区别？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是智能合约？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "您是如何应对 Web3 的安全性、可扩展性等挑战，对此您有哪些看法或解决方案？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "你有使用智能合约的经验吗？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "我们想使用我们的区块链来收集数据，您将允许用户提交哪些类型的数据？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述一种用于提高区块链交易隐私的技术（如零知识证明）？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是DeFi（去中心化金融），它如何运作？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是web3？web2和web3的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "IMU原理介绍及误差分析？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何基于日志审计追踪违规内容并定位责任人？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么是 NeRF-Based SLAM？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么是 Gaussian-Based SLAM？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "sigmoid和softmax的区别？softmax的公式？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是对象分割？你知道有哪些框架吗？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何解决数据不平衡问题？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "如何建立价格预测模型？价格是否正态分布？需要对价格进行预处理吗？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "XGBoost 参数调优的一般步骤是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么要随机抽样？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么要有放回的抽样？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "RF 为什么能够更鲁棒？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "K-means 不适用哪些数据？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "维度灾难是什么？为什么要关心它？",
      "sources": [
        "interview_questions_categorized.json",
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是 A/B test？核心原理和应用场景？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "A/B test 如何合理分流？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "如何验证 A/B test 的结果？",
      "sources": [
        "interview_questions_categorized.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "日志记录被人删除了，你该怎么做？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是数字证书？有什么作用？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是 Metasploit 框架？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是安全运营工程师？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是安全事件响应？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是安全监控？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是交换机？",
      "sources": [
        "interview_questions_categorized.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是数字签名？什么是数字证书？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么需要 TIME_WAIT 状态？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "为什么 TIME_WAIT 等待的时间是 2MSL？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "如何解决 NAT 潜在的问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "ToF 相机原理是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "相似变换、仿射变换、射影变换的区别是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "单应矩阵和基础矩阵的区别是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何求解 Ax=b？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是极线约束（对极几何约束）？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "EKF 和 BA 的区别是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "OpenSea和LooksRare的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是去中心化？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "你对密码学的理解程度如何？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "是什么让你很适合这个角色？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "“去中心化”的基本性质是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "权益证明（PoS）机制的工作原理是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述加密货币钱包的工作原理及其安全性措施？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是ERC-20标准，它为什么重要？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是加密货币的原子交换，它是如何工作的？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释什么是“链上治理”和“链下治理”，以及它们的重要性？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "用一句话讲一下 AMM 机制？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "你玩过哪些应用？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是加密货币的去中心化交易所（DEX），与传统交易所有何不同？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "什么是 Gas？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "你用一句话讲一下AMM机制？",
      "sources": [
        "interview_questions_categorized.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释什么是工作证明（PoW）以及如何实现？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何撰写中国 AI 专利并加快审查？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "对于一个取值较多的类别变量在不能进行 one-hot 的情况下如何使用？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "Wordvec 中 CBOW 指什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Sigmoid 和 Softmax 的区别是什么？Softmax 的公式是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "如何进行拆解子目标和任务分解？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何进行模型自我反省？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是PPO中的采样过程？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "Self-RAG 的创新点是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下PPO中的采样策略？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何解决从复杂 PDF 文件中提取数据的问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何解决内容缺失问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何解决回答不全面问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何解决备用模型问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何解决数据处理能力的挑战问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何解决格式错误问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何解决特异性错误问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何解决结构化数据查询的难题问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何解决错过排名靠前的文档问题？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "模型显存占用的部分有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何让 RAG 支持半结构化 RAG（文本+表格）？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "多查询生成的工作原理是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何通过输入查询与文档对齐提升 RAG 效果？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么选择RRF？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "P-tuning v2 的思路是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何向模型加入 PEFT 策略？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何通过提示压缩提升 RAG 效果？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何通过混合检索提升 RAG 效果？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DeepSpeed 遇到问题时，如何确定调参步骤？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ZeRO-3 会比 ZeRO-2 慢很多，如何优化？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要 FLARE？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要对文本分块？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要构建负难样本？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要识别表格？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "介绍一下 Gradient Accumulation 的显存优化方式。",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "使用DistributedDataParallel（分布式并行）时，显存分布不均衡问题是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何估算需要的显存？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何评估显卡利用率？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何选择不同的 ZeRO stage 和 offload？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何配置 deepspeed 配置文件？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何配置 SSH？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如果对整体推理时延有具体目标，有哪些有效的启发式方法来评估模型？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "数据如何划分？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "计算如何协同？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG 工作流程？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是 Backtranslation？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 Self-Instruct？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Linear 如何实现？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG Fusion 优化策略？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是数据并行？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于批内负采样的对比学习方法是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是流水线并行？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 如何结合 SFT？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ckpt 存储能否实现异步或者部分掩盖？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Gradient partitioning（ZeRO stage 2）是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "LangChain 如何使用？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Nucleus sampler（TopP采样）是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Optimizer state partitioning（ZeRO stage 1）是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Parameter partitioning（ZeRO stage 3）是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAG-Fusion 的优势和不足？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAG 中长上下文的处理问题？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAG 未来发展方向？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAG 生态系统？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAG 的工程应用？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAG 的鲁棒性研究？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "SFT 数据集如何生成？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么要生成多个查询？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 DistributedDataParallel 核心——Ring-AllReduce？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "使用过程中如何维护 RAG，并添加机制来更新过时的文档？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何精确地回答用户关于文档的问题，不重也不漏？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何脱离已有代码库复用这些方法？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何获取最优的 ckpt 存储间隔？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "找到最佳块大小是要找到正确的平衡，如何高效地做到这一点？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "推理时，可将BA加到原参数上，不引入额外的推理延迟？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "推理阶段不引入额外计算量？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "机制和生成策略可能导致模型更倾向于复制输入的文本？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "核心问题：选择一种策略从而最大化预期收益？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "为什么使用 nn.DataParallel 进行多 GPU 运算时，程序耗时可能不减反增？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何区分单双栏论文？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "双栏论文如何确定区块的先后顺序？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Why did you leave your last job?",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "What sort of people do you find it difficult to work with?",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Where did you think you'd be at this stage in your life?",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "What did you look for when you hired people in the past?",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "How do you normally handle criticism?",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "What range of pay-scale are you interested in?",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "What aspects of your job do you consider most crucial?",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "What did you like/dislike about your last job?",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "What are your outstanding qualities?",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "What interests you most about this job?",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "What type of decisions did you make on your last job?",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Were you ever dismissed from your job for a reason that seemed unjustified?",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "What makes this job different from your current/last one?",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何减小两个概率分布之间的KL散度？讲讲优化方法。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 RAG？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 RAG 典型实现方法？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 RAG 典型案例？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 存在什么问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何监控中间步骤的置信度并提前终止低置信链？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于 NVIDIA Sparsity SDK 加速 2:4 结构化稀疏？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何编写 CONTRIBUTING.md 并设置 CI 检查？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "当 PR 冲突时，如何采用 rebase 保持线性历史？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何构建专利检索关键词并监控竞争对手？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何用模拟器预估在8×A100下最大并发请求数？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分布式并行及显存优化技术有哪些，都有什么特点？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "nn.parallel.DistributedDataParallel 实现流程介绍一下？",
      "sources": [
        "interview_questions_categorized.json",
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "nn.parallel.DistributedDataParallel 参数更新介绍一下？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "单例模式的几种实现方式及优化是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Scrapy 怎么做分布式爬虫？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要加入 reading-gate？为什么不直接把控制向量加在输入中？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "EfficientNet 的原理是什么？基于什么模型的搜索？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HMM 与 CRF 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "推导一下 FM 模型和 DeepFM 模型。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "数据并行 vs 张量并行 vs 流水线并行？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "nn.parallel.DistributedDataParallel 函数介绍一下？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是马尔科夫过程？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "马尔科夫过程的核心思想是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HMM 模型三个基本问题的联系？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "最大熵马尔科夫模型（MEMM）是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "最大熵马尔科夫模型（MEMM）如何解决 HMM 问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CRF in TensorFlow V.S. CRF in discrete toolkit？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Dice 系数和 Jaccard 系数的区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简单介绍混淆矩阵和 kappa？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "向量库有哪些？各自优点与区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "LangChain 替代方案有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redo 日志文件（Redo Log Files）的作用是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是基数（Cardinality）和可选择率（Selectivity）？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何处理缓存雪崩问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何创建一个简单的 Flask 应用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是Flask？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "何为Delegated Proof of Stake（DPoS），与PoS有何不同？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "API 与微服务架构有何不同？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果底库涨到 10 亿，单机内存不足，如何设计分布式 HNSW？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么不用 DiskANN？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何把 SQ/RQ 做成实时在线监控？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "内存泄漏和内存溢出有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "反射中，Class.forName() 和 ClassLoader.loadClass() 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "数组在内存中如何分配？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Servlet 的生命周期是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "转发（forward）和重定向（redirect）的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "request.getAttribute() 和 request.getParameter() 有何区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MVC 的各个部分都有哪些技术来实现？如何实现？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Tomcat 容器是如何创建 Servlet 类实例的？用到了什么原理？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Servlet？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "可以作为GC Roots的对象有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "JVM 中一次完整的 GC 流程是怎样的，对象如何晋升到老年代？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "导致 Full GC 一般有哪些情况？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有哪些垃圾回收器？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "JVM 调优命令有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "描述一下 JVM 加载 class 文件的原理机制。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "GC 是什么？为什么要有 GC？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "垃圾回收器的基本原理是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说一下你熟悉的设计模式？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简单工厂和抽象工厂的区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "设计模式的优点是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "设计模式的六大基本原则是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "UML 是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "hibernate 和 mybatis 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "MyBatis 中 #{} 和 ${} 的区别是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring MVC 框架有什么用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring MVC 和 struts2 的区别有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring IOC 是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是控制反转（IOC），什么是依赖注入（DI）？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "AOP 有哪些实现方式？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "解释一下代理模式？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring 框架中都用到了哪些设计模式？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是Spring bean？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是spring 自动装配？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是分布式缓存？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Nginx 优化的方式有哪些？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Nginx 负载均衡的 4 种分配方式是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要用Nginx？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是正向代理？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是反向代理？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是负载均衡？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "可以从哪些方面来优化Nginx服务？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要用MQ？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "使用 MQ 会有什么问题？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么保证 MQ 的高可用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MQ 的优缺点？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Znode 有哪些类型的数据节点？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Dubbo 有哪几种负载均衡策略，默认是哪种？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Spring Boot？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring Boot 有哪些优点？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring Boot 中的监视器是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何在 Spring Boot 中禁用 Actuator 端点安全性？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Apache Kafka？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Spring Cloud？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "使用 Spring Cloud 有什么优势？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "服务注册和发现是什么意思？Spring Cloud 如何实现？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Spring Cloud Bus？我们需要它吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "负载均衡的原理是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么提高并发量？请列举你所知道的方案。",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "迁移之后的数据一致性怎么校验？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Kafka 如何压测？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Flink 任务的并行度优先级如何设置？资源一般如何配置？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Flink 如何实现端到端一致性？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Flink 写入 ClickHouse 怎么保证一致性？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "日志保存多久？有什么作用？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "DIM 层做了哪些事？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "实现数据质量监控，你具体怎么做？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "PCA 为什么要中心化？PCA 的主成分是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "给你一个无序数组，怎么才能合理采样？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Dubbo 和 Spring Cloud 有什么区别？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Dubbo 可以对结果进行缓存吗？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Dubbo 能集成 Spring Boot 吗？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "你觉得用 Dubbo 好还是 Spring Cloud 好？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "怎样申请大块内核内存？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "通过伙伴系统申请内核内存的函数有哪些？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Linux 中的浮点运算由应用程序实现还是内核实现？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TLB 中缓存的是什么内容？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Linux 中有哪几种设备？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Linux 通过什么方式实现系统调用？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分片（sharding）和复制（replication）是怎样工作的？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "在Nginx中，如何使用未定义的服务器名称来阻止处理请求？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "使用反向代理服务器的优点是什么？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何通过不同于 80 的端口开启 Nginx？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "Nginx 是否支持将请求压缩到上游？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何在 Nginx 服务器上添加模块？",
      "sources": [
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "nginx 程序的热更新是如何做的？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何判断自己被 getshell？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何判断目标主机是 Windows 还是 Linux？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你将如何监控/管理顾问？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "制作原型应该在项目生命周期的哪个阶段？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果要设计一个高并发、高性能的系统，你应该考虑哪些因素？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "分布式系统有哪些常见设计模式，如 CAP 理论、BASE 理论等？",
      "sources": [
        "interview_questions_categorized.json",
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何对慢查询进行优化？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是bugzilla？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是loadrunner？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是桩模块？什么是驱动模块？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是扇入和扇出？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "项目中碰到的需求问题，能够直接和客户沟通吗？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "需求确定中不确定的需求怎么解决？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是系统瓶颈？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "发现的缺陷越多，说明软件缺陷越多吗？",
      "sources": [
        "interview_questions_categorized.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "DATA BLOCK、EXTENT 和 SEGMENT 的区别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "行链接和行迁移有什么区别？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何解决 ORA-04030 和 ORA-04031 错误？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是检查点？如何调优检查点？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是大文件表空间（Bigfile Tablespace）？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请描述 UNDO 的作用？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "请描述对 UNDO Retention 的理解？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何评估所需 UNDO 大小？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是物理读和逻辑读？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是直接路径访问？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "执行计划里的 access 和 filter 有什么区别？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是动态采样（Dynamic Sampling）？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "ROWID 和 ROWNUM 有什么区别？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "在高并发、高负载的情况下，如何给表添加字段并设置 DEFAULT 值？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "如何有效地删除一个大表（即表的 EXTENT 数很多）？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "集群有哪几种心跳机制？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAC 的脑裂和健忘分别指的是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "什么是 GPnP？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "oraInventory 目录的作用是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "RAC 节点被踢出可能有哪些原因？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "实例恢复和介质恢复的区别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "DELETE 了一条数据并且提交了，该如何找回？",
      "sources": [
        "Oracle_面试题_only_questions.json",
        "interview_questions_categorized.json"
      ]
    },
    {
      "question": "训练式位置编码的应用场景是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "旋转位置编码 RoPE 思路是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ALiBi（Attention with Linear Biases）思路是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "典型 RAG 架构中，向量数据库存在哪些问题？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RLHF训练过程中，怎么选取最优checkpoint？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "pdfplumber 如何进行表格抽取？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LLaMA 2 中 Margin Loss 的实现逻辑是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "多查询生成的技术实现（提示工程）是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何 解决 大语言模型（LLM）的安全挑战 问题？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何解决未能提取答案问题？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LLaMA 2 中两个 RM 模型的实现逻辑是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "大模型训练 loss 突刺如何解决？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "模型显存占用的优化策略有哪些？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RRF 的技术实现是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ALiBi（Attention with Linear Biases）被哪些 LLMs 应用？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "InstructGPT的原理是什么？请讲讲RLHF和reward。",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何查看DeepSpeed的环境配置是否正确？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "KL 散度与交叉熵的区别是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LoRA 微调的优点是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LoRA这种微调方法和全参数微调比起来有什么劣势？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "PEFT库 中 LoRA 模块 代码介绍？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "不同 ZeRO 如何配置？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么单卡的情况也可以使用 DeepSpeed？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "介绍一下 gradient checkpointing 的显存优化方式？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "增量预训练训练流程是怎么样的？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "增量预训练过程中 loss 上升正常吗？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何使用 PEFT 库中的 LoRA？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何准确衡量模型的推理速度？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何利用 transformers 输出 BERT 指定的 hidden_state？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何解决 PPO 训练过程同时存在 4 个模型（2 训练，2 推理）导致对计算资源要求较高的问题？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如果想要试试 65B 模型但显存不多怎么办？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "学习率大小对大模型继续预训练后下游任务有什么影响？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "自回归语言模型的预训练和下游应用是否完全一致？是否严格遵守只有后面的 token 才能看到前面的 token？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "训练中文大模型有什么经验？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Byte-Pair Encoding（BPE）如何构建词典？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "PEFT 库中 LoRA 模块的整体实现思路是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 RAGAS？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 ZeRO-2？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "显存优化技术有哪些，都有什么特点？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "RAG 检索召回率低一般有哪些解决方案？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 ZeRO-3？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "不同大模型 LLMs 的分词方式有什么区别？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何保存和加载多GPU训练模型？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "大模型微调中，P-Tuning和传统Fine-tuning有什么区别？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 ZeRO-stage-0？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "LangChain 如何做 Embedding 和 vector store？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "vLLM 如何做离线批量推理？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 ZeRO-stage-1？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "大模型【LLMs】后面跟的 175B、60B、540B 等指什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "bit 量化优化主要用于优化静态显存吗？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "_find_and_replace() 的实现思路是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "AdapterDrop 的思路是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "AdapterDrop 的特点是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "AdapterFusion 的思路是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "nn.DataParallel(DP) vs DistributedDataParallel(DDP)介绍一下？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "Llama 2 的 Margin Loss 是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LLMs 推理存在哪些挑战？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "module 是要放到多卡训练的模型吗？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "PDF 解析存在哪些问题？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "PDF 解析有哪些方法？它们的区别是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Prompt 设计在实际业务场景中如何针对性调优？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "RAG 与微调（Fine-tuning）如何协同？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG（Retrieval-Augmented Generation）如何评测？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何编写 Trainer 训练类？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "ZeRO-Infinity 是否需要使用 ZeRO-3？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "ZeRO 优化策略是怎么样的？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "为什么需要 对 pdf 进行解析？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "以ZeRO为例，你的转换流程是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "什么是基于预训练数据集训练出的基础模型？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何对继续预训练数据进行预处理？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何防止 LLM 被诱导泄露文档来源、元数据或其他敏感信息？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何将豆包（云雀大模型）接入 LangChain 体系？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "推理加速框架有哪一些？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "梯度检查点（gradient checkpointing）的原理是什么？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么每张卡上的 loss 要汇总到第 0 张卡上求梯度，更新后再把权重分发到其余卡？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "已有的 LoRA 模型只训练了一部分数据，要训练另一部分数据，是在这个 LoRA 上继续训练，还是跟 base 模型合并后再套一层 LoRA，或者从头开始训练一个 LoRA？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "相同训练数据下，Reward Model 越大 actor 模型能够获得更高的真实 reward 吗？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "在什么情况下撒谎是可以接受的？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "如何解决基于 LLaMA 家族的模型对中文支持不友好的问题？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "采样时如何选择温度（temperature）？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "重新训练时可以直接加载向量化后的数据吗？",
      "sources": [
        "llm_tech_questions_FINAL.json",
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LoRA 为什么可以将 update matrix 重参数化为两个低秩矩阵的乘积？",
      "sources": [
        "llm_tech_questions_FINAL.json"
      ]
    },
    {
      "question": "ALiBi（Attention with Linear Biases）的偏置矩阵是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 PPO 中采样过程？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "介绍一下 PPO 中采样策略？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "大模型训练 loss 突刺是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何从复杂 PDF 文件中提取数据？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何解决结构化数据查询的难题？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何解决脱离上下文（整合策略的限制）问题？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "有监督微调（Supervised Finetuning）的训练数据格式是什么样的？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ALiBi（Attention with Linear Biases）有什么优点？",
      "sources": [
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "PPO 中采样策略里，如何评估“收益”？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "（torch profiler）如何查看训练中的通信开销？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LoRA 的 alpha 参数如何选取？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LoRA 微调的参数量怎么确定？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LoRA 的缺点是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Pretrain 阶段为什么需要拼接？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么情况用 Bert 模型，什么情况用 LLaMA、ChatGLM 类大模型，怎么选？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "多GPU并行训练的原理是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何利用 transformers 输出 Bert 指定 hidden_state？",
      "sources": [
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于LoRA的Llama2微调？",
      "sources": [
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何配置安装 pdsh？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何配置deepspeed文件？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "微调大模型时，如果 batch size 设置太大会出现什么问题？",
      "sources": [
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "测试显卡利用率的实现细节是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何根据参数量估计模型大致所需的 RAM？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "PP 推理时是串行过程，1 个 GPU 计算其他空闲，有没有其他方式？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "LangChain 中 Components 和 Chains 是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG-Fusion 的优势是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "WordPiece 与 BPE 的异同点是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于 LoRA 的 Llama2 二次预训练参数有哪些？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "训练大语言模型存在哪些问题？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "训练数据如何介绍？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "显存优化技术有哪一些，都有什么特点？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG-Fusion 的挑战有哪些？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ZeRO-stage-0 是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "写一下 DeepNorm 的代码实现？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何保存和加载多 GPU 训练的模型？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如果想构建一个大规模并行训练系统，训练框架如何选？",
      "sources": [
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "训练框架如何选？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么第一块 GPU 的显存会占用更多？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG-Fusion 的优化策略有哪些？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "模块化 RAG 的优化策略有哪些？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "BPE 是否是选择频次最大的相邻子词进行合并？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "DistributedDataParallel（DDP）的优点有哪些？",
      "sources": [
        "llm_tech_questions_full_v2.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DistributedDataParallel（DDP）的缺点有哪些？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "gloo 支持 CPU 和 GPU 上的分布式训练吗？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "HIR 是如何工作的？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "MAM Adapter 的思路是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "MAM Adapter 的特点是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "nn.DataParallel（DP）与 DistributedDataParallel（DDP）有什么区别？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何使用 nn.parallel.DistributedDataParallel 进行多卡加速训练？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 OpenAI evals，它的核心思路是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 Optimizer state partitioning（ZeRO Stage 1）？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "DeepSpeed 的 overlap_comm 参数有什么作用？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 PandaLM，它是如何对候选模型进行打分的？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 Parameter partitioning（ZeRO Stage 3）？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "PPO 中的采样过程是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "PyTorch 中 GPU 操作默认是什么样的？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "PyTorch 分布式计算有哪些常见坑或 bug？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG-Fusion 的优势和不足是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG 的工程应用有哪些关键点？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG 如何做水平扩展？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 Reflexion 框架，它如何通过动态记忆与自我反思提升推理能力？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 RLHF（Reinforcement Learning with Human Feedback）？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "tokenizer 中“保存的模型的名称前缀”指的是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "torch.multiprocessing 函数如何使用？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ZeRO-3 中未使用 allgather_partitions、allgather_bucket_size 和 reduce_scatter？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ZeRO-3 会比 ZeRO-2 慢很多。使用以下策略，可以使得ZeRO-3 的速度更接近ZeRO-2？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ZeRO-Infinity 需要使用 ZeRO-3？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ZeRO-Offload to CPU and NVMe？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ZeRO Offload后的计算流程是怎么样？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "ZeRO 优化策略是怎么样？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "上节讲到 DP 只支持 单机多卡场景，主要原因是 DP 无法数据并行中通讯负载不均的问题， 而 DDP 能够解决？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为了从给定的上下文中生成问题和答案，我们需要按照以下步骤操作：？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为了解决负样本构造成本过高的问题，可以考虑以下方法：？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么需要进行pdf解析？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "介绍一下混合精度训练中的动态损失缩放？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何将预训练模型量化为 4 bit？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何创建 DDP 模型进行分布式训练？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何初始化 RAG？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "在预训练阶段，模型会从大量无标注文本数据集中学习通用知识吗？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "多任务学习中，如果各任务的损失差异过大，如何处理？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "多机训练不通时，如何排查 DeepSpeed 配置问题？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何提出一个问题，让模型给出多个不同的答案或解决方案，以测试模型的创造力和多样性？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是 RLHF 及其变种？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何精确地回答用户关于文档的问题，做到不重不漏？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如果想要在某个模型基础上做全参数微调，需要多少显存？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "张量并行的实现难点是什么，为什么会因模型结构而异？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "张量并行只有在 NVLink 环境下才会起正向作用，但提升也不会太明显？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "当你从单卡穷人变成多卡富翁时，你做分布式训练的总体目标是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "怎么合并中英文的词表，并使用 transformers 使用合并后的词表？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "显存够用（模型能装进单卡）时应该用 DDP 还是 ZeRO？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "流水线并行不会减少每层中间激活的显存占用吗？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "梯度累积（gradient accumulation）的原理是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "RAG 的检索后处理流程是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "模型如何判断回答的知识是训练过的已知知识，如何训练这种能力？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "什么是混合精度训练？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何确定关键负样本？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "为什么第一块 GPU 的显存占用会比其他 GPU 更多？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "Ring-AllReduce 的核心思想是什么，它如何解决数据并行中通信负载不均的问题？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "通过从较低的 Transformer 层删除可变数量的 Adapter 来提升推理速度的原理是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何定位 GPU 显存不够（OOM）的问题？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "健康饮食的主要特点是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "居里夫人的主要成就是什么？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "预训练数据参数如何介绍？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "如何根据参数量估算模型大致所需的 RAM？",
      "sources": [
        "llm_tech_questions_full_v2.json"
      ]
    },
    {
      "question": "回归、分类、聚类方法的区别和联系是什么？请举例并简要介绍算法思路。",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "什么是机器学习的欠拟合？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "归一化和标准化的区别是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "常用核函数有哪些？核函数需要满足什么条件？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "基尼系数（Gini）存在的问题是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "构造决策树的步骤是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "决策树的优缺点是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "如果特征很多，决策树中最后没有用到的特征一定是无用的吗？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "梯度提升（GBDT）如何调参？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost 使用泰勒二阶展开的原因是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost 中叶子结点的权重如何计算？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "XGBoost 中一棵树的停止生长条件是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么XGBoost的近似算法比lightgbm慢很多呢？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "为什么随机森林要随机抽样？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "随机森林需要剪枝吗？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "RF 与决策树的区别是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "K 值如何选取？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "聚类和分类有什么区别？",
      "sources": [
        "ml_questions_theory_v3.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "PCA 降维的原理是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "LDA 降维的原理是什么？",
      "sources": [
        "ml_questions_theory_v3.json"
      ]
    },
    {
      "question": "Oracle 19c 新特性有哪些？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "在 Oracle 19c 中如何使用多租户架构？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何升级到 Oracle 19c？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle 19c 中的 Data Guard 有哪些改进？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何在 Oracle 19c 中优化查询性能？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle 19c 中如何管理闪回恢复区？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何在 Oracle 19c 中使用临时表？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle 19c 中如何配置自动工作负载管理？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何在 Oracle 19c 中创建基于角色的访问控制？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何在 Oracle 19c 中使用分区表？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何在 Oracle 19c 中进行表空间管理？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle 19c 中的多线程服务器（MTS）模式是如何工作的？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何在 Oracle 19c 中设置自动备份？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle 19c 中的快照稳定性是如何实现的？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle NET 相关的三个文件具体路径在什么地方？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "控制文件是数据库启动第几阶段加载的文件？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "进程 mman、mmnl 和 mmon 这 3 个进程的作用分别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "本地管理表空间（LMT）和字典管理表空间（DMT）的特点有哪些？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何找到 ORA-01555对应的 SQL？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "若临时表空间使用率过高有什么调优思路？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "常用的 10046 及 10053 诊断事件的区别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "RAC 等待事件 gc buffer busy acquire 和 gc buffer busy release 的区别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Switchover 和 Failover 的区别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "主库丢失归档，物理 DG 如何恢复？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle 的SCN是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何处理 Oracle中的坏块？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "LogMiner 是什么？其有哪些用途？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "什么是 BBED？它有哪些作用？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如果必须利用备份恢复数据库，但是又没有控制文件，如何解决问题？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "在控制文件丢失且无备份的情况下如何恢复？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "在Undo表空间数据文件丢失的情况下如何恢复？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如果控制文件损坏如何恢复？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "AWR 报告中主要关注哪些方面内容？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle 系统进程主要有哪些？分别有什么作用？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Undo 的作用是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "典型的连接类型共有哪 3 种？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "临时表空间使用率过高有什么调优思路？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "46 和 10053 诊断事件的区别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如果 $GRID_HOME 下的权限被人为修改过，如何修复该权限问题？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "LogMiner 是什么？有哪些用途？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "归档和非归档模式之间的不同点是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的回滚段（rollback segment）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "Oracle 数据库中的触发器（Trigger）作用是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "存储过程和函数的区别是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何启用和配置审计？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何设置资源限制？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何使用内存顾问？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何使用段顾问？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "自动健康检查的作用是什么？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何使用自动健康检查？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何使用 ADMF？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何使用 AWR？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "如何使用 AOSC？",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的 SQL优化器的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "请解释 Oracle数据库中的统计信息（statistics）的作用。",
      "sources": [
        "Oracle_面试题_only_questions.json"
      ]
    },
    {
      "question": "在浏览器中输入URL并按下回车之后会发生什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "DNS 是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "公有 IP 地址由谁管理？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "ARP 是如何知道对方的 MAC 地址的？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "路由器与交换机的区别是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "路由器的基本原理是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "从输入URL到页面展示发生了什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "UDP会不会产生粘包问题？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "GET 和 POST 请求的区别是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "HTTP/1.0 和 HTTP/1.1 的区别是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "HTTP/1.1 有哪些特性？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "HTTP/2.0 和 HTTP/1.1 有什么区别？",
      "sources": [
        "questions_only_from_pdf_strict.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "URL和URI是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "TCP 与 UDP 的区别是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TCP KeepAlive 是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是一个东西吗？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "Cookie 和 Session 是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "Cookie 的工作原理是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "Session 的工作原理是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "匿名管道和命名管道之间的区别是什么？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "信号和信号量有什么区别？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "Redis 是单线程吗？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "Redis 为什么又要引入多线程？",
      "sources": [
        "questions_only_from_pdf_strict.json"
      ]
    },
    {
      "question": "有一堆螺丝和螺母：若1个螺丝配2个螺母则多10个螺母；若1个螺丝配3个螺母则少6个螺母。共有多少个螺丝？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Have you done the best work you are capable of doing?",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Describe a difficult problem you have had to deal with?",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "What was the last book you read? How did it effect you?",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "就一般的企业而言，如何进行档案的分类？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Could you please give me your contact information for me to follow up?",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请阐述 Python 中迭代器的概念。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请解释 Python 中生成器有什么作用？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 是解释语言还是编译语言？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 中 range 和 xrange 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 中列表和元组的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 中互换变量有不用创建临时变量的方法吗？讲讲原理。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 中的可变对象和不可变对象是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 中 remove、del 以及 pop 之间的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 中 is 和 == 的区别是什么？两者分别在比较什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "交叉熵公式是什么？分类为什么用交叉熵不用平方差？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请解释残差连接的公式和原理，并说明它在深度神经网络中的作用？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请解释LSTM中遗忘门的计算公式以及其作用？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么大模型推理时显存涨的那么多还一直占着？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "过拟合怎么解决？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "随机梯度下降相比全局梯度下降好处是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "深度学习为什么在计算机视觉领域这么好？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Batch Normalization 的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DDIM是不是确定性生成，为什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CLIP 编码特征的优缺点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 BLIP/BLIP2 的原理。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "使用RAG的好处是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当调用量突增10×时，自托管方案与API方案的成本拐点如何计算？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何用 DVC + Git LFS 管理 500GB 微调数据集并支持回滚到任意版本？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当 GPU 显存限制为 40GB 时，如何估算 r=64 的 LoRA 增量参数量？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当三类任务样本量差异 100× 时，如何设置 softmax 温度系数防止过拟合？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何监控各任务在验证集上的loss曲线并自动触发Early Stopping？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何用 EWC（Elastic Weight Consolidation）计算重要权重矩阵并加入损失？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当示例顺序改变导致结果抖动 >8% 时，如何采用排序熵进行稳定性筛选？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何基于 LASER multilingual embeddings 计算中英提示的语义差距？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当候选段落长度差异 10× 时，如何采用动态 padding 提升 batch 吞吐？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何采用 HNSW 的增量插入算法并设置 efConstruction 保证召回？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当每天新增 100 万篇文档时，如何设计分层索引避免全量重建？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何用 Kafka + FAISS 实现近实时（<5min）索引更新？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何对图片提取OCR+布局信息并生成统一向量表示？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何证明KV-cache INT4量化对PPL影响<2%并提供实验数据？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何设计迭代级调度算法并计算平均吞吐提升？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当 prefill 与 decode 阶段计算密度差异 10× 时，如何分离调度？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何定义流式 SSE 响应格式并兼容OpenAI API 语义？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "面对“百模大战”紧急立项，如何 1 天内快速生成路线图？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 nn.parallel.DistributedDataParallel 的实现流程。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "FasterTransformer 的核心是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "FasterTransformer 做了哪些优化？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "baichuan 进行微调时，领域数据与通用数据的配比如何确定？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "思维图Graph of Thoughts（GOT）的核心思想是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "思维算法Algorithm of Thoughts（AOT）的思路是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "思维算法Algorithm of Thoughts（AOT）与其他COT的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Graph RAG 的排序优化方式有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于 LLM + 向量库的文档对话思路是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "词嵌入向量是否有助于确定两个 tokens 之间的距离？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调模型中正负样本比例的策略是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简单介绍一下 Transformer 的位置编码。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "简单讲一下 Transformer 中的残差结构以及意义。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 的并行化体现在哪个地方？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "使用 Transformer 网络的技巧和最佳实践有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "解释一下深度学习中迁移学习的概念。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 解码器自回归机制详细介绍。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "attention 和 self-attention 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在计算 attention score 的时候如何对 padding 做 mask？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍 Transformer 模型及其与 RNN/LSTM 的区别。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 高效的原因是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 不适宜的任务有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 的应用有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何处理 Transformer 中的缺失/损坏数据并解决过拟合？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 中的前馈神经网络是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BERT 的 mask 为何不学习 Transformer 在 attention 处？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "迭代器和生成器的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "垃圾回收机制是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BLIP-2的架构、优势和之前多模态模型的区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "机器学习和统计里面的 AUC 的物理意义是啥？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Gradient boosting算法(GBM)和随机森林都是基于树的算法，它们有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "深度学习的风控模型，从经验上看，样本量大概要多少条啊？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "最大间隔分类器（Maximum Margin Classifier）的定义是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CNN 怎么做文本分类？优势是什么？缺点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CNN 在文本中的用法是什么？Pooling 的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CNN 算法的原理是什么？Word2vec 的特点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LR（逻辑回归）损失函数是什么？怎么来的？为什么这么定义？里面取 log 是为了什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "牛顿法和梯度下降的区别",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "两个矩阵同构和相似的定义是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "消息队列会吗？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "深度学习的损失函数有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "算法是否看过开源的源代码，或是否自己手动实现过？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "讲讲LSTM 和实习项目中做的改进？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "写个堆排序。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对于图像拼接，基于什么特征？为什么选择这个特征？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对于 EfficientNet，说明一下原理？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络中的梯度消失和梯度膨胀是什么，怎么解决？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么理解“长短时记忆单元”？RNN 中的隐状态 ht 与 LSTM 中的记忆状态 Ct 有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "文本相似度计算常用算法有哪些，tfidf和textrank的不同和适用场景是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请说一说PCA？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TextCNN 的结构是什么？卷积核的层数应该怎么取？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RNN 和 CNN 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Seq2Seq 和 Transformer 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Attention 有哪些类型？它们的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "逻辑回归与线性回归有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "详细推导一下 CNN 模型的工作原理。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "kmeans 算法为什么一定会收敛？讲一下 EM 算法。kmeans 算法有什么缺点？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "逻辑回归的优缺点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分类与聚类的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在 Transformer 模型中，位置编码（Position Encoding）的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 为什么要用 LayerNorm？作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "L1、L2正则化的效果、区别、原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "可以介绍一下attention机制吗？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Attention 机制中 Q、K、V 三个矩阵的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对于非常大的分类类别，Softmax有哪些优化方法？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BERT 的输入有哪几种 Embedding？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "讲一下微调方法p-tuning v2的原理",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 的输入和输出分别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Transformer 的输出和 BERT 有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "lora 的矩阵怎么初始化？为什么要初始化为全",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "叉搜索树和二叉堆的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CNN 和 Transformer 相比有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Python 的深拷贝和浅拷贝的区别是什么？赋值时是浅拷贝还是深拷贝？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "过拟合应该怎样处理？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍下 YOLOv8 算法的模块。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "讲一下batchnorm的计算过程",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "多头注意力机制和单个注意力机制的时间复杂度会变吗？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说一下 Transformer 的模型架构和细节。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么看待计算机网络和操作系统在深度学习中的作用？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍大模型推理过程中，可以通过调节哪些参数提高性能？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型 LLM 的架构是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何利用大模型辅助召回？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Self-RAG 的训练过程？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Self-RAG 的推理过程？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调方法是啥？如何微调？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么需要前缀微调（Prefix-tining）？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "指示微调（Prompt-tuning）与 Prefix-tuning 区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "指示微调（Prompt-tuning）与 fine-tuning 区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何使用 PEFT库 中 LoRA？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "学习率大小对大模型继续预训练后上下游任务有什么影响？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在初始预训练中使用 Rewarmup 对大模型继续预训练，性能有什么影响？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "具体介绍一下有监督微调（Supervised Finetuning）？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有监督微调（Supervised Finetuning）的训练数据格式是什么样？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "InstructGPT 的原理是什么？讲讲 RLHF 和 reward？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RLHF 训练过程，怎么选取最优 checkpoint？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下强化学习中的优势函数 Advantage Functions？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 gradient accumulation 显存优化方式？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "nn.parallel.DistributedDataParallel 参数更新机制介绍一下？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "torch.multiprocessing 介绍一下。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "ALiBi (Attention with Linear Biases) 思路是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对预训练模型进行指令微调数据如何处理？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对预训练模型进行指令微调，模型如何构建？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 LightLLM？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Efficient Router 介绍一下？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "StreamingLLM 优点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "是否可以避开训练集来处理LLMs测试集数据泄露问题？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何判断网络上是否有原题？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MOE 如何与数据并行结合？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MOE 如何与模型并行结合？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "文本分类的具体流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "微调后的模型出现能力劣化（灾难性遗忘）是怎么回事？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "隐马尔可夫算法中的两个假设是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "隐马尔可夫算法存在哪些问题？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何让 LLM 基于 query 和 context 得到高质量的 response？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG 有哪些评测方法？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG与微调（Fine-tuning）的协同作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LLMs 存在模型幻觉问题，如何处理？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LangChain 存在哪些问题及解决方案?",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "隐马尔科夫算法是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "隐马尔科夫算法中两个序列是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "隐马尔科夫算法中两个假设是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "隐马尔科夫算法序列标注（解码）过程是什么样的？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CRF模型和 HMM 和 MEMM 模型区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于深度学习的命名实体识别方法的结构是怎么样？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Dilated CNN？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么会有Dilated CNN？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "循环神经网络 RNN 层介绍？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何将词向量转句向量？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "基于(Bi-)LSTM的词性标注是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "个具体的文本分类任务可以使用哪些特征？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "使用CNN作为文本分类器时，不同通道channels对应着文本的什么信息？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分类问题使用的激活函数 sigmoid 简介？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "文本分类任务使用的评估算法和指标有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是知识图谱呢？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是图（Graph）呢？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "构建知识图谱所涉及的技术？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "传统的相似度算法所存在的问题？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BERT 预训练任务 Next Sentence Prediction 怎么做？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CBOW vs Skip-gram 哪一个好？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BERT 预训练和微调之间的不匹配的解决方法？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "BERT 为什么需要预训练任务 Next Sentence Prediction？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型（LLMs）评测有哪些方法？如何衡量大模型的效果？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型词表扩充的方法及工具？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "大模型应用框架及其功能？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "向量库有哪些？各自优点与区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "RAG（检索增强生成）对于大模型来说有什么好处？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LR和线性回归的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "k-means 算法流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LSTM 和 GRU 的原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "关联规则具体有哪两种算法，它们之间的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是同步锁？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么使用同步锁？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是过拟合？产生过拟合的原因有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是欠拟合？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "决策树和条件概率分布的关系是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "决策树算法的停止条件是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "LSTM 的产生原因是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "神经网络中权值共享怎么理解？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "索引组织表的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Oracle Database Streams 的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "内存顾问的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SQL 顾问的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是自动内存管理（Automatic Memory Management）？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Hash Join 是否有排序？Hash Join 会在什么时候慢？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "等待事件如何分类？常见等待事件有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "你怎么看到为表格定义的所有索引？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当Python退出时，是否会清除所有分配的内存？",
      "sources": [
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "单目相机中，F 和 H 矩阵有何不同？E 和 F 矩阵有何不同？只旋转不平移能不能求 F？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何处理关键帧（可以参考 ORBSLAM2 中的 Tracking 线程）？",
      "sources": [
        "SLAM_算法_面试题_only.json",
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "解释什么是工作证明（PoW）以及如何实现它。",
      "sources": [
        "questions_tech_clean_v2.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述一种区块链的扩容技术（如侧链或闪电网络）。",
      "sources": [
        "questions_tech_clean_v2.json",
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "HTTPS 的特点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HTTPS 和 HTTP 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "IP分类的优缺点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "IP 协议是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "产生 TCP 粘包和拆包的原因是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TCP 和 UDP 的概念和特点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CDN 是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "CDN 的工作流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HTTPS 三次握手流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "读写锁的特点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "并行和并发是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "分段和分页的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "主键、外键、索引的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "索引的优缺点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MongoDB 和 MySQL 有哪些区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 是什么，有哪些特点？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 哨兵机制是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 切片集群的工作原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 过期删除策略是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 的 LRU 算法和 LFU 算法有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 与 MySQL 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 与 Memcached 有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "缓存中的热点数据和冷数据是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 集群模式有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 过期删除策略有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "设计模式的概念是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "代理模式和适配器模式有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "若显示器伽马未知，设计一种自动标定算法并给出实验步骤。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "直方图均衡导致局部过增强的数学原因是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "给出一种无标定板场景下利用 SLAM 地图重优化内参的方法。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "给出一种基于贝叶斯优化的离线增强策略搜索流程",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "给出一种基于遗传算法的 anchor 自动压缩流程。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "轻量化检测（如移动端 NanoDet）把 BN 替换为 GN+EMA 是否还需同步？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "t-SNE 无法在线部署，如何设计“轻量级可视化”供生产环境实时监控？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "t-SNE图好看但指标掉点，如何防止“可视化过拟合”？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "动态场景：当点云随时间移动，如何增量更新哈希表？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "端侧 INT8 部署如何保持 Lipschitz？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 集合类：List、Set、Queue、Map、Stack 的特点与用法？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中 == 和 equals() 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 的多态表现在哪里？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 创建对象的几种方式有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是迭代器（Iterator）？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "字符串常量池存在于内存空间的哪里？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "JSP和Servlet的区别、共同点、各自应用范围是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说出 Servlet 的生命周期，并说出 Servlet 和 CGI 的区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Servlet Filter Listener启动顺序是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "GC触发的条件有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何进行JVM性能调优？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是 Java 内存模型？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "JVM 调优工具有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中的引用类型有几种？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "进程和线程的区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程的几种状态？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中什么是静态条件？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程池的优点？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Java 中 notify 和 notifyAll 有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程池的作用？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "产生死锁的条件？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请写出实现线程安全的几种方式？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "线程池的拒绝策略都有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "桥接模式是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "策略模式是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MyBatis 的优点？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MyBatis 框架的缺点？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring MVC 工作流程？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MyBatis 框架使用的场合？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring 中 BeanFactory 和 ApplicationContext 的联系和区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring Bean 的生命周期是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "解释 Spring 支持的几种 Bean 的作用域？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring 的重要注解有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "列举 Spring 支持的事务管理类型。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring 框架的事务管理有哪些优点？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring AOP（面向切面）编程的原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spring MVC 的运行流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 和 Memcache 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 最适合的场景有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "redis 有哪些数据结构？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 如何实现高并发？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 哨兵机制的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Nginx 相对于 Apache 的优点有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Nginx 如何处理一个请求？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Nginx 是如何实现高并发的？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Zookeeper 是如何保证事务的顺序一致性的？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何重新加载 Spring Boot 上的更改，而无需重新启动服务器？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是Swagger？你用Spring Boot 实现了它吗？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TCP 和 UDP 的区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 的存储引擎有哪些，区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "视图的优缺点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Hash 索引和 B+ 树索引的区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "B 树和 B+ 树的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "聚集索引和非聚集索引的区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "系统的用户量有多少？多用户并发访问时如何解决？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如果有一个特别大的访问量到数据库上，怎么做优化？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HDFS 文件写入和读取流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "介绍一下 HDFS 存数据原理。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SecondaryNameNode 的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DataNode 如何保证数据完整性？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "DistCp 的原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Kafka、ActiveMQ、RabbitMQ、RocketMQ各自的优缺点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Kafka 的 leader 挂掉之后如何处理？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Kafka 的工作流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Kafka 幂等性实现原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Kafka 新旧 API 有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Zookeeper 在 Kafka 中的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HBase 的优缺点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HBase 读写数据流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HBase 常见避免热点问题的方法有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HBase 和 Phoenix 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spark的工作流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spark的调度流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spark的任务调度原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spark的任务提交和执行流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说下Spark中的Transform和Action，为什么Spark要把操作分为Transform和Action？常用的列举一些，说下算子原理",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spark的并行度指的是什么？Spark中的并行度等于什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Hive 和传统数据库的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Spark Streaming和Storm的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Scala 和 Java 有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "死锁避免和死锁预防的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MyISAM 与 InnoDB 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 有哪些存储引擎？它们有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "哈希索引是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "关系型数据库与非关系型数据库的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 与 Redis 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "维度建模和范式建模的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "单事务事实表、多事务事实表的区别与作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Phoenix 二级索引特点是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HBase 为什么比 MySQL 快？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HBase 跟 MySQL 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "创建索引的方法有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Shell中单引号和双引号有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "taildir底层原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Kafka Broker总体工作流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SparkSQL 中 RDD、DataFrame、DataSet 三者的转换及区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Flink分布式快照的原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HBase的写流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何使用 AB Test 评估算法效果？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是聚类？有哪些业务应用场景？常见算法有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是分类？有哪些业务应用场景？常见算法有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是回归？有哪些业务应用场景？常见回归算法有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "回归预测和时间序列预测的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json",
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "扑克牌 54 张平均分成 2 份，求这 2 份都有 2 张 A 的概率。",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是中心极限定理？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "对文件或设备的操作函数保存在什么数据结构中？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Linux 中的文件包括哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要在 MongoDB 中用 \"Code\" 数据类型？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "为什么要在 MongoDB 中用 \"Regular Expression\" 数据类型？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "如何执行事务/加锁？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "我应该启动一个集群分片(sharded)还是一个非集群分片的 MongoDB 环境？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "当我试图更新一个正在被迁移的块(chunk)上的文档时会发生什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请简洁描述 MySQL 中 InnoDB 支持的四种事务隔离级别名称，以及逐级之间的区别？",
      "sources": [
        "questions_tech_clean_v2.json",
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "请简述常用的索引有哪些种类？以及在 MySQL 数据库中索引的工作机制是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请列举 Nginx 的一些特性？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请列举 Nginx 和 Apache 之间的不同点？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请解释Nginx服务器上的Master和Worker进程分别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "在 Nginx 中，解释如何在 URL 中保留双斜线?",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "请解释 ngx_http_upstream_module 的作用是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "用 Nginx 服务器解释 -s 的目的是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 的数据淘汰策略有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 有哪几种数据淘汰策略？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说说 Redis 哈希槽的概念？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis 事务相关的命令有哪几个？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Redis回收进程如何工作的？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "支持一致性哈希的客户端有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "都有哪些办法可以降低 Redis 的内存使用情况呢？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么是梯度下降？SGD 的推导？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "L1正则化产生稀疏性的原因是什么？如何理解稀疏矩阵？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "GBDT如何防止过拟合？由于gbdt是前向加法模型，前面的树往往起到决定性的作用，如何改进这个问题？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "给你一个有 1000 列和 100 万行的训练数据集，这是一个分类问题。经理要求你降低该数据集的维度以减少模型计算时间，但你的机器内存有限。你会怎么做？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "反向 shell 和正向 shell 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "sqlmap 中 --os-shell 的利用条件以及原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "IPS 和 IDS 有什么区别？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "Linux 给文件权限的命令是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TCP 的三次握手过程是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "怎么安装 nginx？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL 和 SQL Server 有什么相似之处？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SQL 注入类型有哪些？SQL 注入的方式有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SQL注入的流程是什么？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "SQL注入防范机制有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "sqlmap 常用的参数有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "有回显的联合查询注入怎么注入（MySQL）？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "mysql 上传 webshell 需要哪些条件",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "登录页的SQL注入怎么测试？测试哪些动作？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "SQL Server 提权的方法有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "XSS的分类有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "通过SSRF进行内网探测，探测了IP和端口之后，如何利用？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "MySQL数据库提权中，UDF提权怎么利用？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "越权漏洞的分类有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "base64 编码到后端，会继续解析吗？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "服务器被入侵了，怎么做应急响应（Windows和Linux）？用到了什么工具？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "socks代理原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是入侵检测系统（IDS）和入侵防御系统（IPS）？它们有何不同？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "reverse_tcp和bind_tcp的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "什么可以被认为是好的密码？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "等保测评中的网络安全管理主要包括哪些方面？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "等保测评中的网络安全技术主要包括哪些方面？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "等保测评中的网络安全事件处置主要包括哪些方面？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "等保测评中的网络安全监测主要包括哪些方面？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "TCP/IP 三次握手的过程以及对应的状态转换？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "网络拓扑如何影响你在建立网络时的决策？",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是代理服务器？它们如何保护计算机网络？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "网线的排列方式有哪些？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说下HTTP/1.0，1.1，2.0 的区别",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "HTTP 与 HTTPS 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "说说 WebSocket 与socket 的区别",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "forward 和 redirect 的区别是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "Http 请求的过程与原理是什么？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "聊聊 SQL 注入？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "SQL 注入是如何攻击的",
      "sources": [
        "questions_tech_clean_v2.json",
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "我可以和你的证明人联系吗？",
      "sources": [
        "questions_tech_clean_v2.json"
      ]
    },
    {
      "question": "AI 目前已在以下哪些领域或方向得到应用？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "手写 softmax 公式；手写 BN 公式；softmax 层的 label 是什么？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "如何基于 n-gram 频率训练小型草案模型并设置接受阈值？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "tf-idf 的原理是什么？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "常用的 SVM 核函数有哪些？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "SVM 不同核方法有什么区别？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "word2vec 和 fastText 对比有什么区别？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "请简述 CBOW 和 fastText 之间的区别？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "fastText 词内的 n-gram 信息的训练过程是什么？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "为什么有 one-hot？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "Word2vec 中 CBOW 指什么？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "LR 和 SVM 的区别是什么？",
      "sources": [
        "recovered_tech_from_removed_v2.json"
      ]
    },
    {
      "question": "什么是 SLAM？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "单目相机原理是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "BA 算法的流程是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "SVO 中深度滤波器原理是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "SURF 和 SIFT 的区别是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "Ceres 的流程是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "为什么要引入李群李代数？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "常用的边缘检测算子有哪些？各自的优缺点是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "为什么 SLAM中常用 L-M？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "如何优化重投影误差？采用什么方法求解？如果误匹配的点重投影之后误差很大，如何解决它对整个优化问题的影响？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "什么是占据栅格地图构建算法？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "高精度地图的制作流程是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "全局 SLAM和局部 SLAM分开方法？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "BA算法的流程？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "如何对匹配好的点做进一步处理以更好保证匹配效果？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "描述下 GN、LM 方法。",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "单目视觉 SLAM中尺寸漂移是怎么产生的？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "位置信息丢失时如何重新确定自己的位置？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "稀疏特征匹配和稠密匹配的区别是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "如何优化重投影误差？采用什么方法？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "纯视觉 SLAM 的尺度不确定性问题是什么？如何解决？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "Flash 激光雷达的原理是什么？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "机器人学中地图的表示方法有哪些？（特征地图、拓扑地图、栅格地图、直接表征法）",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "光探测与测距（激光雷达）方法主要使用激光传感器（或距离传感器），对比相机、ToF 和？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "视觉 SLAM 整体流程大致可以概括？",
      "sources": [
        "SLAM_算法_面试题_only.json"
      ]
    },
    {
      "question": "PoW(工作量证明)和PoS(权益证明)有什么区别？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "你玩过一些什么应用？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "OpenSea 和 LooksRare 的区别？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如果您有使用智能合约的经验，请描述您使用它们解决问题或成功完成项目的时间？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "PoW（工作量证明）和 PoS（权益证明）有什么区别？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "比特币和以太坊的区别在哪里？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "如果您有使用智能合约的经验，请描述您使用它们解决问题或成功完成项目的经历？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述加密货币钱包的工作原理及其安全？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述如何使用区块链技术进行身份验证。",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "解释什么是非同质化代币（NFT）及其？",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "描述什么是智能合约的自我执行特性。",
      "sources": [
        "web3_questions_only_clean.json"
      ]
    },
    {
      "question": "指标的异常波动变化（例如日活下跌）如何分析？",
      "sources": [
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "指标和维度的区别和联系？",
      "sources": [
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "如何评估一场活动的效果？",
      "sources": [
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "销售额下降了如何分析？",
      "sources": [
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是聚类？业务应用场景？常见算法？",
      "sources": [
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是分类？业务应用场景？常见算法？",
      "sources": [
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "什么是回归？业务应用场景？常见回归算法？",
      "sources": [
        "数据分析常考面试题101题_only_questions_theory.json"
      ]
    },
    {
      "question": "Heap 表是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何区分 FLOAT 和 DOUBLE？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "区分 CHAR_LENGTH 和 LENGTH？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何定义 REGEXP？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "CHAR 和 VARCHAR 的区别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "主键和候选键有什么区别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "myisamchk 是用来做什么的？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何控制 HEAP 表的最大尺寸？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "MyISAM Static 和 MyISAM Dynamic 有什么区别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "federated 表是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如果一个表有一列定义为 TIMESTAMP，将发生什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "列设置为 AUTO INCREMENT 时，如果在表中达到最大值，会发生什么情况？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "怎样才能找出最后一次插入时分配了哪个自动增量？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "LIKE 声明中的 % 和 _ 是什么意思？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "列对比运算符是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "LIKE 和 REGEXP 操作有什么区别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "BLOB 和 TEXT 有什么区别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何在 MySQL 中运行批处理模式？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "ISAM 是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "InnoDB 是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何输入字符为十六进制数字？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何显示前 50 行？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "NOW() 和 CURRENT_DATE() 有什么区别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是非标准字符串类型？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Python中的可变对象和不可变对象有何区别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是图灵完备语言？ Python是图灵完备语言吗？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "MySQL 支持哪几种存储引擎？分别有什么特点？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是事务隔离级别？MySQL 支持哪些事务隔离级别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "请解释一下主键、外键和唯一约束的区别",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Linux命令行工具中grep的常用选项有哪些？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是 DNS服务器？其工作原理是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "能否简述一下黑盒测试和白盒测试的区别？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何使用 unittest 模块进行单元测试？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "请解释一下代码覆盖率的概念及如何度量它？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "描述一下你在过去的一个项目中是如何进行测试设计的。",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "在你的职业生涯中，你觉得最大的挑战是什么？你是怎么解决的？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "当你面对多个优先级不同的任务时，你会如何决定处理顺序？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "描述一次你与团队成员意见不合的经历，你是如何处理这种情况的？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何编写高效的测试脚本？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你认为什么是好的测试策略？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "请解释一下哈希表（Hash Table）的工作原理及其时间复杂度。",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你能描述一下二叉搜索树（Binary Search Tree）的特点吗？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "Python支持多重继承吗？谈谈它的优点和缺点。",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "使用 Django框架开发 web应用的基本步骤是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "个编码为GBK的字符串S，要将其转成UTF-8编码的字符串，应如何操作？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "单引号、双引号、三引号的区别是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是猴子补丁？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "为什么不建议以下划线作为标识符的开头？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是 Python的元类？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "深拷贝和浅拷贝之间的区别是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是元组的解封装？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是PEP？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "列表和元组之间的区别是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "不能发现BUG的测试用例不是好的测试用例吗？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试环境是谁搭建的？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你们测试版本是从哪获取的？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "您认为性能测试工作的目的是什么？做好性能测试工作的关键是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "测试活动中，如果发现文档不完善或者不准确，怎么处理？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "没有产品说明书和需求文档的情况下能够进行黑盒测试吗？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "所有的软件缺陷都能修复吗？所有的软件缺陷都要修复吗？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "开发人员老是犯一些低级错误怎么解决？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "您在以往的测试工作中都曾经具体从事过哪些工作？其中最擅长哪部分工作？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "开发人员说不是 bug时，你如何应付？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "你能不能说下你的 3-5年的职业规划？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "缺陷测试报告的组成？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "软件的评审一般由哪些人员参加？其目的是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "进行测试时产生了哪些文档或记录？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "怎样做好测试计划？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么是 bug？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "开发人员修复缺陷后，如何保证不影响其他功能？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "知道 restful 风格吗？怎么做的？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "需求文档是谁编写的？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "高中低优先级的测试用例比例占多少？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "什么叫预测试？预测试是怎么进行的？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "如何提交高质量的软件缺陷（Bug）记录？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "软件测试的目的是什么？",
      "sources": [
        "测试_Jenkins_MySQL_Python_only_questions.json"
      ]
    },
    {
      "question": "常见的应急排查方式有哪些？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "给你一个网站的登录页面你要如何进行渗透测试？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "怎么进行横向移动？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "拿到一个待检测网站，你该如何渗透？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "应急响应流程是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "红队攻击和渗透测试最主要的区别是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "reverse_tcp 和 bind_tcp 有什么区别？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "用扫描和抓包时，HTTPS 和 HTTP 有什么区别？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "XSS攻击原理是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "文件包含漏洞的原理是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "CSRF和XSS怎么结合使用？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "反序列化漏洞原理是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "木马查杀流程是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "APT攻击流程是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是跨站点脚本攻击（XSS）？如何防止XSS攻击？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是跨站请求伪造（CSRF）攻击？如何防止CSRF攻击？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是缓冲区溢出攻击？如何防止缓冲区溢出攻击？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是中间人攻击？如何防止中间人攻击？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是密码破解攻击？如何防止密码破解攻击？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是安全审计？它的目的是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是安全事件响应计划？它的作用是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是 SOC（安全运营中心）？它的作用是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是多因素身份验证？为什么它比单一因素身份验证更安全？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是漏洞评估？它可以用于什么目的？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是内网防火墙？为什么需要它？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是等保测评？等保测评的主要目的是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "请描述 HTTP、HTTPS 分别是什么协议、作用及端口号？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "在 OSI 参考模型方面，TCP/IP 应用层的等同层或多层是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "建立 VLAN 的一个基本要求是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试的步骤是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "渗透测试中的漏洞利用是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是端口扫描？如何防止端口扫描？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "你如何防止 DDoS 攻击？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "什么是端口扫描？它可以用于什么目的？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "等保测评的评估周期是多长时间？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "等保测评的实施流程是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "OSI 会话层的功能是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "简要描述 NAT 的作用及优缺点。",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "简要描述交换机的工作原理。",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "层交换机的作用是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "交换机如何进入配置界面？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "OSPF 的主要目的是什么？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "描述什么是端口号。",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    },
    {
      "question": "说说什么是数字签名？什么是数字证书？",
      "sources": [
        "网安_合并题目_only_questions_strict_v2.json"
      ]
    }
  ]
}